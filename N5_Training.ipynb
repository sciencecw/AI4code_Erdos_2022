{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Machine Learning algorithms\n",
    "\n",
    "Neural Network/ Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from scipy.sparse import csr_matrix, coo_matrix, hstack, vstack, save_npz,  load_npz\n",
    "from functools import reduce\n",
    "\n",
    "import keras\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = \"data/\"\n",
    "#data_base = \"data/old\"\n",
    "ym = np.load(f\"{data_base}train_P4_md.npy\")\n",
    "Xm = load_npz(f\"{data_base}train_P4_md_X.npz\")\n",
    "yc = np.load(f\"{data_base}train_P4_code.npy\")\n",
    "Xc = load_npz(f\"{data_base}train_P4_code_X.npz\")\n",
    "\n",
    "ym_v = np.load(f\"{data_base}valid_P4_md.npy\")\n",
    "Xm_v = load_npz(f\"{data_base}valid_P4_md_X.npz\")\n",
    "yc_v = np.load(f\"{data_base}valid_P4_code.npy\")\n",
    "Xc_v = load_npz(f\"{data_base}valid_P4_code_X.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480306, 458) (1480306,) (4398549, 502) (4398549,)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'> <class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'>\n",
      "(28410, 458) (28410,) (95526, 502) (95526,)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'> <class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(Xm.shape,ym.shape,Xc.shape,yc.shape)\n",
    "print(type(Xm),type(ym),type(Xc),type(yc))\n",
    "print(Xm_v.shape,ym_v.shape,Xc_v.shape,yc_v.shape)\n",
    "print(type(Xm_v),type(ym_v),type(Xc_v),type(yc_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, log_loss, accuracy_score, precision_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc,\n",
    "                                                       shuffle = True,\n",
    "                                                       random_state = 137,\n",
    "                                                       test_size = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym,\n",
    "                                                       shuffle = True,\n",
    "                                                       random_state = 137,\n",
    "                                                       test_size = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4178621, 502) (219928, 502) (4178621,) (219928,)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(1406290, 458) (74016, 458) (1406290,) (74016,)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(Xc_train.shape, Xc_test.shape, yc_train.shape, yc_test.shape)\n",
    "print(type(Xc_train), type(Xc_test), type(yc_train), type(yc_test))\n",
    "print(Xm_train.shape, Xm_test.shape, ym_train.shape, ym_test.shape)\n",
    "print(type(Xm_train), type(Xm_test), type(ym_train), type(ym_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4178621, 502) (219928, 502) (4178621,) (219928,)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(1406290, 458) (74016, 458) (1406290,) (74016,)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(Xc_train.shape, Xc_test.shape, yc_train.shape, yc_test.shape)\n",
    "print(type(Xc_train), type(Xc_test), type(yc_train), type(yc_test))\n",
    "print(Xm_train.shape, Xm_test.shape, ym_train.shape, ym_test.shape)\n",
    "print(type(Xm_train), type(Xm_test), type(ym_train), type(ym_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might cause kernel to crash at later stage\n",
    "\n",
    "# dense array is needed for training\n",
    "#Xc_train_ar = Xc_train.toarray()\n",
    "#Xc_test_ar = Xc_test.toarray()\n",
    "##Xm_train_ar = Xm_train.toarray()\n",
    "#Xm_test_ar = Xm_test.toarray()\n",
    "\n",
    "#Xc_v_ar = Xc_v.toarray() # validation set\n",
    "#Xm_v_ar = Xm_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.round(np.mean(Xc_train_ar,axis=0)[:14],2),\"\\n\" ,np.round(np.std(Xc_train_ar,axis=0)[:14],2),\"\\n\\n\" )\n",
    "##print(np.mean(Xc_train_ar,axis=0)[240:260],\"\\n\\n\" ,np.std(Xc_train_ar,axis=0)[240:260],\"\\n\\n\" )\n",
    "#print(np.round(np.mean(Xc_train_ar,axis=0)[-14:],2),\"\\n\" ,np.round(np.std(Xc_train_ar,axis=0)[-14:],2),\"\\n\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textoutput(ytest, ypred):\n",
    "     yc_correctness = (ytest==ypred)\n",
    "     print(\"#correct\", yc_correctness.sum(), \"total num\", yc_correctness.size)\n",
    "     print(\"Mean Sq Error: \",round(mean_squared_error(ytest*1, 1*ypred),3),\n",
    "          \"X Entropy error: \", round(log_loss(ytest*1, 1*ypred),4))\n",
    "     print(\"Accuracy Score: \",round(accuracy_score(ytest*1, 1*ypred),4),\n",
    "          \"Precision Score: \", round(precision_score(ytest*1, 1*ypred),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code cells\n",
    "\n",
    "## Gaussian Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb =  GaussianNB()\n",
    "gnb.fit(Xc_train.toarray(),yc_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#correct 127305 total num 219928\n",
      "Mean Sq Error:  0.421 X Entropy error:  14.5461\n",
      "Accuracy Score:  0.5788 Precision Score:  0.6502\n"
     ]
    }
   ],
   "source": [
    "yc_predict = gnb.predict(Xc_test.toarray())\n",
    "textoutput(yc_test, yc_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "Reference\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "https://scikit-learn.org/stable/modules/neural_networks_supervised.html#mlp-tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.001, hidden_layer_sizes=(100, 100),\n",
       "              learning_rate=&#x27;invscaling&#x27;, learning_rate_init=0.01,\n",
       "              random_state=137, solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.001, hidden_layer_sizes=(100, 100),\n",
       "              learning_rate=&#x27;invscaling&#x27;, learning_rate_init=0.01,\n",
       "              random_state=137, solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.001, hidden_layer_sizes=(100, 100),\n",
       "              learning_rate='invscaling', learning_rate_init=0.01,\n",
       "              random_state=137, solver='sgd')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='sgd', alpha=1e-3,\n",
    "                    activation=\"logistic\", learning_rate_init=0.01,\n",
    "                        hidden_layer_sizes=(100,100), random_state=137, learning_rate=\"invscaling\")\n",
    "mlp.fit(Xc_train,yc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#correct 144361 total num 219928\n",
      "Mean Sq Error:  0.344 X Entropy error:  11.8676\n",
      "Accuracy Score:  0.6564 Precision Score:  0.6525\n"
     ]
    }
   ],
   "source": [
    "yc_predict_mlp = mlp.predict(Xc_test)\n",
    "textoutput(yc_test, yc_predict_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "building tree 1 of 100\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.5min remaining:    0.0s\n",
      "building tree 2 of 100\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.1min remaining:    0.0s\n",
      "building tree 3 of 100\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.7min remaining:    0.0s\n",
      "building tree 4 of 100\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 14.2min remaining:    0.0s\n",
      "building tree 5 of 100\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 17.8min remaining:    0.0s\n",
      "building tree 6 of 100\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 21.3min remaining:    0.0s\n",
      "building tree 7 of 100\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 24.9min remaining:    0.0s\n",
      "building tree 8 of 100\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 28.5min remaining:    0.0s\n",
      "building tree 9 of 100\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 32.1min remaining:    0.0s\n",
      "building tree 10 of 100\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 35.7min remaining:    0.0s\n",
      "building tree 11 of 100\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 39.3min remaining:    0.0s\n",
      "building tree 12 of 100\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 42.9min remaining:    0.0s\n",
      "building tree 13 of 100\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 46.6min remaining:    0.0s\n",
      "building tree 14 of 100\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 50.1min remaining:    0.0s\n",
      "building tree 15 of 100\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 53.6min remaining:    0.0s\n",
      "building tree 16 of 100\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed: 57.1min remaining:    0.0s\n",
      "building tree 17 of 100\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed: 60.6min remaining:    0.0s\n",
      "building tree 18 of 100\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 64.0min remaining:    0.0s\n",
      "building tree 19 of 100\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed: 83.9min remaining:    0.0s\n",
      "building tree 20 of 100\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 116.4min remaining:    0.0s\n",
      "building tree 21 of 100\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 120.1min remaining:    0.0s\n",
      "building tree 22 of 100\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed: 123.7min remaining:    0.0s\n",
      "building tree 23 of 100\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed: 127.3min remaining:    0.0s\n",
      "building tree 24 of 100\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 131.0min remaining:    0.0s\n",
      "building tree 25 of 100\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 134.6min remaining:    0.0s\n",
      "building tree 26 of 100\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed: 171.8min remaining:    0.0s\n",
      "building tree 27 of 100\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 223.9min remaining:    0.0s\n",
      "building tree 28 of 100\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed: 273.1min remaining:    0.0s\n",
      "building tree 29 of 100\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 298.7min remaining:    0.0s\n",
      "building tree 30 of 100\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 302.2min remaining:    0.0s\n",
      "building tree 31 of 100\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed: 305.6min remaining:    0.0s\n",
      "building tree 32 of 100\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 324.7min remaining:    0.0s\n",
      "building tree 33 of 100\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed: 393.1min remaining:    0.0s\n",
      "building tree 34 of 100\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed: 427.6min remaining:    0.0s\n",
      "building tree 35 of 100\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed: 479.6min remaining:    0.0s\n",
      "building tree 36 of 100\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 530.9min remaining:    0.0s\n",
      "building tree 37 of 100\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed: 565.5min remaining:    0.0s\n",
      "building tree 38 of 100\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed: 630.3min remaining:    0.0s\n",
      "building tree 39 of 100\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed: 697.6min remaining:    0.0s\n",
      "building tree 40 of 100\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 718.3min remaining:    0.0s\n",
      "building tree 41 of 100\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed: 770.0min remaining:    0.0s\n",
      "building tree 42 of 100\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed: 835.0min remaining:    0.0s\n",
      "building tree 43 of 100\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed: 900.8min remaining:    0.0s\n",
      "building tree 44 of 100\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed: 927.5min remaining:    0.0s\n",
      "building tree 45 of 100\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 994.3min remaining:    0.0s\n",
      "building tree 46 of 100\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed: 1035.5min remaining:    0.0s\n",
      "building tree 47 of 100\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed: 1101.4min remaining:    0.0s\n",
      "building tree 48 of 100\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 1155.1min remaining:    0.0s\n",
      "building tree 49 of 100\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed: 1205.6min remaining:    0.0s\n",
      "building tree 50 of 100\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 1241.6min remaining:    0.0s\n",
      "building tree 51 of 100\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed: 1309.4min remaining:    0.0s\n",
      "building tree 52 of 100\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed: 1330.0min remaining:    0.0s\n",
      "building tree 53 of 100\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(min_samples_split = 10, max_features=\"log2\", verbose =100)\n",
    "rfc.fit(Xc_train,yc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_predict_rfc = rfc.predict(Xc_test)\n",
    "textoutput(yc_test, yc_predict_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve\n",
    "\n",
    "The plot shows a little bit of overtraining for Random Forest Classifier, but nothing too worrying as the test set performs wonderfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs1, tprs1, cutoffs1 = roc_curve(np.array(yc_test), gnb.predict_proba(Xc_test_ar)[:,1])\n",
    "fprs1a, tprs1a, cutoffs1a = roc_curve(np.array(yc_train), gnb.predict_proba(Xc_train_ar)[:,1])\n",
    "\n",
    "fprs2, tprs2, cutoffs2 = roc_curve(np.array(yc_test), rfc.predict_proba(Xc_test_ar)[:,1])\n",
    "fprs3, tprs3, cutoffs3 = roc_curve(np.array(yc_train), rfc.predict_proba(Xc_train_ar)[:,1])\n",
    "\n",
    "fprs4, tprs4, cutoffs4 = roc_curve(np.array(yc_test), mlp.predict_proba(Xc_test_ar)[:,1])\n",
    "fprs4a, tprs4a, cutoffs4a = roc_curve(np.array(yc_train), mlp.predict_proba(Xc_train_ar)[:,1])\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot(fprs1, tprs1, label=\"Gaussian Naive Bayes\")\n",
    "plt.plot(fprs1a, tprs1a, 'b', label=\"Gaussian Naive Bayes (train)\", alpha=0.5)\n",
    "plt.plot(fprs2, tprs2, \"r\", label=\"Random Forest\")\n",
    "plt.plot(fprs3, tprs3, \"r\", label=\"Random Forest (train)\", alpha=0.5)\n",
    "plt.plot(fprs4, tprs4, \"g\", label=\"Neural Network\")\n",
    "plt.plot(fprs4a, tprs4a, \"g\", label=\"Neural Network (train)\", alpha=0.5)\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random Guess Curve\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"roc_c_ml.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Markdown\n",
    "\n",
    "## Gaussian Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_m =  GaussianNB()\n",
    "gnb_m.fit(Xm_train.toarray(),ym_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_predict = gnb_m.predict(Xm_test.toarray())\n",
    "textoutput(ym_test, ym_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "Reference\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "https://scikit-learn.org/stable/modules/neural_networks_supervised.html#mlp-tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_m = MLPClassifier(solver='sgd', alpha=1e-3,\n",
    "                    activation=\"logistic\", learning_rate_init=0.01,\n",
    "                        hidden_layer_sizes=(100), random_state=137, learning_rate=\"invscaling\")\n",
    "mlp_m.fit(Xm_train,ym_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_predict_mlp = mlp_m.predict(Xm_test)\n",
    "textoutput(ym_test, ym_predict_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_m = RandomForestClassifier(min_samples_split = 8,verbose=100)\n",
    "rfc_m.fit(Xm_train,ym_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_predict_rfc = rfc_m.predict(Xm_test)\n",
    "textoutput(ym_test, ym_predict_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve\n",
    "\n",
    "The plot shows a little bit of overtraining for Random Forest Classifier, but nothing too worrying as the test set performs wonderfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs1, tprs1, cutoffs1 = roc_curve(np.array(ym_test), gnb.predict_proba(Xm_test_ar)[:,1])\n",
    "fprs1a, tprs1a, cutoffs1a = roc_curve(np.array(ym_train), gnb.predict_proba(Xm_train_ar)[:,1])\n",
    "\n",
    "fprs2, tprs2, cutoffs2 = roc_curve(np.array(ym_test), rfc.predict_proba(Xm_test)[:,1])\n",
    "fprs3, tprs3, cutoffs3 = roc_curve(np.array(ym_train), rfc.predict_proba(Xm_train)[:,1])\n",
    "\n",
    "fprs4, tprs4, cutoffs4 = roc_curve(np.array(ym_test), mlp.predict_proba(Xm_test)[:,1])\n",
    "fprs4a, tprs4a, cutoffs4a = roc_curve(np.array(ym_train), mlp.predict_proba(Xm_train)[:,1])\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot(fprs1, tprs1, label=\"Gaussian Naive Bayes\")\n",
    "plt.plot(fprs1a, tprs1a, 'b', label=\"Gaussian Naive Bayes (train)\", alpha=0.5)\n",
    "plt.plot(fprs2, tprs2, \"r\", label=\"Random Forest\")\n",
    "plt.plot(fprs3, tprs3, \"r\", label=\"Random Forest (train)\", alpha=0.5)\n",
    "plt.plot(fprs4, tprs4, \"g\", label=\"Neural Network\")\n",
    "plt.plot(fprs4a, tprs4a, \"g\", label=\"Neural Network (train)\", alpha=0.5)\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random Guess Curve\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(\"roc_m_ml.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yc_predict_prob = gnb.predict_proba(Xc_test.toarray())\n",
    "Ym_predict_prob = gnb.predict_proba(Xm_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendal Tau \n",
    "\n",
    "This is described in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "\n",
    "\n",
    "# Actually O(N^2), but fast in practice for our data\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):  # O(N)\n",
    "        j = bisect(sorted_so_far, u)  # O(log N)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)  # O(N)\n",
    "    return inversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the formula, where $S_i$  is the number of inversions in the predicted ranks and $n_i$ is the number of cells for notebook $i$\n",
    "\n",
    "$K=1-4 \\frac{\\sum_i S}{\\sum_i n (n-1)}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0  # total inversions in predicted ranks across all instances\n",
    "    total_2max = 0  # maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "testlist = [[\"ukraine\", \"UK\", \"spain\", \"sweden\", \"serbia\", \"italy\"],] #eurovision 2022\n",
    "shuffled_list=[]\n",
    "for l in testlist:\n",
    "    shuffled_list.append(l.copy())\n",
    "    random.shuffle(shuffled_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_tau(testlist, shuffled_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
