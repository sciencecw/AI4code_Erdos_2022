{"cells": [{"cell_type": "markdown", "id": "f4ab374d", "metadata": {}, "source": ["## Preprocessing CSV's for training"]}, {"cell_type": "markdown", "id": "990e17d4", "metadata": {}, "source": ["![](https://www.rsna.org/-/media/Images/RSNA/Menu/logo_sml.ashx?w=100&la=en&hash=9619A8238B66C7BA9692C1FC3A5C9E97C24A06E1)"]}, {"cell_type": "markdown", "id": "3e3c7574", "metadata": {}, "source": ["Are you working a lot with Data Generators (for example Keras' \".flow_from_dataframe\") and competing in the [RSNA Intercranial Hemorrhage 2019 competition](https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection)? \n\nI've created a function that creates a simple preprocessed DataFrame with a column for ImageID and a column for each label in the competition. ('epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any') \n\nI also made a function which translates your predictions into the correct submission format.\n\nIf you are interested in getting the metadata as CSV files also you can check out [this Kaggle kernel](https://www.kaggle.com/carlolepelaars/converting-dicom-metadata-to-csv-rsna-ihd-2019). \n\nI hope this can be of help to you in the competition!"]}, {"cell_type": "markdown", "id": "f1aa3afa", "metadata": {}, "source": ["## Preparation"]}, {"cell_type": "code", "execution_count": 1, "id": "1d503d92", "metadata": {}, "outputs": [], "source": ["# We will only need OS and Pandas for this one\nimport os\nimport pandas as pd\n\n# Path names\nBASE_PATH = \"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/\"\nTRAIN_PATH = BASE_PATH + 'stage_2_train.csv'\nTEST_PATH = BASE_PATH + 'stage_2_sample_submission.csv'\n\n# All labels that we have to predict in this competition\ntargets = ['epidural', 'intraparenchymal', \n           'intraventricular', 'subarachnoid', \n           'subdural', 'any']"]}, {"cell_type": "code", "execution_count": 1, "id": "6c552f57", "metadata": {}, "outputs": [], "source": ["# File sizes and specifications\nprint('\\n# Files and file sizes')\nfor file in os.listdir(BASE_PATH)[2:]:\n    print('{}| {} MB'.format(file.ljust(30), \n                             str(round(os.path.getsize(BASE_PATH + file) / 1000000, 2))))"]}, {"cell_type": "markdown", "id": "470d6ab7", "metadata": {}, "source": ["## Preprocessing CSV's"]}, {"cell_type": "markdown", "id": "3f858f81", "metadata": {}, "source": ["We read in the CSV's remove duplicates and create a column for every label we have to predict. We therefore get one row for each image and this works nicely with datagenerator of popular frameworks like Keras and PyTorch."]}, {"cell_type": "code", "execution_count": 1, "id": "7421e658", "metadata": {}, "outputs": [], "source": ["train_df = pd.read_csv(TRAIN_PATH)\ntrain_df['ImageID'] = train_df['ID'].str.rsplit('_', 1).map(lambda x: x[0]) + '.png'\nlabel_lists = train_df.groupby('ImageID')['Label'].apply(list)"]}, {"cell_type": "code", "execution_count": 1, "id": "23125417", "metadata": {}, "outputs": [], "source": ["train_df[train_df['ImageID'] == 'ID_0002081b6.png']"]}, {"cell_type": "code", "execution_count": 1, "id": "a15a4239", "metadata": {}, "outputs": [], "source": ["def prepare_df(path, train=False, nrows=None):\n    \"\"\"\n    Prepare Pandas DataFrame for fitting neural network models\n    Returns a Dataframe with two columns\n    ImageID and Labels (list of all labels for an image)\n    \"\"\" \n    df = pd.read_csv(path, nrows=nrows)\n    \n    # Get ImageID and type for pivoting\n    df['ImageID'] = df['ID'].str.rsplit('_', 1).map(lambda x: x[0]) + '.png'\n    df['type'] = df['ID'].str.split(\"_\", n = 3, expand = True)[2]\n    # Create new DataFrame by pivoting\n    new_df = df[['Label', 'ImageID', 'type']].drop_duplicates().pivot(index='ImageID', \n                                                                      columns='type', \n                                                                      values='Label').reset_index()\n    return new_df"]}, {"cell_type": "code", "execution_count": 1, "id": "2b069b27", "metadata": {}, "outputs": [], "source": ["# Convert dataframes to preprocessed format\ntrain_df = prepare_df(TRAIN_PATH, train=True)\ntest_df = prepare_df(TEST_PATH)"]}, {"cell_type": "code", "execution_count": 1, "id": "666abd57", "metadata": {}, "outputs": [], "source": ["print('Training data: ')\ndisplay(train_df.head())\n\nprint('Test data: ')\ntest_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "5d3b9a76", "metadata": {}, "outputs": [], "source": ["# Save to CSV\ntrain_df.to_csv('clean_train_df.csv', index=False)\ntest_df.to_csv('clean_test_df.csv', index=False)"]}, {"cell_type": "markdown", "id": "75c25416", "metadata": {}, "source": ["## Creating submission file"]}, {"cell_type": "markdown", "id": "4d2c2d70", "metadata": {}, "source": ["To convert the DataFrame back to the original submission format you can use this function."]}, {"cell_type": "code", "execution_count": 1, "id": "6595dab8", "metadata": {}, "outputs": [], "source": ["def create_submission_file(IDs, preds):\n    \"\"\"\n    Creates a submission file for Kaggle when given image ID's and predictions\n    \n    IDs: A list of all image IDs (Extensions will be cut off)\n    preds: A list of lists containing all predictions for each image\n    \n    Returns a DataFrame that has the correct format for this competition\n    \"\"\"\n    sub_dict = {'ID': [], 'Label': []}\n    # Create a row for each ID / Label combination\n    for i, ID in enumerate(IDs):\n        ID = ID.split('.')[0] # Remove extension such as .png\n        sub_dict['ID'].extend([f\"{ID}_{target}\" for target in targets])\n        sub_dict['Label'].extend(preds[i])\n    return pd.DataFrame(sub_dict)"]}, {"cell_type": "code", "execution_count": 1, "id": "fec3eaf5", "metadata": {}, "outputs": [], "source": ["# Finalize submission files\ntrain_sub_df = create_submission_file(train_df['ImageID'], train_df[targets].values)\ntest_sub_df = create_submission_file(test_df['ImageID'], test_df[targets].values)"]}, {"cell_type": "code", "execution_count": 1, "id": "ff63a516", "metadata": {}, "outputs": [], "source": ["print('Back to the original submission format:')\ntrain_sub_df.head(6)"]}, {"cell_type": "markdown", "id": "f41d2a6c", "metadata": {}, "source": ["That's all! You can find the clean CSV's in the \"output files\" of this kernel.\n\nIf you like this Kaggle kernel, feel free to give an upvote and leave a comment! I will do my best to implement your suggestions!"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}