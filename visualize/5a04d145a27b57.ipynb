{"cells": [{"cell_type": "markdown", "id": "95bc0103", "metadata": {}, "source": ["<h1><center>Basic TF Keras Starter</center></h1>\n\nBased on this excellent work by Stanley Zheng:\nhttps://www.kaggle.com/stanleyjzheng/baseline-nn-with-k-folds\n"]}, {"cell_type": "markdown", "id": "a4fda0bd", "metadata": {}, "source": ["### Import Libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "1a2361c0", "metadata": {}, "outputs": [], "source": ["\nimport numpy as np \nimport pandas as pd \nimport os\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\n \nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M"]}, {"cell_type": "markdown", "id": "3ffac8c5", "metadata": {}, "source": ["### Read Data"]}, {"cell_type": "code", "execution_count": 1, "id": "33c09734", "metadata": {}, "outputs": [], "source": ["test_df = pd.read_csv('../input/lish-moa/test_features.csv')\ntrain_df = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_target_df = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nsub = pd.read_csv('../input/lish-moa/sample_submission.csv')\n\ntarget_cols = train_target_df.columns[1:]\nN_TARGETS = len(target_cols)"]}, {"cell_type": "code", "execution_count": 1, "id": "ddac784c", "metadata": {}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "a1137376", "metadata": {}, "outputs": [], "source": ["sub.head()"]}, {"cell_type": "markdown", "id": "fca91fd9", "metadata": {}, "source": ["### Basic Setup and Helpers"]}, {"cell_type": "code", "execution_count": 1, "id": "bac941a8", "metadata": {}, "outputs": [], "source": ["SEED = 1234\nEPOCHS = 28\nBATCH_SIZE = 128\nFOLDS = 5\nREPEATS = 5\nLR = 0.0005\nN_TARGETS = len(target_cols)"]}, {"cell_type": "code", "execution_count": 1, "id": "2416dbb9", "metadata": {}, "outputs": [], "source": ["def seed_everything(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)"]}, {"cell_type": "code", "execution_count": 1, "id": "95fa3219", "metadata": {}, "outputs": [], "source": ["def multi_log_loss(y_true, y_pred):\n    losses = []\n    for col in y_true.columns:\n        losses.append(log_loss(y_true.loc[:, col], y_pred.loc[:, col]))\n    return np.mean(losses)"]}, {"cell_type": "markdown", "id": "4b44f3a0", "metadata": {}, "source": ["### Encode Categoricals to Binary"]}, {"cell_type": "code", "execution_count": 1, "id": "d4987379", "metadata": {}, "outputs": [], "source": ["def preprocess_df(data):\n    data['cp_type'] = (data['cp_type'] == 'trt_cp').astype(int)\n    data['cp_dose'] = (data['cp_dose'] == 'D2').astype(int)\n    return data"]}, {"cell_type": "code", "execution_count": 1, "id": "c824ea25", "metadata": {}, "outputs": [], "source": ["x_train = preprocess_df(train_df.drop(columns=\"sig_id\"))\nx_test =preprocess_df(test_df.drop(columns=\"sig_id\"))\ny_train = train_target_df.drop(columns=\"sig_id\")\nN_FEATURES = x_train.shape[1]"]}, {"cell_type": "markdown", "id": "079b6e92", "metadata": {}, "source": ["### Define Model Architecture"]}, {"cell_type": "code", "execution_count": 1, "id": "32c55b38", "metadata": {}, "outputs": [], "source": ["def create_model():\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(N_FEATURES),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    #tf.keras.layers.Dropout(0.4),\n    #tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),  \n    #tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(N_TARGETS, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = LR), loss='binary_crossentropy', metrics=[\"accuracy\"])\n    return model"]}, {"cell_type": "markdown", "id": "c113e80b", "metadata": {}, "source": ["### Main CV and Model Training Function"]}, {"cell_type": "code", "execution_count": 1, "id": "c36d85ac", "metadata": {}, "outputs": [], "source": ["def build_train(resume_models = None, repeat_number = 0, folds = 5, skip_folds = 0):\n    \n    models = []\n    oof_preds = y_train.copy()\n    \n\n    kfold = KFold(folds, shuffle = True)\n    for fold, (train_ind, val_ind) in enumerate(kfold.split(x_train)):\n        print('\\n')\n        print('-'*50)\n        print(f'Training fold {fold + 1}')\n        \n        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'binary_crossentropy', factor = 0.4, patience = 2, verbose = 1, min_delta = 0.0001, mode = 'auto')\n        checkpoint_path = f'repeat:{repeat_number}_Fold:{fold}.hdf5'\n        cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = True, mode = 'min')\n\n        model = create_model()\n        model.fit(x_train.values[train_ind],\n              y_train.values[train_ind],\n              validation_data=(x_train.values[val_ind], y_train.values[val_ind]),\n              callbacks = [cb_lr_schedule, cb_checkpt],\n              epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2\n             )\n        model.load_weights(checkpoint_path)\n        oof_preds.loc[val_ind, :] = model.predict(x_train.values[val_ind])\n        models.append(model)\n\n    return models, oof_preds"]}, {"cell_type": "code", "execution_count": 1, "id": "7caead07", "metadata": {}, "outputs": [], "source": ["models = []\noof_preds = []\n# seed everything\nseed_everything(SEED)\nfor i in range(REPEATS):\n    m, oof = build_train(repeat_number = i, folds=FOLDS)\n    models = models + m\n    oof_preds.append(oof)\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "4df560a1", "metadata": {}, "outputs": [], "source": ["mean_oof_preds = y_train.copy()\nmean_oof_preds.loc[:, target_cols] = 0\nfor i, p in enumerate(oof_preds):\n    print(f\"Repeat {i + 1} OOF Log Loss: {multi_log_loss(y_train, p)}\")\n    mean_oof_preds.loc[:, target_cols] += p[target_cols]\n\nmean_oof_preds.loc[:, target_cols] /= len(oof_preds)\nprint(f\"Mean OOF Log Loss: {multi_log_loss(y_train, mean_oof_preds)}\")\nmean_oof_preds.loc[x_train['cp_type'] == 0, target_cols] = 0\nprint(f\"Mean OOF Log Loss (ctl adjusted): {multi_log_loss(y_train, mean_oof_preds)}\")"]}, {"cell_type": "markdown", "id": "621b2377", "metadata": {}, "source": ["### Make Test Predictions and Save Submission"]}, {"cell_type": "code", "execution_count": 1, "id": "92596c4a", "metadata": {}, "outputs": [], "source": ["test_preds = sub.copy()\ntest_preds[target_cols] = 0\nfor model in models:\n    test_preds.loc[:,target_cols] += model.predict(x_test)\ntest_preds.loc[:,target_cols] /= len(models)\ntest_preds.loc[x_test['cp_type'] == 0, target_cols] = 0\ntest_preds.to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}