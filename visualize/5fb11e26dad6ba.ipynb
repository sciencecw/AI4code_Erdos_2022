{"cells": [{"cell_type": "markdown", "id": "16505f2e", "metadata": {}, "source": ["# Wine Quality Prediction!\nHey everyone! In this project we're gonna be looking at the wine quality dataset! <br>\nWe'll be looking at supervised learning machine learning algorithm Random Forest and try to improve the accuracy as we'll tune the hyper parameters! <br>\nHappy Learning!"]}, {"cell_type": "markdown", "id": "07d75940", "metadata": {}, "source": ["Let's start by importing the required libraries! <br>\nA little about the libraries!\n* numpy - for numpy arrays, useful for processing and scientific computing\n* pandas - helpful for creating dataframes and storing data\n* matplotlib.pyplot - useful for creating plots and charts\n* seaborn - useful for data visualization like matplotlib\n* train_test_split - to split the data into training and test set\n* Random forest Classifier - An ensemble model which we'll use to train our model on\n* accuracy_score - to check the accuracy of our model\n\nStandardScalar - in this project we're using support vector machine classification and this class cannot process the data given to it unless the data is standardized.\nsvm - the suport vector machine class in the sklearn package"]}, {"cell_type": "code", "execution_count": 1, "id": "97513f34", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix"]}, {"cell_type": "markdown", "id": "f0c78e70", "metadata": {}, "source": ["Now let's import our data!\nWe're gonna use the wine quality dataset from the UCI ML Dataset! "]}, {"cell_type": "code", "execution_count": 1, "id": "1cf06526", "metadata": {}, "outputs": [], "source": ["wine_data = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\nwine_data.shape"]}, {"cell_type": "markdown", "id": "38dbea7e", "metadata": {}, "source": ["Let's explore the dataset further! <br>\nEploratory data analysis!"]}, {"cell_type": "code", "execution_count": 1, "id": "2f09d56e", "metadata": {}, "outputs": [], "source": ["wine_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "dd5ecc30", "metadata": {}, "outputs": [], "source": ["wine_data.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "ac9f9358", "metadata": {}, "outputs": [], "source": ["wine_data.info()"]}, {"cell_type": "markdown", "id": "446be8f0", "metadata": {}, "source": ["Doesn't look like there's any missing values! Let's be sure! <br>\nChecking for missing values"]}, {"cell_type": "code", "execution_count": 1, "id": "779db301", "metadata": {}, "outputs": [], "source": ["wine_data.isnull().sum()"]}, {"cell_type": "markdown", "id": "66e5a4bc", "metadata": {}, "source": ["As we can see we have a clean dataset without any missing values!"]}, {"cell_type": "markdown", "id": "079413fa", "metadata": {}, "source": ["Data Analysis and Visualization"]}, {"cell_type": "code", "execution_count": 1, "id": "00b55582", "metadata": {}, "outputs": [], "source": ["# Let's check the number of values under each quality classification\nsns.catplot(x='quality',data= wine_data,  kind='count')"]}, {"cell_type": "markdown", "id": "4cd0ef4b", "metadata": {}, "source": ["Let's compare some features with the quality !"]}, {"cell_type": "code", "execution_count": 1, "id": "2417000c", "metadata": {}, "outputs": [], "source": ["# volatile acidity vs quality\nplot = plt.figure(figsize=(5,5))\nplt.title('Volatile acidity vs Quality')\nsns.barplot(x='quality', y='volatile acidity', data=wine_data)"]}, {"cell_type": "code", "execution_count": 1, "id": "1a1a436f", "metadata": {}, "outputs": [], "source": ["# citric acid vs quality\nplot = plt.figure(figsize=(5,5))\nplt.title('Citric acid vs Quality')\nsns.barplot(x='quality', y='citric acid', data=wine_data)"]}, {"cell_type": "markdown", "id": "7f295a44", "metadata": {}, "source": ["Let's find the correlation! <br>\nAbout the heatmap!\n* corr - correlation calculated\n* cbar - color bar to indicate the values range\n* square - To get a square form\n* fmt - we need one floating point value\n* annot - annotations on the sides!\n* annot_kws - size of annotations\n* cmap - color of the heatmap!"]}, {"cell_type": "code", "execution_count": 1, "id": "3732c0be", "metadata": {}, "outputs": [], "source": ["corr = wine_data.corr()\n# Let's create a heatmap!\nplot = plt.figure(figsize=(10,10))\nplt.title('Correlation heatmap!')\nsns.heatmap(corr,cbar=True,square=True,fmt='.1f',annot=True,annot_kws={'size':8},cmap='Blues')"]}, {"cell_type": "markdown", "id": "f1068940", "metadata": {}, "source": ["Data Preprocessing! <br>\nLet's seperate the data and the labels!"]}, {"cell_type": "code", "execution_count": 1, "id": "0b5cce37", "metadata": {}, "outputs": [], "source": ["X = wine_data.drop(columns='quality',axis=1)\nX.head()"]}, {"cell_type": "markdown", "id": "470fe7d2", "metadata": {}, "source": ["For the quality values, we're gonna binarize the values to either good wine quality **1** or bad wine **0**"]}, {"cell_type": "code", "execution_count": 1, "id": "c6ccce80", "metadata": {}, "outputs": [], "source": ["y = wine_data['quality'].apply(lambda y_value: 1 if y_value>=7 else 0 )\ny"]}, {"cell_type": "markdown", "id": "aa9cd385", "metadata": {}, "source": ["Now that we have our data and labels, let's split the data into train and test split!"]}, {"cell_type": "code", "execution_count": 1, "id": "035879fd", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"]}, {"cell_type": "markdown", "id": "49f99090", "metadata": {}, "source": ["Now let's train our model using random forest classifier!"]}, {"cell_type": "code", "execution_count": 1, "id": "a9746357", "metadata": {}, "outputs": [], "source": ["classifier = RandomForestClassifier()\nclassifier.fit(X_train,y_train)"]}, {"cell_type": "markdown", "id": "47210d37", "metadata": {}, "source": ["Model evaluation using K-fold cross validation! <br>\nWhy k-fold cross validation ? To be sure that we didn't get lucky on the train test!"]}, {"cell_type": "code", "execution_count": 1, "id": "09482416", "metadata": {}, "outputs": [], "source": ["y_pred_train = classifier.predict(X_train)\naccuracy = accuracy_score(y_pred_train, y_train)\nprint(\"Accuracy of the model on training data is:\", accuracy)\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier,X = X_train,y= y_train , cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f}\".format(accuracies.std()*100))"]}, {"cell_type": "markdown", "id": "704cda48", "metadata": {}, "source": ["As we can see that's a pretty good accuracy! <br>\nLet's check our model performance on the test set!"]}, {"cell_type": "code", "execution_count": 1, "id": "1482089f", "metadata": {}, "outputs": [], "source": ["y_pred_test = classifier.predict(X_test)\naccuracy = accuracy_score(y_pred_test, y_test)\nprint(\"Accuracy: {:.2f} %\".format(accuracy*100))\ncf_matrix = confusion_matrix(y_pred_test,y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "339f3cd5", "metadata": {}, "outputs": [], "source": ["#.  visualizing the confusion matrix!\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Reds')"]}, {"cell_type": "markdown", "id": "d8f8dcfb", "metadata": {}, "source": ["Now let's check if there is a better hyperparameter we can tune to improve over all accuracy. We use **Grid Search CV** here"]}, {"cell_type": "code", "execution_count": 1, "id": "8f8a4a35", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import GridSearchCV\nparameters = [{'bootstrap': [True], 'max_depth': [10, 20], 'max_features': ['auto', 'sqrt'], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 5, 10], 'n_estimators': [100,200]}]\ngrid_search = GridSearchCV(estimator=classifier,\n                          param_grid=parameters,\n                          scoring='accuracy',\n                          cv=10)\ngrid_search.fit(X_train,y_train)\nprint(\"Best Accuracy: {:.2f} %\".format(grid_search.best_score_*100))\nprint(\"Best Parameters: \", grid_search.best_params_)"]}, {"cell_type": "markdown", "id": "8733a682", "metadata": {}, "source": ["Now that we've come to an end let's look back upon what we did in this project! <br>\n* imported the required libraries!\n* read our data from the **Red Wine Quality** dataset!\n* Checked for any missing values!\n* Found some useful information between different features using plots and graphs!\n* Made a heatmap to find the correlation between different features!\n* Split the data into training and test sets!\n* Trained our model using supervised learning algorithm - Random forest classification ! \n* Used KFold cross validation to get the accuracy !\n* With a little bit of hyper parameter tuning we we're able to get a good accuracy score of **92**% !\n<br>\nHope you all enjoyed this notebook! <br>\nHappy Learning!!"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}