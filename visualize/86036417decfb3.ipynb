{"cells": [{"cell_type": "markdown", "id": "11efd35c", "metadata": {}, "source": ["<a id=\"1\"></a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\"> Train </p>\n### This notebook is a follow-up of [\ud83c\udf1f\ud83d\udc1fDetection using Keras-RetinaNet-Train Notebook](https://www.kaggle.com/mahipalsingh/detection-using-keras-retinanet-train)"]}, {"cell_type": "markdown", "id": "1b98a837", "metadata": {}, "source": ["<a id=\"2\"></a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\"> Import Modules </p>"]}, {"cell_type": "code", "execution_count": 1, "id": "be4acf51", "metadata": {}, "outputs": [], "source": ["import pandas as pd\n# show images inline\n%matplotlib inline\nimport keras\nimport tensorflow\n# import miscellaneous modules\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nimport numpy as np\nimport time\nimport tensorflow as tf\n\n# Create 'RetinaNet' dir for zip extraction\n%mkdir RetinaNet\n\n#%cd RetinaNet/\nfrom distutils.dir_util import copy_tree\n\nf='/kaggle/input/offlineretinanet/'\nt='/kaggle/working/RetinaNet/'\ncopy_tree(f,t)"]}, {"cell_type": "markdown", "id": "63f0620e", "metadata": {}, "source": ["<a id=\"3\"></a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\"> Install RetinaNet Offline  </p>"]}, {"cell_type": "code", "execution_count": 1, "id": "47f20d9f", "metadata": {}, "outputs": [], "source": ["#Clone Git Repository\n#!git clone https://github.com/fizyr/keras-retinanet.git\n#%cd keras-retinanet/\n%cd RetinaNet/\n!python setup.py build_ext --inplace\n\n# import keras_retinanet\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\nfrom keras_retinanet import models\n\n!pip install /kaggle/input/creating-whl-file-retinanet/whlfiles/keras_resnet-0.2.0-py2.py3-none-any.whl\nimport keras\nimport keras_resnet"]}, {"cell_type": "markdown", "id": "88936799", "metadata": {}, "source": ["<a id=\"4\"></a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\"> Load Model  </p>"]}, {"cell_type": "code", "execution_count": 1, "id": "5f662d8e", "metadata": {}, "outputs": [], "source": ["model_path = '/kaggle/input/v2models/bestRetinanet.h5'\n#print(model_path)\n\n# load retinanet model\nmodel = models.load_model(model_path, backbone_name='resnet50')  ## Use backbone as resnet50\nmodel = models.convert_model(model)\n\n# load label to names mapping for visualization purposes\n#labels_to_names = pd.read_csv('/kaggle/input/detection-using-keras-retinanet-train/keras-retinanet/classes.csv',header=None).T.loc[0].to_dict()"]}, {"cell_type": "code", "execution_count": 1, "id": "d0caf7c0", "metadata": {}, "outputs": [], "source": ["#Annotation file for visualizing result\ndf_extrain_main=pd.read_csv(\"/kaggle/input/v2models/annotation.csv\",names=['image_path','x','y','width','height',\"class\"])\ndf_extrain_main"]}, {"cell_type": "markdown", "id": "beba79b1", "metadata": {}, "source": ["<a id=\"5\"></a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\"> Visualizing Results  </p>"]}, {"cell_type": "code", "execution_count": 1, "id": "68d38375", "metadata": {}, "outputs": [], "source": ["THRES_SCORE = 0.5  # Set Score Threshold Value\n\ndef df_plot_orinal(drawOG,img_path,df):\n    df=df[df['image_path']==img_path]\n    for i,r in df.iterrows():\n        cv2.rectangle(drawOG, (r['x'], r['y']), (r['width'], r['height']), (255,0,0),2)\n    \n\ndef img_inference(img_path):\n  image = read_image_bgr(img_path)\n\n  # copy to draw on\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n  drawOG = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  # preprocess image for network\n  image = preprocess_image(image)\n  image, scale = resize_image(image)\n\n  # process image\n  start = time.time()\n  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n  df_plot_orinal(drawOG,img_path,df_extrain_main)\n  # correct for image scale\n  boxes /= scale\n  #print(boxes)\n  # visualize detections\n  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n      # scores are sorted so we can break\n      #print(score)\n      if score < THRES_SCORE:\n          continue\n      #print(score)\n      color = label_color(label)\n      b = box.astype(int)\n      draw_box(draw, b, color=color)\n      #caption = \"{} {:.3f}%\".format(labels_to_names[label], score*100)\n    \n  fig = plt.figure(figsize=(20, 20))\n  ax1=fig.add_subplot(1, 2, 1)\n  plt.imshow(draw)\n  ax2=fig.add_subplot(1, 2, 2)\n  plt.imshow(drawOG)\n\n  ax1.title.set_text('Predicted')\n  ax2.title.set_text('Actual')\n  plt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "85d1f157", "metadata": {}, "outputs": [], "source": ["data=df_extrain_main.sample(n=10)  #Predict on Random 10 Image\nfor i,r in data.iterrows():\n    img_inference(r['image_path'])"]}, {"cell_type": "markdown", "id": "86f3ca3a", "metadata": {}, "source": ["<a id=\"5\"></a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\"> Make Submission  </p>"]}, {"cell_type": "code", "execution_count": 1, "id": "b42db791", "metadata": {}, "outputs": [], "source": ["%cd /kaggle/working/"]}, {"cell_type": "code", "execution_count": 1, "id": "9db81a3c", "metadata": {}, "outputs": [], "source": ["import greatbarrierreef\n\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()"]}, {"cell_type": "code", "execution_count": 1, "id": "707f06a1", "metadata": {}, "outputs": [], "source": ["submission_dict = {\n    'id': [],\n    'prediction_string': [],\n}\n\nfor (image, sample_prediction_df) in iter_test:\n  #image = read_image_bgr(Image.fromarray(image))\n  image = preprocess_image(image[:, :, ::-1])\n  image, scale = resize_image(image)\n\n  bboxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n  #bboxes_, scores_, labels_=bboxes[0], scores[0], labels[0]\n  # correct for image scale\n  bboxes /= scale\n  predictions = []\n  for box, score, label in zip(bboxes[0], scores[0], labels[0]):\n      # scores are sorted so we can break\n      if score < THRES_SCORE:\n          continue\n      x_min = int(box[0])  \n      y_min = int(box[1])\n      x_max = int(box[2])\n      y_max = int(box[3])\n\n      bbox_width = x_max - x_min\n      bbox_height = y_max - y_min\n      predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n\n  prediction_str = ' '.join(predictions)\n  sample_prediction_df['annotations'] = prediction_str\n  env.predict(sample_prediction_df)\n\nprint('Prediction:', sample_prediction_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "0957eaf0", "metadata": {}, "outputs": [], "source": ["sub_df = pd.read_csv('submission.csv')\nsub_df.head()"]}, {"cell_type": "markdown", "id": "0b06bc16", "metadata": {}, "source": ["<p style=\"font-size:220%;text-align:center\"> If you find this notebook interesting, please do upvote :) </p>\n\n# <p style=\"text-align:center\"> <img src=\"https://media.giphy.com/media/3oEdva9BUHPIs2SkGk/giphy.gif\"> </p>\n\n<p style=\"font-size:130%;text-align:center\"> Still lot of improvments is remaining!... \ud83d\udee0\u2699 </p>"]}, {"cell_type": "markdown", "id": "87e72ad1", "metadata": {}, "source": ["<a id=\"5\"></a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\"> Reference  </p>\n\n## [Creating WHL file - Retinanet](https://www.kaggle.com/akhileshdkapse/creating-whl-file-retinanet)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}