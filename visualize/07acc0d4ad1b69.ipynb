{"cells": [{"cell_type": "code", "execution_count": 1, "id": "e42b5552", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\nimport tensorflow as tf #tensorflow using for Image Processing\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e8088497", "metadata": {}, "outputs": [], "source": ["# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nepochs = 15\ntrain_directory = '../input/10-monkey-species/training/training'\nvalidation_directory = '../input/10-monkey-species/validation/validation'\n\nlabel = pd.read_csv('../input/10-monkey-species/monkey_labels.txt')\n\nlabel.columns = label.columns.str.strip()\ntype(label)\nlabel['Latin Name'] = label['Latin Name'].str.replace(\"\\t\",\"\")\nlabel\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "61fd1317", "metadata": {}, "outputs": [], "source": ["CName = list(label[\"Common Name\"])\nlabels = {}\nfor i in range(10):\n    labels[i] = CName[i].strip()\n\nprint(labels)\n"]}, {"cell_type": "markdown", "id": "4c3164a0", "metadata": {}, "source": ["Checking Training Data"]}, {"cell_type": "code", "execution_count": 1, "id": "ab11612a", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 10))\nfor i in range(10):\n    plt.subplot(2, 5, i+1)\n    class_name = 'n' + str(i)\n    plt.imshow(plt.imread('../input/10-monkey-species/validation/validation/' + class_name + '/' + class_name + '00.jpg'))\n    plt.xlabel(class_name)"]}, {"cell_type": "markdown", "id": "741f1693", "metadata": {}, "source": ["Checking Validation Data"]}, {"cell_type": "code", "execution_count": 1, "id": "b514a9b6", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 10))\nfor i in range(10):\n    plt.subplot(2, 5, i+1)\n    class_name = 'n' + str(i)\n    plt.imshow(plt.imread('../input/10-monkey-species/training/training/' + class_name + '/' + class_name + '023.jpg'))\n    plt.xlabel(class_name)"]}, {"cell_type": "code", "execution_count": 1, "id": "ea025ff6", "metadata": {}, "outputs": [], "source": ["training_data = Path(train_directory) \nvalidation_data = Path(validation_directory) \n\ntrain_df = []\nfor folder in os.listdir(training_data):\n    # Define the path to the images\n    imgs_path = training_data / folder\n    \n    # Get the list of all the images stored in that directory\n    imgs = sorted(imgs_path.glob('*.jpg'))\n    \n    # Store each image path and corresponding label \n    for img_name in imgs:\n        train_df.append((str(img_name), (str(folder)[1])))\n\n\ntrain_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n# shuffle the dataset \ntrain_df = train_df.sample(frac=1.).reset_index(drop=True)\n#print(train_df)\n\n\nvalidation_df = []\nfor folder in os.listdir(validation_data):\n    # Define the path to the images\n    imgs_path = validation_data / folder\n    \n    \n    # Get the list of all the images stored in that directory\n    imgs = sorted(imgs_path.glob('*.jpg'))\n    \n    # Store each image path and corresponding label \n    for img_name in imgs:\n        validation_df.append((str(img_name), (str(folder)[1])))\n\n\nvalidation_df = pd.DataFrame(validation_df, columns=['image', 'label'], index=None)\n# shuffle the dataset \nvalidation_df = validation_df.sample(frac=1.).reset_index(drop=True)\n#validation_df\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "65c80ef0", "metadata": {}, "outputs": [], "source": ["print(\"Total number of Images in Training Set \" + str(len(train_df)))\n\nprint(\"Total number of Images in Validation Set \" + str(len(validation_df)))"]}, {"cell_type": "code", "execution_count": 1, "id": "398482d6", "metadata": {}, "outputs": [], "source": ["from PIL import Image\nfor i in range(10):\n    class_name = 'n' + str(i)\n    path = '../input/10-monkey-species/training/training/' + class_name + '/' + class_name + '023.jpg'\n    print(path)\n    img = Image.open(path)\n    width,height = img.size\n    print(\"ht = \" + str(height) + \" width = \" + str(width) )"]}, {"cell_type": "code", "execution_count": 1, "id": "6620c5db", "metadata": {}, "outputs": [], "source": ["print(train_df.label)"]}, {"cell_type": "code", "execution_count": 1, "id": "5572d3d7", "metadata": {}, "outputs": [], "source": ["train_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.0/255)\n\nimage_size = 224\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory = train_directory,\n    batch_size=20,\n    target_size=(image_size, image_size),\n    class_mode='categorical')\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    directory=validation_directory,\n    target_size=(image_size, image_size),\n    shuffle=False,\n    class_mode='categorical')\n\nbatch_size = 32"]}, {"cell_type": "code", "execution_count": 1, "id": "876ba2d7", "metadata": {}, "outputs": [], "source": ["model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size,image_size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])"]}, {"cell_type": "code", "execution_count": 1, "id": "868839db", "metadata": {}, "outputs": [], "source": ["model.compile(optimizer = tf.optimizers.Adam(),\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])"]}, {"cell_type": "code", "execution_count": 1, "id": "18b9d9c4", "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "2fbdae44", "metadata": {}, "outputs": [], "source": ["history = model.fit_generator(train_generator, steps_per_epoch = len(train_df)/batch_size, epochs=120, verbose=1, callbacks=None,\n                        validation_data=validation_generator, validation_steps=len(validation_df)/batch_size)"]}, {"cell_type": "code", "execution_count": 1, "id": "2f7b8b1a", "metadata": {}, "outputs": [], "source": ["acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(len(acc))\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc ,label = \"Training Data\")\nplt.plot  ( epochs, val_acc ,label = \"Validation Data\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title ('Training and validation accuracy')\nplt.legend(loc='best')\nplt.show()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss ,label = \"Training Data\")\nplt.plot  ( epochs, val_loss ,label = \"Validation Data\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.title ('Training and validation loss'   )\nplt.legend(loc = \"best\")"]}, {"cell_type": "code", "execution_count": 1, "id": "c8b3cee3", "metadata": {}, "outputs": [], "source": ["#fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n#ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n#ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n#ax1.set_xticks(np.arange(1, epochs, 1))\n\n\n#ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n#ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n\n#legend = plt.legend(loc='best', shadow=True)\n#plt.tight_layout()\n#plt.show()'''"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}