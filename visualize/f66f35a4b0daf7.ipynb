{"cells": [{"cell_type": "code", "execution_count": 1, "id": "8f41d6a6", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "abc4e087", "metadata": {}, "source": ["merge the datasets (only have to perform once)"]}, {"cell_type": "code", "execution_count": 1, "id": "b6d6da18", "metadata": {}, "outputs": [], "source": ["train_filepath = \"../input/train.csv\"\ntest_filepath = \"../input/test.csv\"\nBuilding_Structure_filepath = \"../input/Building_Structure.csv\"\nBuilding_Ownership_Use_filepath = \"../input/Building_Ownership_Use.csv\"\nres_train_filepath = \"merged_train.csv\"\nres_test_filepath = \"merged_test.csv\"\n\ntrain = pd.read_csv(train_filepath)\nBuilding_Ownership_Use = pd.read_csv(Building_Ownership_Use_filepath)\ntest = pd.read_csv(test_filepath)\nBuilding_Structure = pd.read_csv(Building_Structure_filepath)\n\nBuilding_Info = pd.merge(Building_Ownership_Use,Building_Structure,on=['building_id','vdcmun_id','district_id','ward_id'],how='inner')\n\nres_train = pd.merge(train,Building_Info,on=['building_id','vdcmun_id','district_id'],how='inner')\nres_test = pd.merge(test,Building_Info,on=['building_id','vdcmun_id','district_id'],how='inner')\n\nres_train.to_csv(res_train_filepath,index=False)\nres_test.to_csv(res_test_filepath,index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "9a67e13b", "metadata": {}, "outputs": [], "source": ["# read the merged dataset\nmtrain_filepath = \"merged_train.csv\"\nmtest_filepath = \"merged_test.csv\"\n\ntrain = pd.read_csv(mtrain_filepath)\ntest = pd.read_csv(mtest_filepath)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "150fd730", "metadata": {}, "outputs": [], "source": ["train.head(n=4)"]}, {"cell_type": "code", "execution_count": 1, "id": "70fb5d02", "metadata": {}, "outputs": [], "source": ["test.head(n=4)"]}, {"cell_type": "markdown", "id": "ce757ad5", "metadata": {}, "source": ["feature engineering"]}, {"cell_type": "code", "execution_count": 1, "id": "28d7d2ec", "metadata": {}, "outputs": [], "source": ["train['dist_vdc_ward_id'] = train['district_id'].map(str) + train['vdcmun_id'].map(str) + train['ward_id'].map(str)\ntest['dist_vdc_ward_id'] = test['district_id'].map(str) + test['vdcmun_id'].map(str) + test['ward_id'].map(str)\n\ntrain['count_floors_diff'] = train['count_floors_pre_eq'] - train['count_floors_post_eq']\ntest['count_floors_diff'] = test['count_floors_pre_eq'] - test['count_floors_post_eq']\n\ntrain['height_ft_diff'] = train['height_ft_pre_eq'] - train['height_ft_post_eq']\ntest['height_ft_diff'] = test['height_ft_pre_eq'] - test['height_ft_post_eq']\n\ntrain['risk_count'] = train['has_geotechnical_risk_other'] + train['has_geotechnical_risk_liquefaction'] + train['has_geotechnical_risk_landslide'] + train['has_geotechnical_risk_flood'] + train['has_geotechnical_risk_rock_fall'] + train['has_geotechnical_risk_land_settlement'] + train['has_geotechnical_risk_fault_crack']\ntest['risk_count'] = test['has_geotechnical_risk_other'] + test['has_geotechnical_risk_liquefaction'] + test['has_geotechnical_risk_landslide'] + test['has_geotechnical_risk_flood'] + test['has_geotechnical_risk_rock_fall'] + test['has_geotechnical_risk_land_settlement'] + test['has_geotechnical_risk_fault_crack']\n"]}, {"cell_type": "markdown", "id": "5cb7aba6", "metadata": {}, "source": ["handling null values"]}, {"cell_type": "code", "execution_count": 1, "id": "859efd7d", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import Imputer\n\nimput = Imputer(strategy='most_frequent')\nimput1 = Imputer(strategy='mean')\ntrain['count_families'] = imput1.fit_transform(train[['count_families']]).astype('int')\ntrain['has_repair_started'] = imput.fit_transform(train[['has_repair_started']]).astype('int')\n\ntest['has_repair_started'] = imput.fit_transform(test[['has_repair_started']]).astype('int')\n"]}, {"cell_type": "markdown", "id": "8e7879f8", "metadata": {}, "source": ["feature transformation"]}, {"cell_type": "code", "execution_count": 1, "id": "131868a0", "metadata": {}, "outputs": [], "source": ["train['has_geotechnical_risk'] = train['has_geotechnical_risk'].map(int)\ntrain['has_secondary_use'] = train['has_secondary_use'].map(int)\n\ntest['has_geotechnical_risk'] = test['has_geotechnical_risk'].map(int)\ntest['has_secondary_use'] = test['has_secondary_use'].map(int)\ntest['count_families'] = test['count_families'].map(int)\n\ngrade_enc = {\n\t'Grade 1':1,\n\t'Grade 2':2,\n\t'Grade 3':3,\n\t'Grade 4':4,\n\t'Grade 5':5\n}\n\ntrain_y = pd.Series([grade_enc[i] for i in train['damage_grade']])\n"]}, {"cell_type": "markdown", "id": "a821208b", "metadata": {}, "source": ["drop unwanted columns"]}, {"cell_type": "code", "execution_count": 1, "id": "97a19cc9", "metadata": {}, "outputs": [], "source": ["train_x = train.drop(columns=['building_id','damage_grade'])\ntest_x = test.drop(columns=['building_id'])"]}, {"cell_type": "code", "execution_count": 1, "id": "af5fd007", "metadata": {}, "outputs": [], "source": ["print(test_x.shape)"]}, {"cell_type": "markdown", "id": "d5881b64", "metadata": {}, "source": ["label encoding....\n(running this section multiple times is idempotent)"]}, {"cell_type": "code", "execution_count": 1, "id": "8dbfe10f", "metadata": {}, "outputs": [], "source": ["from sklearn import preprocessing\n\nlabel_enc = preprocessing.LabelEncoder()\n\nfor col in test_x.columns.values:\n    if test_x[col].dtype == 'object':\n        data = train_x[col].append(test_x[col])\n        label_enc.fit(data)\n        train_x[col] = label_enc.transform(train_x[col])\n        test_x[col] = label_enc.transform(test_x[col])"]}, {"cell_type": "markdown", "id": "b800ec74", "metadata": {}, "source": ["training model using random forest"]}, {"cell_type": "code", "execution_count": 1, "id": "939b614e", "metadata": {}, "outputs": [], "source": ["import time\nfrom sklearn.ensemble import RandomForestClassifier\n\nprev_time = time.time()\n\nclf = RandomForestClassifier(n_jobs=-1,n_estimators=100,max_features=.33)\nclf.fit(train_x,train_y)\n\nnew_time = time.time()\n\ntotal_time = round((new_time - prev_time),2)\nprint('total time : ',total_time)"]}, {"cell_type": "markdown", "id": "8dd1e762", "metadata": {}, "source": ["predicting target values"]}, {"cell_type": "code", "execution_count": 1, "id": "9000a76e", "metadata": {}, "outputs": [], "source": ["import time\n\nprev_time = time.time()\n\npredictions_train = clf.predict(train_x)\npredictions_test = clf.predict(test_x)\n\nnew_time = time.time()\n\ntotal_time = round((new_time - prev_time),2)\nprint('total time : ',total_time)"]}, {"cell_type": "markdown", "id": "0c4ef9ef", "metadata": {}, "source": ["evaluating model!"]}, {"cell_type": "code", "execution_count": 1, "id": "3210e85e", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nprint(\"Train Accuracy : \",accuracy_score(train_y,predictions_train))\n\nprint(\"\\nConfusion Matrix : \")\nprint(confusion_matrix(train_y,predictions_train))"]}, {"cell_type": "markdown", "id": "07fb8094", "metadata": {}, "source": ["preparing submission...."]}, {"cell_type": "code", "execution_count": 1, "id": "4a11229e", "metadata": {}, "outputs": [], "source": ["predictions_test = pd.Series(predictions_test)\n\npredict_test = 'Grade ' + predictions_test.map(str)\n\nsubm = {\n    'building_id' : test['building_id'],\n    'damage_grade' : predict_test\n}\nsubmissions = pd.DataFrame(subm)\nsubmissions = submissions.set_index('building_id')\n\nprint(submissions.head())\n\nsubmissions.to_csv('submission.csv')"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}