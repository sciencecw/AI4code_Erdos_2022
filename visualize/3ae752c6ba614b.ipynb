{"cells": [{"cell_type": "markdown", "id": "05bdd62f", "metadata": {}, "source": ["# \ud83d\udce5 Importing Libraries\u00b6"]}, {"cell_type": "code", "execution_count": 1, "id": "6b6781ec", "metadata": {}, "outputs": [], "source": ["import re\nimport string\nimport nltk\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping"]}, {"cell_type": "markdown", "id": "05dd6f7a", "metadata": {}, "source": ["# \ud83d\uddc3\ufe0f Load Dataset\n"]}, {"cell_type": "code", "execution_count": 1, "id": "cc3735d1", "metadata": {}, "outputs": [], "source": ["train_df = pd.read_csv('../input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt', sep=\":::\", header=None, engine='python')\ntest_df = pd.read_csv('../input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data_solution.txt', sep=\":::\", header=None, engine='python')\ntrain_df.columns=['id','title','genre','description']\ntest_df.columns=['id','title','genre','description']\ntrain_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "151e880b", "metadata": {}, "outputs": [], "source": ["train_df.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "c9456125", "metadata": {}, "outputs": [], "source": ["train_df.isnull().sum()"]}, {"cell_type": "markdown", "id": "df4b11c3", "metadata": {}, "source": ["# \ud83d\udd25 EDA & Visualization"]}, {"cell_type": "code", "execution_count": 1, "id": "506c4d61", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12,8))\ncounts = train_df.genre.value_counts()\nsns.barplot(x=counts.index, y=counts)\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.xticks(rotation=90);"]}, {"cell_type": "code", "execution_count": 1, "id": "a7199a0f", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(13,8))\n\nsns.set(style=\"darkgrid\")\nsns.set_color_codes(\"pastel\")\ntrain_df.genre.value_counts().plot.barh()\nsns.despine(left=True, bottom=True)\n\nplt.tight_layout()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "f097edf4", "metadata": {}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "3b2412da", "metadata": {}, "outputs": [], "source": ["sns.countplot(y='genre',data=train_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "3a344dec", "metadata": {}, "outputs": [], "source": ["train_df['length']=train_df['description'].apply(len)\ntrain_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "6c267896", "metadata": {}, "outputs": [], "source": ["train_df['length'].plot(bins=100, kind='hist')"]}, {"cell_type": "code", "execution_count": 1, "id": "6408278e", "metadata": {}, "outputs": [], "source": ["train_df.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "bfef2feb", "metadata": {}, "outputs": [], "source": ["train_df[train_df['length']==42]['description']"]}, {"cell_type": "markdown", "id": "a7d31753", "metadata": {}, "source": ["# \ud83e\uddf9 Text Cleaning"]}, {"cell_type": "code", "execution_count": 1, "id": "22f7df19", "metadata": {}, "outputs": [], "source": ["def clean_text(text):\n    text = text.lower()                                  # lower-case all characters\n    text =  re.sub(r'@\\S+', '',text)                     # remove twitter handles\n    text =  re.sub(r'http\\S+', '',text)                  # remove urls\n    text =  re.sub(r'pic.\\S+', '',text) \n    text =  re.sub(r\"[^a-zA-Z+']\", ' ',text)             # only keeps characters\n    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text+' ')      # keep words with length>1 only\n    text = \"\".join([i for i in text if i not in string.punctuation])\n    words = nltk.tokenize.word_tokenize(text)\n    stopwords = nltk.corpus.stopwords.words('english')   # remove stopwords\n    text = \" \".join([i for i in words if i not in stopwords and len(i)>2])\n    text= re.sub(\"\\s[\\s]+\", \" \",text).strip()            # remove repeated/leading/trailing spaces\n    return text"]}, {"cell_type": "code", "execution_count": 1, "id": "ad8ec20c", "metadata": {}, "outputs": [], "source": ["train_df['Text_cleaning'] = train_df.description.apply(clean_text)\ntest_df['Text_cleaning'] = test_df.description.apply(clean_text)\ntest_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "68aad6a1", "metadata": {}, "outputs": [], "source": ["train_df['length_Text_cleaning']=train_df['Text_cleaning'].apply(len)\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "bfb1d0d4", "metadata": {}, "source": ["# \u2714\ufe0f Tokenizer"]}, {"cell_type": "code", "execution_count": 1, "id": "349f1e0b", "metadata": {}, "outputs": [], "source": ["num_words = 50000\nmax_len = 250\ntokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(train_df['Text_cleaning'].values)"]}, {"cell_type": "code", "execution_count": 1, "id": "e7f2e548", "metadata": {}, "outputs": [], "source": ["X = tokenizer.texts_to_sequences(train_df['Text_cleaning'].values)\nX = pad_sequences(X, maxlen=max_len)\ny = pd.get_dummies(train_df['genre']).values\n\nX_test = tokenizer.texts_to_sequences(test_df['Text_cleaning'].values)\nX_test = pad_sequences(X_test, maxlen=max_len)\ny_test = pd.get_dummies(test_df['genre']).values"]}, {"cell_type": "markdown", "id": "674a224f", "metadata": {}, "source": ["# \ud83d\udcda Training model"]}, {"cell_type": "code", "execution_count": 1, "id": "7a3e75d4", "metadata": {}, "outputs": [], "source": ["EMBEDDING_DIM = 100\nmodel = Sequential()\nmodel.add(Embedding(num_words, EMBEDDING_DIM, input_length=X.shape[1]))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(100, dropout=0.1, recurrent_dropout=0.2))\nmodel.add(Dense(27, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]}, {"cell_type": "code", "execution_count": 1, "id": "52efa398", "metadata": {}, "outputs": [], "source": ["my_callbacks  = [EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=2,\n                              mode='auto')]"]}, {"cell_type": "code", "execution_count": 1, "id": "f91c0db2", "metadata": {}, "outputs": [], "source": ["history = model.fit(X, y, epochs=6, batch_size=32,validation_data=(X_test,y_test), callbacks=my_callbacks)"]}, {"cell_type": "markdown", "id": "91ca4d8e", "metadata": {}, "source": ["# \ud83d\udcc8 Plotting Accuracy & Loss\n"]}, {"cell_type": "code", "execution_count": 1, "id": "56befdea", "metadata": {}, "outputs": [], "source": ["# Plotting Accuracy and val_accuracy\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.legend()\nplt.show();\n\n# Plotting loss and val_loss\nplt.title('Loss')\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show();"]}, {"cell_type": "markdown", "id": "ce4ea81d", "metadata": {}, "source": ["# \ud83e\uddea Test Accuracy"]}, {"cell_type": "code", "execution_count": 1, "id": "4f24f1ab", "metadata": {}, "outputs": [], "source": ["results = model.evaluate(X_test, y_test, verbose=0)\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}