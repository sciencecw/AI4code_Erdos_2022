{"cells": [{"cell_type": "markdown", "id": "64bc923d", "metadata": {}, "source": ["# H2o model"]}, {"cell_type": "code", "execution_count": 1, "id": "59661507", "metadata": {}, "outputs": [], "source": ["#import packages\nimport numpy as np\nimport pandas as pd \n#import matplotlib as mpl\nimport h2o\nfrom h2o.automl import H2OAutoML\nfrom h2o.estimators import H2OWord2vecEstimator, H2OGradientBoostingEstimator\nimport seaborn as sns\nimport matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 1, "id": "ac9c9bcd", "metadata": {}, "outputs": [], "source": ["h2o.init()"]}, {"cell_type": "code", "execution_count": 1, "id": "66a41d12", "metadata": {}, "outputs": [], "source": ["job_titles = h2o.import_file('../input/commonlitreadabilityprize/train.csv')\ntest = h2o.import_file('../input/commonlitreadabilityprize/test.csv')\nsample_submission = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "65ffdd80", "metadata": {}, "outputs": [], "source": ["print(job_titles.shape)\nprint(test.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "17e7655d", "metadata": {}, "outputs": [], "source": ["#desscribe dataset\njob_titles.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "8a70d875", "metadata": {}, "outputs": [], "source": ["STOP_WORDS = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\n              \"lines\",\"re\",\"what\",\"there\",\"all\",\"we\",\"one\",\"the\",\n              \"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\n              \"in\",\"a\",\"not\",\"with\",\"as\",\"was\",\"if\",\"they\",\"are\",\n              \"this\",\"and\",\"it\",\"have\",\"from\",\"at\",\"my\",\"be\",\"by\",\n              \"not\",\"that\",\"to\",\"from\",\"com\",\"org\",\"like\",\"likes\",\n              \"so\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "e524d7ba", "metadata": {}, "outputs": [], "source": ["def tokenize(sentences, stop_word = STOP_WORDS):\n    tokenized = sentences.tokenize(\"\\\\W+\")\n    tokenized_lower = tokenized.tolower()\n    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n    return tokenized_words"]}, {"cell_type": "code", "execution_count": 1, "id": "ea17f886", "metadata": {}, "outputs": [], "source": ["def predict(job_title,w2v, gbm):\n    words = tokenize(h2o.H2OFrame(job_title).ascharacter())\n    job_title_vec = w2v.transform(words, aggregate_method=\"AVERAGE\")\n    print(gbm.predict(test_data=job_title_vec))\n    return (gbm.predict(test_data=job_title_vec))"]}, {"cell_type": "code", "execution_count": 1, "id": "672affca", "metadata": {}, "outputs": [], "source": ["words = tokenize(job_titles[\"excerpt\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "729fd84b", "metadata": {}, "outputs": [], "source": ["w2v_model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 2)\nw2v_model.train(training_frame=words)"]}, {"cell_type": "code", "execution_count": 1, "id": "1b7230a5", "metadata": {}, "outputs": [], "source": ["w2v_model.find_synonyms(\"teacher\", count = 5)"]}, {"cell_type": "code", "execution_count": 1, "id": "8cfd1a7e", "metadata": {}, "outputs": [], "source": ["# Calculate a vector for each job title:\njob_title_vecs = w2v_model.transform(words, aggregate_method = \"AVERAGE\")"]}, {"cell_type": "code", "execution_count": 1, "id": "87499dd4", "metadata": {}, "outputs": [], "source": ["# Prepare training & validation data (keep only job titles made of known words):\nvalid_job_titles = ~ job_title_vecs[\"C4\"].isna()\ndata = job_titles[valid_job_titles,:].cbind(job_title_vecs[valid_job_titles,:])\ndata_split = data.split_frame(ratios=[0.8])"]}, {"cell_type": "code", "execution_count": 1, "id": "bc1cec78", "metadata": {}, "outputs": [], "source": ["# Build a basic GBM model:\ngbm_model = H2OGradientBoostingEstimator()\ngbm_model.train(x = job_title_vecs.names,\n                y=\"target\",\n                training_frame = data_split[0],\n                validation_frame = data_split[1])"]}, {"cell_type": "code", "execution_count": 1, "id": "f1e44eae", "metadata": {}, "outputs": [], "source": ["perf = gbm_model.model_performance()\nperf"]}, {"cell_type": "code", "execution_count": 1, "id": "606dc9ff", "metadata": {}, "outputs": [], "source": ["test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest[\"target\"] = float(1)\ntest1=np.zeros(7)"]}, {"cell_type": "code", "execution_count": 1, "id": "7d93901a", "metadata": {}, "outputs": [], "source": ["# Predict\nfor i in range(0,7):\n    print(test[\"target\"][i])\n    a=predict([test[\"excerpt\"][i]],w2v_model, gbm_model)\n    test[\"target\"][i]=a[\"predict\"]\n    print(test[\"target\"][i])\n#print(predict([\"school teacher having holidays every month\"], w2v_model, gbm_model))\na"]}, {"cell_type": "code", "execution_count": 1, "id": "b1a3d07a", "metadata": {}, "outputs": [], "source": ["test[\"target\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "c6676d51", "metadata": {}, "outputs": [], "source": ["sample_submission[\"target\"]=test[\"target\"]\nsample_submission.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "246a5c6c", "metadata": {}, "outputs": [], "source": ["sample_submission.to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}