{"cells": [{"cell_type": "markdown", "id": "7ad05f50", "metadata": {}, "source": ["# Why EvalML is one of the best AutoML library you can get your hands on"]}, {"cell_type": "markdown", "id": "dcb696c6", "metadata": {}, "source": ["## What is AutoML?\n\n**According to wikipedia** -\n\nAutomated machine learning (*AutoML*) is the process of automating the tasks of applying machine learning to real-world problems. AutoML covers the complete pipeline from the raw dataset to the deployable machine learning model. AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.The high degree of automation in AutoML allows non-experts to make use of machine learning models and techniques without requiring them to become experts in machine learning. Automating the process of applying machine learning end-to-end additionally offers the advantages of producing simpler solutions, faster creation of those solutions, and models that often outperform hand-designed models. AutoML has been used to compare the relative importance of each factor in a prediction model."]}, {"cell_type": "markdown", "id": "132768dc", "metadata": {}, "source": ["# What is EvalML?\nEvalML is an open source automated machine learning library created by Altryx's Innovation team EvalML is an AutoML library that builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions.\n\nBasically EvalML provides a simple low code interface to create machine learning model and use those models to generate insights and to make accurate predictions.    \n\n## What I liked the most about EvalML\n\n- EvalML cuts downs the process of model training and tuning by hand, this includes data quality checks and cross-validation.\n\n- Data Checks and warnings: EvalML helps you in identifying the probelm in the data before using or setting it up for modelling\n\n- Pipeline building: EvalML helps you in consructing a highly optimised pipeline including a state-of-the-art data preprocessing, feature engineering, feature selection and a lot pf modelling techniques \n\n- Model Understanding: Just like Shap, Eli5, Lime and other model explanibility libraries EvalML also provides a broad level of understanding about the model you are building, for the purpose of presentation\n\n- Domain-specific: This is the missing link in most of the AutoML libraries where you can define the objective if the problem. Once you have determined the objective for your business, you can provide that to EvalML to optimize by defining a custom objective function. "]}, {"cell_type": "markdown", "id": "b2265d89", "metadata": {}, "source": ["# Let's get started with EvalML"]}, {"cell_type": "markdown", "id": "8923d9d5", "metadata": {}, "source": ["## How to install "]}, {"cell_type": "markdown", "id": "9b6203b1", "metadata": {}, "source": ["> **Note:** EvalML includes several optional dependencies. The xgboost and catboost packages support pipelines built around those modeling libraries. The plotly and ipywidgets packages support plotting functionality in automl searches. These dependencies are recommended, and are included with EvalML by default but are not required in order to install and use EvalML"]}, {"cell_type": "code", "execution_count": 1, "id": "87a7297d", "metadata": {}, "outputs": [], "source": ["!pip install evalml"]}, {"cell_type": "markdown", "id": "51d72be9", "metadata": {}, "source": ["## Loading a dataset"]}, {"cell_type": "markdown", "id": "f4f8802b", "metadata": {}, "source": ["Loading a dataset in EvalMl is just the usual process we can use any library for this, I am using pandas for this and I am using breast cancer dataset for this\nDataset Link: [Breast Cancer Dataset](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)"]}, {"cell_type": "code", "execution_count": 1, "id": "12fa811d", "metadata": {}, "outputs": [], "source": ["import evalml\nX, y = evalml.demos.load_breast_cancer()\nX_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='binary')\n# Here we'll split the data table using evalml's preprocessing \"split_data\" library"]}, {"cell_type": "markdown", "id": "be47bab8", "metadata": {}, "source": ["Note: EvalML uses data tables as a standard data format but you can read the regular .csv dataset and it gets converted using Woorworks (another altryx project). \nEvalML also accepts and works well with pandas DataFrames. But using the DataTable makes it easy to control how EvalML will treat each feature, as a numeric feature, a categorical feature, a text feature or other type of feature. Woodwork\u2019s DataTable includes features like inferring when a categorical feature should be treated as a text feature."]}, {"cell_type": "code", "execution_count": 1, "id": "acacf845", "metadata": {}, "outputs": [], "source": ["X_train.head()"]}, {"cell_type": "markdown", "id": "ba7a62f2", "metadata": {}, "source": ["## Automated pipeline search"]}, {"cell_type": "markdown", "id": "0ff3d751", "metadata": {}, "source": ["User can use AutoMLSearch() for searching the best pipeline. EvalML uses Bayesian optimization to sort the best pipeline as per the defined objective"]}, {"cell_type": "code", "execution_count": 1, "id": "524120b3", "metadata": {}, "outputs": [], "source": ["from evalml.automl import AutoMLSearch\nautoml = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')"]}, {"cell_type": "markdown", "id": "12e0fd31", "metadata": {}, "source": ["when you use search() function after automl.search() then the search for best pipeline is started. The need for data wrangling is eliminated in EvalML, you can directly load the data and start seaching for the best pipeline after defining feature and outcome variable, let's find the best pipeline now "]}, {"cell_type": "code", "execution_count": 1, "id": "217731eb", "metadata": {}, "outputs": [], "source": ["automl.search()"]}, {"cell_type": "markdown", "id": "141b9d44", "metadata": {}, "source": ["So from the above snippet we got the best pipline i.e \"*Logistic Regression Classifier w/ Imputer + Standard Scaler*\" with Log loss of 0.094\n\nAfter the search we will rank the pipeline on the basis of scores, for this we need to use a simple code \n<automl.rankings>"]}, {"cell_type": "code", "execution_count": 1, "id": "08070bec", "metadata": {}, "outputs": [], "source": ["automl.rankings"]}, {"cell_type": "markdown", "id": "cfb49456", "metadata": {}, "source": ["As per the table Logistic Regression is the best pipeline with high mean_cv_score and validation_score, we can can get the description of the pipeline now by using <automl.describe_pipeline(5)> where \"5\" is the pipeline ID \n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3da1bcfe", "metadata": {}, "outputs": [], "source": ["automl.describe_pipeline(5)"]}, {"cell_type": "markdown", "id": "d1b96941", "metadata": {}, "source": ["We can easily check all the parameteres of any pipeline using pipeline ID"]}, {"cell_type": "code", "execution_count": 1, "id": "5729b49f", "metadata": {}, "outputs": [], "source": ["pipeline = automl.get_pipeline(1)\nprint(pipeline.name)\nprint(pipeline.parameters)"]}, {"cell_type": "markdown", "id": "32a8125a", "metadata": {}, "source": ["# Check the best pipeline required to build a model"]}, {"cell_type": "code", "execution_count": 1, "id": "d5cff7c5", "metadata": {}, "outputs": [], "source": ["best_pipeline = automl.best_pipeline"]}, {"cell_type": "markdown", "id": "f0b4ac72", "metadata": {}, "source": ["# Evaluate the pipeline performance by using it against the holdoff data"]}, {"cell_type": "code", "execution_count": 1, "id": "48caaa15", "metadata": {}, "outputs": [], "source": ["best_pipeline.score(X_test, y_test, objectives=[\"auc\",\"f1\",\"Precision\",\"Recall\"])"]}, {"cell_type": "markdown", "id": "5110def8", "metadata": {}, "source": ["## From here you can change the objective of the model you've built using EvalML"]}, {"cell_type": "code", "execution_count": 1, "id": "12816651", "metadata": {}, "outputs": [], "source": ["automl_auc = AutoMLSearch(X_train=X_train, y_train=y_train,\n                          problem_type='binary',\n                          objective='auc',\n                          additional_objectives=['f1', 'precision'],\n                          max_batches=1,\n                          optimize_thresholds=True)\n\nautoml_auc.search()"]}, {"cell_type": "markdown", "id": "95969832", "metadata": {}, "source": ["The objective to optimize for. Used to propose and rank pipelines, but not for optimizing each pipeline during fit-time.\n When set to 'auto', chooses:\n*     - LogLossBinary for binary classification problems,\n*     - LogLossMulticlass for multiclass classification problems, and\n*     - R^2 for regression problems."]}, {"cell_type": "markdown", "id": "451b6f9b", "metadata": {}, "source": ["# Save the model by pickling it"]}, {"cell_type": "code", "execution_count": 1, "id": "2962315b", "metadata": {}, "outputs": [], "source": ["best_pipeline.save(\"model.pkl\")"]}, {"cell_type": "markdown", "id": "caea4cc2", "metadata": {}, "source": ["# Evaluate the model by testing it against test data"]}, {"cell_type": "code", "execution_count": 1, "id": "66c25afc", "metadata": {}, "outputs": [], "source": ["check_model=automl.load('model.pkl')"]}, {"cell_type": "code", "execution_count": 1, "id": "9b156fab", "metadata": {}, "outputs": [], "source": ["check_model.predict_proba(X_test).to_dataframe()"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}