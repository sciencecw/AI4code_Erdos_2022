{"cells": [{"cell_type": "markdown", "id": "29a01bca", "metadata": {}, "source": ["# Geo Data EDA & Feature Engineering\n\n\uc548\ub155\ud558\uc138\uc694. \uce90\uae00 \ucf54\ub9ac\uc544\uc5d0\uc11c \uc8fc\ucd5c\ud55c 2\ud68c \ub300\ud68c\ub97c \uc990\uac81\uac8c \ud558\uace0 \uc788\ub294 \uc0ac\ub78c\uc73c\ub85c\uc11c \uc81c\uac00 \uc0ac\uc6a9\ud558\uace0 \uc788\ub294 Feature Engineering\uc744 \uacf5\uc720\ud558\ub824\uace0 \ud569\ub2c8\ub2e4.\n\n\uc9d1\uac12\uc744 \uacb0\uc815\ud558\ub294\ub370 \uac00\uc7a5 \uc911\uc694\ud55c \uc694\uc18c\ub294 \uc785\uc9c0\ub77c\ub294 \uac83\uc740 \ubaa8\ub450 \uc798 \uc544\uc2e4\uac70\ub77c\uace0 \uc0dd\uac01\ud569\ub2c8\ub2e4. \uadf8\ub798\uc11c \uc800\ub294 \uae30\ubcf8 \ub370\uc774\ud130\uc5d0 \ub300\ud55c Feature Engineering \uc678\uc5d0 \uc704\uce58\uc5d0 \uad00\ub828\ub41c Feature Engineering\uc5d0 \uac00\uc7a5 \uc2dc\uac04\uc744 \uc3df\uace0 \uc788\ub294\ub370\uc694.\n\n\uae30\ubcf8 \ub370\uc774\ud130\uc5d0 \ub300\ud55c EDA \ubc0f Feature Engineering\uc740 \ub2e4\ub978 \ubd84\ub4e4\uc774 \uacf5\uac1c\ud55c \uc88b\uc740 \ucee4\ub110\uc774 \ub9ce\uc774 \uc788\uc73c\ubbc0\ub85c \uc0dd\ub7b5\ud558\uace0, \uc704\uce58\uc5d0 \uad00\ub828\ub41c zipcode, lat, long \ub370\uc774\ud130\uc758 Feature Engineering\uc5d0 \uc9d1\uc911\ud574\uc11c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\ubcf4\uc2dc\uace0 \ub3c4\uc6c0\uc774 \ub410\ub2e4\uba74 \uc81c Kernel\uc5d0 Vote \ud574\uc8fc\uc2dc\uba74 \uac10\uc0ac\ud558\uaca0\uc2b5\ub2c8\ub2e4! "]}, {"cell_type": "markdown", "id": "60c14108", "metadata": {}, "source": ["* [Baseline Model](#Baseline-Model)\n* Geo Data Feature Engineering\n  * [Zipcode Feature Engineering](#Zipcode-Feature-Engineering)\n  * [PCA Transformation - Lat, Long](#PCA-Transformation---Lat,-Long)\n  * [K-Means Clustering - Lat, Long](#K-Means-Clustering---Lat,-Long)\n    * [Determine K by Elbow method](#Determine-K-by-Elbow-method)\n    * [Determine K by CV Score](#Determine-K-by-CV-Score)\n  * [Haversine Distance](#Haversine-Distance)\n* [Conclusion](#Conclusion)"]}, {"cell_type": "markdown", "id": "104f62e7", "metadata": {}, "source": ["\uae30\ubcf8\uc801\uc778 \ucf54\ub4dc\ub294 \uc544\ub798\uc758 \ucee4\ub110\ub4e4\uc744 \ub9ce\uc774 \ucc38\uace0\ud588\uc2b5\ub2c8\ub2e4.\n* https://www.kaggle.com/chocozzz/house-price-prediction-eda-updated-2019-03-12\n* https://www.kaggle.com/yeonmin/default-eda-stacking-introduction"]}, {"cell_type": "markdown", "id": "a2dca33b", "metadata": {}, "source": ["\uc704\ub3c4(Lat), \uacbd\ub3c4(Long) \ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c\ud55c Feature Engineering\uc740 \uc544\ub798 \uae00\uc744 \ucc38\uace0\ud588\uc2b5\ub2c8\ub2e4.\n\n[Good Feature Building Techniques\u200a\u2014\u200aTricks for Kaggle\u200a\u2014\u200aMy Kaggle Code Repository](https://becominghuman.ai/good-feature-building-techniques-tricks-for-kaggle-my-kaggle-code-repository-c953b934f1e6)"]}, {"cell_type": "code", "execution_count": 1, "id": "8e678b48", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "e20a3c33", "metadata": {}, "outputs": [], "source": ["# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# Set a few plotting defaults\nplt.style.use('ggplot')\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.rcParams['font.size'] = 12\n\npd.options.display.max_rows = 10000\npd.options.display.max_columns = 10000\npd.options.display.max_colwidth = 1000"]}, {"cell_type": "code", "execution_count": 1, "id": "1f8e3210", "metadata": {}, "outputs": [], "source": ["RANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)"]}, {"cell_type": "code", "execution_count": 1, "id": "19d3ca9d", "metadata": {}, "outputs": [], "source": ["def rmse_exp(y_true, y_pred):\n    return np.sqrt(mean_squared_error(np.expm1(y_true), np.expm1(y_pred)))\n\ndef train_test_split(data, do_ohe=True):\n    df = data.drop(['id','price','data'], axis=1).copy()\n    cat_cols = df.select_dtypes('object').columns\n    for col in cat_cols:\n        if do_ohe:\n            ohe_df = pd.get_dummies(df[[col]], prefix='ohe_'+col)\n            df.drop(col, axis=1, inplace=True)\n            df = pd.concat([df, ohe_df], axis=1)\n        else:\n            le = LabelEncoder()\n            df[col] = le.fit_transform(df[col])\n\n    train_len = data[data['data'] == 'train'].shape[0]\n    X_train = df.iloc[:train_len]\n    X_test = df.iloc[train_len:]\n    y_train = data[data['data'] == 'train']['price']\n    \n    return X_train, X_test, y_train\n\ndef get_oof_lgb(X_train, y_train, X_test, lgb_param, verbose_eval=False, return_cv_score_only=False):\n\n    folds = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n    oof = np.zeros(len(X_train))\n    predictions = np.zeros(len(X_test))\n    feature_importance_df = pd.DataFrame()\n\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values, y_train.values)):\n        if verbose_eval > 0: print(f'Fold : {fold_ + 1}')\n        trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n        val_data = lgb.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n\n        num_round = 100000\n        clf = lgb.train(lgb_param, trn_data, num_round, valid_sets=[trn_data, val_data],\n                        verbose_eval=verbose_eval, early_stopping_rounds=200)\n        oof[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=clf.best_iteration)\n        predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n        \n        cv_fold_score = rmse_exp(y_train.iloc[val_idx], oof[val_idx])\n        \n        if verbose_eval > 0: print(f'Fold {fold_ + 1} / CV-Score: {cv_fold_score:.6f}')\n        \n        fold_importance_df = pd.DataFrame()\n        fold_importance_df['feature'] = X_train.columns.tolist()\n        fold_importance_df['importance'] = clf.feature_importance('gain')\n        fold_importance_df['fold'] = fold_ + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    cv_score = rmse_exp(y_train, oof)\n    print(f'CV-Score: {cv_score:.6f}')\n    if return_cv_score_only: return cv_score\n    else: return oof, predictions, cv_score, feature_importance_df\n    \ndef plot_feature_importance(fi_df, num_feature=20):\n    cols = (fi_df[['feature', 'importance']]\n            .groupby('feature')\n            .mean()\n            .sort_values(by='importance', ascending=False)[:num_feature].index)\n    best_features = fi_df.loc[fi_df.feature.isin(cols)]\n\n    sns.barplot(x='importance', y='feature', data=best_features.sort_values(by='importance', ascending=False))\n    plt.title('Feature Importances (averaged over folds)')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_numeric_for_regression(df, field, target_field='price'):\n    df = df[df[field].notnull()]\n\n    fig = plt.figure(figsize = (16, 7))\n    ax1 = plt.subplot(121)\n    \n    sns.distplot(df[df['data'] == 'train'][field], label='Train', hist_kws={'alpha': 0.5}, ax=ax1)\n    sns.distplot(df[df['data'] == 'test'][field], label='Test', hist_kws={'alpha': 0.5}, ax=ax1)\n\n    plt.xlabel(field)\n    plt.ylabel('Density')\n    plt.legend()\n    \n    ax2 = plt.subplot(122)\n    \n    df_copy = df[df['data'] == 'train'].copy()\n\n    sns.scatterplot(x=field, y=target_field, data=df_copy, ax=ax2)\n    \n    plt.show()\n    \ndef plot_categorical_for_regression(df, field, target_field='price', show_missing=True, missing_value='NA'):\n    df_copy = df.copy()\n    if show_missing: df_copy[field] = df_copy[field].fillna(missing_value)\n    df_copy = df_copy[df_copy[field].notnull()]\n\n    ax1_param = 121\n    ax2_param = 122\n    fig_size = (16, 7)\n    if df_copy[field].nunique() > 30:\n        ax1_param = 211\n        ax2_param = 212\n        fig_size = (16, 10)\n    \n    fig = plt.figure(figsize = fig_size)\n    ax1 = plt.subplot(ax1_param)\n    \n    sns.countplot(x=field, hue='data', order=np.sort(df_copy[field].unique()), data=df_copy)\n    plt.xticks(rotation=90, fontsize=11)\n    \n    ax2 = plt.subplot(ax2_param)\n    \n    df_copy = df_copy[df_copy['data'] == 'train']\n\n    sns.boxplot(x=field, y=target_field, data=df_copy, order=np.sort(df_copy[field].unique()), ax=ax2)\n    plt.xticks(rotation=90, fontsize=11)\n    \n    plt.show()\n    \ndef load_original_data():\n    train = pd.read_csv('../input/train.csv')\n    test = pd.read_csv('../input/test.csv')\n\n    train_copy = train.copy()\n    train_copy['data'] = 'train'\n    test_copy = test.copy()\n    test_copy['data'] = 'test'\n    test_copy['price'] = np.nan\n\n    # remove outlier\n    train_copy = train_copy[~((train_copy['sqft_living'] > 12000) & (train_copy['price'] < 3000000))].reset_index(drop=True)\n\n    # concat train, test data to preprocess\n    data = pd.concat([train_copy, test_copy], sort=False).reset_index(drop=True)\n    data = data[train_copy.columns]\n\n    data.drop('date', axis=1, inplace=True)\n    data['zipcode'] = data['zipcode'].astype(str)\n\n    # fix skew feature\n    skew_columns = ['price']\n\n    for c in skew_columns:\n        data[c] = np.log1p(data[c])\n        \n    return data"]}, {"cell_type": "code", "execution_count": 1, "id": "f8cfd2a7", "metadata": {}, "outputs": [], "source": ["data = load_original_data()\n\nprint(data.shape)\ndata.head()"]}, {"cell_type": "markdown", "id": "04c8a2a1", "metadata": {}, "source": ["# Baseline Model"]}, {"cell_type": "markdown", "id": "1fdd02ee", "metadata": {}, "source": ["LightGBM 5-Fold Out Of Fold Prediction\uc744 Baseline model\ub85c \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uae30\ubcf8 \ub370\uc774\ud130\uc758 Baseline model CV \uc2a4\ucf54\uc5b4\ub294 \uc544\ub798\uc640 \uac19\uc2b5\ub2c8\ub2e4. Categorical \ub370\uc774\ud130\ub294 One Hot Encoding\uc73c\ub85c \ucc98\ub9ac\ud558\uaca0\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "7b543aec", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train = train_test_split(data)\nprint(X_train.shape, X_test.shape)\n\nlgb_param = {\n    'objective': 'regression',\n    'learning_rate': 0.05,\n    'num_leaves': 15,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 1,\n    'feature_fraction': 0.7,\n    'seed': RANDOM_SEED,\n    'metric': ['rmse'],\n}\n\noof, pred, cv_score, fi_df = get_oof_lgb(X_train, y_train, X_test, lgb_param)"]}, {"cell_type": "code", "execution_count": 1, "id": "3f02b5e4", "metadata": {}, "outputs": [], "source": ["plot_feature_importance(fi_df)"]}, {"cell_type": "markdown", "id": "57f1843a", "metadata": {}, "source": ["Feature Importance\ub97c \ubcf4\uba74 zipcode\uc758 98004, 98023, 98112, 98108\uc774 \uc911\uc694\ud55c feature\ub85c \ub098\uc624\ub294\ub370\uc694.\n\nzipcode\uc640 price\uc758 boxplot\uc744 \uadf8\ub824\ubcf4\uba74 98004, 98112\ub294 \uc9d1\uac12\uc774 \ube44\uc2fc \uc9c0\uc5ed 98023, 98108\uc740 \uc9d1\uac12\uc774 \ub0ae\uc740 \uc9c0\uc5ed\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "1c580ecb", "metadata": {}, "outputs": [], "source": ["plot_categorical_for_regression(data, 'zipcode')"]}, {"cell_type": "markdown", "id": "1f20bbf2", "metadata": {}, "source": ["98004, 98112, 98023, 98108 \uc9c0\uc5ed\uc774 \uc5b4\ub290 \uc704\uce58\uc5d0 \uc788\ub294\uc9c0 \uc704\ub3c4, \uacbd\ub3c4 \ub370\uc774\ud130\ub97c \ud1b5\ud574 \ud655\uc778\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "d51341aa", "metadata": {}, "outputs": [], "source": ["df = X_train\ndf['price'] = y_train\n\nfig = plt.figure(figsize = (16, 12))\n\nax1 = plt.subplot(221)\nsns.scatterplot(x='long', y='lat', hue='ohe_zipcode_98004', size='price', data=df, ax=ax1)\n\nax2 = plt.subplot(222)\nsns.scatterplot(x='long', y='lat', hue='ohe_zipcode_98112', size='price', data=df, ax=ax2)\n\nax3 = plt.subplot(223)\nsns.scatterplot(x='long', y='lat', hue='ohe_zipcode_98023', size='price', data=df, ax=ax3)\n\nax4 = plt.subplot(224)\nsns.scatterplot(x='long', y='lat', hue='ohe_zipcode_98108', size='price', data=df, ax=ax4)\n\nplt.show()"]}, {"cell_type": "markdown", "id": "925f2cb3", "metadata": {}, "source": ["# Zipcode Feature Engineering"]}, {"cell_type": "markdown", "id": "862e597f", "metadata": {}, "source": ["Zipcode\ub294 \ub2e4\uc12f\uc790\ub9ac\ub85c \ub41c \uc22b\uc790\ud615\uc758 \ub370\uc774\ud130\uc778\ub370, \ub370\uc774\ud130\ub97c \ubcf4\uba74 \uc55e\uc758 \ub450 \uc790\ub9ac\ub294 98\ub85c \ub3d9\uc77c\ud569\ub2c8\ub2e4.\n\n\uadf8\ub798\uc11c \ub4a4\uc758 \uc138 \uc790\ub9ac\uc758 \uc22b\uc790\ub97c \uc5ec\ub7ec\uac00\uc9c0 \ubc29\ubc95\uc73c\ub85c \ucabc\uac1c\uc11c \uc0c8\ub85c\uc6b4 feature\ub97c \ub9cc\ub4e4\uc5b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.  "]}, {"cell_type": "code", "execution_count": 1, "id": "5deaedd2", "metadata": {}, "outputs": [], "source": ["data = load_original_data()\n\ndata['zipcode-3'] = 'z_' + data['zipcode'].str[2:3]\ndata['zipcode-4'] = 'z_' + data['zipcode'].str[3:4]\ndata['zipcode-5'] = 'z_' + data['zipcode'].str[4:5]\ndata['zipcode-34'] = 'z_' + data['zipcode'].str[2:4]\ndata['zipcode-45'] = 'z_' + data['zipcode'].str[3:5]\ndata['zipcode-35'] = 'z_' + data['zipcode'].str[2:3] + data['zipcode'].str[4:5]\n\nprint(data.shape)\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "c9009601", "metadata": {}, "outputs": [], "source": ["data['zipcode'] = 'z_' + data['zipcode']\nsns.scatterplot(x='long', y='lat', hue='zipcode', hue_order=np.sort(data['zipcode'].unique()), data=data);"]}, {"cell_type": "markdown", "id": "75d48d5d", "metadata": {}, "source": ["\uc0c8\ub86d\uac8c \ub9cc\ub4e0 zipcode feature\ub97c \uc9c0\ub3c4\uc5d0\uc11c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "ca5bfda3", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='long', y='lat', hue='zipcode-3', hue_order=np.sort(data['zipcode-3'].unique()), data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "21b34c50", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='long', y='lat', hue='zipcode-4', hue_order=np.sort(data['zipcode-4'].unique()), data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "f9bbe44c", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='long', y='lat', hue='zipcode-5', hue_order=np.sort(data['zipcode-5'].unique()), data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "553aa397", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='long', y='lat', hue='zipcode-34', hue_order=np.sort(data['zipcode-34'].unique()), data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "be12d75f", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='long', y='lat', hue='zipcode-45', hue_order=np.sort(data['zipcode-45'].unique()), data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "c481dda0", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='long', y='lat', hue='zipcode-35', hue_order=np.sort(data['zipcode-35'].unique()), data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "dc67f878", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train = train_test_split(data)\nprint(X_train.shape, X_test.shape)\n\nlgb_param = {\n    'objective': 'regression',\n    'learning_rate': 0.05,\n    'num_leaves': 15,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 1,\n    'feature_fraction': 0.7,\n    'seed': RANDOM_SEED,\n    'metric': ['rmse'],\n}\n\noof, pred, cv_score, fi_df = get_oof_lgb(X_train, y_train, X_test, lgb_param)"]}, {"cell_type": "markdown", "id": "88d51ce4", "metadata": {}, "source": ["\uc0c8\ub86d\uac8c \ub9cc\ub4e0 zipcode feature\ub85c CV Score\uac00 \ub354 \uc88b\uc544\uc9c4 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "852c670f", "metadata": {}, "outputs": [], "source": ["plot_feature_importance(fi_df)"]}, {"cell_type": "markdown", "id": "4862500f", "metadata": {}, "source": ["Feature Importance\ub97c \ubcf4\uba74 zipcode-35\uc758 18, zipcode-5\uc758 8\uc774 \uc911\uc694\ud55c feature\ub85c \ub098\uc624\uace0 boxplot\uc744 \uadf8\ub824\ubcf4\uba74 \uc9d1\uac12\uc774 \uc2fc \uc9c0\uc5ed\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "584a3c49", "metadata": {}, "outputs": [], "source": ["plot_categorical_for_regression(data, 'zipcode-35')"]}, {"cell_type": "code", "execution_count": 1, "id": "f13a42af", "metadata": {}, "outputs": [], "source": ["plot_categorical_for_regression(data, 'zipcode-5')"]}, {"cell_type": "markdown", "id": "24f7b911", "metadata": {}, "source": ["# PCA Transformation - Lat, Long"]}, {"cell_type": "markdown", "id": "1e86e680", "metadata": {}, "source": ["PCA\ub294 \ucc28\uc6d0\ucd95\uc18c\uc5d0 \uc8fc\ub85c \uc0ac\uc6a9\ub418\ub294 \uc54c\uace0\ub9ac\uc998\uc785\ub2c8\ub2e4. \uc704\ub3c4, \uacbd\ub3c4\uc758 \ub370\uc774\ud130\ub9cc \ubcf4\uba74 2\ucc28\uc6d0\uc758 \ub370\uc774\ud130\uc778\ub370, \uc774 \ub370\uc774\ud130\ub97c \ucc28\uc6d0\ucd95\uc18c\ub294 \ud558\uc9c0 \uc54a\uace0 2\ucc28\uc6d0 \uadf8\ub300\ub85c PCA Transformation\uc744 \ud558\uba74 \uc6d0\ubcf8 \ub370\uc774\ud130\ub97c \ubcc0\ud615\ud574\uc11c \uc0c8\ub85c\uc6b4 feature\ub97c \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "86f80227", "metadata": {}, "outputs": [], "source": ["# pca for lat, long\ndata = load_original_data()\n\ncoord = data[['lat','long']]\npca = PCA(n_components=2)\npca.fit(coord)\n\ncoord_pca = pca.transform(coord)\n\ndata['coord_pca1'] = coord_pca[:, 0]\ndata['coord_pca2'] = coord_pca[:, 1]"]}, {"cell_type": "markdown", "id": "215916e9", "metadata": {}, "source": ["\uc774\ub807\uac8c \ub9cc\ub4e4\uc5b4\uc9c4 feature\ub97c 2\ucc28\uc6d0\uc5d0 \uadf8\ub824\ubcf4\uba74 \uc6d0\ubcf8 \ub370\uc774\ud130\uac00 \ubcc0\ud615\ub418\uc11c \uc0c8\ub85c\uc6b4 feature\ub85c \ub9cc\ub4e4\uc5b4\uc9c4 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "28587ae0", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='coord_pca2', y='coord_pca1', hue='price', data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "c79acd15", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train = train_test_split(data)\nprint(X_train.shape, X_test.shape)\n\nlgb_param = {\n    'objective': 'regression',\n    'learning_rate': 0.05,\n    'num_leaves': 15,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 1,\n    'feature_fraction': 0.7,\n    'seed': RANDOM_SEED,\n    'metric': ['rmse'],\n}\n\noof, pred, cv_score, fi_df = get_oof_lgb(X_train, y_train, X_test, lgb_param)"]}, {"cell_type": "markdown", "id": "f0893c3b", "metadata": {}, "source": ["PCA\ub97c \ud1b5\ud574 \ub9cc\ub4e0 feature\ub85c CV Score\uac00 \ub354 \uc88b\uc544\uc9c4 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uace0, \uc544\ub798 feature importance\uc5d0\uc11c\ub3c4 \uc911\uc694\ud55c feature\ub85c \ub098\uc624\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "0cdebcf5", "metadata": {}, "outputs": [], "source": ["plot_feature_importance(fi_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "30cc148f", "metadata": {}, "outputs": [], "source": ["plot_numeric_for_regression(data, 'coord_pca2')\nplot_numeric_for_regression(data, 'coord_pca1')"]}, {"cell_type": "markdown", "id": "74dbd96d", "metadata": {}, "source": ["# K-Means Clustering - Lat, Long"]}, {"cell_type": "markdown", "id": "745ee37f", "metadata": {}, "source": ["K-Means Clustering\uc740 Clustering\uc5d0 \uc0ac\uc6a9\ub418\ub294 \ube44\uc9c0\ub3c4\ud559\uc2b5 \uc54c\uace0\ub9ac\uc998 \uc911\uc758 \ud558\ub098\uc785\ub2c8\ub2e4. \uc704\ub3c4, \uacbd\ub3c4 \ub370\uc774\ud130\ub97c K-Means Clustering \ud558\uba74 \uac00\uae4c\uc6b4 \uc9c0\uc5ed\ub07c\ub9ac Cluster\uac00 \ub9cc\ub4e4\uc5b4\uc9c0\uae30 \ub54c\ubb38\uc5d0 zipcode\uc640 \uc720\uc0ac\ud55c \uac1c\ub150\uc758 \uc0c8\ub85c\uc6b4 feature\ub97c \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "markdown", "id": "8ba8be4e", "metadata": {}, "source": ["# Determine K by Elbow method"]}, {"cell_type": "markdown", "id": "e72e12f0", "metadata": {}, "source": ["K-Means Clustering\uc5d0\uc11c \uc911\uc694\ud55c \uac74 K \uac12\uc744 \uc5b4\ub5bb\uac8c \uacb0\uc815\ud558\ub290\ub0d0 \uc778\ub370\uc694. \uc77c\ubc18\uc801\uc73c\ub85c \ub9ce\uc774 \uc4f0\uc774\ub294 \ubc29\ubc95\uc740 K \uac12\uc744 \ub298\ub824\uac00\uba74\uc11c \uc5ec\ub7ec \uac1c \ub3cc\ub824\ubcf4\uba74, Cluster \uac04\uc758 \uac70\ub9ac\uc758 \ud569\uc744 \ub098\ud0c0\ub0b4\ub294 inertia\uac00 \uae09\uaca9\ud788 \ub5a8\uc5b4\uc9c0\ub294 \uad6c\uac04\uc774 \uc0dd\uae30\ub294\ub370 \uc774 \uc9c0\uc810\uc758 K \uac12\uc744 \ub9ce\uc774 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub7f0 \ubc29\uc2dd\uc744 Elbow Method\ub77c\uace0 \ud569\ub2c8\ub2e4. \uba3c\uc800 Elbow Method\ub97c \ud1b5\ud574 K \uac12\uc744 \uacb0\uc815\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "cb7493fd", "metadata": {}, "outputs": [], "source": ["inertia_arr = []\n\nk_range = range(2, 16)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=RANDOM_SEED).fit(coord)\n \n    # Sum of distances of samples to their closest cluster center\n    interia = kmeans.inertia_\n    print (\"k:\",k, \" cost:\", interia)\n    inertia_arr.append(interia)\n    \ninertia_arr = np.array(inertia_arr)\n\nplt.plot(k_range, inertia_arr)\nplt.vlines(5, ymin=inertia_arr.min()*0.9999, ymax=inertia_arr.max()*1.0003, linestyles='--', colors='b')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia');"]}, {"cell_type": "markdown", "id": "92946865", "metadata": {}, "source": ["\uc704\uc758 \uadf8\ub798\ud504\ub97c \ubcf4\uba74 5\uac00 \uac00\uc7a5 \uc801\uc808\ud55c K \uac12\uc73c\ub85c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "070acfe8", "metadata": {}, "outputs": [], "source": ["data = load_original_data()\n\n# kmeans for lat, long\nkmeans = KMeans(n_clusters=5, random_state=RANDOM_SEED).fit(coord)\ncoord_cluster = kmeans.predict(coord)\ndata['coord_cluster'] = coord_cluster\ndata['coord_cluster'] = data['coord_cluster'].map(lambda x: 'c_' + str(x).rjust(2, '0'))\n\nX_train, X_test, y_train = train_test_split(data)\nprint(X_train.shape, X_test.shape)\n\nlgb_param = {\n    'objective': 'regression',\n    'learning_rate': 0.05,\n    'num_leaves': 15,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 1,\n    'feature_fraction': 0.7,\n    'seed': RANDOM_SEED,\n    'metric': ['rmse'],\n}\n\noof, pred, cv_score, fi_df = get_oof_lgb(X_train, y_train, X_test, lgb_param)"]}, {"cell_type": "markdown", "id": "532ea43f", "metadata": {}, "source": ["# Determine K by CV Score"]}, {"cell_type": "markdown", "id": "8e18b38e", "metadata": {}, "source": ["\ub610, \ub2e4\ub978 \ubc29\uc2dd\uc73c\ub85c K \uac12\uc744 \uacb0\uc815\ud574\ubcfc \uc218 \ub3c4 \uc788\ub294\ub370\uc694. K-Means Clustering\uc73c\ub85c \ub9cc\ub4e0 feature\ub97c Regression Model\uc5d0\uc11c \uacb0\uad6d \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 K \uac12\ub3c4 \ud558\ub098\uc758 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub85c \ubcf4\uace0 CV Score\uac00 \uac00\uc7a5 \ub0ae\uac8c \ub098\uc624\ub294 K\ub97c \uc120\ud0dd\ud574\uc11c \uc0ac\uc6a9\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "2946d435", "metadata": {}, "outputs": [], "source": ["k_range = range(2, 80, 5)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=RANDOM_SEED).fit(coord)\n    coord_cluster = kmeans.predict(coord)\n    data['coord_cluster'] = coord_cluster\n    data['coord_cluster'] = data['coord_cluster'].map(lambda x: str(x).rjust(2, '0'))\n    \n    X_train, X_test, y_train = train_test_split(data)\n\n    lgb_param = {\n        'objective': 'regression',\n        'learning_rate': 0.05,\n        'num_leaves': 15,\n        'bagging_fraction': 0.7,\n        'bagging_freq': 1,\n        'feature_fraction': 0.7,\n        'seed': RANDOM_SEED,\n        'metric': ['rmse'],\n    }\n\n    print('K :', k)\n    get_oof_lgb(X_train, y_train, X_test, lgb_param)\n    print()"]}, {"cell_type": "code", "execution_count": 1, "id": "45c08d24", "metadata": {}, "outputs": [], "source": ["k_range = range(28, 37)\n\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=RANDOM_SEED).fit(coord)\n    coord_cluster = kmeans.predict(coord)\n    data['coord_cluster'] = coord_cluster\n    data['coord_cluster'] = data['coord_cluster'].map(lambda x: str(x).rjust(2, '0'))\n    \n    X_train, X_test, y_train = train_test_split(data)\n\n    lgb_param = {\n        'objective': 'regression',\n        'learning_rate': 0.05,\n        'num_leaves': 15,\n        'bagging_fraction': 0.7,\n        'bagging_freq': 1,\n        'feature_fraction': 0.7,\n        'seed': RANDOM_SEED,\n        'metric': ['rmse'],\n    }\n\n    print('K :', k)\n    get_oof_lgb(X_train, y_train, X_test, lgb_param)\n    print()"]}, {"cell_type": "markdown", "id": "d7929726", "metadata": {}, "source": ["K \uac12\uc774 32\uc77c \ub54c CV Score\uac00 \uac00\uc7a5 \uc88b\uac8c \ub098\uc624\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. Elbow Method\ub85c K \uac12\uc744 \uc120\ud0dd\ud588\uc744 \ub54c\ubcf4\ub2e4 CV Score \uae30\uc900\uc73c\ub85c K\ub97c \uc120\ud0dd\ud560 \ub54c\uac00 \ub354 \ubaa8\ub378 \uc131\ub2a5\uc774 \uc88b\uae30 \ub54c\ubb38\uc5d0 \ucd5c\uc885 K \uac12\uc740 32\ub85c \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.  "]}, {"cell_type": "code", "execution_count": 1, "id": "8d5003d0", "metadata": {}, "outputs": [], "source": ["# kmeans for lat, long\nkmeans = KMeans(n_clusters=32, random_state=RANDOM_SEED).fit(coord)\ncoord_cluster = kmeans.predict(coord)\ndata['coord_cluster'] = coord_cluster\ndata['coord_cluster'] = data['coord_cluster'].map(lambda x: 'c_' + str(x).rjust(2, '0'))"]}, {"cell_type": "code", "execution_count": 1, "id": "0733194a", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='long', y='lat', hue='coord_cluster', hue_order=np.sort(data['coord_cluster'].unique()), data=data);"]}, {"cell_type": "code", "execution_count": 1, "id": "e40647b7", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train = train_test_split(data)\nprint(X_train.shape, X_test.shape)\n\nlgb_param = {\n    'objective': 'regression',\n    'learning_rate': 0.05,\n    'num_leaves': 15,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 1,\n    'feature_fraction': 0.7,\n    'seed': RANDOM_SEED,\n    'metric': ['rmse'],\n}\n\noof, pred, cv_score, fi_df = get_oof_lgb(X_train, y_train, X_test, lgb_param)"]}, {"cell_type": "code", "execution_count": 1, "id": "47b2f9d9", "metadata": {}, "outputs": [], "source": ["plot_feature_importance(fi_df)"]}, {"cell_type": "markdown", "id": "195a1826", "metadata": {}, "source": ["Feature Importance\ub97c \ubcf4\uba74 11\ubc88 cluster\uac00 \uc911\uc694\ud55c feature\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc544\ub798 \uadf8\ub798\ud504\uc5d0\uc11c 11\ubc88 cluster\uc758 \uc704\uce58\ub97c \ud655\uc778\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "8c8fe730", "metadata": {}, "outputs": [], "source": ["df = X_train\ndf['price'] = y_train\nsns.scatterplot(x='long', y='lat', hue='ohe_coord_cluster_c_11', data=df);"]}, {"cell_type": "markdown", "id": "68e16958", "metadata": {}, "source": ["Cluster\uc758 boxplot\uc744 \ud655\uc778\ud574\ubcf4\uba74 11\ubc88 cluster\uac00 \uc9d1\uac12\uc774 \uac00\uc7a5 \ube44\uc2fc \uc9c0\uc5ed\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "08b2f988", "metadata": {}, "outputs": [], "source": ["plot_categorical_for_regression(data, 'coord_cluster')"]}, {"cell_type": "markdown", "id": "1694ea6f", "metadata": {}, "source": ["# [Haversine Distance](https://en.wikipedia.org/wiki/Haversine_formula)"]}, {"cell_type": "markdown", "id": "da2450be", "metadata": {}, "source": ["\ub9c8\uc9c0\ub9c9\uc73c\ub85c Haversine Distance\ub97c \uc0ac\uc6a9\ud55c feature \uc0dd\uc131\uc785\ub2c8\ub2e4. Haversine Distance\ub294 \ub450 \uac1c\uc758 \uc704\ub3c4, \uacbd\ub3c4 \uc88c\ud45c\uc5d0\uc11c \uc9c0\uad6c\uc758 \uace1\ub960\uc744 \uace0\ub824\ud574 \ub450 \uc88c\ud45c \uac04\uc758 \uac70\ub9ac\ub97c \uad6c\ud558\ub294 \ubc29\ubc95\uc785\ub2c8\ub2e4.\n\n\uc544\ub798\uc758 function\uc73c\ub85c Haversine Distance\ub97c \uad6c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "9588aafe", "metadata": {}, "outputs": [], "source": ["def haversine_array(lat1, lng1, lat2, lng2): \n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2)) \n    AVG_EARTH_RADIUS = 6371 # in km \n    lat = lat2 - lat1 \n    lng = lng2 - lng1 \n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2 \n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d)) \n    return h"]}, {"cell_type": "markdown", "id": "6ec9d05a", "metadata": {}, "source": ["\uc8fc\uc5b4\uc9c4 \ub370\uc774\ud130\uc5d0\uc11c \uc704\ub3c4, \uacbd\ub3c4\uc758 \ucd5c\uc18c\uac12\uacfc, \ucd5c\ub300\uac12 \ub450 \uac1c\uc758 \uc88c\ud45c\uc5d0 \ub300\ud574 \uac70\ub9ac\ub97c \uad6c\ud574\ubcf4\uba74 113.88km\uac00 \ub098\uc624\ub294\ub370, \uac00\uc7a5 \uba3c \uac70\ub9ac\uc758 \uac70\ub9ac\uac00 \uc774 \uc815\ub3c4\ub77c\ub294 \uc598\uae30\uac00 \ub418\uaca0\ub124\uc694."]}, {"cell_type": "code", "execution_count": 1, "id": "d2c425f2", "metadata": {}, "outputs": [], "source": ["print(data['lat'].min(), data['lat'].max(), data['long'].min(), data['long'].max())\n\nhaversine_dist = haversine_array(data['lat'].min(), data['long'].min(), data['lat'].max(), data['long'].max())\nprint(f'max distance: {haversine_dist:.2f}km')"]}, {"cell_type": "markdown", "id": "d6a83044", "metadata": {}, "source": ["\uc544\ub798\ub294 id\uac00 0\uc778 \uc9d1\uacfc \uc804\uccb4 \uc9d1\uacfc\uc758 \uac70\ub9ac\ub97c \uad6c\ud55c \ub370\uc774\ud130\uc785\ub2c8\ub2e4. 0\ubc88 \uc9d1\uacfc \uac00\uae4c\uc6b4 \uc774\uc6c3\uc740 \uc9d1\uac12\uc774 \ube44\uc2b7\ud560 \ud655\ub960\uc774 \ub192\uae30 \ub54c\ubb38\uc5d0 \uac70\ub9ac\ub97c \uae30\ubc18\uc73c\ub85c \uac00\uae4c\uc6b4 \uc774\uc6c3\uc9d1\uc758 \ub370\uc774\ud130\ub97c \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7f0 \uc2dd\uc73c\ub85c \uc804\uccb4 \uc9d1\ub4e4\uc758 Haversine Distance\ub97c \uad6c\ud558\uba74 \ub098\uc640 \uac00\uae4c\uc6b4 \uc774\uc6c3\uc9d1\ub4e4\uc758 \uc815\ubcf4\ub97c \uc0c8\ub85c\uc6b4 feature\ub85c \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."]}, {"cell_type": "code", "execution_count": 1, "id": "ba7928a2", "metadata": {}, "outputs": [], "source": ["neighbor_df = pd.DataFrame()\nlat2 = data['lat'].values\nlong2 = data['long'].values\n\nlat1 = data.loc[0, 'lat'] # id = 0 house lat\nlong1 = data.loc[0, 'long'] # id = 0 house long\ndist_arr = haversine_array(lat1, long1, lat2, long2)\nneighbor_df = pd.DataFrame({\n    'id': np.tile(np.array([data.loc[0, 'id']]), data.shape[0]),\n    'neighbor_id': data['id'],\n    'neighbor_lat': lat2,\n    'neighbor_long': long2,\n    'distance': dist_arr,\n})\n    \nprint(neighbor_df.shape)\nneighbor_df.head()"]}, {"cell_type": "markdown", "id": "9f52dabc", "metadata": {}, "source": ["\uc544\ub798\ub294 0\ubc88 \uc9d1\uc758 \ubc18\uacbd 5km \uc774\ub0b4\uc758 \uc774\uc6c3\ub4e4\uc744 \uadf8\ub824\ubcf8 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4. "]}, {"cell_type": "code", "execution_count": 1, "id": "ff141b0d", "metadata": {}, "outputs": [], "source": ["neighbor_df['neighbor_10km'] = neighbor_df['distance'] <= 5\nsns.scatterplot(x='neighbor_long', y='neighbor_lat', hue='neighbor_10km', data=neighbor_df);"]}, {"cell_type": "markdown", "id": "363e82eb", "metadata": {}, "source": ["# Conclusion\n\n\uc9c0\uae08\uae4c\uc9c0 \uc704\uce58 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud55c Feature Engineering\uc744 \uc0b4\ud3b4\ubd24\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \ub9c8\uc9c0\ub9c9\uc758 Haversine Distance\ub97c \ud65c\uc6a9\ud558\uba74 \uac01 \uc9d1\uc5d0\uc11c \uac00\uae4c\uc6b4 \uc774\uc6c3\uc9d1\uc744 \uacc4\uc0b0\ud560 \uc218 \uc788\uace0, \uc774\ub97c \ubc14\ud0d5\uc73c\ub85c \ub2e4\uc591\ud55c feature\ub97c \ub9cc\ub4e4\uc5b4 \ub0bc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc800\uac19\uc740 \uacbd\uc6b0 \uc774\ub7ec\ud55c Geo Data Feature Engineering\uacfc Stacking Ensemble\uc744 \ud1b5\ud574 \ud37c\ube14\ub9ad \ub9ac\ub354\ubcf4\ub4dc \uae30\uc900\uc73c\ub85c RMSE \uc2a4\ucf54\uc5b4\uac00 96000\ub300\uae4c\uc9c0 \uc131\ub2a5\uc774 \ub098\uc624\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4. \uc81c\uac00 \uacf5\uc720\ud55c \ub0b4\uc6a9\uc774 \ub2e4\ub978 \ubd84\ub4e4\uc5d0\uac8c\ub3c4 \ub3c4\uc6c0\uc774 \ub410\uc73c\uba74 \uc88b\uaca0\ub124\uc694.\n\n\uac10\uc0ac\ud569\ub2c8\ub2e4."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}