{"cells": [{"cell_type": "code", "execution_count": 1, "id": "2c37d804", "metadata": {}, "outputs": [], "source": ["import numpy as np # linear algebra\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('max_colwidth', None)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"]}, {"cell_type": "code", "execution_count": 1, "id": "74eae7ff", "metadata": {}, "outputs": [], "source": ["# train=pd.read_csv('/kaggle/input/ames-housing-dataset/AmesHousing.csv')\ntest=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ntrain2=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "75325211", "metadata": {}, "outputs": [], "source": ["train2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "7fb3da05", "metadata": {}, "outputs": [], "source": ["train2.columns = train2.columns.str.replace(' ', '')\ntrain2=train2.rename(columns={\"YearRemod/Add\": \"YearRemodAdd\"})"]}, {"cell_type": "code", "execution_count": 1, "id": "206f488c", "metadata": {}, "outputs": [], "source": ["train2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "468bab3f", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "fd3a8652", "metadata": {}, "outputs": [], "source": ["# print(\"Size of the Ames Dataset\",len(train))\nprint(\"Size of the Housing Dataset\",len(train2))\nprint(\"Size of the Housing Test Dataset\",len(test))"]}, {"cell_type": "markdown", "id": "213454af", "metadata": {}, "source": ["Finding duplicates in data"]}, {"cell_type": "code", "execution_count": 1, "id": "3de6b939", "metadata": {}, "outputs": [], "source": ["print(train2.shape)\ntrain2 = train2.drop_duplicates()\nprint(train2.shape)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "448f0fa5", "metadata": {}, "outputs": [], "source": ["useless = ['Id'] \ntrain2 = train2.drop(useless, axis = 1)\ntrain2.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "8f3b95de", "metadata": {}, "outputs": [], "source": ["from scipy.stats import norm\n(mu, sigma) = norm.fit(train2['SalePrice'])\nplt.figure(figsize = (12,6))\nsns.distplot(train2['SalePrice'], kde = True, hist=True, fit = norm)\nplt.title('SalePrice distribution vs Normal Distribution', fontsize = 13)\nplt.xlabel(\"House's sale Price in $\", fontsize = 12)\nplt.legend(['Normal dist ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma),'actual price dist'],loc='best')\nplt.show()"]}, {"cell_type": "markdown", "id": "2ee23b95", "metadata": {}, "source": ["In literature, acceptable values for skewness are between -0.5 and 0.5 while -2 and 2 for Kurtosis. Looking at the plot, we can clearly see how the distribution does not seem to be normal, but highly right-skewed. The non-normality of our distribution is also supported by the Shapiro test for normality (p-value really small that allows us to reject the hypotesis of normality). Despite that, let's leave it like that for now, we'll deal with that later in the notebook."]}, {"cell_type": "code", "execution_count": 1, "id": "8f3f3031", "metadata": {}, "outputs": [], "source": ["from scipy import stats\nshap = stats.shapiro(train2['SalePrice'])\nprint('Skewness : %f' % abs(train2['SalePrice']).skew())\nprint('Kurtosis : %f' % abs(train2['SalePrice']).kurt())\nprint('Shapiro_Test_statistic : %f' % shap.statistic )\nprint('Shapiro_Test_pvalue : %f' % shap.pvalue )"]}, {"cell_type": "code", "execution_count": 1, "id": "782e473e", "metadata": {}, "outputs": [], "source": ["f, ax = plt.subplots(figsize=(50, 35))\nmat = train2.corr('pearson')\nmask = np.triu(np.ones_like(mat, dtype=bool))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(mat, mask=mask, cmap=cmap, vmax=1, center=0, annot = True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "27f52255", "metadata": {}, "outputs": [], "source": ["# OverallQuall - SalePrice [Pearson = 0.8]\nfig,ax=plt.subplots(1,3,figsize=(20,10))\nsns.stripplot(data=train2,x='OverallQual',y='SalePrice',ax=ax[1])\nsns.violinplot(data=train2,x='OverallQual',y='SalePrice',ax=ax[2])\nsns.boxplot(data=train2,x='OverallQual',y='SalePrice',ax=ax[0])\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "5aa8a1a8", "metadata": {}, "outputs": [], "source": ["# BsmtFinSF2 - SalePrice [Pearson = -0.011\nfig,ax=plt.subplots(1,3,figsize=(20,10))\nsns.stripplot(data=train2,x='BsmtFinSF2',y='SalePrice',ax=ax[1])\nsns.violinplot(data=train2,x='BsmtFinSF2',y='SalePrice',ax=ax[2])\nsns.boxplot(data=train2,x='BsmtFinSF2',y='SalePrice',ax=ax[0])\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "a83efa52", "metadata": {}, "outputs": [], "source": ["# GrLivArea vs SalePrice [corr = 0.71]\n\nPearson_GrLiv = 0.71\nplt.figure(figsize = (12,6))\nsns.regplot(data=train2, x = 'GrLivArea', y='SalePrice', scatter_kws={'alpha':0.2})\nplt.title('GrLivArea vs SalePrice', fontsize = 12)\nplt.legend(['$Pearson=$ {:.2f}'.format(Pearson_GrLiv)], loc = 'best')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "cdc03d2d", "metadata": {}, "outputs": [], "source": ["# YearBuilt vs SalePrice\n\nPearson_YrBlt = 0.56\nplt.figure(figsize = (12,6))\nsns.regplot(data=train2, x = 'YearBuilt', y='SalePrice', scatter_kws={'alpha':0.2})\nplt.title('YearBuilt vs SalePrice', fontsize = 12)\nplt.legend(['$Pearson=$ {:.2f}'.format(Pearson_YrBlt)], loc = 'best')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "db64ee22", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,10))\nsns.barplot(x='YrSold',y='SalePrice',data=train2,estimator=np.median)\nplt.title('Median of Sale Price by Year')\nplt.xlabel('Year of Selling')\nplt.ylabel('Median of Price')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "b15c2206", "metadata": {}, "outputs": [], "source": ["# Separating Target and Features\n\ntarget = train2['SalePrice']\ntest_id = test['Id']\ntest = test.drop(['Id'],axis = 1)\ntrain2_1 = train2.drop(['SalePrice'],axis = 1)\nprint(\"train_datasets shape\",train2.shape)\nprint(\"test_datasets shape\",test.shape)\n\ntrain_test = pd.concat([train2_1,test], axis=0, sort=False)\nprint(train_test.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "45e6ee5f", "metadata": {}, "outputs": [], "source": ["nan=pd.DataFrame(train_test.isna().sum(),columns=['Nan_sum'])\nnan['feat']=nan.index\nnan=nan[nan['Nan_sum']>0]\nnan['Percentage']=(nan['Nan_sum']/1460)*100\n\nnan=nan.sort_values(by=['Nan_sum'])\nnan.insert(0,'Serial No.',range(1,len(nan)+1))\nnan"]}, {"cell_type": "code", "execution_count": 1, "id": "0ac706b4", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20,10))\nsns.barplot(x=nan['feat'],y=nan['Percentage'])\nplt.xticks(rotation=40)\nplt.title('Features Containing Nan')\nplt.xlabel('Features')\nplt.ylabel('% of Missing Data')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "c901f95c", "metadata": {}, "outputs": [], "source": ["# Converting non-numeric predictors stored as numbers into string\n\ntrain_test['MSSubClass'] = train_test['MSSubClass'].apply(str)\ntrain_test['YrSold'] = train_test['YrSold'].apply(str)\ntrain_test['MoSold'] = train_test['MoSold'].apply(str)\ntrain_test['OverallQual'] = train_test['OverallQual'].apply(str)\ntrain_test['OverallCond'] = train_test['OverallCond'].apply(str)"]}, {"cell_type": "code", "execution_count": 1, "id": "3873192c", "metadata": {}, "outputs": [], "source": ["# Filling Categorical NaN (That we know how to fill due to the description file )\n\ntrain_test['Functional'] = train_test['Functional'].fillna('Typ')\ntrain_test['Electrical'] = train_test['Electrical'].fillna(\"SBrkr\")\ntrain_test['KitchenQual'] = train_test['KitchenQual'].fillna(\"TA\")\ntrain_test['Exterior1st'] = train_test['Exterior1st'].fillna(train_test['Exterior1st'].mode()[0])\ntrain_test['Exterior2nd'] = train_test['Exterior2nd'].fillna(train_test['Exterior2nd'].mode()[0])\ntrain_test['SaleType'] = train_test['SaleType'].fillna(train_test['SaleType'].mode()[0])\ntrain_test[\"PoolQC\"] = train_test[\"PoolQC\"].fillna(\"None\")\ntrain_test[\"Alley\"] = train_test[\"Alley\"].fillna(\"None\")\ntrain_test['FireplaceQu'] = train_test['FireplaceQu'].fillna(\"None\")\ntrain_test['Fence'] = train_test['Fence'].fillna(\"None\")\ntrain_test['MiscFeature'] = train_test['MiscFeature'].fillna(\"None\")\nfor col in ('GarageArea', 'GarageCars'):\n    train_test[col] = train_test[col].fillna(0)\n        \nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    train_test[col] = train_test[col].fillna('None')\n    \nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    train_test[col] = train_test[col].fillna('None')\n    \nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea','BsmtUnfSF', 'TotalBsmtSF'):\n    train_test[col] = train_test[col].fillna(0)\n\ntrain_test['LotFrontage'] = train_test['LotFrontage'].fillna(train2['LotFrontage'].median())\n    \n    # Checking the features with NaN remained out\n\nfor col in train_test:\n    if train_test[col].isna().sum() > 0:\n        print(train_test[col].isna().sum(),'::::',train_test[col].name)"]}, {"cell_type": "code", "execution_count": 1, "id": "21b85c65", "metadata": {}, "outputs": [], "source": ["train_test[\"SqFtPerRoom\"] = train_test[\"GrLivArea\"] / (train_test[\"TotRmsAbvGrd\"] +\n                                                       train_test[\"FullBath\"] +\n                                                       train_test[\"HalfBath\"] +\n                                                       train_test[\"KitchenAbvGr\"])\n\ntrain_test['Total_Home_Quality'] = train_test['OverallQual'] + train_test['OverallCond']\n\ntrain_test['Total_Bathrooms'] = (train_test['FullBath'] + (0.5 * train_test['HalfBath']) +\n                               train_test['BsmtFullBath'] + (0.5 * train_test['BsmtHalfBath']))\n\ntrain_test[\"HighQualSF\"] = train_test[\"1stFlrSF\"] + train_test[\"2ndFlrSF\"]\ntrain_test['renovated']=train_test['YearRemodAdd']+train_test['YearBuilt']"]}, {"cell_type": "code", "execution_count": 1, "id": "96582720", "metadata": {}, "outputs": [], "source": ["# Removing the useless variables\n\nuseless = ['GarageYrBlt'] \ntrain_test = train_test.drop(useless, axis = 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "70254487", "metadata": {}, "outputs": [], "source": ["# Creating dummy variables from categorical features\n\ntrain_test_dummy = pd.get_dummies(train_test)\nfrom scipy.stats import skew\nnumeric_features = train_test_dummy.dtypes[train_test_dummy.dtypes != object].index\nskewed_features = train_test_dummy[numeric_features].apply(lambda x: skew(x)).sort_values(ascending=False)\nhigh_skew = skewed_features[skewed_features > 0.5]\nskew_index = high_skew.index\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e2fc72f9", "metadata": {}, "outputs": [], "source": ["# Normalize skewed features using log_transformation\n    \nfor i in skew_index:\n    train_test_dummy[i] = np.log1p(train_test_dummy[i] )"]}, {"cell_type": "markdown", "id": "352b5b74", "metadata": {}, "source": ["Checking for Nan values after dummy"]}, {"cell_type": "code", "execution_count": 1, "id": "eea83206", "metadata": {}, "outputs": [], "source": ["nan=pd.DataFrame(train_test_dummy.isna().sum(),columns=['Nan_sum'])\nnan['feat']=nan.index\nnan=nan[nan['Nan_sum']>0]\nnan['Percentage']=(nan['Nan_sum']/1460)*100\nnan=nan.sort_values(by=['Nan_sum'])\nnan.insert(0,'Serial No.',range(1,len(nan)+1))\nnan"]}, {"cell_type": "markdown", "id": "a829abbf", "metadata": {}, "source": ["checking if the values are in infinity or not after log transformation"]}, {"cell_type": "code", "execution_count": 1, "id": "2d6e40f7", "metadata": {}, "outputs": [], "source": ["inf=pd.DataFrame(np.isinf(train_test_dummy).sum() ,columns=['Inf_sum'])\ninf['feat']=inf.index\ninf=inf[inf['Inf_sum']>0]\ninf=inf.sort_values(by=['Inf_sum'])\ninf.insert(0,'Serial No.',range(1,len(inf)+1))\ninf"]}, {"cell_type": "code", "execution_count": 1, "id": "a5a13d8d", "metadata": {}, "outputs": [], "source": ["import statsmodels.api as sm\n# SalePrice before transformation\n\nfig, ax = plt.subplots(1,2, figsize= (15,5))\nfig.suptitle(\" qq-plot & distribution SalePrice \", fontsize= 15)\n\nsm.qqplot(target, stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\n#research sm \nsns.distplot(target, kde = True, hist=True, fit = norm, ax = ax[1])\nplt.show()"]}, {"cell_type": "markdown", "id": "b0822bac", "metadata": {}, "source": ["transforming the sale price "]}, {"cell_type": "code", "execution_count": 1, "id": "2585d161", "metadata": {}, "outputs": [], "source": ["# SalePrice after transformation\n\ntarget_log = np.log1p(target)\n\nfig, ax = plt.subplots(1,2, figsize= (15,5))\nfig.suptitle(\"qq-plot & distribution SalePrice \", fontsize= 15)\n\nsm.qqplot(target_log, stats.t, distargs=(4,),fit=True, line=\"45\", ax = ax[0])\nsns.distplot(target_log, kde = True, hist=True, fit = norm, ax = ax[1])\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "b9e2cff3", "metadata": {}, "outputs": [], "source": ["import shap\nfrom xgboost import XGBRegressor\nfrom catboost import Pool\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeRegressor\nfrom mlxtend.regressor import StackingRegressor\nfrom sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error"]}, {"cell_type": "code", "execution_count": 1, "id": "0ef8402c", "metadata": {}, "outputs": [], "source": ["# Train-Test separation\n\nX_train = train_test_dummy[0:train2.shape[0]]\nX_test = train_test_dummy[train2.shape[0]:]\nprint(X_train.shape)\nprint(X_test.shape)\n\n# Creation of the RMSE metric:\n    \ndef rmse(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef cv_rmse(model):\n    rmse = np.sqrt(-cross_val_score(model, X_train, target_log, scoring=\"neg_mean_squared_error\", cv=kf))\n    return (rmse)"]}, {"cell_type": "markdown", "id": "ff32af4e", "metadata": {}, "source": ["checking for nan values in training set"]}, {"cell_type": "code", "execution_count": 1, "id": "e1949002", "metadata": {}, "outputs": [], "source": ["nan=pd.DataFrame(X_train.isna().sum(),columns=['Nan_sum'])\nnan['feat']=nan.index\nnan=nan[nan['Nan_sum']>0]\nnan['Percentage']=(nan['Nan_sum']/1460)*100\nnan=nan.sort_values(by=['Nan_sum'])\nnan.insert(0,'Serial No.',range(1,len(nan)+1))\nnan"]}, {"cell_type": "markdown", "id": "1831a54d", "metadata": {}, "source": ["checking for nan values in test set"]}, {"cell_type": "code", "execution_count": 1, "id": "bb2ea54d", "metadata": {}, "outputs": [], "source": ["nan=pd.DataFrame(X_test.isna().sum(),columns=['Nan_sum'])\nnan['feat']=nan.index\nnan=nan[nan['Nan_sum']>0]\nnan['Percentage']=(nan['Nan_sum']/1460)*100\nnan['Perc']=(nan['Nan_sum']/2919)*100\nnan=nan.sort_values(by=['Nan_sum'])\nnan.insert(0,'Serial No.',range(1,len(nan)+1))\nnan"]}, {"cell_type": "code", "execution_count": 1, "id": "c1261cff", "metadata": {}, "outputs": [], "source": ["# 10 Fold Cross validation\n\nkf = KFold(n_splits=11, random_state=42, shuffle=True)\n\ncv_scores = []\ncv_std = []\n\n# baseline_models = ['Linear_Reg.','Bayesian_Ridge_Reg.','LGBM_Reg.','SVR',\n#                    'Dec_Tree_Reg.','Random_Forest_Reg.', 'XGB_Reg.',\n#                    'Grad_Boost_Reg.','Cat_Boost_Reg.','Stacked_Reg.','Stacked_Reg2']\n\nbaseline_models = ['Linear_Reg.','XGB_Reg.',\n                   'Grad_Boost_Reg.','Cat_Boost_Reg.','Stacked_Reg.','Stacked_Reg2']"]}, {"cell_type": "code", "execution_count": 1, "id": "4d191864", "metadata": {}, "outputs": [], "source": ["# Linear Regression\n\nlreg = LinearRegression()\nscore_lreg = cv_rmse(lreg)\ncv_scores.append(score_lreg.mean())\ncv_std.append(score_lreg.std())\n\n# # Bayesian Ridge Regression\n\n# brr = BayesianRidge(compute_score=True)\n# score_brr = cv_rmse(brr)\n# cv_scores.append(score_brr.mean())\n# cv_std.append(score_brr.std())\n\n# # Light Gradient Boost Regressor\n\n# l_gbm = LGBMRegressor(objective='regression')\n# score_l_gbm = cv_rmse(l_gbm)\n# cv_scores.append(score_l_gbm.mean())\n# cv_std.append(score_l_gbm.std())\n\n# # Support Vector Regression\n\n# svr = SVR()\n# score_svr = cv_rmse(svr)\n# cv_scores.append(score_svr.mean())\n# cv_std.append(score_svr.std())\n\n# # Decision Tree Regressor\n\n# dtr = DecisionTreeRegressor()\n# score_dtr = cv_rmse(dtr)\n# cv_scores.append(score_dtr.mean())\n# cv_std.append(score_dtr.std())\n\n# # Random Forest Regressor\n\n# rfr = RandomForestRegressor()\n# score_rfr = cv_rmse(rfr)\n# cv_scores.append(score_rfr.mean())\n# cv_std.append(score_rfr.std())\n\n# XGB Regressor\n\nxgb = XGBRegressor()\nscore_xgb = cv_rmse(xgb)\ncv_scores.append(score_xgb.mean())\ncv_std.append(score_xgb.std())\n\n# Gradient Boost Regressor\n\ngbr = GradientBoostingRegressor()\nscore_gbr = cv_rmse(gbr)\ncv_scores.append(score_gbr.mean())\ncv_std.append(score_gbr.std())\n\n# Cat Boost Regressor\n\ncatb = CatBoostRegressor()\nscore_catb = cv_rmse(catb)\ncv_scores.append(score_catb.mean())\ncv_std.append(score_catb.std())\n\n# Stacked Regressor\n\nstack_gen = StackingRegressor(regressors=(CatBoostRegressor(),\n                                          BayesianRidge()),\n                              meta_regressor = CatBoostRegressor(),\n                              use_features_in_secondary = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "7f87154a", "metadata": {}, "outputs": [], "source": ["score_stack_gen = cv_rmse(stack_gen)\ncv_scores.append(score_stack_gen.mean())\ncv_std.append(score_stack_gen.std())\n"]}, {"cell_type": "code", "execution_count": 1, "id": "dc6b2c60", "metadata": {}, "outputs": [], "source": ["# Stacked Regressor\n\nstack_gen2 = StackingRegressor(regressors=(CatBoostRegressor(),\n                                          XGBRegressor()),\n                              meta_regressor = CatBoostRegressor(),\n                              use_features_in_secondary = True)\n\nscore_stack_gen2 = cv_rmse(stack_gen2)\ncv_scores.append(score_stack_gen2.mean())\ncv_std.append(score_stack_gen2.std())\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "95b55cb7", "metadata": {}, "outputs": [], "source": ["final_cv_score = pd.DataFrame(baseline_models, columns = ['Regressors'])\nfinal_cv_score['RMSE_mean'] = cv_scores\nfinal_cv_score['RMSE_std'] = cv_std"]}, {"cell_type": "code", "execution_count": 1, "id": "5272ddcb", "metadata": {}, "outputs": [], "source": ["final_cv_score"]}, {"cell_type": "code", "execution_count": 1, "id": "bfa663ba", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize = (12,8))\nsns.barplot(final_cv_score['Regressors'],final_cv_score['RMSE_mean'])\nplt.xlabel('Regressors', fontsize = 12)\nplt.ylabel('CV_Mean_RMSE', fontsize = 12)\nplt.xticks(rotation=40)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "3032c7db", "metadata": {}, "outputs": [], "source": ["cat = CatBoostRegressor()\ncat_model = cat.fit(X_train,target_log,\n                     plot=True,\n                     verbose = 0)"]}, {"cell_type": "code", "execution_count": 1, "id": "509b7cb9", "metadata": {}, "outputs": [], "source": ["feat_imp = cat_model.get_feature_importance(prettified=True)\nfeat_imp.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "7c4858d2", "metadata": {}, "outputs": [], "source": ["# Plotting top 30 features' importance\n\nplt.figure(figsize = (12,8))\nsns.barplot(feat_imp['Importances'][:30],feat_imp['Feature Id'][:30], orient = 'h')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "f4a0591b", "metadata": {}, "outputs": [], "source": ["params = {'iterations': 6000,\n          'learning_rate': 0.005,\n          'depth': 4,\n          'l2_leaf_reg': 1,\n          'eval_metric':'RMSE',\n          'early_stopping_rounds': 200,\n          'verbose': 200,\n          'random_seed': 42}\n         \ncat_f = CatBoostRegressor(**params)\ncat_model_f = cat_f.fit(X_train,target_log,\n                     plot=True,\n                     verbose = False)"]}, {"cell_type": "code", "execution_count": 1, "id": "0300a3a5", "metadata": {}, "outputs": [], "source": ["test_pred = cat_f.predict(X_test)\nsubmission = pd.DataFrame(test_id, columns = ['Id'])\ntest_pred = np.expm1(test_pred)\nsubmission['SalePrice'] = test_pred \nsubmission.head()\nsubmission.to_csv(r\"C:\\Users\\Administrator\\Desktop\\cat.csv\", index = False, header = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "b83fd2f4", "metadata": {}, "outputs": [], "source": ["stack_f=stack_gen.fit(X_train,target_log)\ntest_stack = stack_gen.predict(X_test)\nsubmission = pd.DataFrame(test_id, columns = ['Id'])\ntest_pre = np.expm1(test_stack)\nsubmission['SalePrice'] = test_pre\n\nsubmission.to_csv(r\"C:\\Users\\Administrator\\Desktop\\stack.csv\", index = False, header = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "623c3aed", "metadata": {}, "outputs": [], "source": ["stack_f2=stack_gen2.fit(X_train,target_log)\ntest_stack = stack_gen2.predict(X_test)\nsubmission = pd.DataFrame(test_id, columns = ['Id'])\ntest_pre = np.expm1(test_stack)\nsubmission['SalePrice'] = test_pre\n\nsubmission.to_csv(\"C:\\Users\\Administrator\\Desktop\\stack2.csv\", index = False, header = True)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}