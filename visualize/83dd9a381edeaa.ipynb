{"cells": [{"cell_type": "code", "execution_count": 1, "id": "8ecd4bb5", "metadata": {}, "outputs": [], "source": ["import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]}, {"cell_type": "code", "execution_count": 1, "id": "b2a1bb35", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('../input/articles/articles.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "2ce49469", "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "83f48104", "metadata": {}, "outputs": [], "source": ["df.isnull().sum() ## Check for empty data"]}, {"cell_type": "code", "execution_count": 1, "id": "1f592069", "metadata": {}, "outputs": [], "source": ["df['Article'][1029]"]}, {"cell_type": "code", "execution_count": 1, "id": "d1fd2d99", "metadata": {}, "outputs": [], "source": ["len(df)"]}, {"cell_type": "code", "execution_count": 1, "id": "21649344", "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import CountVectorizer\ncvr = CountVectorizer(max_df=0.9, min_df=2, stop_words='english') \n# max_df = discard 90% of the words that are common in all documents/rows\n# min_df = check freq of a word so that it should be common in atleast 2 documents"]}, {"cell_type": "markdown", "id": "6980e82f", "metadata": {}, "source": ["> `Applying un-supervised learning`"]}, {"cell_type": "code", "execution_count": 1, "id": "e3451cd5", "metadata": {}, "outputs": [], "source": ["dtm = cvr.fit_transform(df['Article'])"]}, {"cell_type": "code", "execution_count": 1, "id": "9a29c08f", "metadata": {}, "outputs": [], "source": ["dtm"]}, {"cell_type": "markdown", "id": "7021ed1d", "metadata": {}, "source": ["`Let's perform Latent Dirichlet Allocation using Scikit-Learn`"]}, {"cell_type": "code", "execution_count": 1, "id": "555782fc", "metadata": {}, "outputs": [], "source": ["from sklearn.decomposition import LatentDirichletAllocation\nimport torch\ntorch.cuda.is_available()"]}, {"cell_type": "code", "execution_count": 1, "id": "09adb33f", "metadata": {}, "outputs": [], "source": ["if torch.cuda.is_available():  \n  dev = \"cuda:0\" \nelse:  \n  dev = \"cpu\"\n\ndevice = torch.device(dev)"]}, {"cell_type": "code", "execution_count": 1, "id": "1763d863", "metadata": {}, "outputs": [], "source": ["LDA = LatentDirichletAllocation(n_components=7, random_state=42) # n_components = Topics"]}, {"cell_type": "code", "execution_count": 1, "id": "bf8cfd4b", "metadata": {}, "outputs": [], "source": ["LDA"]}, {"cell_type": "code", "execution_count": 1, "id": "5afba907", "metadata": {}, "outputs": [], "source": ["LDA.fit(dtm).to(device)"]}, {"cell_type": "code", "execution_count": 1, "id": "db7a5469", "metadata": {}, "outputs": [], "source": ["print(f'{\"DONE FINALLY!!!!!!\"}')"]}, {"cell_type": "code", "execution_count": 1, "id": "1c88d923", "metadata": {}, "outputs": [], "source": ["# Grab vocabulary of words\nlen(cvr.get_feature_names())"]}, {"cell_type": "code", "execution_count": 1, "id": "603d758b", "metadata": {}, "outputs": [], "source": ["type(cvr.get_feature_names())"]}, {"cell_type": "code", "execution_count": 1, "id": "644cbbfc", "metadata": {}, "outputs": [], "source": ["cvr.get_feature_names()[1029]"]}, {"cell_type": "code", "execution_count": 1, "id": "3f64c3e1", "metadata": {}, "outputs": [], "source": ["## We can import any random words from the list(54777)\nimport random\n\nrandom_word_id = random.randint(0, 54777)\ncvr.get_feature_names()[random_word_id]"]}, {"cell_type": "code", "execution_count": 1, "id": "843a0c0c", "metadata": {}, "outputs": [], "source": ["# Grab the topics\nlen(LDA.components_)## checking the length of components/topics"]}, {"cell_type": "code", "execution_count": 1, "id": "434b4e25", "metadata": {}, "outputs": [], "source": ["type(LDA.components_) ## Just a numpy array containing probabilities of each word"]}, {"cell_type": "code", "execution_count": 1, "id": "2f0d79b0", "metadata": {}, "outputs": [], "source": ["# Grab single topic out of those 7 components\nsingle_topic = LDA.components_[0] # grabbing very first topic"]}, {"cell_type": "code", "execution_count": 1, "id": "7a59a438", "metadata": {}, "outputs": [], "source": ["single_topic.argsort() # returns index position to sort the array from lowest value to highest value"]}, {"cell_type": "code", "execution_count": 1, "id": "85075a90", "metadata": {}, "outputs": [], "source": ["## example how argsort() works\nimport numpy as np\n\narr = np.array([5, 100, 23, 1])\nprint(f'Simple array:- {arr}')\nprint(f'Argsort:- {arr.argsort()}') ## will return index value of the numbers in an ascending order"]}, {"cell_type": "code", "execution_count": 1, "id": "82f06b5c", "metadata": {}, "outputs": [], "source": ["# Let's grab top 10 values (top 10 greatest values) from single_topic using argsort()\n\nsingle_topic.argsort()[-10:] ## since argsort() works in ascending order, hence, [-10:] is bringing last 10 greatest values"]}, {"cell_type": "code", "execution_count": 1, "id": "36bb979c", "metadata": {}, "outputs": [], "source": ["top_10_words = single_topic.argsort()[-10:]"]}, {"cell_type": "code", "execution_count": 1, "id": "e8e4de08", "metadata": {}, "outputs": [], "source": ["for index in top_10_words:\n    print(cvr.get_feature_names()[index])"]}, {"cell_type": "code", "execution_count": 1, "id": "399ca212", "metadata": {}, "outputs": [], "source": ["# The above was for first topic. Let's do it for 3rd topic and grab top 20 words\nthird_topic = LDA.components_[2]\nthird_topic.argsort()\ntop_20_words_in_3rd = third_topic.argsort()[-20:]\n\nfor i in top_20_words_in_3rd:\n    print(cvr.get_feature_names()[i])"]}, {"cell_type": "code", "execution_count": 1, "id": "17f2ac99", "metadata": {}, "outputs": [], "source": ["# Grab the highest probability words per topic\nfor i, topic in enumerate(LDA.components_):\n    print(f'TOP 15 WORDS FOR TOPIC #{i}')\n    print([cvr.get_feature_names()[index] for index in topic.argsort()[-15:]])\n    print('\\n\\n')"]}, {"cell_type": "code", "execution_count": 1, "id": "da43f38f", "metadata": {}, "outputs": [], "source": ["topic_results = LDA.transform(dtm)"]}, {"cell_type": "code", "execution_count": 1, "id": "b8bf4054", "metadata": {}, "outputs": [], "source": ["topic_results"]}, {"cell_type": "code", "execution_count": 1, "id": "08f900b6", "metadata": {}, "outputs": [], "source": ["topic_results.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "fa2fe7a6", "metadata": {}, "outputs": [], "source": ["# Probabilities belonging to a particular topic\nprint(topic_results[0])\n\nprint(f'-------------------------------------------------------------')\n# Percentages in a rounded off form\nprint(topic_results[0].round(2))"]}, {"cell_type": "code", "execution_count": 1, "id": "51a0b7d4", "metadata": {}, "outputs": [], "source": ["# Getting index position of the highest probability\ntopic_results[0].argmax()"]}, {"cell_type": "code", "execution_count": 1, "id": "8b10ec41", "metadata": {}, "outputs": [], "source": ["df['Topics'] = topic_results.argmax(axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "b83ed5c7", "metadata": {}, "outputs": [], "source": ["df ## which all rows of article data are under general topics"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}