{"cells": [{"cell_type": "markdown", "id": "06ec51fd", "metadata": {}, "source": ["#### Thank You very much for passing and check this out \n- This is my very first Convolutional Neural Network\n- In here you will find some amazing charts such as ***Circular Bar Chart**\n- Some technique that I learn - such as *** apply Batch Normalizarion before Passing into Fuction/transformation ***\n\n### Interesting fact\n- I am surprised that the model didnt improve after applied Image Augmentation *** Maybe I was not doing properly***  please let your comment / or any feedback below \n- This is a Very common architecture but it was very porwerfull, Eventually i will use transfer learning with Google models to compare or learn how to improve this model \n"]}, {"cell_type": "markdown", "id": "625d6220", "metadata": {}, "source": ["# Libraries and Fuctions"]}, {"cell_type": "code", "execution_count": 1, "id": "784028a5", "metadata": {}, "outputs": [], "source": ["import numpy as np \nimport pandas as pd \nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nimport tensorflow as tf \nfrom keras.utils import to_categorical\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "a047a854", "metadata": {}, "outputs": [], "source": ["##### Plotting\ndef Plotting_NeuralNet (data):\n    fig, ax = plt.subplots(1,2 , figsize = (20,7))\n    # summarize history for accuracy\n    ax[0].plot(data.history['accuracy'])\n    ax[0].plot(data.history['val_accuracy'])\n    ax[0].set_title('model accuracy')\n    ax[0].legend(['train', 'test'], loc='upper left')\n\n    # summarize history for loss\n    ax[1].plot(data.history['loss'], label =['loss'])\n    ax[1].plot(data.history['val_loss'] ,label =['val_loss'])\n    ax[1].set_title('model loss')\n    ax[1].legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n#### Visualization\ndef get_label_rotation(angle, offset):\n    # Rotation must be specified in degrees :(\n    rotation = np.rad2deg(angle + offset)\n    if angle <= np.pi:\n        alignment = \"right\"\n        rotation = rotation + 180\n    else: \n        alignment = \"left\"\n    return rotation, alignment\n\ndef add_labels(angles, values, labels, offset, ax):\n    \n    # This is the space between the end of the bar and the label\n    padding = 4\n    \n    # Iterate over angles, values, and labels, to add all of them.\n    for angle, value, label, in zip(angles, values, labels):\n        angle = angle\n        \n        # Obtain text rotation and alignment\n        rotation, alignment = get_label_rotation(angle, offset)\n\n        # And finally add the text\n        ax.text(x=angle, y=value + padding, \n            s=label, ha=alignment, va=\"center\", \n            rotation=rotation, rotation_mode=\"anchor\")"]}, {"cell_type": "markdown", "id": "cfa1fd92", "metadata": {}, "source": ["# Loading Data"]}, {"cell_type": "code", "execution_count": 1, "id": "94a35a46", "metadata": {}, "outputs": [], "source": ["# Getting Data <----------\npath = '../input/tmnist-alphabet-94-characters/94_character_TMNIST.csv'\ndf = pd.read_csv(path)\ndf.sample()"]}, {"cell_type": "markdown", "id": "1f47b56f", "metadata": {}, "source": ["## Visualization\n\n- The following Visualization is known as ***Circular bar chart*** each group A,B,C,D represent the different types of data, ***Numbers, Symbols, Letters, etc***\n- The ***Left circular*** bar chart represents the number of pixels in each image - the represeantion might not be that accuracte because I had to scale and the visualization is for practicing purpose only.\n- The  ***Rigth circular*** bar chart represents the number of imaes or distribution.\n- ***Observation*** The data is well Distributed, each class has equal number of images as you can see in the Circular chart bar "]}, {"cell_type": "code", "execution_count": 1, "id": "393fa220", "metadata": {}, "outputs": [], "source": ["# All labels\nall_ = list(df['labels'].unique())\n\n# Regex Pattern\npattern_uc = re.compile(r\"[A-Z]\")\npattern_lc = re.compile(r\"[a-z]\")\npattern_numbers = re.compile(r\"[0-9]\")\npattern_symbols = re.compile(r\"[\\W]|[\\_\\,]\")\n\n# Extracting Pattern\nlower_case = pattern_lc.findall(str(all_))\nUpper_case = pattern_uc.findall(str(all_))\nNumbers_ = pattern_numbers.findall(str(all_))\nSymbols_ = list(set(pattern_symbols.findall(str(all_))))\nSymbols_.pop(27)\n\n# Creating Gropus\ngroup = 1\nfor list_ in (lower_case,Upper_case,Numbers_,Symbols_):\n    df.loc[df['labels'].isin(list_), 'group'] = str(group)\n    group += 1\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7d1e53ab", "metadata": {}, "outputs": [], "source": ["VALUES = df.groupby(['labels']).sum().reset_index()\nVALUES = (VALUES.iloc[:,1:-1].sum(axis=1))*0.000001\nIMAGES_ = (df.groupby(['labels']).count()['names'].values)*0.025\nLABELS = df.groupby(['labels','group']).count().reset_index().sort_values('group')['labels'].values\nGROUP = df.groupby(['labels','group']).count().reset_index().sort_values('group')['group'].values\nGROUPS_SIZE = [26, 26, 10, 32]"]}, {"cell_type": "code", "execution_count": 1, "id": "11e2f143", "metadata": {}, "outputs": [], "source": ["# Add three empty bars to the end of each group\nPAD = 3\nANGLES_N = len(VALUES) + PAD * len(np.unique(GROUP))\nANGLES = np.linspace(0, 2 * np.pi, num=ANGLES_N, endpoint=False)\nWIDTH = (2 * np.pi) / len(ANGLES)\n\noffset = 0\nOFFSET = np.pi / 2\nIDXS = []\nGROUPS_SIZE = [26, 26, 10, 32]\n\nfor size in GROUPS_SIZE:\n    IDXS += list(range(offset + PAD, offset + size + PAD))\n    offset += size + PAD\n\nfig, ax = plt.subplots(1,2,figsize=(20, 10), subplot_kw={\"projection\": \"polar\"})\nax[0].set_theta_offset(OFFSET)\nax[0].set_ylim(-100, 100)\nax[0].set_frame_on(False)\nax[0].xaxis.grid(False)\nax[0].yaxis.grid(False)\nax[0].set_xticks([])\nax[0].set_yticks([])\n\nCOLORS = [f\"C{i}\" for i, size in enumerate(GROUPS_SIZE) for _ in range(size)]\n\nax[0].bar(\n    ANGLES[IDXS], VALUES, width=WIDTH, color=COLORS, \n    edgecolor=\"white\", linewidth=2\n)\n\nadd_labels(ANGLES[IDXS], VALUES, LABELS, OFFSET, ax[0])\noffset = 0 \nfor group, size in zip([\"Lower\",\"Upper\",\"Numb\",\"Symb\"], GROUPS_SIZE):\n    # Add line below bars\n    x1 = np.linspace(ANGLES[offset + PAD], ANGLES[offset + size + PAD - 1], num=50)\n    ax[0].plot(x1, [-5] * 50, color=\"#333333\")\n    \n    # Add text to indicate group\n    ax[0].text(\n        np.mean(x1), -20, group, color=\"#333333\", fontsize=14, \n        fontweight=\"bold\", ha=\"center\", va=\"center\"\n    )\n    \n    # Add reference lines at 20, 40, 60, and 80\n    x2 = np.linspace(ANGLES[offset], ANGLES[offset + PAD - 1], num=50)\n    ax[0].plot(x2, [20] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [40] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [60] * 50, color=\"#bebebe\", lw=0.8)\n    ax[0].plot(x2, [80] * 50, color=\"#bebebe\", lw=0.8)\n    \n    offset += size + PAD\n    \n# -------------------------------------\nPAD = 3\nANGLES_N = len(IMAGES_) + PAD * len(np.unique(GROUP))\nANGLES = np.linspace(0, 2 * np.pi, num=ANGLES_N, endpoint=False)\nWIDTH = (2 * np.pi) / len(ANGLES)\n\noffset = 0\nOFFSET = np.pi / 2\nIDXS = []\nGROUPS_SIZE = [26, 26, 10, 32]\n\nfor size in GROUPS_SIZE:\n    IDXS += list(range(offset + PAD, offset + size + PAD))\n    offset += size + PAD\n    \nax[1].set_theta_offset(OFFSET)\nax[1].set_ylim(-100, 100)\nax[1].set_frame_on(False)\nax[1].xaxis.grid(False)\nax[1].yaxis.grid(False)\nax[1].set_xticks([])\nax[1].set_yticks([])\n\nCOLORS = [f\"C{i}\" for i, size in enumerate(GROUPS_SIZE) for _ in range(size)]\n\nax[1].bar(\n    ANGLES[IDXS], IMAGES_, width=WIDTH, color=COLORS, \n    edgecolor=\"white\", linewidth=2\n)\n\nadd_labels(ANGLES[IDXS], IMAGES_, LABELS, OFFSET, ax[1])\noffset = 0 \nfor group, size in zip([\"Lower\",\"Upper\",\"Numb\",\"Symb\"], GROUPS_SIZE):\n    # Add line below bars\n    x1 = np.linspace(ANGLES[offset + PAD], ANGLES[offset + size + PAD - 1], num=50)\n    ax[1].plot(x1, [-5] * 50, color=\"#333333\")\n    \n    # Add text to indicate group\n    ax[1].text(\n        np.mean(x1), -20, group, color=\"#333333\", fontsize=14, \n        fontweight=\"bold\", ha=\"center\", va=\"center\"\n    )\n    \n    # Add reference lines at 20, 40, 60, and 80\n    x2 = np.linspace(ANGLES[offset], ANGLES[offset + PAD - 1], num=50)\n    ax[1].plot(x2, [20] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [40] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [60] * 50, color=\"#bebebe\", lw=0.8)\n    ax[1].plot(x2, [80] * 50, color=\"#bebebe\", lw=0.8)\n    \n    offset += size + PAD\n "]}, {"cell_type": "markdown", "id": "7840f05d", "metadata": {}, "source": ["# Spliting Labels & Images "]}, {"cell_type": "code", "execution_count": 1, "id": "8b0158a2", "metadata": {}, "outputs": [], "source": ["X = df.iloc[:, 2:-1].astype('float32') # Splitting and turning into Float\ny  = df[['labels']] #Extracting Labels"]}, {"cell_type": "code", "execution_count": 1, "id": "7c579363", "metadata": {}, "outputs": [], "source": ["labels = y['labels'].unique()\nvalues = [num for num in range(len(df['labels'].unique()))]\nlabel_dict= dict(zip(labels,values)) #Creating Dictionary \nlabel_dict_inv = dict(zip(values,labels))\n\nprint(sorted(label_dict.items(), key=lambda x:x[1])[35:45])  #For visualization Purpose"]}, {"cell_type": "code", "execution_count": 1, "id": "464f284d", "metadata": {}, "outputs": [], "source": ["# Transforming\ny['labels'].replace(label_dict, inplace=True) #Maping Values\ny.tail(5)"]}, {"cell_type": "markdown", "id": "fbc230a1", "metadata": {}, "source": ["# Creating Training and Test Sets"]}, {"cell_type": "markdown", "id": "144ae058", "metadata": {}, "source": ["### Reshaping and Displaying some Images"]}, {"cell_type": "code", "execution_count": 1, "id": "74c53898", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"]}, {"cell_type": "code", "execution_count": 1, "id": "aec78725", "metadata": {}, "outputs": [], "source": ["Length, Height = 28,28  # <---- Defining LxH \nNCl = y_train.nunique()[0] # Unique targets -- > 94 \n\n# ------>  N of images 28x28\nX_train = np.reshape(X_train.values, (X_train.shape[0] ,Length, Height)) \nX_test = np.reshape(X_test.values, (X_test.shape[0] ,Length, Height))\n\n# -------> Target into Categorical Values\ny_train = to_categorical(y_train, NCl, dtype='int' )\ny_test = to_categorical(y_test, NCl, dtype='int' )\n\nprint(f'X:Train, Test data shape:{X_train.shape},{X_test.shape}')\nprint(f'Y:Train, Test data shape:{y_train.shape},{y_test.shape}')"]}, {"cell_type": "code", "execution_count": 1, "id": "24c5a14d", "metadata": {}, "outputs": [], "source": ["random = shuffle(X_train[:500]) #Randomly shuffle (array  in a consistent way)\nfig,ax = plt.subplots(3,4 , figsize = (10,10)) \naxes = ax.flatten()\n\nfor i in range(12):\n    _,shu = cv2.threshold(random[i], 30, 200, cv2.THRESH_BINARY)\n    axes[i].imshow(np.reshape(random[i], (Length, Height)), cmap = 'Greys')\nplt.show()"]}, {"cell_type": "markdown", "id": "83630b3c", "metadata": {}, "source": ["# Building Deep Learning FrameWork\n\n- This is a representation of the Architecture that Iw as using \nStarted with 32 Conv - > Apply some Batch Normalization -> ReLu Transformation X 3 - > Flatten - Dense Layer \n*** My apology*** , the visualization wasnt that good, in my defense I can say I was in my way to my job when I posted this \"Code\"."]}, {"cell_type": "code", "execution_count": 1, "id": "983300eb", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.models import Sequential,load_model\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D,Flatten,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop\nfrom keras.callbacks import EarlyStopping"]}, {"cell_type": "code", "execution_count": 1, "id": "441674ff", "metadata": {}, "outputs": [], "source": ["from IPython.display import display\nfrom PIL import Image\npath=('../input/convo-image/Convo.png')\ndisplay(Image.open(path))"]}, {"cell_type": "markdown", "id": "b2be9621", "metadata": {}, "source": ["### Reshaping for CNN"]}, {"cell_type": "code", "execution_count": 1, "id": "ae39ecbb", "metadata": {}, "outputs": [], "source": ["RGB = 1  # In this case only one instead of 3 because we dont have Color images\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1],X_train.shape[2], RGB)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],RGB)\n\n\nX_train = X_train/255\nX_test = X_test/255\nprint(f'Train, Test shapes: {X_train.shape},{X_test.shape}')"]}, {"cell_type": "markdown", "id": "6a04bdb1", "metadata": {}, "source": ["## First Convolutional Architecture"]}, {"cell_type": "code", "execution_count": 1, "id": "69cd4f33", "metadata": {}, "outputs": [], "source": ["model = Sequential ()\n\n# Conv -> Maxpool - Dropout [1st - 4rd] ~ Flatten - >  Dense - Dense - output \nmodel.add(Conv2D(filters = 32 , kernel_size = (3,3),input_shape = (Length, Height, RGB), padding = 'same',))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32 , kernel_size = (3,3) ,padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64 , kernel_size = (3,3) ,padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(350))\nmodel.add(BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(NCl, activation = 'softmax'))\n# model.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "2b1dff63", "metadata": {}, "outputs": [], "source": ["optimizer  = Adam(learning_rate=0.01)\ncallback =EarlyStopping(monitor='loss', patience=5)\nBatch_ = 64\nEpochs_ = 50\n\n#Training -------------- >\nmodel.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\nhistory= model.fit(X_train,y_train, validation_data = (X_test,y_test),batch_size = Batch_ ,\n                   epochs = Epochs_, verbose = 0)\n\nscore = model.evaluate(X_test,y_test, batch_size = Batch_)\nprint(f\"Loss:{round(score[0],4)}\")\nprint(f\"Test Accuracy:{round(score[1],4)}\")\nPlotting_NeuralNet(history)"]}, {"cell_type": "markdown", "id": "5d7fdbf9", "metadata": {}, "source": ["## Making Prediction"]}, {"cell_type": "code", "execution_count": 1, "id": "c7fca3b5", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28)) # reshaping it for displaying\n    ax.imshow(img, cmap=\"Greys\")\n    img_final =np.reshape(img, (1,28,28,1)) # reshapng it for passing into model for prediction\n    pred = label_dict_inv[np.argmax(model.predict(img_final))]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()"]}, {"cell_type": "markdown", "id": "f3f404b9", "metadata": {}, "source": ["## Second Convolutional Architecture + Data Augmentation"]}, {"cell_type": "code", "execution_count": 1, "id": "63dfd9ec", "metadata": {}, "outputs": [], "source": ["from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1)"]}, {"cell_type": "code", "execution_count": 1, "id": "bfd6e2a8", "metadata": {}, "outputs": [], "source": ["Batch_ = 62\nhistory= model.fit_generator(datagen.flow(X_train,y_train,batch_size = Batch_), \n                             validation_data = (X_test,y_test), epochs = Epochs_,callbacks=[callback], verbose = 0)\nscore = model.evaluate(X_test,y_test, batch_size = Batch_)\nprint(f\"Test Score:{round(score[0],4)}\")\nprint(f\"Test Accuracy:{round(score[1],4)}\")\nPlotting_NeuralNet(history)"]}, {"cell_type": "markdown", "id": "0eddde12", "metadata": {}, "source": ["### Making Predictions"]}, {"cell_type": "code", "execution_count": 1, "id": "e318b7c9", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28)) # reshaping it for displaying\n    ax.imshow(img, cmap=\"Greys\")\n    img_final =np.reshape(img, (1,28,28,1)) # reshapng it for passing into model for prediction\n    pred = label_dict_inv[np.argmax(model.predict(img_final))]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()"]}, {"cell_type": "markdown", "id": "5187e138", "metadata": {}, "source": ["# Transfer Learning and More......"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}