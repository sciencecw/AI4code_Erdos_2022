{"cells": [{"cell_type": "code", "execution_count": 1, "id": "75e96fc8", "metadata": {}, "outputs": [], "source": ["# Data Processing and Cleaning\nimport numpy as np\nimport pandas as pd\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import axes3d\nimport seaborn as sns\n\n# Sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import export_graphviz\n\n# Modeling\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\n\n#Miscellaneous\nfrom tqdm import tqdm_notebook\n\n# Input data files are available in the \"../input/\" directory.\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "55cf9675", "metadata": {}, "source": ["## Reading Data"]}, {"cell_type": "code", "execution_count": 1, "id": "a378fe40", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "de87a76a", "metadata": {}, "outputs": [], "source": ["train.head(3).T"]}, {"cell_type": "markdown", "id": "82dfcb02", "metadata": {}, "source": ["From a first peek at the data, we can spot missing values and features that are JSON objects. Let's dig a bit more into the dataset and its features"]}, {"cell_type": "code", "execution_count": 1, "id": "a59f3049", "metadata": {}, "outputs": [], "source": ["train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "8fe7dce6", "metadata": {}, "outputs": [], "source": ["test.shape"]}, {"cell_type": "markdown", "id": "507f731b", "metadata": {}, "source": ["The train data has less observations than the test data! Challenge accepted"]}, {"cell_type": "markdown", "id": "fd30d69f", "metadata": {}, "source": ["Editing erronous Data in train and test set (based on Discussion forums)"]}, {"cell_type": "code", "execution_count": 1, "id": "00ecbb37", "metadata": {}, "outputs": [], "source": ["train.loc[train['id'] == 16,'revenue'] = 192864         \ntrain.loc[train['id'] == 90,'budget'] = 30000000                  \ntrain.loc[train['id'] == 118,'budget'] = 60000000       \ntrain.loc[train['id'] == 149,'budget'] = 18000000       \ntrain.loc[train['id'] == 313,'revenue'] = 12000000       \ntrain.loc[train['id'] == 451,'revenue'] = 12000000      \ntrain.loc[train['id'] == 464,'budget'] = 20000000       \ntrain.loc[train['id'] == 470,'budget'] = 13000000       \ntrain.loc[train['id'] == 513,'budget'] = 930000         \ntrain.loc[train['id'] == 797,'budget'] = 8000000        \ntrain.loc[train['id'] == 819,'budget'] = 90000000       \ntrain.loc[train['id'] == 850,'budget'] = 90000000       \ntrain.loc[train['id'] == 1007,'budget'] = 2              \ntrain.loc[train['id'] == 1112,'budget'] = 7500000       \ntrain.loc[train['id'] == 1131,'budget'] = 4300000        \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       \ntrain.loc[train['id'] == 1542,'budget'] = 1             \ntrain.loc[train['id'] == 1570,'budget'] = 15800000       \ntrain.loc[train['id'] == 1571,'budget'] = 4000000        \ntrain.loc[train['id'] == 1714,'budget'] = 46000000       \ntrain.loc[train['id'] == 1721,'budget'] = 17500000       \ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      \ntrain.loc[train['id'] == 1885,'budget'] = 12             \ntrain.loc[train['id'] == 2091,'budget'] = 10             \ntrain.loc[train['id'] == 2268,'budget'] = 17500000       \ntrain.loc[train['id'] == 2491,'budget'] = 6              \ntrain.loc[train['id'] == 2602,'budget'] = 31000000       \ntrain.loc[train['id'] == 2612,'budget'] = 15000000       \ntrain.loc[train['id'] == 2696,'budget'] = 10000000      \ntrain.loc[train['id'] == 2801,'budget'] = 10000000       \ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9              \ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000"]}, {"cell_type": "code", "execution_count": 1, "id": "4054faac", "metadata": {}, "outputs": [], "source": ["test.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30"]}, {"cell_type": "markdown", "id": "6c78825d", "metadata": {}, "source": ["## EDA"]}, {"cell_type": "markdown", "id": "d0af27b5", "metadata": {}, "source": ["### Null and Missing Values"]}, {"cell_type": "code", "execution_count": 1, "id": "3beeb424", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(train.isnull().sum()).T"]}, {"cell_type": "markdown", "id": "b24ec41d", "metadata": {}, "source": ["*Belongs to collection* and *homepage* have a lot of null values. Let's put a **percentage** to these missing values for both the train and test set"]}, {"cell_type": "code", "execution_count": 1, "id": "cb02d9d5", "metadata": {}, "outputs": [], "source": ["((pd.DataFrame(train.isnull().sum()).T)/len(train))*100"]}, {"cell_type": "code", "execution_count": 1, "id": "a76c2688", "metadata": {}, "outputs": [], "source": ["((pd.DataFrame(test.isnull().sum()).T)/len(test))*100"]}, {"cell_type": "markdown", "id": "4e51dc7a", "metadata": {}, "source": ["1. The distribution of null values across both the train and test set is roughly the same. This is good news!\n2. *Budget* feature has 0 null values. But this doesn't mean that all values of this feature are meaningful. It could simply be due to the common practive of replacing null values with a dummy value like -1, 0, or 999\n\nLet's look at the frequency of unique values held by the *Budget* feature to see if anything out of the ordinary pops up"]}, {"cell_type": "code", "execution_count": 1, "id": "95104542", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(train.budget.value_counts()).T"]}, {"cell_type": "markdown", "id": "542b96a9", "metadata": {}, "source": ["So the *Budget* feature has 812 values as 0. The likely cause is that information wasn't collected or available for those observations. It is unlikely that some of the movies had an extremely low budget, close to zero. \n\nWe are immediately faced with a decision. How to deal with these missing values? Dropping more than 25% of the training set is not the best idea, and the *test* set is likely to have the same problem. Therefore, we should should look to fill values for these observations from external sources or the median value for budget. Let's deal with this later."]}, {"cell_type": "markdown", "id": "bb472d8a", "metadata": {}, "source": ["### Target Variable Problems"]}, {"cell_type": "markdown", "id": "c8a6a179", "metadata": {}, "source": ["Another issue we will have to take care of is the units of the budget and target variable, revenue. Let's deal with this in the data cleaning section later."]}, {"cell_type": "code", "execution_count": 1, "id": "5286192e", "metadata": {}, "outputs": [], "source": ["train[train['revenue'] < 10][['imdb_id', 'title']].T"]}, {"cell_type": "markdown", "id": "7222edc4", "metadata": {}, "source": ["### Visualizations"]}, {"cell_type": "markdown", "id": "7edeab44", "metadata": {}, "source": ["Let's plot different variables in the dataset to potentially gain interesting insights about distributions and target variables."]}, {"cell_type": "code", "execution_count": 1, "id": "ea1972a8", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(18,15))\nplt.subplots_adjust(hspace=0.5)\n\n# Plot 1: Target Variable Distribution\nplt.subplot2grid((4,2), (0,0))\n\nsns.distplot(np.log1p(train['revenue']), kde=False, bins=40)\n\nplt.title('Distribution for Target Variable', fontsize = 15)\nplt.xlabel('Revenue - log(1+x)', fontsize=12)\n\n# Plot 2: Revenue and Budget\nplt.subplot2grid((4,2), (0,1))\n\nsns.scatterplot(x = 'budget', y = 'revenue', data=train)\n\nplt.title('Revenue vs. Budget', fontsize = 15)\nplt.xlabel('Budget', fontsize=12)\nplt.ylabel('Revenue', fontsize=12)\n\n# Plot 3: Revenue, Runtime, and Popularity\nax = plt.subplot2grid((4,2), (1,0), projection='3d', rowspan = 2, colspan = 2)\n\nx3d = np.array(train['runtime'])\ny3d = np.array(train['popularity'])\nz3d = np.array(train['revenue'])\n\n# Unique category labels\ncolor_labels = train['original_language'].unique()\n\n# List of RGB triplets\nrgb_values = sns.color_palette(\"Set2\", len(color_labels))\n\n# Map label to RGB\ncolor_map = dict(zip(color_labels, rgb_values))\ncolors = train['original_language'].map(color_map)\ncolors = np.random.rand(len(train))\n\nax.scatter(\n    x3d, y3d, z3d,\n    c = colors,\n    alpha = 0.8,\n    )\n\nax.set_xlabel('Runtime')\nax.set_ylabel('Popularity')\nax.set_zlabel('Revenue')\nax.set_title('3D plot for Runtime, Popularity and Revenue', fontsize = 15)\n\n# Plot 4: Correlation matrix\nplt.subplot2grid((4,2), (3,0))\n\ncorr = train.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, mask = mask, cmap = 'PiYG', annot = True, fmt=\".2f\")\n\nplt.yticks(rotation=0) \nplt.xticks(rotation=0)\nplt.title('Correlation Matrix for Train Data', fontsize = 15)\n\n# Plot 5: Distribution of Films by Language\nplt.subplot2grid((4,2), (3,1), colspan = 2)\n\ntop5_languages = train['original_language'].value_counts()[:5]\ntop5_languages.plot(kind = 'bar')\n\nplt.yticks(rotation=0) \nplt.xticks(rotation=0)\nplt.title('Distribution of Films by Language', fontsize = 15)\n\n# Display Plot\nplt.show()"]}, {"cell_type": "markdown", "id": "d4840497", "metadata": {}, "source": ["1. **Target Variable Distribution:** It's never a bad idea to start by plotting the distribution of the target variable. Using np.log1p allows us to plot the several values between 0 and 1 million USD and get a much more uniform distribution.\n2. **Revenue vs. Budget:** A scatterplot to explore the relationship between these two numerical features. We have plenty of zero values for budget\n3. **3D Plot:** A 3D plot to explore the relationship between *Runtime, Popularity, and Revenue.*\n4. **Correlation Matrix:** So revenue and budget are highly correlated. Let's try to predict the target variable with just with this one variable and get a baseline score and leaderboard rank!\n5. **Distribution by Language** The data is dominated by English language films. French, Russian, Spanish, and Hindi films follow."]}, {"cell_type": "markdown", "id": "815f1b96", "metadata": {}, "source": ["## Simple Models"]}, {"cell_type": "markdown", "id": "baabc095", "metadata": {}, "source": ["Before using external data or performing extensive cleaning and parsing of features, let us fit the simplest linear regression and Random Forest model to get a baseline score. Before we do that though, we need to take the log of the target variable, as the competition metric is RMSLE (Root Mean Squared Log Error)"]}, {"cell_type": "code", "execution_count": 1, "id": "5139214b", "metadata": {}, "outputs": [], "source": ["train['revenue'] = np.log1p(train['revenue'])"]}, {"cell_type": "markdown", "id": "c34fe5f2", "metadata": {}, "source": ["### Linear Regression"]}, {"cell_type": "markdown", "id": "d354cd30", "metadata": {}, "source": ["Let's perform a simple linear regression Model using just the budget feature."]}, {"cell_type": "code", "execution_count": 1, "id": "32c4cce4", "metadata": {}, "outputs": [], "source": ["x = train.budget.values.reshape(-1,1)\ny = train.revenue\nreg = LinearRegression().fit(x, y)"]}, {"cell_type": "code", "execution_count": 1, "id": "c42be617", "metadata": {}, "outputs": [], "source": ["print(f'Regression Score: {reg.score(x, y)}')\nprint(f'Regression Coefficient: {reg.coef_[0]}')\nprint(f'Regression Intercept: {reg.intercept_}')"]}, {"cell_type": "code", "execution_count": 1, "id": "963c93f7", "metadata": {}, "outputs": [], "source": ["predictions = reg.predict(test['budget'].values.reshape(-1,1))"]}, {"cell_type": "markdown", "id": "ef63035b", "metadata": {}, "source": ["#### Preparing Submission for Linear Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "a97a3287", "metadata": {}, "outputs": [], "source": ["submission['revenue'] = np.round(np.expm1(predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "4fd98b10", "metadata": {}, "outputs": [], "source": ["submission.to_csv('submission_budget_linreg.csv', index = False)"]}, {"cell_type": "markdown", "id": "3005e43f", "metadata": {}, "source": ["This gives us a Kaggle score of *2.71*, and would place you around the top 75th percenticle of this competition. It is a significant improvement over the default predictions, which led to a Kaggle score of *3.79*. We have barely used any brainpower so this is not bad at all."]}, {"cell_type": "markdown", "id": "40dd3929", "metadata": {}, "source": ["### Random Forest"]}, {"cell_type": "code", "execution_count": 1, "id": "46fad0ab", "metadata": {}, "outputs": [], "source": ["rf_cols = ['budget', 'original_language', 'popularity', 'release_date', 'runtime', 'status', 'homepage', 'overview', 'revenue']\nrf_train = train[rf_cols].copy()\nrf_cols.remove('revenue')\nrf_test = test[rf_cols].copy()"]}, {"cell_type": "markdown", "id": "e871ced2", "metadata": {}, "source": ["#### Budget Feature\nFill zero values for the budget feature in train and test data with median of the feature in the train set. We shall use only the train set to calculate median budget. This will avoid data leakage. We will also create another binary feature, *'budget_is_median'* which will hold the value 1 for indices that have been filled with median budget"]}, {"cell_type": "code", "execution_count": 1, "id": "7215a843", "metadata": {}, "outputs": [], "source": ["median_budget = rf_train[rf_train['budget'] > 0]['budget'].median()\nmedian_budget"]}, {"cell_type": "code", "execution_count": 1, "id": "ccd4b3d5", "metadata": {}, "outputs": [], "source": ["def fill_budget(df, median_budget):\n    df['budget_is_median'] = 0\n    df.loc[df.budget == 0, 'budget_is_median'] = 1\n    df.loc[df.budget == 0, 'budget'] = median_budget\n    return df"]}, {"cell_type": "code", "execution_count": 1, "id": "f015e493", "metadata": {}, "outputs": [], "source": ["rf_train = fill_budget(rf_train, median_budget)\nrf_test = fill_budget(rf_test, median_budget)"]}, {"cell_type": "markdown", "id": "dd90c65c", "metadata": {}, "source": ["#### Original Language Feature\nWe will label encode this categorical feature using sklearn. For now, let's do this in the simplest manner and not worry about any smart encoding. We will have to concatenate the train and test set in order before fitting the label encodings"]}, {"cell_type": "code", "execution_count": 1, "id": "409e7b3a", "metadata": {}, "outputs": [], "source": ["rf_combined = pd.concat([rf_train, rf_test], sort=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "54d3274c", "metadata": {}, "outputs": [], "source": ["le = LabelEncoder()\nle.fit(rf_combined['original_language'])\nrf_train['original_language'] = le.transform(rf_train['original_language'])\nrf_test['original_language'] = le.transform(rf_test['original_language'])"]}, {"cell_type": "markdown", "id": "15485d7e", "metadata": {}, "source": ["#### Status Feature\nWe will deal with the *Status* categorical feature in the same manner. From our EDA section, we know that there are 2 missing values in the test set. Let's replace these values with the most common occurence of the variable, *'Released'*"]}, {"cell_type": "code", "execution_count": 1, "id": "3214e387", "metadata": {}, "outputs": [], "source": ["rf_test.loc[rf_test['status'].isnull() == True, 'status'] = 'Released'\nrf_combined.loc[rf_combined['status'].isnull() == True, 'status'] = 'Released'"]}, {"cell_type": "code", "execution_count": 1, "id": "4927caa4", "metadata": {}, "outputs": [], "source": ["le = LabelEncoder()\nle.fit(rf_combined['status'])\nrf_train['status'] = le.transform(rf_train['status'])\nrf_test['status'] = le.transform(rf_test['status'])"]}, {"cell_type": "markdown", "id": "6e92f2fd", "metadata": {}, "source": ["#### Homepage Feature"]}, {"cell_type": "markdown", "id": "98df62b2", "metadata": {}, "source": ["This feature will store 0 for movies that don't have a homepage, and 1 for movies that do."]}, {"cell_type": "code", "execution_count": 1, "id": "528c7ecf", "metadata": {}, "outputs": [], "source": ["rf_train.loc[rf_train['homepage'].isnull() == True, 'homepage'] = 0\nrf_train.loc[rf_train['homepage'].isnull() == False, 'homepage'] = 1\n\nrf_test.loc[rf_test['homepage'].isnull() == True, 'homepage'] = 0\nrf_test.loc[rf_test['homepage'].isnull() == False, 'homepage'] = 1"]}, {"cell_type": "markdown", "id": "b1678813", "metadata": {}, "source": ["#### Runtime Feature\nWe have some null values for *Runtime* feature. There are also some values that have the value 0. Let's fill them with the median value for runtime from the train set."]}, {"cell_type": "code", "execution_count": 1, "id": "b8012b3e", "metadata": {}, "outputs": [], "source": ["median_runtime = rf_train['runtime'].median()\nmedian_runtime"]}, {"cell_type": "code", "execution_count": 1, "id": "d12bd31a", "metadata": {}, "outputs": [], "source": ["def fill_runtime(df, median_runtime):\n    df['runtime_is_median'] = 0\n    df.loc[df.runtime == 0, 'runtime_is_median'] = 1\n    df.loc[df.runtime.isnull() == True, 'runtime_is_median'] = 1\n    df.loc[df.runtime == 0, 'runtime'] = median_runtime\n    df.loc[df.runtime.isnull() == True, 'runtime'] = median_runtime\n    return df"]}, {"cell_type": "code", "execution_count": 1, "id": "43fd5752", "metadata": {}, "outputs": [], "source": ["rf_train = fill_runtime(rf_train, median_runtime)\nrf_test = fill_runtime(rf_test, median_runtime)"]}, {"cell_type": "markdown", "id": "5364c67a", "metadata": {}, "source": ["#### Release Data Feature"]}, {"cell_type": "markdown", "id": "496a27cd", "metadata": {}, "source": ["Parse release date and extract features such as day, month, year!"]}, {"cell_type": "code", "execution_count": 1, "id": "30b578d4", "metadata": {}, "outputs": [], "source": ["from datetime import timedelta, date"]}, {"cell_type": "markdown", "id": "fa8d0967", "metadata": {}, "source": ["Filling missing data with external ground truth"]}, {"cell_type": "code", "execution_count": 1, "id": "020b63e9", "metadata": {}, "outputs": [], "source": ["rf_test.loc[rf_test['release_date'].isnull() == True, 'release_date'] = '10/19/2001'\ntest.loc[test['release_date'].isnull() == True, 'release_date'] = '10/19/2001'"]}, {"cell_type": "code", "execution_count": 1, "id": "298edf8c", "metadata": {}, "outputs": [], "source": ["def add_date_features(df, col, prefix):\n    df[col] = pd.to_datetime(df[col])\n    future = df[col] > pd.Timestamp(year=2017,month=12,day=31)\n    df.loc[future, col] -= timedelta(days=365.25*100)\n    \n    df[prefix+'_day_of_week'] = df[col].dt.dayofweek\n    df[prefix+'_day_of_year'] = df[col].dt.dayofyear\n    df[prefix+'_month'] = df[col].dt.month\n    df[prefix+'_year'] = df[col].dt.year\n    df[prefix+'_day'] = df[col].dt.day\n    df[prefix+'_is_year_end'] = df[col].dt.is_year_end\n    df[prefix+'_is_year_start'] = df[col].dt.is_year_start\n    df[prefix+'_week'] = df[col].dt.week\n    df[prefix+'_quarter'] = df[col].dt.quarter    \n    \n    df.drop(col, axis = 1, inplace = True)\n\n    return df"]}, {"cell_type": "code", "execution_count": 1, "id": "81771456", "metadata": {}, "outputs": [], "source": ["rf_train = add_date_features(rf_train, 'release_date', 'release')\nrf_test = add_date_features(rf_test, 'release_date', 'release')"]}, {"cell_type": "markdown", "id": "b2b10d4e", "metadata": {}, "source": ["## Parsing JSON Features"]}, {"cell_type": "markdown", "id": "1671260e", "metadata": {}, "source": ["So far, we haven't parsed any JSON features. Let's go through the *production companies*, *production countries*, *cast*, *crew*, *keywords*, and *belongs to collection* feature and try and extract information that might help our model"]}, {"cell_type": "code", "execution_count": 1, "id": "75d345ff", "metadata": {}, "outputs": [], "source": ["def get_dictionary(s):\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d"]}, {"cell_type": "markdown", "id": "4eeaa509", "metadata": {}, "source": ["A note on the *eval* function being used.  The *eval()* method parses the expression passed to this method and runs python expression (code) within the program. In simple terms, the *eval()* method runs the python code (which is passed as an argument) within the program."]}, {"cell_type": "code", "execution_count": 1, "id": "20dffd19", "metadata": {}, "outputs": [], "source": ["json_cols = ['production_companies', 'production_countries', 'cast', 'crew', 'Keywords', 'belongs_to_collection']\nfor col in json_cols:\n    rf_train[col] = train[col]\n    rf_train[col] = rf_train[col].apply(lambda x: get_dictionary(x))\n    rf_test[col] = test[col]\n    rf_test[col] = rf_test[col].apply(lambda x: get_dictionary(x))"]}, {"cell_type": "markdown", "id": "0c4bdcc5", "metadata": {}, "source": ["## Feature Engineering"]}, {"cell_type": "markdown", "id": "d1e9f044", "metadata": {}, "source": ["1. For features such as cast, crew, production companies, keywords, and production countries, get the length/size of the feature. \n2. If the movie belongs to a collection, extract the name of the collection, and label encode it.\n3. For movie overview, count the number of words in overview\n4. Feature interactions"]}, {"cell_type": "code", "execution_count": 1, "id": "3420bea1", "metadata": {}, "outputs": [], "source": ["for col in json_cols:\n    # Get name of collection movie belongs to\n    if col == 'belongs_to_collection':\n        rf_train['collection_name'] = rf_train[col].apply(lambda row: row[0]['name'] if row != {} else '0')\n        rf_test['collection_name'] = rf_test[col].apply(lambda row: row[0]['name'] if row != {} else '0')\n        rf_combined = pd.concat([rf_train, rf_test], sort=False)\n        le = LabelEncoder()\n        le.fit(rf_combined['collection_name'])\n        rf_train['collection_name'] = le.transform(rf_train['collection_name'])\n        rf_test['collection_name'] = le.transform(rf_test['collection_name'])    \n    \n    # Size of feature\n    rf_train[col] = rf_train[col].apply(lambda row: 0 if row is None else len(row))\n    rf_test[col] = rf_test[col].apply(lambda row: 0 if row is None else len(row))\n\n# Word count for overview\nrf_train['overview_wordcount'] = rf_train['overview'].str.split().str.len()\nrf_train.drop('overview', axis = 1, inplace = True)\nrf_train.loc[rf_train['overview_wordcount'].isnull() == True, 'overview_wordcount'] = 0\n\nrf_test['overview_wordcount'] = rf_test['overview'].str.split().str.len()\nrf_test.drop('overview', axis = 1, inplace = True)\nrf_test.loc[rf_test['overview_wordcount'].isnull() == True, 'overview_wordcount'] = 0\n\n# Feature Interactions\nrf_train['_budget_runtime_ratio'] = np.round(rf_train['budget']/rf_train['runtime'], 2)\nrf_train['_budget_year_ratio'] = np.round(rf_train['budget']/(rf_train['release_year']*rf_train['release_year']), 2)\nrf_train['_releaseYear_popularity_ratio'] = np.round(rf_train['release_year']/rf_train['popularity'], 2)\n\nrf_test['_budget_runtime_ratio'] = np.round(rf_test['budget']/rf_test['runtime'], 2)\nrf_test['_budget_year_ratio'] = np.round(rf_test['budget']/(rf_test['release_year']*rf_test['release_year']), 2)\nrf_test['_releaseYear_popularity_ratio'] = np.round(rf_test['release_year']/rf_test['popularity'], 2)\n"]}, {"cell_type": "markdown", "id": "c554e548", "metadata": {}, "source": ["So this is what the training data looks like after performing all the required cleaning"]}, {"cell_type": "code", "execution_count": 1, "id": "51d60fa5", "metadata": {}, "outputs": [], "source": ["rf_train.head()"]}, {"cell_type": "markdown", "id": "0c89304a", "metadata": {}, "source": ["## Training"]}, {"cell_type": "markdown", "id": "8135a588", "metadata": {}, "source": ["#### Peform Train and Validation Split"]}, {"cell_type": "code", "execution_count": 1, "id": "4a885ff7", "metadata": {}, "outputs": [], "source": ["X_train, X_valid, y_train, y_valid = train_test_split(\n    rf_train.drop('revenue', axis = 1), rf_train['revenue'], \n    test_size=0.1, \n    random_state=42\n)"]}, {"cell_type": "markdown", "id": "aded6fc9", "metadata": {}, "source": ["#### Functions to evaluate our Random Forest"]}, {"cell_type": "code", "execution_count": 1, "id": "d1906b55", "metadata": {}, "outputs": [], "source": ["def rmse(y_pred, y_true):\n    return np.sqrt(mean_squared_error(y_pred, y_true))\n\ndef print_rf_score(model):\n    print(f'Train R2:   {model.score(X_train, y_train)}')\n    print(f'Valid R2:   {model.score(X_valid, y_valid)}')\n    print(f'Train RMSE: {rmse(model.predict(X_train), y_train)}')\n    print(f'Valid RMSE: {rmse(model.predict(X_valid), y_valid)}')"]}, {"cell_type": "markdown", "id": "09215db9", "metadata": {}, "source": ["#### Random Forest with default hyperparameters"]}, {"cell_type": "code", "execution_count": 1, "id": "2fd26a79", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(n_jobs = -1, random_state = 42)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)"]}, {"cell_type": "markdown", "id": "2ee45289", "metadata": {}, "source": ["Our validation R squared is very low compared to the training R squared, suggesting we are overfitting. Although the validation RMSE will place us in the top 40% of the competition, much better than our naive linear regression model."]}, {"cell_type": "markdown", "id": "28da80ca", "metadata": {}, "source": ["#### Drawing a Single Decision Tree"]}, {"cell_type": "markdown", "id": "a67855e9", "metadata": {}, "source": ["Here, we will draw a single decision tree that is builds our Random Forest ensemble. We will make a small tree which is easy to visualize. To achieve this, we set *max_depth* to 3. We will also turn *bootstrap* to False in order to sample all of the data and build a deterministic tree."]}, {"cell_type": "code", "execution_count": 1, "id": "d453fbb7", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(\n    n_estimators = 1, \n    max_depth = 3, \n    bootstrap = False, \n    n_jobs = -1, \n    random_state = 42\n)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)"]}, {"cell_type": "code", "execution_count": 1, "id": "646c6438", "metadata": {}, "outputs": [], "source": ["# Export as dot file\nexport_graphviz(\n    rf.estimators_[0], \n    out_file='tree.dot', \n    feature_names = X_train.columns,\n    rounded = True, \n    proportion = False, \n    precision = 2, \n    filled = True,\n    rotate = True\n)\n\n# Convert to png using system command (requires Graphviz)\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree.png', height = 600, width = 800)"]}, {"cell_type": "markdown", "id": "9fe370c3", "metadata": {}, "source": ["#### Creating a deeper Single Tree"]}, {"cell_type": "markdown", "id": "5cef2542", "metadata": {}, "source": ["Previously, we set our *max_depth* to 3 to make the tree easy to visualize. Now, let's remove this hyperparameter and observe the difference in evaluation."]}, {"cell_type": "code", "execution_count": 1, "id": "aaabbe39", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(\n    n_estimators = 1, \n    bootstrap = False, \n    n_jobs = -1, \n    random_state = 42\n)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)"]}, {"cell_type": "markdown", "id": "c74a2509", "metadata": {}, "source": ["As expected, we have a training R squared of 1. This is because each observation in the training data is a leaf node and can be accounted for easily. Our R squared and validation score on test data, however, has decreased tremendously."]}, {"cell_type": "markdown", "id": "83b8fe64", "metadata": {}, "source": ["#### Bagging Trees"]}, {"cell_type": "markdown", "id": "1c80ea7a", "metadata": {}, "source": ["As we saw, our deep single tree massively overfit. Bagging, an important concept in ensembling, suggests that if we create a large number of such trees built on random samples of data and average their errors, we will get a good model. To illustrate this process better, let's return to our default random forest with no hyperparameter tuning."]}, {"cell_type": "code", "execution_count": 1, "id": "63f92255", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(n_estimators = 10, n_jobs = -1, random_state = 42)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)"]}, {"cell_type": "markdown", "id": "91fa9228", "metadata": {}, "source": ["The value of *n_estimators* is 10, which is the default. Let's grab predictions for each of these 10 trees and look at how they perform on the first validation sample."]}, {"cell_type": "code", "execution_count": 1, "id": "9dd15429", "metadata": {}, "outputs": [], "source": ["tree_preds = np.stack([tree.predict(X_valid) for tree in rf.estimators_])\nprint(f' Individual Tree Predictions: {[np.around(tree_preds[:,0], 1)]}')\nprint(f' Mean of Tree Predictions:    {np.mean(tree_preds[:,0])}')\nprint(f' Ground truth for sample:     {y_valid[0]}')"]}, {"cell_type": "markdown", "id": "146fd3a5", "metadata": {}, "source": ["As is visible, the predictions for individual trees are all over the place but their average is fairly reasonable."]}, {"cell_type": "markdown", "id": "8ab1b72a", "metadata": {}, "source": ["#### Visualizing the imapct of additional Trees"]}, {"cell_type": "code", "execution_count": 1, "id": "7793cee5", "metadata": {}, "outputs": [], "source": ["%%time\ntrain_scores_r2 = []\nvalid_scores_r2 = []\ntrain_scores_rmse = []\nvalid_scores_rmse = []\nfor trees in tqdm_notebook(range(1, 100)):\n    rf = RandomForestRegressor(n_estimators = trees, n_jobs = -1, random_state = 42)\n    rf.fit(X_train, y_train)\n    train_scores_r2.append(rf.score(X_train, y_train))\n    valid_scores_r2.append(rf.score(X_valid, y_valid))    \n    train_scores_rmse.append(rmse(rf.predict(X_train), y_train))\n    valid_scores_rmse.append(rmse(rf.predict(X_valid), y_valid))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "09ca284b", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(10,8))\nplt.subplots_adjust(hspace=0.5)\n\n# Plot 1: Train R2\nplt.subplot2grid((2,2), (0,0))\n\nplt.plot(train_scores_r2)\nplt.title('Training Data R Squared', fontsize = 15)\nplt.xlabel('Estimators', fontsize=12)\n\n# Plot 2: Valid R2\nplt.subplot2grid((2,2), (0,1))\n\nplt.plot(valid_scores_r2, color='r')\nplt.title('Validation Set R Squared', fontsize = 15)\nplt.xlabel('Estimators', fontsize=12)\n\n# Plot 1: Train RMSE\nplt.subplot2grid((2,2), (1,0))\n\nplt.plot(train_scores_rmse)\nplt.title('Training Data RMSE', fontsize = 15)\nplt.xlabel('Estimators', fontsize=12)\n\n# Plot 2: Valid RMSE\nplt.subplot2grid((2,2), (1,1))\n\nplt.plot(valid_scores_rmse, color='r')\nplt.title('Validation Set RMSE', fontsize = 15)\nplt.xlabel('Estimators', fontsize=12)\n\nplt.show()"]}, {"cell_type": "markdown", "id": "9eb5f251", "metadata": {}, "source": ["#### Out of Bag Evaluation"]}, {"cell_type": "markdown", "id": "16283567", "metadata": {}, "source": ["To know if our validation score is worse because our model is overfitting or because the validation set is from a different distribution, or both, we can leverage a hyperparameter called *oob_score*, or Out of Bag score. The idea behind it is to calculate error on the training set while only including those trees in the calculation of a row's error where that row was not included in the training the tree. \n\nIf you have a lot of trees, all of the rows in the dataset should appear a few times in the out of bag samples. This approach is beneficial as we can see if our model generalizes, even if we have a small amount of data. We can avoid creating a separate validation set and lose valuable training data."]}, {"cell_type": "code", "execution_count": 1, "id": "6e606bc8", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(\n    n_estimators = 20, \n    n_jobs = -1, \n    oob_score = True, \n    random_state = 42\n)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)\nprint(f'OOB Score:  {rf.oob_score_}')"]}, {"cell_type": "markdown", "id": "e5693889", "metadata": {}, "source": ["The Out of Bag R2 score is in the same range as the validation R2 score, which is good news."]}, {"cell_type": "markdown", "id": "dae524b5", "metadata": {}, "source": ["#### Min_Samples_Leaf"]}, {"cell_type": "markdown", "id": "03fc6dd6", "metadata": {}, "source": ["To prevent overfitting, we will tune min_samples_leaf. This will reduce the depth of our trees by a couple of levels"]}, {"cell_type": "code", "execution_count": 1, "id": "6481dfb6", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(\n    n_estimators = 20, \n    min_samples_leaf = 4, \n    n_jobs = -1, \n    oob_score = True, \n    random_state = 42\n)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)\nprint(f'OOB Score:  {rf.oob_score_}')"]}, {"cell_type": "markdown", "id": "f59bb624", "metadata": {}, "source": ["#### Max_Features"]}, {"cell_type": "code", "execution_count": 1, "id": "b5da4b25", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(\n    n_estimators = 20, \n    min_samples_leaf = 4, \n    max_features = 0.3, \n    n_jobs = -1, \n    oob_score = True, \n    random_state = 42\n)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)\nprint(f'OOB Score:  {rf.oob_score_}')"]}, {"cell_type": "markdown", "id": "62ebd7ec", "metadata": {}, "source": ["#### Random Forest with Hyperparameter Tuning"]}, {"cell_type": "code", "execution_count": 1, "id": "c6bcecd3", "metadata": {}, "outputs": [], "source": ["rf = RandomForestRegressor(\n    n_estimators = 20, \n    min_samples_leaf = 4, \n    max_features = 0.3, \n    n_jobs = -1,\n    oob_score = True, \n    random_state = 42,\n)\nrf.fit(X_train, y_train)\nprint_rf_score(rf)\nprint(f'OOB Score:  {rf.oob_score_}')"]}, {"cell_type": "markdown", "id": "6ec9f69b", "metadata": {}, "source": ["#### Predictions for Random Forest model"]}, {"cell_type": "code", "execution_count": 1, "id": "453e6740", "metadata": {}, "outputs": [], "source": ["predictions = np.expm1(rf.predict(rf_test))\nsubmission['revenue'] = np.round(predictions)\nsubmission.to_csv('submission_simple_rf.csv', index = False)"]}, {"cell_type": "markdown", "id": "5bab38d4", "metadata": {}, "source": ["## Ensembling"]}, {"cell_type": "markdown", "id": "23caa649", "metadata": {}, "source": ["### XGBoost"]}, {"cell_type": "code", "execution_count": 1, "id": "c2854dfe", "metadata": {}, "outputs": [], "source": ["def xgtrain(X_train, X_valid, y_train, y_valid):\n    regressor = XGBRegressor(\n        n_estimators = 50000, \n        learning_rate = 0.001,\n        max_depth = 6, \n        subsample = 0.3, \n        colsample_bytree = 0.2\n        )\n    \n    regressor_ = regressor.fit(\n        X_train.values, y_train.values, \n        eval_metric = 'rmse', \n        eval_set = [\n            (X_train.values, y_train.values), \n            (X_valid.values, y_valid.values)\n        ],\n        verbose = 1000,\n        early_stopping_rounds = 500,\n        )\n    \n    return regressor_"]}, {"cell_type": "code", "execution_count": 1, "id": "4a98d8ce", "metadata": {}, "outputs": [], "source": ["%%time\nregressor_ = xgtrain(X_train, X_valid, y_train, y_valid)"]}, {"cell_type": "markdown", "id": "b6477ba5", "metadata": {}, "source": ["### Light GBM"]}, {"cell_type": "code", "execution_count": 1, "id": "8ae5269f", "metadata": {}, "outputs": [], "source": ["def lgbtrain(X_train, y_train, X_valid, y_valid):\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n\n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'l2_root'},\n        'max_depth': 4,\n        'learning_rate': 0.001,\n        'feature_fraction': 0.3,\n        'bagging_fraction': 1,\n        'bagging_freq': 1,\n    }\n    \n    gbm = lgb.train(\n        params,\n        lgb_train,\n        valid_sets = lgb_eval,\n        num_boost_round=50000,\n        early_stopping_rounds=500,\n        verbose_eval = 1000\n    )\n    \n    return gbm"]}, {"cell_type": "code", "execution_count": 1, "id": "45219949", "metadata": {}, "outputs": [], "source": ["%%time\ngbm = lgbtrain(X_train, y_train, X_valid, y_valid)"]}, {"cell_type": "markdown", "id": "87c8dad4", "metadata": {}, "source": ["## Feature Importances"]}, {"cell_type": "code", "execution_count": 1, "id": "602de343", "metadata": {}, "outputs": [], "source": ["feature_importances = pd.DataFrame(rf.feature_importances_, index = X_train.columns, columns=['importance'])\nfeature_importances = feature_importances.sort_values('importance', ascending=True)\nfeature_importances.plot(kind = 'barh', figsize = (10,8))\nplt.show()"]}, {"cell_type": "markdown", "id": "8a13fedf", "metadata": {}, "source": ["### Preparing Submission"]}, {"cell_type": "code", "execution_count": 1, "id": "a11e46a7", "metadata": {}, "outputs": [], "source": ["predictions = np.expm1(rf.predict(rf_test)) + np.expm1(regressor_.predict(rf_test.values)) + np.expm1(gbm.predict(rf_test.values))\npredictions /= 3"]}, {"cell_type": "code", "execution_count": 1, "id": "ae6fe1b4", "metadata": {}, "outputs": [], "source": ["submission['revenue'] = np.round(predictions)"]}, {"cell_type": "code", "execution_count": 1, "id": "23477e09", "metadata": {}, "outputs": [], "source": ["submission.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "975dbf19", "metadata": {}, "outputs": [], "source": ["submission.to_csv('submission_ensemble.csv', index = False)"]}, {"cell_type": "markdown", "id": "7bf73fcb", "metadata": {}, "source": ["Get Output files without committing"]}, {"cell_type": "code", "execution_count": 1, "id": "90d5f02c", "metadata": {}, "outputs": [], "source": ["from IPython.display import FileLinks\nFileLinks('.')"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}