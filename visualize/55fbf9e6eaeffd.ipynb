{"cells": [{"cell_type": "code", "execution_count": 1, "id": "0ffb569a", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "e4f6f853", "metadata": {}, "outputs": [], "source": ["from gensim.models import Word2Vec\nfrom nltk.tokenize import sent_tokenize, word_tokenize"]}, {"cell_type": "code", "execution_count": 1, "id": "cc0224de", "metadata": {}, "outputs": [], "source": ["f = open(r'/kaggle/input/textdata/sinhala.txt', 'r')\ntext = f.read()\nsent = sent_tokenize(text)\nsent = [word_tokenize(s) for s in sent]\n\nprint(sent[:10])"]}, {"cell_type": "markdown", "id": "a3d3635a", "metadata": {}, "source": ["## Skipgram model"]}, {"cell_type": "code", "execution_count": 1, "id": "e9811908", "metadata": {}, "outputs": [], "source": ["skipgramModel = Word2Vec(min_count=1, \n                         sg=1, \n                         size=300,\n                         window=5,\n                        seed=3)\n\nskipgramModel.build_vocab(sentences = sent, \n                           progress_per=1000)\n\nskipgramModel.train(sentences = sent,\n                     total_examples=skipgramModel.corpus_count, \n                     epochs=10, \n                     report_delay=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "6edb03a7", "metadata": {}, "outputs": [], "source": ["print(\"Vocabulary size:\" + str(len(skipgramModel.wv.vocab)))\nprint(\"Corpus size:\" + str(skipgramModel.corpus_count))"]}, {"cell_type": "code", "execution_count": 1, "id": "4f6386eb", "metadata": {}, "outputs": [], "source": ["print(skipgramModel.wv['\u0db8\u0dc4\u0dad\u0dcf'])"]}, {"cell_type": "code", "execution_count": 1, "id": "275e09ad", "metadata": {}, "outputs": [], "source": ["print(\"Dimention of a word vector\" + str(len(skipgramModel.wv['\u0db8\u0dc4\u0dad\u0dcf'])))"]}, {"cell_type": "markdown", "id": "51a60fed", "metadata": {}, "source": ["### try to increase min_count=2 to ignore some words"]}, {"cell_type": "code", "execution_count": 1, "id": "df43d2a2", "metadata": {}, "outputs": [], "source": ["skipgramModel2 = Word2Vec(min_count=2, \n                         sg=1, \n                         size=300,\n                         window=5,\n                         seed=3)\n\nskipgramModel2.build_vocab(sentences = sent, \n                           progress_per=1000)\n\nskipgramModel2.train(sentences = sent,\n                     total_examples=skipgramModel2.corpus_count, \n                     epochs=10, \n                     report_delay=1)\n\nprint(\"Vocabulary size:\" + str(len(skipgramModel2.wv.vocab)))"]}, {"cell_type": "markdown", "id": "ca6d26ef", "metadata": {}, "source": ["### since vocabulary size of the model has significantly dropped, continue to use min_count=1"]}, {"cell_type": "markdown", "id": "3670ccfc", "metadata": {}, "source": ["## CBOW model"]}, {"cell_type": "code", "execution_count": 1, "id": "0b1f1935", "metadata": {}, "outputs": [], "source": ["cbowModel = Word2Vec(min_count=1, \n                    sg=0, \n                    size=300,\n                    window=5,\n                    seed=3)\n\ncbowModel.build_vocab(sentences = sent, \n                      progress_per=1000)\n\ncbowModel.train(sentences = sent,\n                total_examples=cbowModel.corpus_count, \n                epochs=10, \n                report_delay=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "8290f495", "metadata": {}, "outputs": [], "source": ["common_words = ['\u0da2\u0dcf\u0dad\u0dd2\u0d9a', '\u0da2\u0db1\u0dad\u0dcf', '\u0d91\u0db8', '\u0d85\u0d82\u0d9a', '\u0db8\u0dc4\u0dad\u0dcf', '\u0d9a\u0ddc\u0db4\u0db8\u0dab\u0daf', '\u0dba\u0da7\u0dad\u0dda', '\u0dc3\u0db3\u0dc4\u0dcf', '\u0d8a\u0da7', '\u0dbd\u0daf\u0dd3']"]}, {"cell_type": "markdown", "id": "0af1f444", "metadata": {}, "source": ["## similar words predicted by skipgram model"]}, {"cell_type": "code", "execution_count": 1, "id": "d46b2940", "metadata": {}, "outputs": [], "source": ["skipgramOutFile = open(r'SkipgramOut.txt','w')\n\nfor w in common_words:\n    print(\"\\r\\n\" + w + \"------------>\\r\\n\")\n    skipgramOutFile.write('\\r\\n' + w + '------------>\\r\\n')\n    lst = skipgramModel.wv.similar_by_word(word=w)\n    [print(i) for i in lst]\n    skipgramOutFile.write('\\r\\n'.join('{} {}'.format(x[0],x[1]) for x in lst))"]}, {"cell_type": "markdown", "id": "b8086fac", "metadata": {}, "source": ["## Similar words predicted by CBOW model"]}, {"cell_type": "code", "execution_count": 1, "id": "add5a128", "metadata": {}, "outputs": [], "source": ["cbowOutFile = open(r'CBOWOut.txt','w')\n\nfor w in common_words:   \n    print(\"\\r\\n\" + w + \"------------>\\r\\n\")\n    cbowOutFile.write('\\r\\n' + w + '------------>\\r\\n')\n    lst = cbowModel.wv.similar_by_word(word=w)\n    [print(i) for i in lst]\n    cbowOutFile.write('\\r\\n'.join('{} {}'.format(x[0],x[1]) for x in lst))"]}, {"cell_type": "markdown", "id": "cb1777c7", "metadata": {}, "source": ["### Use pretrained fasttext word vectors from Facebook to generate similar words to the same set of above common words\n[https://fasttext.cc/docs/en/crawl-vectors.html](http://)"]}, {"cell_type": "code", "execution_count": 1, "id": "2876f125", "metadata": {}, "outputs": [], "source": ["import fasttext.util\nfasttext.util.download_model('si', if_exists='ignore')"]}, {"cell_type": "code", "execution_count": 1, "id": "117035c3", "metadata": {}, "outputs": [], "source": ["ft = fasttext.load_model('cc.si.300.bin')\nfor w in common_words:   \n    print(\"\\r\\n\" + w + \"------------>\\r\\n\")\n    lst = ft.get_nearest_neighbors(word=w)\n    [print(i) for i in lst]"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}