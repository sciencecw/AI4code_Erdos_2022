{"cells": [{"cell_type": "code", "execution_count": 1, "id": "3284d54f", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "5990e31c", "metadata": {}, "source": ["# Libraries "]}, {"cell_type": "code", "execution_count": 1, "id": "1b6ac789", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\", context=\"talk\")\n\nimport re\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import roc_curve, accuracy_score, roc_auc_score, confusion_matrix, classification_report, cohen_kappa_score, recall_score, precision_score\nfrom sklearn import ensemble\nfrom sklearn.inspection import permutation_importance\n\n\nimport warnings\nwarnings.filterwarnings('ignore')"]}, {"cell_type": "markdown", "id": "30c70e3b", "metadata": {}, "source": ["# Data input"]}, {"cell_type": "code", "execution_count": 1, "id": "702bb174", "metadata": {}, "outputs": [], "source": ["testing = pd.read_csv('/kaggle/input/titanic/test.csv')\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = testing.copy()\n\ntarget = 'Survived'\n\ndata = pd.concat([train, test], axis = 0)\ndata.info()\ndata.head(5)"]}, {"cell_type": "code", "execution_count": 1, "id": "684722d6", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(10, 4))\nplt.pie(data['Survived'].value_counts()\n        ,labels = data['Survived'].value_counts().index\n        ,autopct='%1.1f%%'\n        ,shadow=True\n        ,explode = (0.05, 0.0)\n       )\nplt.title('Survived')\nplt.show()"]}, {"cell_type": "markdown", "id": "7f970375", "metadata": {}, "source": ["# Data cleansing"]}, {"cell_type": "code", "execution_count": 1, "id": "396bcdee", "metadata": {}, "outputs": [], "source": ["data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "d132eeb3", "metadata": {}, "outputs": [], "source": ["data[data['Fare'].isna()]"]}, {"cell_type": "code", "execution_count": 1, "id": "112d37ea", "metadata": {}, "outputs": [], "source": ["data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Fare']"]}, {"cell_type": "code", "execution_count": 1, "id": "eb8b98a1", "metadata": {}, "outputs": [], "source": ["data['Fare'] = data['Fare'].fillna(data.groupby(['Pclass'])['Fare'].transform('median'))"]}, {"cell_type": "code", "execution_count": 1, "id": "61562cd3", "metadata": {}, "outputs": [], "source": ["data.isna().sum()"]}, {"cell_type": "markdown", "id": "8219c813", "metadata": {}, "source": ["# Feature engineering"]}, {"cell_type": "code", "execution_count": 1, "id": "7dcfce2b", "metadata": {}, "outputs": [], "source": ["data['Family_size'] =  data[\"Parch\"] + data[\"SibSp\"] + 1\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'Family_size',y = 'Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "7393023e", "metadata": {}, "outputs": [], "source": ["# data.loc[ data['Family_size'] == 1, 'Family_size_group'] = 0\ndata.loc[(data['Family_size'] > 1) & (data['Family_size'] <= 4), 'small_family_size'] = 1\ndata.loc[(data['Family_size'] > 4) | (data['Family_size'] == 1), 'small_family_size'] = 0\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'small_family_size',y = 'Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "a9d6ac72", "metadata": {}, "outputs": [], "source": ["data.loc[data['Family_size'] == 1, 'Alone'] = 1\ndata.loc[data['Family_size'] > 1, 'Alone'] = 0\n\nplt.subplots(figsize=(10, 4))\nsns.barplot(data = data,x = 'Alone',y = 'Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "c3130e7a", "metadata": {}, "outputs": [], "source": ["data['Title'] = data.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\ndata['Title'].unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "ff3575f6", "metadata": {}, "outputs": [], "source": ["data['Title'] = data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\ndata['Title'] = data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr', 'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Title', y='Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "ebf66b1f", "metadata": {}, "outputs": [], "source": ["data['Title'].value_counts(normalize = True).round(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "f43e9ec5", "metadata": {}, "outputs": [], "source": ["data['Age'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "f7e74d27", "metadata": {}, "outputs": [], "source": ["data[data['Age'] < 1]"]}, {"cell_type": "code", "execution_count": 1, "id": "3834ba09", "metadata": {}, "outputs": [], "source": ["data.loc[data['Age'] < 1, 'Age'] = None\ndata['Age'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "b6b6aad7", "metadata": {}, "outputs": [], "source": ["data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Age']"]}, {"cell_type": "code", "execution_count": 1, "id": "d9a0f47b", "metadata": {}, "outputs": [], "source": ["# np.random.seed(42)\n# data['Age'][data['Age'].isna()] = np.random.randint(high = data['Age'].mean() + data['Age'].std()\n#                                                     ,low = data['Age'].mean() - data['Age'].std()\n#                                                     ,size = data['Age'].isna().sum())\n\ndata['Age'] = data['Age'].fillna(data.groupby(['Pclass', 'Title'])['Age'].transform('median'))\n\ndata['Age'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "ecafb5a6", "metadata": {}, "outputs": [], "source": ["data.groupby('Title')['Age'].median()"]}, {"cell_type": "code", "execution_count": 1, "id": "e179a57e", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize = (10, 5))\nsns.distplot(data['Age'][data['Survived'] == 1].dropna(), kde = True, label = 'Survived = 1', color = 'orange', bins = 15)\nsns.distplot(data['Age'][data['Survived'] == 0].dropna(), kde = True, label = 'Survived = 0', bins = 15)\nplt.legend(prop = {'size': 12})\nplt.title('Surival by age groups')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "520902a2", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "bc72a73c", "metadata": {}, "outputs": [], "source": ["data_corr = data.corr().abs().unstack().sort_values(kind = \"quicksort\", ascending = False).reset_index()\ndata_corr.loc[data_corr['level_0'] == 'Age']"]}, {"cell_type": "code", "execution_count": 1, "id": "d9a14f53", "metadata": {}, "outputs": [], "source": ["def age_grouping(age):\n    if (age < 4):\n        return 'Infants'\n    elif (age >= 4) & (age < 6):\n        return 'Preschool'\n    elif (age >= 6) & (age < 13):\n        return 'Children'\n    elif (age >= 13) & (age < 19):\n        return 'Adolescents'\n    elif (age >= 19) & (age < 45):\n        return 'Adults'\n    elif (age >= 45) & (age < 60):\n        return 'Middle age'\n    else:\n        return 'Seniors'  \n    \ndata['age_group'] = np.vectorize(age_grouping)(data['Age'])\n    \nplt.subplots(figsize=(18, 5))\nsns.barplot(data = data, x = 'age_group', y = 'Survived')\nplt.show()"]}, {"cell_type": "markdown", "id": "418ed57f", "metadata": {}, "source": ["# EDA"]}, {"cell_type": "code", "execution_count": 1, "id": "25506cc7", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Parch', y='Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "ac85dc53", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='SibSp', y='Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "d4f60488", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Pclass', y='Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "4f432a06", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Embarked', y='Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "2223bc4c", "metadata": {}, "outputs": [], "source": ["data[['Pclass', 'Embarked', 'Survived']].groupby(['Pclass', 'Embarked']).mean().round(2)"]}, {"cell_type": "code", "execution_count": 1, "id": "95665d5a", "metadata": {}, "outputs": [], "source": ["data['Cabin'].unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "c090181e", "metadata": {}, "outputs": [], "source": ["data['Cabin_group'] = data['Cabin'].str[:1]\ndata.loc[data['Cabin'].isna(), 'Cabin_group'] = 'unkown'\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Cabin_group', y='Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "cd001020", "metadata": {}, "outputs": [], "source": ["print('Pclass: ', data[data['Cabin_group'] == 'T']['Pclass'].values)\ndata.loc[data['Cabin'] == 'T', 'Cabin_group'] = 'A'"]}, {"cell_type": "code", "execution_count": 1, "id": "7d9906a9", "metadata": {}, "outputs": [], "source": ["data[['Cabin_group', 'Pclass', 'Survived']].groupby(['Cabin_group', 'Pclass']).mean().round(2)"]}, {"cell_type": "code", "execution_count": 1, "id": "cdcd7a99", "metadata": {}, "outputs": [], "source": ["data.loc[data['Cabin_group'].isin(['A', 'B', 'C']), 'Cabin_group'] = 'ABC'\ndata.loc[data['Cabin_group'].isin(['D', 'E']), 'Cabin_group'] = 'DE'\ndata.loc[data['Cabin_group'].isin(['F', 'G']), 'Cabin_group'] = 'FG'\n\nplt.subplots(figsize=(13, 5))\nsns.barplot(data=data, x='Cabin_group', y='Survived')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "72832aab", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize = (10, 7))\nsns.distplot(data['Fare'][data['Survived'] == 1].dropna(), kde = True, label = 'Survived = 1', color = 'orange', bins = 8)\nsns.distplot(data['Fare'][data['Survived'] == 0].dropna(), kde = True, label = 'Survived = 0', bins = 8)\nplt.legend(prop = {'size': 12})\nplt.title('Surival by age groups')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "7643f478", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "66895432", "metadata": {}, "outputs": [], "source": ["data['Cabin_group'].unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "6bb072d7", "metadata": {}, "outputs": [], "source": ["data['Sex_int'] = data['Sex'].replace({'male': 1, 'female': 0})\ndata['Embarked_int'] = data['Embarked'].replace({'S': 0, 'C': 1, 'Q':2})\ndata['Title_int'] = data['Title'].replace({'Mr': 0, 'Mrs': 1, 'Miss':2, 'Master':3, 'Special':4})\ndata['age_group_int'] = data['age_group'].replace({'Adults': 0, 'Middle age': 1, 'Infants':2, 'Adolescents':3, 'Preschool':4, 'Children':5, 'Seniors':6})\ndata['Cabin_group_int'] = data['Cabin_group'].replace({'unkown': 0, 'ABC': 1, 'DE':2, 'FG':3})"]}, {"cell_type": "code", "execution_count": 1, "id": "f599d6b9", "metadata": {}, "outputs": [], "source": ["corrMatrix = data.corr()\n\nplt.subplots(figsize=(22, 10))\nsns.heatmap(corrMatrix, annot=True)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "3f7152a0", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(12, 4))\ncorrMatrix['Survived'].drop(['Survived']).sort_values().plot(kind = 'bar')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "b8e141d9", "metadata": {}, "outputs": [], "source": ["data = data.loc[:,~data.columns.str.endswith('_int')]"]}, {"cell_type": "markdown", "id": "a6f035dd", "metadata": {}, "source": ["# Prep before model"]}, {"cell_type": "code", "execution_count": 1, "id": "2e6ac5b8", "metadata": {}, "outputs": [], "source": ["data.info()\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "474a1c30", "metadata": {}, "outputs": [], "source": ["# Preparing features for analysis\ndummy_features = ['Sex'\n                  , 'Pclass'\n                  , 'Embarked'\n                  , 'Cabin_group'\n                  , 'Title'\n                  , 'age_group'\n                 ]\n\nfor col in dummy_features:\n    data[col] = data[col].astype(object)\n    \ndrop_features = ['PassengerId', 'Ticket', 'Name', 'Cabin'\n                 ,'small_family_size'\n#                  ,'Family_size'\n                 ,'Alone'\n                 ,'SibSp'\n                 ,'Parch'\n#                  ,'Embarked'\n#                  ,'Cabin_group'\n#                  ,'Title'\n                 ,'Age'\n#                  ,'age_group'\n                ]\n    \ndata = pd.concat([data, pd.get_dummies(data[dummy_features], drop_first = True)], axis = 1, sort = False)\ndata.drop(columns = data[dummy_features], inplace = True)\ndata.drop(columns = data[drop_features], inplace = True)\n\ndata.tail()"]}, {"cell_type": "code", "execution_count": 1, "id": "cec06bc4", "metadata": {}, "outputs": [], "source": ["test = data[data['Survived'].isnull()].drop(['Survived'], axis = 1)\ntrain = data[data['Survived'].notnull()]\n\ntrain.info()\nprint('-'*70)\ntest.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "00230343", "metadata": {}, "outputs": [], "source": ["# Drop Nan just to be safe\ntrain.dropna(inplace = True)\ntest.dropna(inplace = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "db061dd9", "metadata": {}, "outputs": [], "source": ["# Separating target column from other features\ny = train['Survived']\nx = train.drop(columns = target)\n\n# Train and Test dataset split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42\n                                                    , stratify = y\n                                                   )"]}, {"cell_type": "markdown", "id": "8b85d1af", "metadata": {}, "source": ["# Modelling"]}, {"cell_type": "code", "execution_count": 1, "id": "e4dce1e6", "metadata": {}, "outputs": [], "source": ["# random forest model hyper-tuned\nRF = ensemble.RandomForestClassifier()\nparams = {\n          'n_estimators':[n for n in range(100, 250, 50)] # default 100 \n          ,'max_depth':[n for n in range(3, 8)] # default None \n#           ,'criterion': ['gini', 'entropy'] # default 'gini'\n          ,'min_samples_leaf': [n for n in range(3, 6, 1)] # default 1\n          ,'max_features' : [None] # default 'sqrt'\n          ,'random_state' : [42]\n          }\n\nRF_model = GridSearchCV(RF, param_grid = params, cv = 5, n_jobs = -1).fit(x_train, y_train)\nprint(\"Best Hyper Parameters:\",RF_model.best_params_)\n\n# Area under the curve probability score\nRF_probs = RF_model.predict_proba(x_test)\nRF_probs = RF_probs[:, 1]\nRF_auc = roc_auc_score(y_test, RF_probs)\nprint('AUC: %.3f' % RF_auc)\n\nRF_predictions = RF_model.predict(x_test).astype(int)\nRF_accuracy = accuracy_score(y_test, RF_predictions)\nprint(\"RF accuracy: %.3f\" % RF_accuracy)\nprint(\"RF Recall: \" + '%.3f' % recall_score(y_test, RF_predictions)) # The recall is intuitively the ability of the classifier to find all the positive samples.\nprint(\"RF Precission: \" + '%.3f' % precision_score(y_test, RF_predictions)) # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\nprint(\"RF cohen_kappa_score: %.3f\" % cohen_kappa_score(y_test, RF_predictions)) # Scores above .8 are generally considered good agreement\n\n# AUC plot\nplt.figure(figsize = (8, 6))\nRF_fpr, RF_tpr, RF_thresholds = roc_curve(y_test, RF_probs)\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.plot(RF_fpr, RF_tpr, color = 'tab:green')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "e3e26c65", "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, RF_predictions)\nplot_confusion_matrix(cm)\nplt.title('RF')\nplt.show()"]}, {"cell_type": "markdown", "id": "669247fb", "metadata": {}, "source": ["# Feature Importance"]}, {"cell_type": "code", "execution_count": 1, "id": "be842606", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize = [6, 6])\npd.Series(RF_model.best_estimator_.feature_importances_, index = x.columns).nlargest(10).plot(kind = 'barh')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "e0d34e24", "metadata": {}, "outputs": [], "source": ["perm_importance = permutation_importance(RF_model, x_test, y_test)\nsorted_idx = perm_importance.importances_mean.argsort()\n\nplt.figure(figsize = [8, 8])\nplt.barh(x.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\nplt.xlabel(\"Permutation Importance\")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "aa325dcc", "metadata": {}, "outputs": [], "source": ["# from sklearn.feature_selection import SelectFromModel\n# selector = SelectFromModel(RF_model.best_estimator_, threshold = 0.05, prefit = True)\n# feature_idx = selector.get_support()\n# feature_name = x.columns[feature_idx]\n# feature_name"]}, {"cell_type": "markdown", "id": "b71259d4", "metadata": {}, "source": [" # Model investigation"]}, {"cell_type": "code", "execution_count": 1, "id": "32fa93c6", "metadata": {}, "outputs": [], "source": ["data['churn_proba'] = RF_model.best_estimator_.predict_proba(data[x.columns])[:,1]"]}, {"cell_type": "code", "execution_count": 1, "id": "2b21f2ae", "metadata": {}, "outputs": [], "source": ["import shap\nshap.initjs()\n\nexplainer = shap.TreeExplainer(RF_model.best_estimator_)\nshap_values = explainer.shap_values(data[x.columns])\n\nshap.summary_plot(shap_values[1], data[x.columns], plot_type = \"bar\")"]}, {"cell_type": "code", "execution_count": 1, "id": "783f101f", "metadata": {}, "outputs": [], "source": ["shap.summary_plot(shap_values[1], data[x.columns])"]}, {"cell_type": "code", "execution_count": 1, "id": "ddcde0f7", "metadata": {}, "outputs": [], "source": ["shap.dependence_plot(\"Fare\", shap_values[1], data[x.columns])"]}, {"cell_type": "code", "execution_count": 1, "id": "4e04e2a2", "metadata": {}, "outputs": [], "source": ["row = 1\n\nshap.force_plot(explainer.expected_value[1], shap_values[1][:1000], data[x.columns].iloc[:1000], matplotlib = False)\n\nclass ShapObject:\n    def __init__(self, base_values, data, values, feature_names):\n        self.base_values = base_values # Single value\n        self.data = data # Raw feature values for 1 row of data\n        self.values = values # SHAP values for the same row of data\n        self.feature_names = feature_names # Column names\n        \nshap_object = ShapObject(base_values = explainer.expected_value[1],\n                         values = shap_values[1][row,:],\n                         feature_names = data[x.columns].columns,\n                         data = data[x.columns].iloc[row,:])\n\nshap.waterfall_plot(shap_object)"]}, {"cell_type": "code", "execution_count": 1, "id": "dedfef7d", "metadata": {}, "outputs": [], "source": ["shap.force_plot(explainer.expected_value[1], shap_values[1][:500], data[x.columns].iloc[:500], matplotlib = False)"]}, {"cell_type": "markdown", "id": "e23c3bf0", "metadata": {}, "source": ["# Export data"]}, {"cell_type": "code", "execution_count": 1, "id": "0eaa88d8", "metadata": {}, "outputs": [], "source": ["predict_RF = RF_model.predict(test).astype(int)\nsubmit_RF = pd.DataFrame({'PassengerId': testing['PassengerId'],\n                          'Survived': predict_RF})\n\n#creating submission file\nfilename_RF = 'Titanic Prediction RF.csv'\nsubmit_RF.to_csv(filename_RF,index=False)\nprint('Saved file: ' + filename_RF)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}