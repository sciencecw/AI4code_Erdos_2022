{"cells": [{"cell_type": "markdown", "id": "09300e63", "metadata": {}, "source": ["## Disclosure\nThis kernel is only my humble attempts to learn new library for me. \n<br>I am trying to use fully connected classifier and train it only on data without the CV and sentiment analysis first.\n<br>Any suggestions are more than welcome!!!\n\n### To DO:\n- Weights initialization???\n- Try to build custom loss function, using the weighted kappa criterion.\n- Scale all the numerical features\n\n### Different Versions and Tests:\nV35 - Trying to create regressor rather than predictor."]}, {"cell_type": "code", "execution_count": 1, "id": "3300a805", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nprint(os.listdir(\"../input\"))"]}, {"cell_type": "code", "execution_count": 1, "id": "9c4a1f82", "metadata": {}, "outputs": [], "source": ["train_on_gpu = torch.cuda.is_available()\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]}, {"cell_type": "code", "execution_count": 1, "id": "a09f8b98", "metadata": {}, "outputs": [], "source": ["def GetRawData(TestOrTrain):\n    source = f'../input/{TestOrTrain}/{TestOrTrain}.csv'\n    data =  pd.read_csv(source)\n    return data"]}, {"cell_type": "code", "execution_count": 1, "id": "d03a3614", "metadata": {}, "outputs": [], "source": ["data = GetRawData('train')\nlen(set(data['Color2']))"]}, {"cell_type": "code", "execution_count": 1, "id": "b64c1666", "metadata": {}, "outputs": [], "source": ["# Scalers:\nmaxFee = max(data.Fee.values)\nmaxVideo = max(data.VideoAmt.values)\nmaxPhoto = max(data.PhotoAmt.values)\nScalers = [maxFee, maxVideo, maxPhoto]"]}, {"cell_type": "code", "execution_count": 1, "id": "4a6af04d", "metadata": {}, "outputs": [], "source": ["def PrepareFeatures(TestOrTrain, Scalers):\n    source = f'../input/{TestOrTrain}/{TestOrTrain}.csv'\n    data =  pd.read_csv(source)\n    \n    data['hasFee'] = data.Fee>0\n    data.hasFee[data['hasFee'] == True] = 1\n    data.hasFee[data['hasFee'] == False] = 0\n    data['hasPhoto'] = data.PhotoAmt>0\n    data.hasPhoto[data['hasPhoto'] == True] = 1\n    data.hasPhoto[data['hasPhoto'] == False] = 0\n\n    encoder = OneHotEncoder(categories='auto')\n    type_feat = encoder.fit_transform(data[['Type']]).toarray()\n    type_feat = pd.DataFrame(type_feat, columns=['Dog', 'Cat'])\n    gender_feat = encoder.fit_transform(data[['Gender']]).toarray()\n    gender_feat = pd.DataFrame(gender_feat, columns=['Male', 'Female', 'Mixed'])\n    \n    color1_feat = encoder.fit_transform(data[['Color1']]).toarray()\n    color1_feat = pd.DataFrame(color1_feat, columns=['1', '2', '3', '4', '5', '6', '7'])\n    color2_feat = encoder.fit_transform(data[['Color2']]).toarray()\n    color2_feat = pd.DataFrame(color2_feat, columns=['1', '2', '3', '4', '5', '6', '7'])\n    size_feat = encoder.fit_transform(data[['MaturitySize']]).toarray()\n    size_feat = pd.DataFrame(size_feat, columns=['S', 'M', 'L', 'XL'])\n    fur_feat = encoder.fit_transform(data[['FurLength']]).toarray()\n    fur_feat = pd.DataFrame(fur_feat, columns=['S', 'M', 'L'])\n    \n    vacc_feat = encoder.fit_transform(data[['Vaccinated']]).toarray()\n    vacc_feat = pd.DataFrame(vacc_feat, columns=['Yes', 'No', 'Unknown'])\n    deworm_feat = encoder.fit_transform(data[['Dewormed']]).toarray()\n    deworm_feat = pd.DataFrame(deworm_feat, columns=['Yes', 'No', 'Unknown'])\n    sterile_feat = encoder.fit_transform(data[['Sterilized']]).toarray()\n    sterile_feat = pd.DataFrame(sterile_feat, columns=['Yes', 'No', 'Unknown'])\n    health_feat = encoder.fit_transform(data[['Health']]).toarray()\n    health_feat = pd.DataFrame(health_feat, columns=['Healthy', 'Minor Injury', 'Serious Injury'])\n    \n    #le = LabelEncoder()\n    #data['StateLabel'] = le.fit_transform(data.State)\n    #state_feat = encoder.fit_transform(data[['StateLabel']]).toarray()\n    #state_feat = pd.DataFrame(state_feat)\n    \n    #features = pd.concat([type_feat, gender_feat, color1_feat, color2_feat, \n    #                      size_feat, fur_feat,\n    #                      vacc_feat, deworm_feat, sterile_feat, health_feat,\n    #                      data.Quantity, data.Age, data.Fee, data.VideoAmt, data.PhotoAmt], axis=1)\n    \n    features = pd.concat([type_feat, gender_feat,\n                          size_feat, fur_feat,\n                          vacc_feat, deworm_feat, sterile_feat, health_feat,\n                          data.hasFee, data.hasPhoto], axis=1)\n        \n    features = features.values.astype(np.float32)\n    if TestOrTrain=='train':\n        label = data.AdoptionSpeed.values.astype(np.float32)\n    else:\n        label = np.zeros(features.shape[0])\n    pet_ids = data.PetID\n    return features, label, pet_ids\n\n'''\nfeatures = [\"Type\", \"Age\", \"Breed1\", \"Breed2\", \"Gender\",\n            \"Color1\", \"Color2\", \"Color3\", \"MaturitySize\", \"FurLength\",\n            \"Vaccinated\", \"Dewormed\", \"Sterilized\", \"Health\", \"Quantity\", \"Fee\", \"State\",\n            \"VideoAmt\", \"PhotoAmt\"]\n'''\nfeatures = [\"Type\", \"Age\", \"Gender\",\n            \"MaturitySize\", \"FurLength\",\n            \"Vaccinated\", \"Dewormed\", \"Sterilized\", \"Health\", \"Quantity\", \"Fee\",\n            \"VideoAmt\", \"PhotoAmt\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "623b1d7f", "metadata": {}, "outputs": [], "source": ["x, y, train_pet_ids = PrepareFeatures('train', Scalers)\nraw_data = GetRawData('train')"]}, {"cell_type": "code", "execution_count": 1, "id": "6741c4f4", "metadata": {}, "outputs": [], "source": ["raw_data.head(2)"]}, {"cell_type": "code", "execution_count": 1, "id": "19b48c39", "metadata": {}, "outputs": [], "source": ["label_std = raw_data.AdoptionSpeed.std(axis=0)\nlabel_mean = raw_data.AdoptionSpeed.mean(axis=0)\nprint(\"Labels: mean={} and std={}\".format(label_mean, label_std))"]}, {"cell_type": "code", "execution_count": 1, "id": "1cb51226", "metadata": {}, "outputs": [], "source": ["mean_label_dog_male = np.mean(raw_data.AdoptionSpeed[(raw_data['Type']==1) & (raw_data['Gender']==1)].values)\nmean_label_dog_female = np.mean(raw_data.AdoptionSpeed[(raw_data['Type']==1) & (raw_data['Gender']==2)].values)\n\nmean_label_cat_male = np.mean(raw_data.AdoptionSpeed[(raw_data['Type']==2) & (raw_data['Gender']==1)].values)\nmean_label_cat_female = np.mean(raw_data.AdoptionSpeed[(raw_data['Type']==2) & (raw_data['Gender']==2)].values)\n\nprint(f'Mean adoption speed for dogs: Male={mean_label_dog_male:.2f}, Female={mean_label_dog_female:.2f}')\nprint(f'Mean adoption speed for cats: Male={mean_label_cat_male:.2f}, Female={mean_label_cat_female:.2f}')"]}, {"cell_type": "code", "execution_count": 1, "id": "ba49aeba", "metadata": {}, "outputs": [], "source": ["# Check the Correctness of encoding and Pet IDs associations:\nfor i in range(3):\n    cur_type = raw_data.Type[raw_data['PetID']==train_pet_ids[i]].values[0]\n    cur_gender = raw_data.Gender[raw_data['PetID']==train_pet_ids[i]].values[0]\n    cur_label = raw_data.AdoptionSpeed[raw_data['PetID']==train_pet_ids[i]].values[0]\n    print(f\"Encoded features: {x[i]} for label {y[i]}={cur_label}, pet id = {train_pet_ids[i]}: Type={cur_type}, Gender={cur_gender}\")"]}, {"cell_type": "code", "execution_count": 1, "id": "5c328fd0", "metadata": {}, "outputs": [], "source": ["num_entries = x.shape[0]\nsplit_idx = int(num_entries*0.8)\ntrain_x, val_x = x[:split_idx], x[split_idx:]\ntrain_y, val_y = y[:split_idx], y[split_idx:]\ntest_x, test_y, test_pet_ids = PrepareFeatures('test', Scalers)\n\nprint(\"\\t\\t\\tFeature Shapes:\")\nprint(\"Train set: \\t\\t{}\".format(train_x.shape), \n      \"\\nValidation set: \\t{}\".format(val_x.shape),\n      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "4c89832d", "metadata": {}, "outputs": [], "source": ["# create Tensor datasets\ntrain_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n\n# dataloaders\nbatch_size = 50\n\n# make sure the SHUFFLE your training data\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\ntest_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"]}, {"cell_type": "markdown", "id": "d54ed406", "metadata": {}, "source": ["## Define Regression Model:"]}, {"cell_type": "code", "execution_count": 1, "id": "4edfd899", "metadata": {}, "outputs": [], "source": ["class ComplexRegressor3(nn.Module):\n    def __init__(self, n_input, n_hidden1, n_hidden2, n_hidden3, n_output):\n        super().__init__()\n        self.fc1 = nn.Linear(n_input, n_hidden1)\n        self.fc2 = nn.Linear(n_hidden1, n_hidden2)\n        self.fc3 = nn.Linear(n_hidden2, n_hidden3)\n        self.fc4 = nn.Linear(n_hidden3, n_output)\n        \n    def forward(self, x):\n        # make sure input tensor is flattened\n        x = x.view(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x"]}, {"cell_type": "markdown", "id": "3de114d9", "metadata": {}, "source": ["## Create the Classifier Model:"]}, {"cell_type": "code", "execution_count": 1, "id": "be506667", "metadata": {}, "outputs": [], "source": ["n_inputs = x.shape[1]\nn_outputs = 1\nprint(f\"Model should have {n_inputs} inputs and {n_outputs} outputs\")"]}, {"cell_type": "code", "execution_count": 1, "id": "177ba7fd", "metadata": {}, "outputs": [], "source": ["model = ComplexRegressor3(n_inputs, 128, 128, 128, n_outputs)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)"]}, {"cell_type": "markdown", "id": "bde9fbe7", "metadata": {}, "source": ["## Training the model:"]}, {"cell_type": "code", "execution_count": 1, "id": "a0f7d919", "metadata": {}, "outputs": [], "source": ["n_epochs = 200\nprint_every = 2\n\nmin_val_loss = 1000\n\nfor epoch in range(n_epochs):\n    running_loss = 0.0\n    batch_i = 0\n    \n    # Train for one epoch:\n    for inputs, labels in train_loader:\n        batch_i += 1\n        optimizer.zero_grad()\n        outputs = model.forward(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    # Test the model on validation set:\n    model.eval()\n    with torch.no_grad():\n        test_loss, accuracy  = 0, 0       \n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model.forward(inputs)\n            batch_loss = criterion(outputs, labels)                  \n            test_loss += batch_loss.item()\n            \n            # Calculate accuracy\n    model.train()\n    \n    cur_train_loss = running_loss/len(train_loader)\n    cur_val_loss = test_loss/len(valid_loader)\n    \n    if (epoch%print_every==0) | (epoch ==n_epochs-1):\n        print(f\"Epoch {epoch+1}/{n_epochs}\")   \n        print(f\"Train Loss: {cur_train_loss:.4f}..\"       \n              f\"Val Loss: {cur_val_loss:.4f}.. \"\n              f\"Val accuracy: {accuracy/val_x.shape[0]:.4f}\")\n        \n    if cur_val_loss < min_val_loss:\n        print(f\"Epoch {epoch+1}/{n_epochs}: Validation loss decreased from {min_val_loss:.4f} to {cur_val_loss:.4f}\")\n        state_dict = model.state_dict()\n        min_val_loss = cur_val_loss"]}, {"cell_type": "code", "execution_count": 1, "id": "f9eb9fc5", "metadata": {}, "outputs": [], "source": ["model_dict = model.state_dict()\npretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\nmodel_dict.update(state_dict) \nmodel.load_state_dict(state_dict)\nmodel.to(device);"]}, {"cell_type": "code", "execution_count": 1, "id": "0b1f4a1a", "metadata": {}, "outputs": [], "source": ["predicted_labels = []\nfor inputs, labels in test_loader:\n    inputs, labels = inputs.to(device), labels.to(device)\n    pred = model.forward(inputs)\n    pred = torch.round(pred)\n    xxx = [pred[0] for pred in pred.data.cpu().numpy().astype('int32').tolist()]\n    predicted_labels.extend(xxx)\n    print(f\"Classes predicted in current batch: {set(xxx)}\")"]}, {"cell_type": "code", "execution_count": 1, "id": "1856dfda", "metadata": {}, "outputs": [], "source": ["submission = pd.DataFrame({'PetID': test_pet_ids, 'AdoptionSpeed': predicted_labels})\nsubmission.to_csv('submission.csv', index = False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}