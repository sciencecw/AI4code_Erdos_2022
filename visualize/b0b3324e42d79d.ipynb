{"cells": [{"cell_type": "markdown", "id": "9b45fd81", "metadata": {}, "source": ["#### 1. Setting  \n    1.1 Import Libraries and Load Data  \n    1.2 Arranging content data\n#### 2. Tweets by year  \n#### 3. WordCloud before he took office at White House, and after  \n#### 4. Features by Cluster \n    4.1 WorCloud by Cluster\n    4.2 Typical Tweets - Top 5 tweets with cosine similality to Cluster Center\n    4.3 Other features"]}, {"cell_type": "markdown", "id": "72839329", "metadata": {}, "source": ["1  Setting"]}, {"cell_type": "code", "execution_count": 1, "id": "47c95985", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "066d1afa", "metadata": {}, "source": ["1.1 Import Libraries and Load data"]}, {"cell_type": "code", "execution_count": 1, "id": "e4ecdacc", "metadata": {}, "outputs": [], "source": ["import warnings; warnings.simplefilter('ignore')\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nimport re\nfrom wordcloud import WordCloud\nimport textwrap\nfrom sklearn.cluster import KMeans\nfrom absl import logging\nimport tensorflow_hub as hub\n# Embed with Universal Sentence Encoder\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"]}, {"cell_type": "code", "execution_count": 1, "id": "a881268e", "metadata": {}, "outputs": [], "source": ["data=pd.read_csv('../input/trump-tweets/trumptweets.csv').set_index('id')\ndata.drop(['link','mentions','hashtags','geo'], axis=1, inplace=True)\ndata.head()"]}, {"cell_type": "markdown", "id": "00c948ec", "metadata": {}, "source": ["1.2 Arranging content data"]}, {"cell_type": "code", "execution_count": 1, "id": "4758ec30", "metadata": {}, "outputs": [], "source": ["# removing URLs\nurl_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\npic_pattern = re.compile('pic\\.twitter\\.com/.{10}')\ndata['text'] = data['content'].apply(lambda buf: url_pattern.sub('',buf))\ndata['text'] = data['text'].apply(lambda buf: pic_pattern.sub('', buf))\n\n# removing space in mentions and hashtags\ndata['text'] = data['text'].apply(lambda buf: buf.replace('@ ', '@'))\ndata['text'] = data['text'].apply(lambda buf: buf.replace('# ', '#'))\ndata['year'] = data['date'].apply(lambda buf: int(buf[:4]))"]}, {"cell_type": "markdown", "id": "e105e258", "metadata": {}, "source": ["#### 2  Tweets by year  \n> \nHe has made a lot of tweets in the last ten years, but of course #favs and #retweets jumped up when he was inaugurated as President  \n\u6614\u304b\u3089\u5927\u91cf\u306etweet\u3092\u3057\u3066\u304d\u305f\u304c\u3001\u5f53\u7136\u5927\u7d71\u9818\u5c31\u4efb\u3067favorits\u6570\u3084retweet\u6570\u306f\u6fc0\u5897"]}, {"cell_type": "code", "execution_count": 1, "id": "e514c314", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(3,1,figsize=(12,12))\nplt.subplots_adjust(hspace=0.3)\nsns.countplot(x='year', data=data, ax=ax[0])\nsns.barplot(x='year', y='favorites', data=data, ax=ax[1])\nsns.barplot(x='year', y='retweets', data=data, ax=ax[2]);"]}, {"cell_type": "markdown", "id": "8ef843bf", "metadata": {}, "source": ["#### 3  WordCloud before he took office at White House, and after"]}, {"cell_type": "code", "execution_count": 1, "id": "68fe9300", "metadata": {}, "outputs": [], "source": ["data_president = data[data['year'] > 2016]\ndata_pre_president = data[data['year'] < 2017]\ndef wc_president(president):\n    if president:\n        tmp_data = data_president\n        title = 'As President (2017-)'\n    else:\n        tmp_data = data_pre_president\n        title = 'Before President (-2016)'\n    words = ' '.join([text for text in tmp_data['text']])\n    wordcloud = WordCloud(width=800, height=400, background_color='white', max_font_size=110).generate(words)\n    plt.figure(figsize=(16, 8))\n    plt.title(title, fontsize=32)\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis('off');"]}, {"cell_type": "markdown", "id": "2bd9d74d", "metadata": {}, "source": ["\u5927\u7d71\u9818\u5c31\u4efb\u524d\u306etweet\u306f\u3068\u3082\u304b\u304f\u81ea\u5206\u306e\u540d\u524d\u3092\u9023\u547c"]}, {"cell_type": "code", "execution_count": 1, "id": "fa7476a2", "metadata": {}, "outputs": [], "source": ["wc_president(False)\nwc_president(True)"]}, {"cell_type": "markdown", "id": "bb5be4aa", "metadata": {}, "source": ["#### 4 Features by Cluster"]}, {"cell_type": "code", "execution_count": 1, "id": "c821eefd", "metadata": {}, "outputs": [], "source": ["# Eliminate too short tweets in order to clustering make sence\ndata_president['len_word'] = data_president['text'].str.split().map(lambda x:len(x))\ndata_president2 = data_president[data_president['len_word']>1]\n\n# text embedding with Universal Sentence Encoder \nX = embed(data_president2['text'].values)\n\n# Clustering\nkmeans = KMeans(n_clusters=4, random_state=42).fit(X)\n\n# Assign cluster number to each text\ndata_president2= pd.concat([data_president2,\n                            pd.DataFrame(kmeans.labels_, index=data_president2.index).rename(columns={0:'Cluster'})],\n                           axis=1)\n\n# Assign Cosine Similality to each Cluster Center\ndef cos_sim(v1, v2):\n    return np.dot(v1, v2)/(np.linalg.norm(v1) * np.linalg.norm(v2))\n\nnorm = np.array(np.zeros(len(X)*4).reshape(len(X), 4))\nfor i in range(len(X)):\n    for j in range(4):\n        norm[i, j] = cos_sim(X[i], kmeans.cluster_centers_[j])\n\ngrp_df = pd.concat([data_president2,\n                    pd.DataFrame(norm, index=data_president2.index).rename(columns={0:'sim0', 1:'sim1', 2:'sim2', 3:'sim3'})],\n                    axis=1)\n\n# Divide tweets data by Cluster\ndf_0 = grp_df[grp_df['Cluster']==0].sort_values('sim0', ascending=False)\ndf_1 = grp_df[grp_df['Cluster']==1].sort_values('sim1', ascending=False)\ndf_2 = grp_df[grp_df['Cluster']==2].sort_values('sim2', ascending=False)\ndf_3 = grp_df[grp_df['Cluster']==3].sort_values('sim3', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "456daa33", "metadata": {}, "outputs": [], "source": ["def wcshow(df, title):\n    words = ' '.join([text for text in df['text']])\n    wordcloud = WordCloud(width=800, height=400, background_color='white', max_font_size=110).generate(words)\n    plt.figure(figsize=(16, 8))\n    plt.title(title, fontsize=32)\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis('off');\n\ndef typical_tweets(df):\n    for i in range(5):\n        wrap_list = textwrap.wrap(df.iloc[i,4], 76)\n        print('\\n'.join(wrap_list),'\\n')"]}, {"cell_type": "markdown", "id": "e7c6a0e0", "metadata": {}, "source": ["4.1 WordCloud by Cluster"]}, {"cell_type": "code", "execution_count": 1, "id": "9837a068", "metadata": {}, "outputs": [], "source": ["wcshow(df_0, 'Cluster: 0')\nwcshow(df_1, 'Cluster: 1')\nwcshow(df_2, 'Cluster: 2')\nwcshow(df_3, 'Cluster: 3')"]}, {"cell_type": "markdown", "id": "418ae82f", "metadata": {}, "source": ["4.2 Typical Tweets - Top 5 tweets with cosine similality to Cluster Center"]}, {"cell_type": "markdown", "id": "d000dc81", "metadata": {}, "source": ["Cluster 0: Praise, Appreciation, #MAGA,..."]}, {"cell_type": "code", "execution_count": 1, "id": "6468c520", "metadata": {}, "outputs": [], "source": ["typical_tweets(df_0)"]}, {"cell_type": "markdown", "id": "1ac07973", "metadata": {}, "source": ["Cluster 1: Domestic Political Issues"]}, {"cell_type": "code", "execution_count": 1, "id": "118456ab", "metadata": {}, "outputs": [], "source": ["typical_tweets(df_1)"]}, {"cell_type": "markdown", "id": "920e4a37", "metadata": {}, "source": ["Cluster 2: About Media Reports"]}, {"cell_type": "code", "execution_count": 1, "id": "73f59055", "metadata": {}, "outputs": [], "source": ["typical_tweets(df_2)"]}, {"cell_type": "markdown", "id": "ff9e430a", "metadata": {}, "source": ["Cluster 3: International Political Issues"]}, {"cell_type": "code", "execution_count": 1, "id": "6dbc5d69", "metadata": {}, "outputs": [], "source": ["typical_tweets(df_3)"]}, {"cell_type": "markdown", "id": "b4b656f4", "metadata": {}, "source": ["4.3 Other features"]}, {"cell_type": "code", "execution_count": 1, "id": "e7e71ea0", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(3, 1, figsize=(9,15))\nplt.subplots_adjust(hspace=0.3)\nsns.barplot(x='Cluster', y='len_word', data=grp_df, ax=ax[0])\nsns.barplot(x='Cluster', y='retweets', data=grp_df, ax=ax[1])\nsns.barplot(x='Cluster', y='favorites', data=grp_df, ax=ax[2]);"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}