{"cells": [{"cell_type": "markdown", "id": "5511004a", "metadata": {}, "source": ["# MNIST Classification using Tensorflow\n\nTraining a Deep Learning model on handwritten digits using Tensorflow and Keras to accurately predict the test set\n\nKaggle link to the challenge - https://www.kaggle.com/c/digit-recognizer\n\n## Contents"]}, {"cell_type": "markdown", "id": "22d3e8a3", "metadata": {}, "source": ["## 0: Importing libraries and the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "0a74ce45", "metadata": {}, "outputs": [], "source": ["# Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")"]}, {"cell_type": "code", "execution_count": 1, "id": "6bb6c03f", "metadata": {}, "outputs": [], "source": ["# Reading the data\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "e00f75c8", "metadata": {}, "outputs": [], "source": ["# Seperating features and label\ny_train = train[\"label\"]\nX_train = train.drop([\"label\"], axis=1)"]}, {"cell_type": "markdown", "id": "b2a1720c", "metadata": {}, "source": ["## 1: Exploratory Data Analysis\n\nPerforming EDA on the training dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "a17fbe3f", "metadata": {}, "outputs": [], "source": ["# Size of the training data\nX_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "05bb742b", "metadata": {}, "outputs": [], "source": ["X_train.head(5)"]}, {"cell_type": "code", "execution_count": 1, "id": "6480d640", "metadata": {}, "outputs": [], "source": ["# Visualize the number of digits under each class\nplt.figure(figsize=(9, 5))\nsns.countplot(y_train)\nplt.title(\"Count plot\");"]}, {"cell_type": "code", "execution_count": 1, "id": "77f19893", "metadata": {}, "outputs": [], "source": ["y_train.value_counts()"]}, {"cell_type": "markdown", "id": "e7e512ba", "metadata": {}, "source": ["There seem to be an equal distribution of class labels"]}, {"cell_type": "code", "execution_count": 1, "id": "52f8eb56", "metadata": {}, "outputs": [], "source": ["# Displaying some training samples\nimg_matrix = X_train.iloc[100].to_numpy()\nimg_matrix = img_matrix.reshape(28, 28)\n\nplt.imshow(img_matrix, cmap=plt.cm.binary)"]}, {"cell_type": "markdown", "id": "926d159d", "metadata": {}, "source": ["## 3: Feature Engineering\n\nFeature engineering is an essential step of data preprocessin, this helps the model converge much faster.\nWe will be performing 3 main steps here\n1. Normalization - We will perform grey scale normalization to reduce the illumination difference it also helps the model train faster\n2. Reshape - We will drop the shape to 28x28. We will be adding an extra dimension, i.e 28x28x1 (Greyscale data). We have to add this extra dimension for keras, as \n3. Label Encoding - encoding labels to one hot vectors"]}, {"cell_type": "code", "execution_count": 1, "id": "1a130351", "metadata": {}, "outputs": [], "source": ["# Normalization\nX_train = tf.keras.utils.normalize(X_train, axis=1)\ntest = tf.keras.utils.normalize(test, axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "ad1fef3f", "metadata": {}, "outputs": [], "source": ["# Reshape\nX_train = X_train.values.reshape(-1, 28, 28)\ntest = test.values.reshape(-1, 28, 28)"]}, {"cell_type": "markdown", "id": "91bd37b0", "metadata": {}, "source": ["## 4: Train Test Split\n\nSplitting `X_train` into training data (90%) and test data (10%) using `sklearn.model_selection.train_test_split`"]}, {"cell_type": "code", "execution_count": 1, "id": "6e85965a", "metadata": {}, "outputs": [], "source": ["X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"]}, {"cell_type": "code", "execution_count": 1, "id": "ec9b4136", "metadata": {}, "outputs": [], "source": ["X_train.shape, X_eval.shape, y_train.shape, y_eval.shape"]}, {"cell_type": "markdown", "id": "3d094d28", "metadata": {}, "source": ["## 5: Creating, Training and Fitting the model"]}, {"cell_type": "code", "execution_count": 1, "id": "577cd6c0", "metadata": {}, "outputs": [], "source": ["# 1: Building the model\nmodel = Sequential()\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=tf.nn.relu))\nmodel.add(Dense(128, activation=tf.nn.relu))\nmodel.add(Dense(10, activation=tf.nn.sigmoid))\n\n# 2. Compile the model\nmodel.compile(optimizer=\"adam\",\n             loss=\"sparse_categorical_crossentropy\",\n             metrics=[\"accuracy\"])\n\n# 3. Train the model\nhistory = model.fit(X_train, y_train,\n         validation_data=(X_eval, y_eval),\n         epochs=100)"]}, {"cell_type": "markdown", "id": "c2ed2c19", "metadata": {}, "source": ["## 6: Visualize Train and Validation Results"]}, {"cell_type": "code", "execution_count": 1, "id": "22ef5e51", "metadata": {}, "outputs": [], "source": ["history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, [\"loss\", \"accuracy\"]].plot()\nhistory_df.loc[:, [\"val_loss\", \"val_accuracy\"]].plot()"]}, {"cell_type": "code", "execution_count": 1, "id": "0d5adaf7", "metadata": {}, "outputs": [], "source": ["# Summary of the scores\nhistory_df.describe()"]}, {"cell_type": "markdown", "id": "46cb814c", "metadata": {}, "source": ["Since the validation accuracy is over ~ 97.9, the same model will be used to submit the result."]}, {"cell_type": "markdown", "id": "5a943cd9", "metadata": {}, "source": ["## 7. Submit Results"]}, {"cell_type": "code", "execution_count": 1, "id": "fb02a35d", "metadata": {}, "outputs": [], "source": ["results = model.predict(test)\nresults = np.argmax(results, axis=1)\n\nsubmission = pd.DataFrame({\"ImageId\": [i for i in range(1, 28001)] , \"Label\": list(results)})\n\nsubmission.to_csv(\"mnist_submission.csv\", index=False)"]}, {"cell_type": "markdown", "id": "58846223", "metadata": {}, "source": ["# 8. Random Validation\n\nA random sample of the test set is taken to validate with the predictions made by the model"]}, {"cell_type": "code", "execution_count": 1, "id": "90f5ce52", "metadata": {}, "outputs": [], "source": ["plt.imshow(test[10].reshape(28, 28))"]}, {"cell_type": "code", "execution_count": 1, "id": "608dc2be", "metadata": {}, "outputs": [], "source": ["submission.iloc[10]"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}