{"cells": [{"cell_type": "markdown", "id": "81bd39ae", "metadata": {}, "source": ["# Import"]}, {"cell_type": "code", "execution_count": 1, "id": "b53fa6ef", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "a2c37db0", "metadata": {}, "outputs": [], "source": ["## look into the dater\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n#!pip install dtreeviz \n\nfrom IPython.display import Image, display_svg, SVG"]}, {"cell_type": "code", "execution_count": 1, "id": "a3b43d92", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, roc_auc_score, plot_confusion_matrix, precision_score, recall_score, classification_report, plot_roc_curve, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, GroupKFold"]}, {"cell_type": "code", "execution_count": 1, "id": "137c2492", "metadata": {}, "outputs": [], "source": ["import gc\nimport random as r\nimport joblib"]}, {"cell_type": "code", "execution_count": 1, "id": "4d256413", "metadata": {}, "outputs": [], "source": ["## pandas\npd.options.display.max_rows = None\npd.options.display.max_columns = None"]}, {"cell_type": "code", "execution_count": 1, "id": "9f362504", "metadata": {}, "outputs": [], "source": ["main_path = \"../input/fraud-detection-categorified-and-split/\""]}, {"cell_type": "markdown", "id": "ccbc039c", "metadata": {}, "source": ["## Load data"]}, {"cell_type": "code", "execution_count": 1, "id": "4ccaa697", "metadata": {}, "outputs": [], "source": ["## Choosing the type simulations\nbuildLv = False ## Hold out validation\nbuildSkf = True ## stratified k fold \n\nAV=True ## Adeverserial Validation"]}, {"cell_type": "code", "execution_count": 1, "id": "1c473dea", "metadata": {}, "outputs": [], "source": ["%%time\n## Load pre-processed tabular pandas (fastai) test and train\ndset_str=\"all\"#all#50k#10k\n\nto = load_pickle(main_path+\"to_\"+dset_str+\"c.pkl\") \nto_tst = load_pickle(main_path+\"to_tst_\"+dset_str+\"c.pkl\")\n\n## split as Xs and Ys\nxs,y = to.train.xs,to.train.y\nvalid_xs,valid_y = to.valid.xs,to.valid.y\n\ntest_xs = to_tst.xs.copy()\nxs.shape, test_xs.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "39784e00", "metadata": {}, "outputs": [], "source": ["## delete large unused variables\ndel to, to_tst; x=gc.collect()"]}, {"cell_type": "markdown", "id": "53913fb8", "metadata": {}, "source": ["## Functions"]}, {"cell_type": "code", "execution_count": 1, "id": "ce263847", "metadata": {}, "outputs": [], "source": ["## Function to easily get the metrics in the format for saving\ndef m_rep(m,xs,y): return classification_report(y, m.predict(xs), labels=[1,0], digits=4, output_dict=True)\n\ndef metrics(m, xs, y , valid_xs, valid_y): \n    tr_rep = m_rep(m,xs,y)\n    vd_rep = m_rep(m,valid_xs,valid_y)\n    tr_auc = roc_auc_score(y,m.predict_proba(xs)[:,1])\n    oob_auc=0.0000\n    #oob_auc = roc_auc_score(y,m.oob_decision_function_[:,1])\n    vd_auc = roc_auc_score(valid_y,m.predict_proba(valid_xs)[:,1])\n    print('{:.4f} ; {:.4f} ; {:.4f}'\n          .format(tr_auc, oob_auc, vd_auc))"]}, {"cell_type": "code", "execution_count": 1, "id": "b352f943", "metadata": {}, "outputs": [], "source": ["## Generate table of important features from the model with other useful information\ndef xgb_fi(m, df,df_real=None):\n    fi = pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False).reset_index(drop=True)\n    #fi[\"isCont\"] = fi.cols.isin(cont)\n    fi[\"countNA\"] = [df.loc[:,col].isna().sum()/len(df) if col in df.columns else float(\"NaN\") for col in fi.cols]\n    return fi\n\ndef plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "282f7732", "metadata": {}, "outputs": [], "source": ["## Format Test Predictions for Submission\ndef format_test_preds(preds,test_xs,comment):\n    #preds = m.predict_proba(test_xs[cols])[:,1]\n    print(pd.DataFrame(preds).describe())\n    \n    ## Make into submission dataframe\n    df_pred = pd.DataFrame({\"TransactionID\":test_xs.TransactionID.to_list(),\n                            \"isFraud\": preds})\n    \n    ## save\n    df_pred.to_csv(comment+\"my_subs.csv\",index=False)\n    print(df_pred.shape)\n    del df_pred; x=gc.collect()"]}, {"cell_type": "code", "execution_count": 1, "id": "3d81d3b4", "metadata": {}, "outputs": [], "source": ["def xgb_lvd_fun(get_feat_imp):\n    ## model\n    clf = xgb.XGBClassifier(n_estimators=2000, \n                        max_depth=8, #12\n                        learning_rate= 0.05,\n                        subsample= 0.6,#0.8 \n                        colsample_bytree= 0.4, \n                        random_state = r.randint(0,9999),\n                        use_label_encoder=False,\n                        # USE GPU\n                        tree_method='gpu_hist')\n\n    m = clf.fit(xs[cols].iloc[idxT], y.iloc[idxT], eval_set=[(xs[cols].iloc[idxV],y.iloc[idxV])],\n                eval_metric= \"auc\", verbose=100, early_stopping_rounds=100)\n    ## score prediction\n    tr_auc = roc_auc_score(y.iloc[idxT], m.predict_proba(xs[cols].iloc[idxT])[:,1])\n    vd_auc = roc_auc_score(y.iloc[idxV],m.predict_proba(xs[cols].iloc[idxV])[:,1])\n    \n    ## test results predictions\n    te_pred = m.predict_proba(test_xs[cols])[:,1]\n    \n    ## Getting feature importances\n    if get_feat_imp:\n        fi = xgb_fi(m, xs[cols])\n        fi.to_csv(\"fi_lv.csv\",index=False)\n        print(fi)\n    \n    ## remove large files    \n    del m, clf; x=gc.collect()\n    return [tr_auc, vd_auc], te_pred\n    "]}, {"cell_type": "code", "execution_count": 1, "id": "00821dc0", "metadata": {}, "outputs": [], "source": ["def xgb_pred_fun():\n    \n    ## setup kfold\n    skf = KFold(n_splits = 5, shuffle = False)\n    tr_pred = np.zeros(len(xs))\n    oof_pred = np.zeros(len(xs))\n    te_pred = np.zeros(len(test_xs))\n\n    for i, (idxT, idxV) in enumerate(skf.split(xs,y)):\n        ## model\n        print('Fold',i)\n        print(' n_rows of train =',len(idxT),'rows of holdout =',min(idxV),\"to\",max(idxV))#len(idxV))        \n        clf = xgb.XGBClassifier(n_estimators=1000, \n                        max_depth=12, #12\n                        learning_rate= 0.02,\n                        subsample= 0.8,#0.8 \n                        colsample_bytree= 0.4, \n                        random_state = r.randint(0,9999),\n                        use_label_encoder=False,\n                        # USE GPU\n                        tree_method='gpu_hist')\n\n        m = clf.fit(xs[cols].iloc[idxT], y.iloc[idxT], eval_set=[(xs[cols].iloc[idxV],y.iloc[idxV])],\n                eval_metric= \"auc\", verbose=100, early_stopping_rounds=100)\n        \n        ## predicting the probabilities of for Train OOF and Test\n        tr_pred[idxT] += m.predict_proba(xs[cols].iloc[idxT])[:,1]/(skf.n_splits-1)\n        oof_pred[idxV] += m.predict_proba(xs[cols].iloc[idxV])[:,1]\n        te_pred += m.predict_proba(test_xs[cols])[:,1]/skf.n_splits\n        \n        ## Getting Feature Importances\n        if i==4:\n            fi = xgb_fi(m, xs[cols])\n            fi.to_csv(\"fi_lv.csv\",index=False)\n            print(fi)\n            \n        ## remove large files    \n        del m; x=gc.collect()\n\n    print('{:.4f} ; {:.4f} ; {:.4f}'\n              .format(roc_auc_score(y,tr_pred),roc_auc_score(y,oof_pred),0.000))\n    \n    return te_pred"]}, {"cell_type": "markdown", "id": "1fd137e7", "metadata": {}, "source": ["## Column selection from EDA."]}, {"cell_type": "code", "execution_count": 1, "id": "fcd29f4b", "metadata": {}, "outputs": [], "source": ["## collecting all columns\ncols = xs.columns.to_list()"]}, {"cell_type": "code", "execution_count": 1, "id": "81107938", "metadata": {}, "outputs": [], "source": ["## Vcol buckets (first filter based on correlation) From fraud detection v11's EDA \nv = []\nv += ['V1', 'V3', 'V11', 'V9', 'V5', 'V7']\nv += ['V13', 'V17', 'V24', 'V14', 'V20', 'V27', 'V34', 'V26', 'V30']\nv += ['V36', 'V37', 'V47', 'V40', 'V48', 'V52', 'V41', 'V45']\nv += ['V54', 'V65', 'V60', 'V67', 'V56', 'V68', 'V62', 'V55', 'V70']\nv += ['V76', 'V89', 'V91', 'V81', 'V82', 'V87', 'V78', 'V88']\nv += ['V127', 'V121', 'V99', 'V110', 'V104', 'V130', 'V129', 'V131', 'V109', 'V136', 'V116', 'V120', 'V125', 'V113', 'V118', 'V98', 'V107', 'V117', 'V115']\nv += ['V138', 'V140', 'V142', 'V147', 'V155', 'V162']\nv += ['V165', 'V160', 'V166']\nv += ['V203', 'V207', 'V216', 'V187', 'V176', 'V173', 'V183', 'V215']\nv += ['V169', 'V195', 'V201', 'V171', 'V174', 'V175', 'V209', 'V185', 'V188', 'V210', 'V198', 'V180']\nv += ['V274', 'V264', 'V265', 'V261', 'V235', 'V223', 'V258', 'V260', 'V246', 'V252', 'V241', 'V266', 'V240', 'V277', 'V228', 'V226']\nv += ['V220', 'V239', 'V271', 'V221', 'V234', 'V251']\nv += ['V307', 'V291', 'V285', 'V290', 'V312', 'V297', 'V305', 'V320', 'V303', 'V286', 'V309', 'V284', 'V310']\nv += ['V281', 'V301', 'V282', 'V315', 'V289', 'V296', 'V314', 'V283']\nv += ['V332', 'V338', 'V337', 'V336', 'V325', 'V326', 'V328', 'V335']\nlen(v)\n\ndef set_approach(a,b):\n    return list(set(a)-set(b))\n\n## Remove all v columns using below code\ntf_V = [bool(re.search(\"^V\"+\"[0-9]+\",col)) for col in xs.columns.to_list()]\ncols = xs.columns[list(~np.array(tf_V))].to_list()"]}, {"cell_type": "code", "execution_count": 1, "id": "f70e863f", "metadata": {}, "outputs": [], "source": ["## add specific v columns\ncols +=v\nprint(len(cols))"]}, {"cell_type": "code", "execution_count": 1, "id": "78f73714", "metadata": {}, "outputs": [], "source": ["## remove time and other columns that don't add to score\ncols_rem = ['TransactionID', 'TransactionDT']\n\ncols_rem +=[\"DayNum\",\"HrOfDay\",\"WkDayNum\",'R_emaildomain1', 'R_emaildomain2', 'P_emaildomain1', 'P_emaildomain2','id_31_browser',\"DeviceInfo_make\"]\ncols = set_approach(cols,cols_rem)"]}, {"cell_type": "code", "execution_count": 1, "id": "11975a3d", "metadata": {}, "outputs": [], "source": ["len(cols)"]}, {"cell_type": "markdown", "id": "5830737a", "metadata": {}, "source": ["## Clean up D columns"]}, {"cell_type": "code", "execution_count": 1, "id": "eb3c3bed", "metadata": {}, "outputs": [], "source": ["## function to one hot encode\ndef ohe(df,cols):\n    for col in cols:\n        df[col+\"_OHE\"] = df[col].isna().astype(int)"]}, {"cell_type": "code", "execution_count": 1, "id": "748acce6", "metadata": {}, "outputs": [], "source": ["## OHE of cols_ohe\ncols_ohe = [\"D2\",\"D9\"] \n\nohe(xs,cols_ohe)\nohe(test_xs,cols_ohe)\ncols += [\"D2_OHE\",\"D9_OHE\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "c14675b5", "metadata": {}, "outputs": [], "source": ["cols_rem =[\"D2\",\"D9\",\"D12\"]\ncols = set_approach(cols,cols_rem)"]}, {"cell_type": "code", "execution_count": 1, "id": "2efcbcd2", "metadata": {}, "outputs": [], "source": ["len(cols)"]}, {"cell_type": "markdown", "id": "c3846669", "metadata": {}, "source": ["## Adding Dn columns"]}, {"cell_type": "code", "execution_count": 1, "id": "f47aba93", "metadata": {}, "outputs": [], "source": ["cols += [\"DayNum\",\"HrOfDay\",\"WkDayNum\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "077756cf", "metadata": {}, "outputs": [], "source": ["def Dn(df,cols):\n    for col in cols:\n        df[col+\"n\"] = df[\"DayNum\"] - df[col]"]}, {"cell_type": "code", "execution_count": 1, "id": "e515a230", "metadata": {}, "outputs": [], "source": ["d_cols = ['D1',\"D2\", 'D3', 'D4', 'D5', 'D6', 'D7', \"D8\", \"D9\", 'D10', 'D11', \"D12\",\n          'D13', 'D14', 'D15']\nDn(xs,d_cols)\nDn(test_xs,d_cols)\nd_cols = [string +\"n\" for string in d_cols]\ncols +=d_cols"]}, {"cell_type": "code", "execution_count": 1, "id": "327a5ef3", "metadata": {}, "outputs": [], "source": ["len(cols)"]}, {"cell_type": "code", "execution_count": 1, "id": "509daca5", "metadata": {}, "outputs": [], "source": ["print(cols)"]}, {"cell_type": "markdown", "id": "33b53921", "metadata": {}, "source": ["## Combine and group aggregation funtions"]}, {"cell_type": "code", "execution_count": 1, "id": "8ef508ae", "metadata": {}, "outputs": [], "source": ["def encode_CB2(df1,df2,uid):\n    newcol = \"_\".join(uid)\n    ## make combined column\n    df1[newcol] = df1[uid].astype(str).apply(lambda x: '_'.join(x), axis=1)\n    df2[newcol] = df2[uid].astype(str).apply(lambda x: '_'.join(x), axis=1)\n    \n    ## concat and then factorize\n    temp_df = pd.concat([df1[newcol],df2[newcol]],axis=0)\n    temp_df,_ = temp_df.factorize(sort=True)\n    \n    ## unconcat    \n    if temp_df.max()>32000: \n        df1[newcol+\"_fact\"] = temp_df[:len(df1)].astype('int32')\n        df2[newcol+\"_fact\"] = temp_df[len(df1):].astype('int32')\n    else:\n        df1[newcol+\"_fact\"] = temp_df[:len(df1)].astype('int16')\n        df2[newcol+\"_fact\"] = temp_df[len(df1):].astype('int16')\n    print(newcol+\"_fact\")\n    return [newcol+\"_fact\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "1d712ce5", "metadata": {}, "outputs": [], "source": ["## Aggregations \ndef encode_ag(df,df_te,uid,cols_ag,func_list,ag=True):\n    ## concat test and train\n    new_cols_ret = []\n    ## 1. concat test and train\n    temp_df = pd.concat([df[uid+cols_ag],df_te[uid+cols_ag]],axis=0).reset_index(drop=True)\n    temp_df[uid] = temp_df[uid].fillna(-9999)\n    ## 2. group them by UID\n    grouped = temp_df.groupby(uid)\n    for func in func_list:\n        ## 3. Create new features based on \"func\"\n        temp2_df = grouped[cols_ag].transform(func).reset_index(drop=True)#.iloc[:,0]\n        if ag:\n            new_cols = [col+\"_\"+\"_\".join(uid)+\"_\"+func+\"2\" for col in cols_ag]\n        else:\n            new_cols = [\"_\".join(uid)+\"_FE2\" for col in cols_ag]\n        new_cols_ret +=new_cols\n        ## 4. Save functions\n        df[new_cols] = temp2_df[0:len(df)].fillna(-9999).astype('float32')\n        df_te[new_cols] = temp2_df[len(df):].fillna(-9999).reset_index(drop=True).astype('float32')\n    print(new_cols_ret)\n    return new_cols_ret"]}, {"cell_type": "markdown", "id": "8baa0aa3", "metadata": {}, "source": ["## Group aggregation "]}, {"cell_type": "code", "execution_count": 1, "id": "47f87afc", "metadata": {}, "outputs": [], "source": ["## UID definition\nuid = [\"D1n\",\"card1\",\"addr1\",\"P_emaildomain\"] ## uid1\n#uid = [\"D1n\",\"card1\",\"addr1\",\"P_emaildomain\",\"D3n\",\"V1\",\"M7\"]\nprint(xs[uid].isna().sum())\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a39f7358", "metadata": {}, "outputs": [], "source": ["len(cols)"]}, {"cell_type": "markdown", "id": "78f38217", "metadata": {}, "source": ["## My aggregations"]}, {"cell_type": "code", "execution_count": 1, "id": "0de5158c", "metadata": {}, "outputs": [], "source": ["# ## Combine\ncols+= encode_CB2(xs,test_xs,[\"card1\",\"addr1\"])\ncols+= encode_CB2(xs,test_xs,uid)\n\n## Frequency Encoding (FE)\ncols += encode_ag(xs,test_xs,[\"addr1\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"card1\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"card2\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"dist1\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"card1\",\"addr1\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,uid,[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"card1\",\"D1n\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"P_emaildomain\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"TransactionAmt\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"cents\"],[\"TransactionID\"],[\"count\"],ag=False)\n## Additional FE\ncols += encode_ag(xs,test_xs,[\"ProductCD\"],[\"TransactionID\"],[\"count\"],ag=False)\ncols += encode_ag(xs,test_xs,[\"HrOfDay\"],[\"TransactionID\"],[\"count\"],ag=False)\n\n## Aggregation\ncols_ag_av = [\"D3n\",\"M7\",\"D9\",\"D10n\",\"D13n\",\"D5n\",\"D15n\",\"D4n\",\"D6n\",\"D11n\",\"HrOfDay\",\"D14n\",\"id_13\"] ## cols from AV importance\ncols_ag_other = [\"TransactionAmt\",\"cents\"]\ncols_C = [\"C\"+str(i) for i in range(1,15)]##v96\ncols_M = ['M'+str(x) for x in range(1,10) if x!= 7]##v96\n\ncols += encode_ag(xs,test_xs,uid,cols_ag_av+cols_ag_other, [\"std\",\"mean\"])\ncols += encode_ag(xs,test_xs,[\"card1\",\"addr1\",\"P_emaildomain\"],cols_ag_av+cols_ag_other, [\"std\",\"mean\"])##v95\ncols += encode_ag(xs,test_xs,uid,cols_C, [\"std\",\"mean\"]) ##v96\n\ncols_ag_v = [\"V9\",\"V314\",\"V3\",\"V171\",\"V81\",\"V289\",\"V88\",\"V89\",\"V271\",\"V326\",\"V7\",\"V52\",\"V1\"]\ncols += encode_ag(xs,test_xs,uid,cols_ag_v, [\"std\",\"mean\"])\n## Agg nunique\n\ncols_ag_numb = [\"addr2\",\"ProductCD\",\"dist1\",\"DeviceType\"]#,\"P_emaildomain\"]\n\ncols += encode_ag(xs,test_xs,uid,cols_ag_numb+cols_M, [\"nunique\"])"]}, {"cell_type": "markdown", "id": "1279efcc", "metadata": {}, "source": ["## Final list of columns"]}, {"cell_type": "code", "execution_count": 1, "id": "d378b493", "metadata": {}, "outputs": [], "source": ["cols = set_approach(cols,[\"DayNum\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "2bbb54fc", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(xs[cols].dtypes).reset_index().sort_values(\"index\").reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "8df1be5a", "metadata": {}, "outputs": [], "source": ["len(cols)"]}, {"cell_type": "code", "execution_count": 1, "id": "167b2e33", "metadata": {}, "outputs": [], "source": ["## Fillna\nxs.fillna(-9999, inplace=True)\ntest_xs.fillna(-9999, inplace=True)"]}, {"cell_type": "markdown", "id": "ea1f7684", "metadata": {}, "source": ["## Local validation: Hold out"]}, {"cell_type": "code", "execution_count": 1, "id": "a3454f8c", "metadata": {}, "outputs": [], "source": ["## variable to trigget getting FI\ni=4\nif i==4: get_feat_imp=True\nget_feat_imp"]}, {"cell_type": "code", "execution_count": 1, "id": "26293662", "metadata": {}, "outputs": [], "source": ["## Linear split 80% 20%\nmsk = np.arange(len(xs))<0.8*len(xs) #usually 0.8, 0.8851 for the oversampling case\nidxT = list(np.where(msk)[0])\nidxV = list(np.where(~msk)[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "ed03ab43", "metadata": {}, "outputs": [], "source": ["%%time\n## Run LV 5 times\n\nif buildLv:\n    get_feat_imp=False\n    n=5\n    preds = np.zeros(len(test_xs))\n    auc_lst = []\n    for i in range(n):\n        print(\"iteation\",i)\n        if i==4: get_feat_imp=True\n        a,temp = xgb_lvd_fun(get_feat_imp)\n        preds += temp/n\n        auc_lst.append(a)\n        del temp; x=gc.collect()\n        #print(a)\n    auc_lst = np.array(auc_lst)\n    print(auc_lst.mean(axis=0))\n    print(auc_lst.std(axis=0))\n    format_test_preds(preds,test_xs,\"baselineLV\")\n"]}, {"cell_type": "markdown", "id": "ec864b4b", "metadata": {}, "source": ["## Local Validation: kfold"]}, {"cell_type": "code", "execution_count": 1, "id": "682ed111", "metadata": {}, "outputs": [], "source": ["%%time\n## Run 6 time kfold along with OOF prediction and fold based prediction of Test\n\nif buildSkf:\n\n    preds = xgb_pred_fun()\n    format_test_preds(preds,test_xs,\"baseline\")\n    #del preds; x=gc.collect()\n    \n#     ## Post_Proc\n#     df_ptr = pd.concat([xs[[\"TransactionID\"]+uid],y],axis=1)\n#     print(df_ptr.sample())\n#     df_pte = pd.concat([test_xs[[\"TransactionID\"]+uid],pd.DataFrame({\"isFraud\":preds})],axis=1)\n#     print(df_pte.sample())\n#     encode_ag(df_ptr,df_pte,uid,[\"isFraud\"],[\"mean\"])\n#     print(df_pte.sample())\n#     format_test_preds(df_pte.isFraud_D1n_card1_addr1_mean2.to_list(),test_xs,\"post_proc_\")\n#     del df_ptr, df_pte; x=gc.collect();"]}, {"cell_type": "markdown", "id": "68f58944", "metadata": {}, "source": ["## Adverserial Validation"]}, {"cell_type": "code", "execution_count": 1, "id": "12c3b8ff", "metadata": {}, "outputs": [], "source": ["## AV\nif AV:\n    df_dom = pd.concat([xs[cols], test_xs[cols]])\n    is_test = pd.DataFrame([0]*len(xs) + [1]*len(test_xs))\n    idxT,idxV = train_test_split(np.arange(len(df_dom)),test_size=0.2)\n    del xs, test_xs; x=gc.collect()\n\n    clf = xgb.XGBClassifier(n_estimators=1000, \n                            max_depth=8, #12\n                            learning_rate= 0.05,\n                            subsample= 0.6,#0.8 \n                            colsample_bytree= 0.4, \n                            random_state = r.randint(0,9999),\n                            use_label_encoder=False,                            \n    #                         #USE CPU\n    #                         nthread=4)\n                            # USE GPU\n                            tree_method='gpu_hist')\n\n    m = clf.fit(df_dom.iloc[idxT], is_test.iloc[idxT], eval_set=[(df_dom[cols].iloc[idxV],is_test.iloc[idxV])],\n                    eval_metric= \"auc\", verbose=100, early_stopping_rounds=100)\n\n    fi = xgb_fi(m, df_dom,df_dom)\n    fi.to_csv(\"fi_av.csv\",index=False)\n    fi"]}, {"cell_type": "code", "execution_count": 1, "id": "5d075697", "metadata": {}, "outputs": [], "source": ["fi"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}