{"cells": [{"cell_type": "code", "execution_count": 1, "id": "df359832", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport json\n\nmeta = pd.DataFrame(json.load(open('/kaggle/input/deepfake-detection-challenge/train_sample_videos/metadata.json'))).T\nprint(meta.head())\n\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "6ada4cbc", "metadata": {}, "outputs": [], "source": ["meta['label'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "9a0f8089", "metadata": {}, "outputs": [], "source": ["meta[meta['label']=='REAL'].head()"]}, {"cell_type": "code", "execution_count": 1, "id": "76f14cfe", "metadata": {}, "outputs": [], "source": ["# read a random real video in memory and analyse\nimport random\ntry:\n    import imageio\n    import pylab\nexcept Exception as e:\n    !pip install imageio\n    !pip install pylab\n    import pylab\n    import imageio\n!pip install imageio-ffmpeg\nreal_vids = meta[(meta['label'] == 'REAL') & (meta['split'] == 'train')]\nrand_real_vid = real_vids.index[random.randint(0,len(real_vids))] \nfilename = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'+rand_real_vid\nprint(filename)\nvid = imageio.get_reader(filename,  'ffmpeg')\ntype(vid)"]}, {"cell_type": "code", "execution_count": 1, "id": "12d42386", "metadata": {}, "outputs": [], "source": ["vid.count_frames()"]}, {"cell_type": "code", "execution_count": 1, "id": "b78fb867", "metadata": {}, "outputs": [], "source": ["image = vid.get_data(1)\npylab.imshow(image)"]}, {"cell_type": "code", "execution_count": 1, "id": "ead7d250", "metadata": {}, "outputs": [], "source": ["#Find number of frames in each video\nimport tqdm\nframes_per_video = list()\nfor file in tqdm.tqdm(meta.index):\n    filename = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'+file\n    vid = imageio.get_reader(filename,  'ffmpeg')\n    frames_per_video.append(vid.count_frames())"]}, {"cell_type": "code", "execution_count": 1, "id": "c997d0c9", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nplt.plot(frames_per_video)\nplt.show()"]}, {"cell_type": "markdown", "id": "806df36b", "metadata": {}, "source": ["### all images does not have same number of frames"]}, {"cell_type": "code", "execution_count": 1, "id": "2c9da3b4", "metadata": {}, "outputs": [], "source": ["# read meta data info about each video\nimport tqdm\nmeta_per_video = list()\nfor file in tqdm.tqdm(meta.index):\n    filename = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/'+file\n    vid = imageio.get_reader(filename,  'ffmpeg')\n    vid_meta = vid._meta\n    # append other info from meta file\n    vid_meta['num_frames'] = vid.count_frames()\n    vid_meta['filename'] = file\n    vid_meta['label'] = meta.loc[file]['label']\n    vid_meta['split'] = meta.loc[file]['split']\n    vid_meta['original'] = meta.loc[file]['original']\n    meta_per_video.append(vid_meta)\n#convert list of dict to pandas dataframe for easy analysis\nmeta_videos = pd.DataFrame(meta_per_video)"]}, {"cell_type": "code", "execution_count": 1, "id": "e8c619a9", "metadata": {}, "outputs": [], "source": ["meta_videos.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "495f3909", "metadata": {}, "outputs": [], "source": ["list(filter(lambda x:x.split('.')[1]!='mp4',os.listdir('../input/deepfake-detection-challenge/test_videos')))"]}, {"cell_type": "markdown", "id": "2d91d156", "metadata": {}, "source": ["### there is no meta data file in test directory"]}, {"cell_type": "code", "execution_count": 1, "id": "d4d65306", "metadata": {}, "outputs": [], "source": ["\nmeta_per_video = list()\nfor file in tqdm.tqdm(os.listdir('../input/deepfake-detection-challenge/test_videos')):\n    filename = '/kaggle/input/deepfake-detection-challenge/test_videos/'+file\n    vid = imageio.get_reader(filename,  'ffmpeg')\n    vid_meta = vid._meta\n    # append other info from meta file\n    vid_meta['num_frames'] = vid.count_frames()\n    vid_meta['filename'] = file\n    meta_per_video.append(vid_meta)\n#convert list of dict to pandas dataframe for easy analysis\nmeta_test_videos = pd.DataFrame(meta_per_video)"]}, {"cell_type": "code", "execution_count": 1, "id": "aa363eb1", "metadata": {}, "outputs": [], "source": ["meta_test_videos.head()"]}, {"cell_type": "markdown", "id": "f62db5e2", "metadata": {}, "source": ["### test videos num_frams distibution"]}, {"cell_type": "code", "execution_count": 1, "id": "3bcb2e84", "metadata": {}, "outputs": [], "source": ["plt.plot(meta_test_videos['num_frames'])\nplt.show()"]}, {"cell_type": "markdown", "id": "f747650a", "metadata": {}, "source": ["## Reading the entire data"]}, {"cell_type": "code", "execution_count": 1, "id": "f16f5dc0", "metadata": {}, "outputs": [], "source": ["#import the libraries \nimport PIL.Image\nimport PIL.ImageDraw\ntry:\n    import face_recognition\nexcept:\n    !pip install face_recognition\n    import face_recognition\n    \n# load a video\nvid = imageio.get_reader('/kaggle/input/deepfake-detection-challenge/train_sample_videos/aagfhgtpmv.mp4',  'ffmpeg')\n\n# get a random frame of video\nimage = vid.get_data(random.randint(0,vid.count_frames()))\n\n# Load the jpg file into a NumPy array\n#image = face_recognition.load_image_file(image)\n\n# Find all the faces in the image\nface_locations = face_recognition.face_locations(image)\n\nnumber_of_faces = len(face_locations)\nprint(\"I found {} face(s) in this photograph.\".format(number_of_faces))\n\n# Load the image into a Python Image Library object so that we can draw on top of it and display it\npil_image = PIL.Image.fromarray(image)\n\nfor face_location in face_locations:\n\n    # Print the location of each face in this image. Each face is a list of co-ordinates in (top, right, bottom, left) order.\n    top, right, bottom, left = face_location\n    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n    # Let's draw a box around the face\n    draw = PIL.ImageDraw.Draw(pil_image)\n    draw.rectangle([left, top, right, bottom], outline=\"red\")\n\n# Display the image on screen\npil_image.show()\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}