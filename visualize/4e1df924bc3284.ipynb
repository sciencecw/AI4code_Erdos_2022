{"cells": [{"cell_type": "markdown", "id": "d21f90b8", "metadata": {}, "source": ["# \u6982\u8981\n\nKeras\u3092\u4f7f\u3046\u306e\u306f\u521d\u3081\u3066\u3067\u81ea\u5206\u7528\u306e\u30e1\u30e2\u3068\u3057\u3066\u516c\u958b\u3057\u307e\u3059\n\n\n1. \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306e\u524a\u9664\n\u30ab\u30c6\u30b4\u30ea\u95a2\u6570ctl_vehicle\u306f\u5e38\u306b\u76ee\u7684\u5909\u65700\u3068\u306a\u308b\u3053\u3068\u304c\u77e5\u3089\u308c\u3066\u3044\u308b\u306e\u3067\u5b66\u7fd2\u306b\u4e0d\u8981 Reason: notebook\n\n2. Keras \u3092\u4f7f\u3063\u305f\u5358\u7d14\u306a\u6df1\u5c64\u5b66\u7fd2\n\u30fb\u3000BatchNormalization \u3068DropOut\u5c64\n\u30fb\u3000\u30a2\u30fc\u30ea\u30fc\u30b9\u30c8\u30c3\u30d4\u30f3\u30b0\n\u30fb\u3000\u5b66\u7fd2\u7387\u306e\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\n\u30fb\u300032\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\nhttps://arxiv.org/abs/1804.07612\n\u2191\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306f32\u304f\u3089\u3044\u304c\u3044\u3044\u3088\u3063\u3066\u8ad6\u6587\n\u2192\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092\u304a\u304a\u304d\u304f\u3057\u305f\u65b9\u304c\u826f\u3044\u7d50\u679c\u304c\u51fa\u308b\n\n\n3. KN-FOLD\nAdd Data \u304b\u3089\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u52a0\u3048\u3001MultilabelStratifiedKFold \u306e\u30a4\u30f3\u30dd\u30fc\u30c8\n\n4. RankGauss\nRankGauss \u3067\u524d\u51e6\u7406\n\n\n### \u53c2\u8003\u8cc7\u6599\n- https://www.kaggle.com/simakov/keras-multilabel-neural-network-v1-2\n"]}, {"cell_type": "code", "execution_count": 1, "id": "f8d234f9", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.preprocessing import QuantileTransformer\nimport tensorflow_addons as tfa\nfrom sklearn.metrics import log_loss\n\nimport sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold"]}, {"cell_type": "code", "execution_count": 1, "id": "53f2283f", "metadata": {}, "outputs": [], "source": ["X_train = pd.read_csv('../input/lish-moa/train_features.csv')\ny_train = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nX_test = pd.read_csv('../input/lish-moa/test_features.csv')\n\nss = pd.read_csv('../input/lish-moa/sample_submission.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "f8bd5f20", "metadata": {}, "outputs": [], "source": ["# RankGauss\n# \u6570\u5024\u5909\u6570\u3092\u9806\u4f4d\u306b\u5909\u63db\u3057\u305f\u3042\u3068\u9806\u4f4d\u3092\u4fdd\u3063\u305f\u307e\u307e\u534a\u3070\u7121\u7406\u3084\u308a\u6b63\u898f\u5206\u5e03\u306b\u306a\u308b\u3088\u3046\u306b\u5909\u63db\u3059\u308b\u624b\u6cd5\ndef rank_gauss(df):\n    for col in df.columns:\n        transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution='normal')\n        vec_len = len(df[col].values)\n        raw_vec = df[col].values.reshape(vec_len, 1)\n        transformer.fit(raw_vec)\n\n        # \u5909\u63db\u5f8c\u306e\u30c7\u30fc\u30bf\u3067\u5404\u5217\u3092\u7f6e\u63db\n        df[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n\n    return df\n"]}, {"cell_type": "code", "execution_count": 1, "id": "1c049342", "metadata": {}, "outputs": [], "source": ["def preprocess(df):\n    df = df.copy()\n    # \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092\u6570\u5024\u5909\u63db\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    del df['sig_id']\n    \n    df = rank_gauss(df)\n    return df"]}, {"cell_type": "markdown", "id": "dbc1b2e2", "metadata": {}, "source": ["\u30ab\u30c6\u30b4\u30ea\u95a2\u6570ctl_vehicle\u306f\u5e38\u306b\u76ee\u7684\u5909\u65700\u3068\u306a\u308b\u3053\u3068\u304c\u77e5\u3089\u308c\u3066\u3044\u308b\u306e\u3067\u5b66\u7fd2\u306b\u4e0d\u8981\nReason: [notebook](https://www.kaggle.com/demetrypascal/t-test-pca-rfe-logistic-regression)"]}, {"cell_type": "code", "execution_count": 1, "id": "b4b5b10c", "metadata": {}, "outputs": [], "source": ["# cp_type == 0 \u306e\u307f\u5229\u7528\n# \u3042\u308f\u305b\u3066y\u3082\u540c\u3058\u3088\u3046\u306b\u843d\u3068\u3059\ny_train = y_train.loc[X_train['cp_type']=='trt_cp'].reset_index(drop=True)\nX_train = X_train.loc[X_train['cp_type']=='trt_cp'].reset_index(drop=True)\n\ntrain = preprocess(X_train)\ntest = preprocess(X_test)\ndel y_train['sig_id']"]}, {"cell_type": "code", "execution_count": 1, "id": "6591ac81", "metadata": {}, "outputs": [], "source": ["def create_model(num_columns):\n    model = keras.models.Sequential([\n        keras.layers.Input(num_columns),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dropout(rate=0.2),\n        tfa.layers.WeightNormalization(keras.layers.Dense(2048, activation='relu')),\n        \n        keras.layers.BatchNormalization(),\n        keras.layers.Dropout(rate=0.2),\n        tfa.layers.WeightNormalization(keras.layers.Dense(1024, activation='relu')),\n        \n        keras.layers.BatchNormalization(),\n        keras.layers.Dropout(rate=0.5),\n        tfa.layers.WeightNormalization(keras.layers.Dense(512, activation='relu')),                            \n        \n        # == final layer == \n         keras.layers.BatchNormalization(),\n         keras.layers.Dropout(rate=0.5),\n         tfa.layers.WeightNormalization(keras.layers.Dense(206, activation='sigmoid'))\n    ])\n    model.compile(\n        optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(),sync_period=10),\n        loss='binary_crossentropy'\n    )\n\n    return model"]}, {"cell_type": "code", "execution_count": 1, "id": "dac561e9", "metadata": {}, "outputs": [], "source": ["top_feats = [i for i in range(train.shape[1])]\n# len(train.columns) \u3068\u540c\u3058"]}, {"cell_type": "code", "execution_count": 1, "id": "d5270814", "metadata": {}, "outputs": [], "source": ["# \u73fe\u5728\u306e\u30a8\u30dd\u30c3\u30af\u3092\u5f15\u6570\u3068\u3057\u3066\u5b66\u7fd2\u7387\u3092\u8fd4\u3059\u95a2\u6570\u3092\u5b9a\u7fa9\n# \u305d\u308c\u307e\u3067\u306e\u5b66\u7fd2\u6563\u308b\u306b0.1 ** (epoch/20)\u3092\u304b\u3051\u3066\u3044\u3066\u5b66\u7fd2\u7387\u306f\u6307\u6570\u95a2\u6570\u7684\u306a\u6e1b\u8870\u3092\u3059\u308b\n# keras.optimizer.schedules \u3092\u4f7f\u3046\u65b9\u6cd5\u3082\u3042\u308b\n\ndef exponential_delay_fn(epoch):\n    return 0.01 * 0.1 ** (epoch/20)"]}, {"cell_type": "code", "execution_count": 1, "id": "3e30d647", "metadata": {}, "outputs": [], "source": ["N_STARTS = 7\nK_FOLD = 7\nBATCH_NUM = 128\nEPOCH_NUM = 35\ntf.random.set_seed(1)\nss.loc[:, y_train.columns] = 0\nres = y_train.copy()\nres.loc[:, y_train.columns] = 0\n\nhistorys = dict()\n\n# N_STARS * KFOLD\u3000\u56de\u5b66\u7fd2\u3059\u308b\n# MultilabelStratifielsKFold \u306f\u30e9\u30f3\u30c0\u30e0\u30b7\u30e3\u30c3\u30d5\u30eb\u3092\u3057\u3066\u304f\u308c\u308bgroup-k-fold \u306e\u3088\u3046\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\nfor seed in range(N_STARTS):\n    for n, (tr, te) in enumerate(\n        MultilabelStratifiedKFold(n_splits=K_FOLD,\n                                  random_state=seed, shuffle=True).split(train, train)):\n        print(f\"--{train.values[tr].shape}--{train.values[te].shape}--\")\n        print(f\"Seed: {seed}, Fold: {n}\")\n        \n        # \u30e2\u30c7\u30eb\u4f5c\u6210\n        model = create_model(len(top_feats))\n        \n        # === \u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u95a2\u6570\u306e\u8a2d\u5b9a ===\n        checkpoint_path = f'repeated:{seed}_Fold:{n}.hdf5'\n        \n        # \u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u95a2\u6570\u3092\u5f15\u6570\u3068\u3057\u3066LearningRateScheduler \u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3092\u4f5c\u308a\u305d\u306e\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3092fit()\u30e1\u30bd\u30c3\u30c9\u306b\u6e21\u3059\n        # model.fit(...., callback=[exponential_delay_fn(epoch)])\u306e\u3088\u3046\u306b\u4f7f\u3046\n\n        lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_delay_fn)\n\n        # \u30d9\u30b9\u30c8\u306a\u30e2\u30c7\u30eb\u3092checkpoint_path \u306b\u4fdd\u5b58\u3057\u3066\u304a\u3044\u3066\u304f\u308c\u308b\u8a2d\u5b9a\n        checkpoint_cb = keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n        # early_stopping \u306e\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u95a2\u6570\n        # val_loss \u3092\u76e3\u8996\n        # mode\u306f\u4e0a\u66f8\u304d\u3059\u308b\u3068\u304d\u306e\u8a2d\u5b9a\u3001\u57fa\u672c\u7684\u306bauto\u306b\u3057\u3066\u304a\u3051\u3070OK\n        early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n        \n        # ===========================\n        \n        history = model.fit(train.values[tr][:, top_feats],\n                  y_train.values[tr],\n                  validation_data=(train.values[te][:, top_feats], y_train.values[te]),\n                  epochs=EPOCH_NUM, \n                  batch_size=BATCH_NUM, \n                  callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler], \n                  verbose=2 #\u3000\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306b1\u884c\u306e\u30ed\u30b0\u3092\u51fa\u529b\n                 )\n        \n        historys[f'history_{seed+1}'] = history\n        \n        model.load_weights(checkpoint_path)\n        test_predict = model.predict(test.values[:, top_feats])\n        \n        # \u81ea\u5df1\u8a55\u4fa1\u7528\u306bvalidation\u30e2\u30c7\u30eb\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u3082\u4fdd\u5b58\u3057\u3066\u304a\u304f\n        val_predict = model.predict(train.values[te][:, top_feats]) \n        \n        ss.loc[:, y_train.columns] += test_predict\n        res.loc[te, y_train.columns] += val_predict\n        print('')\n\n# \u6700\u7d42\u7684\u306b\u8db3\u3057\u5408\u308f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u8a66\u884c\u56de\u6570\u5206\u306e\u5e73\u5747\u3092\u53d6\u308b\nss.loc[:, y_train.columns] /= ((n+1) * N_STARTS)\n# val \u306b\u3064\u3044\u3066\u306fN_STARTS\u5206\nres.loc[:, y_train.columns] /= N_STARTS\n        \n"]}, {"cell_type": "code", "execution_count": 1, "id": "f2ddaf64", "metadata": {}, "outputs": [], "source": ["# Show Model loss in plots\n#\u3000\u8a13\u7df4\u306e\u53ef\u8996\u5316\n# https://keras.io/ja/visualization/\n\nfor k,v in historys.items():\n    loss = []\n    val_loss = []\n    loss.append(v.history['loss'][:40])\n    val_loss.append(v.history['val_loss'][:40])\n    \nimport matplotlib.pyplot as plt\nplt.figure(figsize = (15, 6))\nplt.plot(np.mean(loss, axis=0))\nplt.plot(np.mean(val_loss, axis=0))\nplt.yscale('log')\nplt.yticks(ticks=[1,1e-1,1e-2])\nplt.xlabel('Epochs')\nplt.ylabel('Average Logloss')\nplt.legend(['Training','Validation'])\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "cdf653f3", "metadata": {}, "outputs": [], "source": ["def metric(y_true, y_pred):\n    metrics = []\n    for _target in y_train.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float)))\n    return np.mean(metrics)"]}, {"cell_type": "code", "execution_count": 1, "id": "e3c88d1a", "metadata": {}, "outputs": [], "source": ["# OOF (Out of Fold)\u3068\u306f\u3001k-Fold \u306a\u3069\u3067\u30c7\u30fc\u30bf\u3092\u5206\u5272\u3057\u305f\u969b\u306b\u5b66\u7fd2\u306b\u4f7f\u308f\u306a\u304b\u3063\u305f\u30c7\u30fc\u30bf\u3092\u6307\u3059\n# OOF \u306b\u5bfe\u3057\u3066log_loss \u306e\u5e73\u5747\u3092\u51fa\u529b\nprint(f'OOF Metric :{metric(y_train, res)}')"]}, {"cell_type": "code", "execution_count": 1, "id": "7aba7181", "metadata": {}, "outputs": [], "source": ["# \u4e88\u6e2c\u6642\u306b\u306f\u7701\u3044\u3066\u3044\u305fcp_type=1 \u306e\u30ab\u30e9\u30e0\u306f\u5f37\u5236\u7684\u306b0\u3092\u4ee3\u5165\u3059\u308b\n# \u3067\u3082\u3082\u3068\u3082\u3068\u5168\u90e80\u3063\u307d\u3044\nss.loc[test['cp_type']==1, y_train.columns] = 0\nss.to_csv('submission1.csv', index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "0b6e8a52", "metadata": {}, "outputs": [], "source": ["del historys"]}, {"cell_type": "markdown", "id": "b18d2c0c", "metadata": {}, "source": ["# XGBOOST\n"]}, {"cell_type": "code", "execution_count": 1, "id": "c66ab8f3", "metadata": {}, "outputs": [], "source": ["from xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom category_encoders import CountEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.multioutput import MultiOutputClassifier\nimport warnings\nwarnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": 1, "id": "e68a6667", "metadata": {}, "outputs": [], "source": ["X_train = pd.read_csv('../input/lish-moa/train_features.csv')\ny_train = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nX_test = pd.read_csv('../input/lish-moa/test_features.csv')\n\n# cp_type == 0 \u306e\u307f\u5229\u7528\n# \u3042\u308f\u305b\u3066y\u3082\u540c\u3058\u3088\u3046\u306b\u843d\u3068\u3059\ny_train = y_train.loc[X_train['cp_type']=='trt_cp'].reset_index(drop=True)\nX_train = X_train.loc[X_train['cp_type']=='trt_cp'].reset_index(drop=True)\n\ntrain = preprocess(X_train)\ntest = preprocess(X_test)\ndel y_train['sig_id']\n\n# drop id col\nX = train.to_numpy()\nX_test = test.to_numpy()\ny = y_train.to_numpy()"]}, {"cell_type": "code", "execution_count": 1, "id": "3449cbd9", "metadata": {}, "outputs": [], "source": ["\nclassifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n\nclf = Pipeline([('encode', CountEncoder(cols=[0, 2])),\n                ('classify', classifier)\n               ])\n\nparams = {'classify__estimator__colsample_bytree': 0.6522,\n          'classify__estimator__gamma': 3.6975,\n          'classify__estimator__learning_rate': 0.0503,\n          'classify__estimator__max_delta_step': 2.0706,\n          'classify__estimator__max_depth': 10,\n          'classify__estimator__min_child_weight': 31.5800,\n          'classify__estimator__n_estimators': 166,\n          'classify__estimator__subsample': 0.8639\n         }\n\n_ = clf.set_params(**params)\n"]}, {"cell_type": "markdown", "id": "72f64389", "metadata": {}, "source": ["control_mask = train['cp_type']=='ctl_vehicle'\noof_preds[control_mask] = 0\n\nprint('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))"]}, {"cell_type": "code", "execution_count": 1, "id": "aab46d6b", "metadata": {}, "outputs": [], "source": ["N = 7\noof_preds = np.zeros(y.shape)\ntest_preds = np.zeros((test.shape[0], y.shape[1]))\noof_losses = []\nkf = KFold(n_splits=N)\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold: ', fn)\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n\n    \n    clf.fit(X_train, y_train)\n    val_preds = clf.predict_proba(X_val) # list of preds per class\n    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n    oof_losses.append(loss)\n    preds = clf.predict_proba(X_test)\n    preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds / N\n    \nprint(oof_losses)\nprint('Mean OOF loss across folds', np.mean(oof_losses))\nprint('STD OOF loss across folds', np.std(oof_losses))"]}, {"cell_type": "code", "execution_count": 1, "id": "595e836e", "metadata": {}, "outputs": [], "source": ["# set control train preds to 0\ncontrol_mask = train['cp_type']=='ctl_vehicle'\noof_preds[control_mask] = 0\n\nprint('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))"]}, {"cell_type": "code", "execution_count": 1, "id": "cc52c850", "metadata": {}, "outputs": [], "source": ["sub = pd.read_csv('../input/lish-moa/sample_submission.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "49ee0e02", "metadata": {}, "outputs": [], "source": ["# create the submission file\nsub.iloc[:,1:] = test_preds\nsub.to_csv('submission2.csv', index=False)"]}, {"cell_type": "markdown", "id": "5685c467", "metadata": {}, "source": ["# Ensumble"]}, {"cell_type": "code", "execution_count": 1, "id": "77efda01", "metadata": {}, "outputs": [], "source": ["stack = (oof_preds + res)/2"]}, {"cell_type": "code", "execution_count": 1, "id": "7bfa4c1e", "metadata": {}, "outputs": [], "source": ["stack.to_csv('submission.csv', index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "cb1b82b2", "metadata": {}, "outputs": [], "source": ["# stacked_test_pred = np.columns_stack(test_preds, ss)\n# meta_model_pred = meta_model.predict(stacked_test_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "50d3cc93", "metadata": {}, "outputs": [], "source": ["# meta_model_pred.to_csv('submission_stacked,csv', index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "dce40c53", "metadata": {}, "outputs": [], "source": ["# assert(len(meta_model_pred) == len(ss))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}