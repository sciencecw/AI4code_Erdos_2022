{"cells": [{"cell_type": "markdown", "id": "24fd3fe0", "metadata": {}, "source": ["# 2019 Data Science Bowl\n\nIn this competition, we will analyse usage event of \"PBS KIDS Measure Up!\" app.<br>\nThe goal is to predict how many times the user answers to get correct answer for \"Assesement\" (problem).<br>\nI will proceed with exploratory data analysis to understand this competition. Especially focusing on **how the labels are made**.\n\n\n# Table of Contents:\n\n**1. [PBS KIDS Measure UP!](#id1)** <br>\n**2. [Data description](#id2)** <br>\n**3. [Data Visualization](#id3)** <br>\n**4. [References](#ref)** <br>\n"]}, {"cell_type": "markdown", "id": "5ba2b553", "metadata": {}, "source": ["<a id=\"id1\"></a>\n## PBS KIDS Measure UP!\n\nCite from official website [PBS KIDS Measure Up!](https://pbskids.org/apps/pbs-kids-measure-up.html):\n\nchildren ages 3 to 5 learn early math concepts focused on length, width, capacity, and weight while going on an adventure through Treetop City, Magma Peak, and Crystal Caves.\n\n### Specific features of Measure Up! include:\n\n - 19 unique measuring games.\n - 10 measurement-focused video clips.\n - Sticker books featuring favorite PBS KIDS characters.\n - Rewards for completion of tasks.\n - Embedded challenges and reports to help parents and caregivers monitor kids\u2019 progress.\n - Ability to track your child's progress using the PBS KIDS Super Vision companion app. (Read more about Super Vision below.)\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "1c411a42", "metadata": {}, "outputs": [], "source": ["from IPython.display import HTML, IFrame\n\nHTML('<iframe width=\"400\" height=\"200\" src=\"https://pbskids.org/apps/media/video/Seesaw_v6_subtitled_ccmix.mp4\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"]}, {"cell_type": "code", "execution_count": 1, "id": "ee6fac13", "metadata": {}, "outputs": [], "source": ["import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm import tqdm_notebook as tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb"]}, {"cell_type": "markdown", "id": "54844c28", "metadata": {}, "source": ["<a id=\"id2\"></a>\n# Data description"]}, {"cell_type": "code", "execution_count": 1, "id": "53e0f947", "metadata": {}, "outputs": [], "source": ["# Input data files are available in the \"../input/\" directory.\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"]}, {"cell_type": "markdown", "id": "827f2897", "metadata": {}, "source": ["Be careful that data size is very big and it takes time (about 1min) to load the data.<br>\nWe may refer [How to Work with BIG Datasets on Kaggle Kernels (16G RAM)](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask) by @yuliagm to load data efficiently."]}, {"cell_type": "code", "execution_count": 1, "id": "73d6e5e9", "metadata": {}, "outputs": [], "source": ["%%time\ndatadir = Path('/kaggle/input/data-science-bowl-2019')\n\n# Read in the data CSV files\ntrain = pd.read_csv(datadir/'train.csv')\ntrain_labels = pd.read_csv(datadir/'train_labels.csv')\ntest = pd.read_csv(datadir/'test.csv')\nspecs = pd.read_csv(datadir/'specs.csv')\nss = pd.read_csv(datadir/'sample_submission.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "1853e480", "metadata": {}, "outputs": [], "source": ["train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\ntest[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])"]}, {"cell_type": "markdown", "id": "4bfd39db", "metadata": {}, "source": ["Train data consists of 11M rows, while test data hasa 1M rows.\n\ntrain labels has 17K rows, which means the task is not to predict the value each row, as we will see later."]}, {"cell_type": "code", "execution_count": 1, "id": "241a8b0e", "metadata": {}, "outputs": [], "source": ["print(f'train.shape        : {train.shape}')\nprint(f'train_labels.shape : {train_labels.shape}')\nprint(f'test.shape         : {test.shape}')\nprint(f'specs.shape        : {specs.shape}')\nprint(f'ss.shape           : {ss.shape}')      "]}, {"cell_type": "markdown", "id": "593706af", "metadata": {}, "source": ["# train and test data\n\ntrain data and test data consists of event information."]}, {"cell_type": "code", "execution_count": 1, "id": "94d342ff", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "id": "ca90de5f", "metadata": {}, "source": ["Same `installation_id` continues, which means same user try to play \"Welcome to Loast lagoon!\" -> \"Magma Peak - Level 1\" -> \"Sandcastle Builder (Activity)\".\n\nThese game are separated by `game_session`, even in same game there are many events happing which is described by `event_id`."]}, {"cell_type": "markdown", "id": "f87ad645", "metadata": {}, "source": ["# train_labels\n\n`accuracy_group` is the label that we want to predict in this competition, it is categorized as\n\n - 3: the assessment was solved on the first attempt\n - 2: the assessment was solved on the second attempt\n - 1: the assessment was solved after 3 or more attempts\n - 0: the assessment was never solved\n\nMore detailed information is given by `num_correct`, `num_incorrect` and `accuracy`.\n\n - When `num_correct` is 0, which means `accuracy_group` is 0.\n - When `num_correct` is 1 and `num_incorrect` is 0, which means `accuracy_group` is 3.\n - When `num_correct` is 1 and `num_incorrect` is 1, which means `accuracy_group` is 2.\n - When `num_correct` is 1 and `num_incorrect` is more than 1, which means `accuracy_group` is 1."]}, {"cell_type": "code", "execution_count": 1, "id": "ad576e31", "metadata": {}, "outputs": [], "source": ["train_labels.head()"]}, {"cell_type": "markdown", "id": "22f03b11", "metadata": {}, "source": ["`accuracy_group` is determined by each assesement play.\n\nYou can see several `accuracy_group` exists in same `installation_id`.\n\nBecause when the same user (specified by `installation_id`) plays several games (specified by `game_session`), `accuracy_group` is calculated for each play.\n\nSame user can play same game several times as well. As you can see above, user `0006a69f` plays `Mushroom Sorter` more than 3 times."]}, {"cell_type": "code", "execution_count": 1, "id": "28494ffe", "metadata": {}, "outputs": [], "source": ["train_labels['accuracy_group'].value_counts().sort_index().plot(kind=\"bar\", title='accuracy group counts')"]}, {"cell_type": "markdown", "id": "4eff547c", "metadata": {}, "source": ["It seems many assesements are solved without incorrect trial, yay! :)"]}, {"cell_type": "markdown", "id": "1f0e6825", "metadata": {}, "source": ["# sample_submission\n\n`sample_submission` shows the submission format. It seems we need to predict `accuracy_group` for each `installation_id`."]}, {"cell_type": "code", "execution_count": 1, "id": "22995979", "metadata": {}, "outputs": [], "source": ["ss.head()"]}, {"cell_type": "markdown", "id": "028291b8", "metadata": {}, "source": ["I get confused when I compare `train_labels` and `sample_submission` at first time.<br>\n`train_labels` contains many `accuracy_group` in one `installation_id` but `sample_submission` assumes only one `accuracy_group` is assigned for each `installtion_id`. \n\nWhy?\n\nIt can be understood by carefully looking test data. <br>\nAs a conclusion, you need to predict the `accuracy_group` of the last game play for each user (`installation_id`) in the test dataset.\nI will explain details following."]}, {"cell_type": "markdown", "id": "3e25ee05", "metadata": {}, "source": ["# Checking test data for each installation_id\n\n\nThe number of `installation_id` in the `test` dataset is 1000. This is same with the number of rows of `sample_submission`."]}, {"cell_type": "code", "execution_count": 1, "id": "0f6adc84", "metadata": {}, "outputs": [], "source": ["test.installation_id.nunique()"]}, {"cell_type": "markdown", "id": "3674cc0d", "metadata": {}, "source": ["Let's forcus on one user's total history in the test dataset."]}, {"cell_type": "code", "execution_count": 1, "id": "44a390cd", "metadata": {}, "outputs": [], "source": ["#101999d8\n# f47ef997\n\ntest_tmp = test[test['installation_id'] == '101999d8']"]}, {"cell_type": "code", "execution_count": 1, "id": "7072d04c", "metadata": {}, "outputs": [], "source": ["test_tmp"]}, {"cell_type": "markdown", "id": "5dce9ba7", "metadata": {}, "source": ["As you can see, user starts from the \"Welcome to Lost Lagoon!\" event and ends with **\"Chest Sorter (Assessment)\" at last**.\n\nIt seems all the test data's last row data of each `installation_id` is some `Assessment` event. We are going to predict this las Assessment's `accuracy_group`.<br>\nOf course, user may play different \"Assessment\" in the past, so Assessment event may be contained several times and you can understand this user could anwer or not in the past \"Assessment\"."]}, {"cell_type": "markdown", "id": "d7d36517", "metadata": {}, "source": ["I chose an installation_id with very small history in the above example.<br>\nBut most of them contains thousands of events. Some user has 20000~ events."]}, {"cell_type": "code", "execution_count": 1, "id": "b2829d08", "metadata": {}, "outputs": [], "source": ["ax = sns.distplot(test['installation_id'].value_counts().values)\nax.set_title('Number of event ids for each installation id')"]}, {"cell_type": "markdown", "id": "44d8e30f", "metadata": {}, "source": ["# Calculating labels from train/test data\n\nNow we understand the meaning of input `train`, `test` data and true labels `train_labels` and submission format `sample_submission` for test.<br>\nBut how `train_labels` are calculated from `train` data? I will try writing a code to re-construct these labels."]}, {"cell_type": "markdown", "id": "96942ece", "metadata": {}, "source": ["Again, let's focus on specific `installation_id, 0006a69f` for the data analysis.<br>\nThis user solved Assessment 5 times."]}, {"cell_type": "code", "execution_count": 1, "id": "e5f3939c", "metadata": {}, "outputs": [], "source": ["train_labels[train_labels.installation_id == '0006a69f']"]}, {"cell_type": "markdown", "id": "440645f6", "metadata": {}, "source": ["Let's see this user's event."]}, {"cell_type": "code", "execution_count": 1, "id": "4da573a6", "metadata": {}, "outputs": [], "source": ["tmp_train = train[train.installation_id == '0006a69f']\ntmp_train"]}, {"cell_type": "markdown", "id": "dd2bd60c", "metadata": {}, "source": ["The event consists of 3801 rows, we cannot see all in detail... \n\nAs written in the [data description](https://www.kaggle.com/c/data-science-bowl-2019/data):\n\n> Assessment attempts are captured in event_code 4100 for all assessments except for Bird Measurer, which uses event_code 4110. If the attempt was correct, it contains \"correct\":true.\n\nSo let's extract rows with `event_code` is 4100 or 4110. Also we are only intersted in \"Assessments\" type."]}, {"cell_type": "code", "execution_count": 1, "id": "578f606c", "metadata": {}, "outputs": [], "source": ["tmp_train[tmp_train['event_code'].isin([4100, 4110]) & (tmp_train['type'] == 'Assessment')]"]}, {"cell_type": "markdown", "id": "b73cf969", "metadata": {}, "source": ["Now the size is reduced and we can see all the rows.\n\nAs we can see, for each game_session:\n\n - `901acc108f55a5a1`: Tried \"Mushroom Sorter (Assessment)\", correct with 1 try\n - `77b8ee947eb84b4e`: Tried \"Bird Measurer (Assessment)\", incorrect 11 times\n - `6bdf9623adc94d89`: Tried \"Mushroom Sorter (Assessment)\", correct with 1 try\n - `9501794defd84e4d`: Tried \"Mushroom Sorter (Assessment)\", incorrect 1 time and correct\n - `a9ef3ecb3d1acc6a`: Tried \"Bird Measurer (Assessment)\", incorrect 1 time and correct\n \nThis is consistent with the `train_labels` we saw above!"]}, {"cell_type": "markdown", "id": "f1aa6d0e", "metadata": {}, "source": ["<a id=\"id3\"></a>\n# Data visualization\n\nNow let's proceed with some data visualization to understand data more deeply."]}, {"cell_type": "markdown", "id": "cf9982ab", "metadata": {}, "source": ["### Difficulty by each Assessment\n\nIt seems \"Mushroom Sorter\" and \"Cart Balancer\" are easy (many 3), and \"Chest Sorter\" is difficult (many 0s)."]}, {"cell_type": "code", "execution_count": 1, "id": "4887fa5e", "metadata": {}, "outputs": [], "source": ["g = sns.FacetGrid(train_labels, col=\"title\")\ng = g.map(plt.hist, \"accuracy_group\")\n\n# sns.distplot(train_labels, x='accuracy_group', hue='title')"]}, {"cell_type": "markdown", "id": "301b91dd", "metadata": {}, "source": ["All Assessment are solved comparable times."]}, {"cell_type": "code", "execution_count": 1, "id": "a299e1bd", "metadata": {}, "outputs": [], "source": ["train_labels['title'].value_counts().plot(kind=\"bar\")"]}, {"cell_type": "markdown", "id": "34c05d77", "metadata": {}, "source": ["How many users are in `train_labels` and how many Assessments are solved by each user?\n\nMany people solved ~10 Assessments, but some user solved 160 Assessments!"]}, {"cell_type": "code", "execution_count": 1, "id": "90a0f62a", "metadata": {}, "outputs": [], "source": ["print('{} users solved {} Assessments in train_labels'\n      .format(train_labels['installation_id'].nunique(), len(train_labels)))"]}, {"cell_type": "code", "execution_count": 1, "id": "7c4a8077", "metadata": {}, "outputs": [], "source": ["sns.distplot(train_labels['installation_id'].value_counts().values)"]}, {"cell_type": "markdown", "id": "bc1e8e63", "metadata": {}, "source": ["## Users usage in time\n\nCode inspired from this [great kernel](https://www.kaggle.com/robikscube/2019-data-science-bowl-an-introduction), \nbut I modified `timestamp` column to be datetime to show it in proper time scale. Also used `plotly` for interactive visualization.\n\nThis user played Aug 6 6am and 5pm and Aug 9 6pm and Aug 29 4pm."]}, {"cell_type": "code", "execution_count": 1, "id": "6cc58b71", "metadata": {}, "outputs": [], "source": ["target_id = '0006a69f'\n\npx.scatter(train[train['installation_id'] == target_id], x='timestamp', y='event_code')"]}, {"cell_type": "markdown", "id": "212416b3", "metadata": {}, "source": ["Check all the event title and type."]}, {"cell_type": "code", "execution_count": 1, "id": "8e231d46", "metadata": {}, "outputs": [], "source": ["train.groupby(['title', 'type']).size().reset_index().rename(columns={0: 'count'}).sort_values('type')"]}, {"cell_type": "markdown", "id": "10a2dc57", "metadata": {}, "source": ["# Specs\n\nFrom [data description](https://www.kaggle.com/c/data-science-bowl-2019/data),\n\n> This file gives the specification of the various event types.\n - event_id - Global unique identifier for the event type. Joins to event_id column in events table.\n - info - Description of the event.\n - args - JSON formatted string of event arguments. Each argument contains:\n    - name - Argument name.\n    - type - Type of the argument (string, int, number, object, array).\n    - info - Description of the argument."]}, {"cell_type": "code", "execution_count": 1, "id": "fe007816", "metadata": {}, "outputs": [], "source": ["specs.head()"]}, {"cell_type": "markdown", "id": "1272b817", "metadata": {}, "source": ["Each `args` stores a lot of information, how to utilize these information is the feature engineering task left for you!"]}, {"cell_type": "code", "execution_count": 1, "id": "7d63263e", "metadata": {}, "outputs": [], "source": ["specs.loc[0, 'args']"]}, {"cell_type": "markdown", "id": "5fac2c28", "metadata": {}, "source": ["Work in progress for checking below questions...\n\n - Understanding each Assessments difficulty.\n   - Each assessments has some \"stage\" or \"level\"??"]}, {"cell_type": "markdown", "id": "5ec6c49a", "metadata": {}, "source": [" <h3 style=\"color:red\">If this kernel helps you, please upvote to keep me motivated \ud83d\ude01<br>Thanks!</h3>"]}, {"cell_type": "markdown", "id": "520b744d", "metadata": {}, "source": ["<a id=\"ref\"></a>\n# Reference\n\n - [A baseline for DSB 2019](https://www.kaggle.com/mhviraf/a-baseline-for-dsb-2019): This kernel explains me how to understand the relation ship between event data and labels\n \n - [\ud83d\udeb8 2019 Data Science Bowl - An Introduction](https://www.kaggle.com/robikscube/2019-data-science-bowl-an-introduction)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}