{"cells": [{"cell_type": "markdown", "id": "289ce893", "metadata": {}, "source": ["# IMPORTING THE LIBRARIES"]}, {"cell_type": "code", "execution_count": 1, "id": "a85b3e03", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\nimport warnings\nimport os \nwarnings.filterwarnings(\"ignore\")\nimport datetime\n"]}, {"cell_type": "markdown", "id": "763a3844", "metadata": {}, "source": ["# LOADING THE DATASET"]}, {"cell_type": "code", "execution_count": 1, "id": "c829756e", "metadata": {}, "outputs": [], "source": ["data=pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b7474257", "metadata": {}, "outputs": [], "source": ["data.head()      #displaying the head of dataset they gives the 1st to 5 rows of the data"]}, {"cell_type": "code", "execution_count": 1, "id": "4e3f766c", "metadata": {}, "outputs": [], "source": ["data.describe()      #description of dataset "]}, {"cell_type": "code", "execution_count": 1, "id": "e2a3ab3b", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "c185e563", "metadata": {}, "outputs": [], "source": ["data.shape       #569 rows and 33 columns"]}, {"cell_type": "code", "execution_count": 1, "id": "a43ef665", "metadata": {}, "outputs": [], "source": ["data.columns     #displaying the columns of dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "581b2d23", "metadata": {}, "outputs": [], "source": ["data.value_counts"]}, {"cell_type": "code", "execution_count": 1, "id": "1b195a4f", "metadata": {}, "outputs": [], "source": ["data.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "992673c4", "metadata": {}, "outputs": [], "source": ["data.isnull().sum()"]}, {"cell_type": "markdown", "id": "3b12d96c", "metadata": {}, "source": ["**So we have to drop the Unnamed: 32 coulumn which contains NaN values**"]}, {"cell_type": "code", "execution_count": 1, "id": "59bc9226", "metadata": {}, "outputs": [], "source": ["data.drop('Unnamed: 32', axis = 1, inplace = True)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "8ab84da8", "metadata": {}, "outputs": [], "source": ["data"]}, {"cell_type": "markdown", "id": "3a82c583", "metadata": {}, "source": ["# VISUALIZING THE DATA"]}, {"cell_type": "code", "execution_count": 1, "id": "a2664e10", "metadata": {}, "outputs": [], "source": ["data.corr()"]}, {"cell_type": "code", "execution_count": 1, "id": "36470c29", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(18,9))\nsns.heatmap(data.corr(),annot = True, cmap =\"Accent_r\")\n\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "c6367b3e", "metadata": {}, "outputs": [], "source": ["sns.barplot(x=\"id\", y=\"diagnosis\",data=data[160:190])\nplt.title(\"Id vs Diagnosis\",fontsize=15)\nplt.xlabel(\"Id\")\nplt.ylabel(\"Diagonis\")\nplt.show()\nplt.style.use(\"ggplot\")\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2707083f", "metadata": {}, "outputs": [], "source": ["sns.barplot(x=\"radius_mean\", y=\"texture_mean\", data=data[170:180])\nplt.title(\"Radius Mean vs Texture Mean\",fontsize=15)\nplt.xlabel(\"Radius Mean\")\nplt.ylabel(\"Texture Mean\")\nplt.show()\nplt.style.use(\"ggplot\")\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ff7b2f41", "metadata": {}, "outputs": [], "source": [" \nmean_col = ['diagnosis','radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n\nsns.pairplot(data[mean_col],hue = 'diagnosis', palette='Accent')\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a8bd81ee", "metadata": {}, "outputs": [], "source": ["sns.violinplot(x=\"smoothness_mean\",y=\"perimeter_mean\",data=data)"]}, {"cell_type": "code", "execution_count": 1, "id": "ee4e1240", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(14,7))\nsns.lineplot(x = \"concavity_mean\",y = \"concave points_mean\",data = data[0:400], color='green')\nplt.title(\"Concavity Mean vs Concave Mean\")\nplt.xlabel(\"Concavity Mean\")\nplt.ylabel(\"Concave Points\")\nplt.show()\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0e77a14e", "metadata": {}, "outputs": [], "source": ["worst_col = ['diagnosis','radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']\n\nsns.pairplot(data[worst_col],hue = 'diagnosis', palette=\"CMRmap\")"]}, {"cell_type": "markdown", "id": "86c45b81", "metadata": {}, "source": ["# TRAINING AND TESTING DATA"]}, {"cell_type": "code", "execution_count": 1, "id": "0fdfb4de", "metadata": {}, "outputs": [], "source": ["# Getting Features\n\nx = data.drop(columns = 'diagnosis')\n\n# Getting Predicting Value\ny = data['diagnosis']\n"]}, {"cell_type": "code", "execution_count": 1, "id": "4e81ccd6", "metadata": {}, "outputs": [], "source": ["\n#train_test_splitting of the dataset\nfrom sklearn.model_selection import train_test_split \nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5d2e5452", "metadata": {}, "outputs": [], "source": ["print(len(x_train))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5f8c6812", "metadata": {}, "outputs": [], "source": ["print(len(x_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "19d54831", "metadata": {}, "outputs": [], "source": ["print(len(y_train))"]}, {"cell_type": "code", "execution_count": 1, "id": "3fb1cebf", "metadata": {}, "outputs": [], "source": ["print(len(y_test))"]}, {"cell_type": "markdown", "id": "cef563ba", "metadata": {}, "source": ["# MODELS"]}, {"cell_type": "markdown", "id": "583e11b0", "metadata": {}, "source": ["# 1. Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "72d7e747", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\nreg = LogisticRegression()\nreg.fit(x_train,y_train)                         \n"]}, {"cell_type": "code", "execution_count": 1, "id": "990c9c84", "metadata": {}, "outputs": [], "source": ["y_pred=reg.predict(x_test)\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix,r2_score\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",reg.score(x_train,y_train)*100)\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "142412b5", "metadata": {}, "outputs": [], "source": ["data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndata\n\n\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a32212ca", "metadata": {}, "outputs": [], "source": ["print(accuracy_score(y_test,y_pred)*100)"]}, {"cell_type": "markdown", "id": "ff0aeb07", "metadata": {}, "source": ["**So we get a accuracy score of 58.7 % using logistic regression**"]}, {"cell_type": "code", "execution_count": 1, "id": "0c87873d", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import GridSearchCV\nparam = {\n         'penalty':['l1','l2'],\n         'C':[0.001, 0.01, 0.1, 1, 10, 20,100, 1000]\n}\nlr= LogisticRegression(penalty='l1')\ncv=GridSearchCV(reg,param,cv=5,n_jobs=-1)\ncv.fit(x_train,y_train)\ncv.predict(x_test)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "716bb63b", "metadata": {}, "outputs": [], "source": ["print(\"Best CV score\", cv.best_score_*100)"]}, {"cell_type": "markdown", "id": "12cadedf", "metadata": {}, "source": ["# 2. DECISION TREE CLASSIFIER"]}, {"cell_type": "code", "execution_count": 1, "id": "cb77f63a", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(max_depth=6, random_state=123)\n\ndtree.fit(x_train,y_train)\n\n#y_pred = dtree.predict(x_test)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5734b47a", "metadata": {}, "outputs": [], "source": ["y_pred=dtree.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",dtree.score(x_train,y_train)*100)\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "79ec3976", "metadata": {}, "outputs": [], "source": ["print(accuracy_score(y_test,y_pred)*100)"]}, {"cell_type": "markdown", "id": "1cee5642", "metadata": {}, "source": ["**So we get a accuracy score of 94.73 % using Decision Tree Classifier**"]}, {"cell_type": "markdown", "id": "8a66f350", "metadata": {}, "source": ["# 3. Random Forest Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "a365bdb8", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(x_train,y_train)\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e0392a8a", "metadata": {}, "outputs": [], "source": ["y_pred=rfc.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",rfc.score(x_train,y_train)*100)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7d3222c5", "metadata": {}, "outputs": [], "source": ["print(accuracy_score(y_test,y_pred)*100)"]}, {"cell_type": "markdown", "id": "3f425486", "metadata": {}, "source": ["**So we get a accuracy score of 96.49 % using Random Forest Classifier**"]}, {"cell_type": "markdown", "id": "29db2044", "metadata": {}, "source": ["# 4. KNeighborsClassifier\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b4d2a4d0", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=7)\n\nknn.fit(x_train,y_train)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "c5b74a5c", "metadata": {}, "outputs": [], "source": ["y_pred=knn.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error,r2_score\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",knn.score(x_train,y_train)*100)\nprint(knn.score(x_test,y_test))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5387b236", "metadata": {}, "outputs": [], "source": ["print(accuracy_score(y_test,y_pred)*100)\n"]}, {"cell_type": "markdown", "id": "41a25306", "metadata": {}, "source": ["**So we get a accuracy score of 70.17 % using KNeighborsClassifier**"]}, {"cell_type": "markdown", "id": "ccb2bdfb", "metadata": {}, "source": ["# 5. SVC"]}, {"cell_type": "code", "execution_count": 1, "id": "385989f0", "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "1a44fb27", "metadata": {}, "outputs": [], "source": ["y_pred=svc.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error,r2_score\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",svc.score(x_train,y_train)*100)\nprint(svc.score(x_test,y_test))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e75c1f5e", "metadata": {}, "outputs": [], "source": ["print(\"Training Score: \",svc.score(x_train,y_train)*100)"]}, {"cell_type": "markdown", "id": "49c683da", "metadata": {}, "source": ["**So we get a accuracy score of 63.7 % using SVC**"]}, {"cell_type": "markdown", "id": "3ce7b980", "metadata": {}, "source": ["# 6. AdaBoostClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "3634509f", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import AdaBoostClassifier\nadb = AdaBoostClassifier(base_estimator = None)\nadb.fit(x_train,y_train)\n\n\n\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "45ed6773", "metadata": {}, "outputs": [], "source": ["y_pred=adb.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error,r2_score\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",adb.score(x_train,y_train)*100)"]}, {"cell_type": "code", "execution_count": 1, "id": "81a517b7", "metadata": {}, "outputs": [], "source": ["print(accuracy_score(y_test,y_pred)*100)"]}, {"cell_type": "markdown", "id": "98b20bc8", "metadata": {}, "source": ["**So we get a accuracy score of 98.24 % using AdaBoostClassifier**"]}, {"cell_type": "markdown", "id": "7d6b361b", "metadata": {}, "source": ["#  7. Gradient Boosting Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "8f61f5ad", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingClassifier\ngbc=GradientBoostingClassifier()\ngbc.fit(x_train,y_train)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "fbff528d", "metadata": {}, "outputs": [], "source": ["y_pred=gbc.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error,r2_score\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",gbc.score(x_train,y_train)*100)\nprint(gbc.score(x_test,y_test))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "65755e4a", "metadata": {}, "outputs": [], "source": ["print(accuracy_score(y_test,y_pred)*100)"]}, {"cell_type": "markdown", "id": "4adf49e7", "metadata": {}, "source": ["**So we get a accuracy score of 95.61 % using GradientBoostingClassifier**"]}, {"cell_type": "markdown", "id": "c22bed6d", "metadata": {}, "source": ["# 8. XGBClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "f46ee51c", "metadata": {}, "outputs": [], "source": ["from xgboost import XGBClassifier\n\nxgb =XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10)\n\nxgb.fit(x_train, y_train)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a0ba8086", "metadata": {}, "outputs": [], "source": ["y_pred=xgb.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error,r2_score\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Training Score: \",xgb.score(x_train,y_train)*100)\nprint(xgb.score(x_test,y_test))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "88f75412", "metadata": {}, "outputs": [], "source": ["print(\"Training Score: \",xgb.score(x_train,y_train)*100)"]}, {"cell_type": "code", "execution_count": 1, "id": "65e63f52", "metadata": {}, "outputs": [], "source": ["data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndata"]}, {"cell_type": "markdown", "id": "cc2d960d", "metadata": {}, "source": ["**So we get a accuracy score of 97.80 % using  XGBClassifier**"]}, {"cell_type": "markdown", "id": "a2d07532", "metadata": {}, "source": ["# 9. Naive Bayes"]}, {"cell_type": "code", "execution_count": 1, "id": "6d62ce4d", "metadata": {}, "outputs": [], "source": ["from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "c4c85d13", "metadata": {}, "outputs": [], "source": ["y_pred=gnb.predict(x_test)\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,mean_squared_error,r2_score\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))\nprint(\"Training Score: \",gnb.score(x_train,y_train)*100)\nprint(gnb.score(x_test,y_test))\n"]}, {"cell_type": "markdown", "id": "3a14e503", "metadata": {}, "source": ["**So we get a accuracy score of 63.29 % using Naive Bayes**"]}, {"cell_type": "code", "execution_count": 1, "id": "ffe673a3", "metadata": {}, "outputs": [], "source": ["data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndata"]}, {"cell_type": "markdown", "id": "6bd1bf1e", "metadata": {}, "source": ["**So now we conclude the accuracy of different models:**\n\n**1. AdaBoost Classifier = 98.24 %**\n\n**2. XGB Classifier= 97.84 %**\n\n**3. Random Forest Classifier =96.57 %**\n\n**4. Gradient Boosting Classifier= 95.66%**\n\n**5. Decision Tree Classifier= 94.78 %**\n\n**6. K Neighbours Classifier= 70.18 %**\n\n**7. SVC = 63.80 %**\n\n**8. Naiye Bayes= 63.30 %**\n\n**9. Logistic Regression = 58.82%**\n"]}, {"cell_type": "markdown", "id": "90cc1c04", "metadata": {}, "source": ["**Ada Boost Classifier got the highest accuracy**"]}, {"cell_type": "markdown", "id": "6f022a87", "metadata": {}, "source": ["# If you liked this notebook, please UPVOTE it."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}