{"cells": [{"cell_type": "markdown", "id": "8e1929dc", "metadata": {}, "source": ["# Predicting heart disease using ML\n\nIn this notebook we are going to use various ML libraries in an attempt to build a ML model which can predict whether some one has heart disease or not"]}, {"cell_type": "markdown", "id": "007fd5a2", "metadata": {}, "source": ["## Approach followed\n\n1. Problem definition\n2. Data \n3. Evaluation\n4. Features\n5. Modelling\n6. Experimenting(will be followed in ever step)\n\n### 1. Problem Defenition\n\n> Given the required clinical data can we predict whether a person has heart disease or not\n\n### 2. DATA\n\n* refer UCI : https://archive.ics.uci.edu/ml/datasets/heart+Disease\n* refer Kaggle : https://www.kaggle.com/ronitf/heart-disease-uci\n\nWe are going to user 14(Widely used) dataset out of 76(Original) attributes\n\n### 3. Evaluation\n\n> If we can get an accuracy of accuracy >= 95% .Then we can say it as a good model.\n\n### 4. Features\n\n*** Creating Data Dictionary ***\n\n \n#### Attributes (13) : (Independent variables)\n\n* age\n* sex\n* chest pain type (4 values)\n* resting blood pressure\n* serum cholestoral in mg/dl\n* fasting blood sugar > 120 mg/dl\n* resting electrocardiographic results (values 0,1,2)\n* maximum heart rate achieved\n* exercise induced angina\n* oldpeak = ST depression induced by exercise relative to rest\n* the slope of the peak exercise ST segment\n* number of major vessels (0-3) colored by flourosopy\n* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n\n#### Final (1) : (Dependent on Attributes)\n\n* target (yes - 1 / no - 0)"]}, {"cell_type": "markdown", "id": "48c19af8", "metadata": {}, "source": ["## Preparing the tools\n\n* pandas\n* numpy\n* seaborn\n* matplotlib\n\nfor data analysis and manipulation\n\n* Regression\n* Classification\n\nScikit-learn models\n\n* Spliting\n* Cross validation\n* Evaluation method libraries\n \nfor evaluation \n"]}, {"cell_type": "code", "execution_count": 1, "id": "dc18e9c2", "metadata": {}, "outputs": [], "source": ["# Data analysis libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n# to make the plots appear in the notebook\n%matplotlib inline \nimport matplotlib.pyplot as plt\n\n# Models from scikit-learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model Evaluation\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import plot_roc_curve\n"]}, {"cell_type": "markdown", "id": "69d22b91", "metadata": {}, "source": ["## Load the data"]}, {"cell_type": "code", "execution_count": 1, "id": "e7369949", "metadata": {}, "outputs": [], "source": ["\nheart_disease = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\n\n# Displaying the first 10 data in the dataset\nheart_disease.head(10)"]}, {"cell_type": "markdown", "id": "c143f470", "metadata": {}, "source": ["### Data Exploration\nThe goal here is to gain more information from the data\n\n1. What are you trying to solve ?\n2. What kind of data we have and how to treat different types ?\n3. What is missing from the data and how to deal with it ?\n4. Where are the outliers and why should you care about them?\n5. How can you add, change or remove features to get more out of your data ?"]}, {"cell_type": "code", "execution_count": 1, "id": "164b9d6a", "metadata": {}, "outputs": [], "source": ["# How many class we have\nheart_disease[\"target\"].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "9f121411", "metadata": {}, "outputs": [], "source": ["heart_disease[\"target\"].value_counts().plot(kind = \"bar\", color = [\"red\",\"green\"]);"]}, {"cell_type": "code", "execution_count": 1, "id": "b4f7f1c8", "metadata": {}, "outputs": [], "source": ["# Checking whether our data has any missing values\nheart_disease.isna().sum()"]}, {"cell_type": "markdown", "id": "ebe530df", "metadata": {}, "source": ["we don't have any missing data here "]}, {"cell_type": "code", "execution_count": 1, "id": "7281c88c", "metadata": {}, "outputs": [], "source": ["# Describing our data\nheart_disease.describe()"]}, {"cell_type": "markdown", "id": "2e9a52b5", "metadata": {}, "source": ["> [NOTE]: The upcoming steps can be performed with an attributes but here we are going to use some columns which gets our eyes"]}, {"cell_type": "markdown", "id": "342714ba", "metadata": {}, "source": ["## Heart Disease Frequency VS Sex\n\n### SEX\n* 1 - MALE\n* 0 - FEMALE\n\n### Target\n* 1 - YES\n* 0 - NO"]}, {"cell_type": "code", "execution_count": 1, "id": "0fcd14ce", "metadata": {}, "outputs": [], "source": ["heart_disease.sex.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "42c98223", "metadata": {}, "outputs": [], "source": ["pd.crosstab(heart_disease.target,heart_disease.sex)"]}, {"cell_type": "markdown", "id": "d983c333", "metadata": {}, "source": ["this based on our present dataset it may be different in the real world"]}, {"cell_type": "code", "execution_count": 1, "id": "0891f46e", "metadata": {}, "outputs": [], "source": ["# ploting the cross tab\n\npd.crosstab(heart_disease.target,heart_disease.sex).plot(kind = \"bar\",\n                                                         figsize = (10,6),\n                                                         color=[\"hotpink\",\"blue\"]);\nplt.title(\"Heart Disease Frequency VS Sex\")\nplt.xlabel(\"1 - affected    0 - not affected\")\nplt.ylabel(\"no.of people\")\nplt.legend([\"Female\",\"Male\"]);"]}, {"cell_type": "markdown", "id": "2fd5c26d", "metadata": {}, "source": ["### Max heart rate(thalach)  VS  Age for heart disease"]}, {"cell_type": "code", "execution_count": 1, "id": "99aa00d4", "metadata": {}, "outputs": [], "source": ["heart_disease[\"thalach\"].value_counts()"]}, {"cell_type": "markdown", "id": "919fd1b6", "metadata": {}, "source": ["as the length is 91(91 differnt values) we cannot use bar graph "]}, {"cell_type": "code", "execution_count": 1, "id": "e0368e9f", "metadata": {}, "outputs": [], "source": ["# Scatter plot\nplt.figure(figsize = (10,6))\n\n# Scatter with positive examples\nplt.scatter(heart_disease.age[heart_disease.target == 1],\n            heart_disease.thalach[heart_disease.target == 1],\n            c=\"red\")\n\n#Scatter with negative examples\nplt.scatter(heart_disease.age[heart_disease.target == 0],\n            heart_disease.thalach[heart_disease.target == 0],\n            c=\"green\")\n\n# Labeling\nplt.title(\"Affected VS Not affected: AGE and MAX HEART RATE\")\nplt.xlabel(\"AGE\")\nplt.ylabel(\"HEART RATE\")\nplt.legend([\"Affected\",\"Not affected\"]);"]}, {"cell_type": "markdown", "id": "2f84bcaa", "metadata": {}, "source": ["As the finding the trend by ourself is dificult we will make the ML model to do the work for us"]}, {"cell_type": "code", "execution_count": 1, "id": "63d3f0ff", "metadata": {}, "outputs": [], "source": ["# Check how the data has been spread over\nheart_disease.age.plot.hist();"]}, {"cell_type": "markdown", "id": "862e64e5", "metadata": {}, "source": ["A perfectly distributed data looks like : https://www.simplypsychology.org/normal-distribution.html"]}, {"cell_type": "markdown", "id": "6f5b5353", "metadata": {}, "source": ["Here we are looking for outliers but we dont have any here"]}, {"cell_type": "markdown", "id": "f3be526e", "metadata": {}, "source": ["## Hear Disease vs Chest pain types\n Chest pain:\n* 0: Typical angina - related to heart\n* 1: Atypical angina - not related to heart\n* 2: Non-anginal - not related to heart\n* 3: Asymptomatic - not showing signs of disease"]}, {"cell_type": "code", "execution_count": 1, "id": "78df0db5", "metadata": {}, "outputs": [], "source": ["pd.crosstab(heart_disease.cp,heart_disease.target)"]}, {"cell_type": "code", "execution_count": 1, "id": "1875ef92", "metadata": {}, "outputs": [], "source": ["# Plot the crosstab\n\npd.crosstab(heart_disease.cp,heart_disease.target).plot(kind = \"bar\",\n                                                        figsize = (10,6),\n                                                        color = [\"green\",\"red\"])\n\nplt.title(\"Heart disease frequency for different chest pain\")\nplt.xlabel(\"Chest pain type\")\nplt.ylabel(\"Frequency\")\nplt.legend([\"No Disease\",\"Disease\"]);"]}, {"cell_type": "markdown", "id": "e1f66a78", "metadata": {}, "source": ["## Correlation between the Attributes and the target"]}, {"cell_type": "code", "execution_count": 1, "id": "29490fef", "metadata": {}, "outputs": [], "source": ["# Tabular format\nheart_disease.corr()"]}, {"cell_type": "code", "execution_count": 1, "id": "5ab54be5", "metadata": {}, "outputs": [], "source": ["# Visual format\ncorr_mat = heart_disease.corr()\nfig, ax = plt.subplots(figsize = (15,10))\nax = sns.heatmap(corr_mat,\n                 annot=True,\n                 linewidths=0.5,\n                 fmt=\".2f\",\n                 cmap=\"YlGnBu\")"]}, {"cell_type": "markdown", "id": "ccb799d5", "metadata": {}, "source": ["To know more about correlation : https://www.displayr.com/what-is-a-correlation-matrix/#:~:text=A%20correlation%20matrix%20is%20a,a%20diagnostic%20for%20advanced%20analyses."]}, {"cell_type": "markdown", "id": "63ad8bd2", "metadata": {}, "source": ["## Modeling \n* We have a classification problem\n\nTo know more about Supervised data Classification VS Regression:https://www.google.com/search?q=classification+vs+regression&rlz=1C1ONGR_enIN973IN973&oq=classification+vs+&aqs=chrome.0.0i433i512j0i512j69i57j0i512l7.9790j1j15&sourceid=chrome&ie=UTF-8"]}, {"cell_type": "code", "execution_count": 1, "id": "1dc3ce17", "metadata": {}, "outputs": [], "source": ["# Splitting the data\n\nx = heart_disease.drop(\"target\",axis=1)\ny = heart_disease[\"target\"]"]}, {"cell_type": "markdown", "id": "7460ce53", "metadata": {}, "source": ["Visualizing X an Y"]}, {"cell_type": "code", "execution_count": 1, "id": "967ddd13", "metadata": {}, "outputs": [], "source": ["x"]}, {"cell_type": "code", "execution_count": 1, "id": "8ba839d8", "metadata": {}, "outputs": [], "source": ["y"]}, {"cell_type": "code", "execution_count": 1, "id": "98b10d47", "metadata": {}, "outputs": [], "source": ["# Spliting the data into train and test dataset\n\n# to reproduce the exact data chosen\nnp.random.seed(42) \n\n# Actual splitting\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n"]}, {"cell_type": "markdown", "id": "eaeaa841", "metadata": {}, "source": ["why we need to split our data into test and train : https://docs.microsoft.com/en-us/analysis-services/data-mining/training-and-testing-data-sets?view=asallproducts-allversions#:~:text=Separating%20data%20into%20training%20and,of%20evaluating%20data%20mining%20models.&text=Because%20the%20data%20in%20the,the%20model's%20guesses%20are%20correct."]}, {"cell_type": "code", "execution_count": 1, "id": "9702b13e", "metadata": {}, "outputs": [], "source": ["x_train"]}, {"cell_type": "code", "execution_count": 1, "id": "68720a74", "metadata": {}, "outputs": [], "source": ["y_train,len(y_train)"]}, {"cell_type": "markdown", "id": "c46ed112", "metadata": {}, "source": ["### Train and Test the set by Fitting it into a Model"]}, {"cell_type": "markdown", "id": "47ce23da", "metadata": {}, "source": ["* LogisticRegression\n* KNeighbors\n* Ensembler(RandomForestClassifier)"]}, {"cell_type": "markdown", "id": "f8c1b4c4", "metadata": {}, "source": ["Yes we can use Logistic\"Regression\" for classification for more details : https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"]}, {"cell_type": "code", "execution_count": 1, "id": "e7d97e03", "metadata": {}, "outputs": [], "source": ["# Put models in a dictionary\nmodels = {\n          \"Logistic Regression\": LogisticRegression(solver='liblinear'), \n          \"KNN\": KNeighborsClassifier(),\n          \"Random Forest\": RandomForestClassifier()\n          }\n\n# Create function to fit and score models\ndef fit_and_score(models, x_train, x_test, y_train, y_test):\n    \"\"\"\n    Fits and evaluates given machine learning models.\n    models : a dict of different Scikit-Learn machine learning models\n    X_train : training data\n    X_test : testing data\n    y_train : labels assosciated with training data\n    y_test : labels assosciated with test data\n    \"\"\"\n    # Random seed for reproducible results\n    np.random.seed(42)\n    # Make a list to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit the model to the data\n        model.fit(x_train, y_train)\n        # Evaluate the model and append its score to model_scores\n        model_scores[name] = model.score(x_test, y_test)\n    return model_scores"]}, {"cell_type": "code", "execution_count": 1, "id": "43d15f54", "metadata": {}, "outputs": [], "source": ["model_scores = fit_and_score(models = models,\n                             x_train = x_train,\n                             x_test = x_test,\n                             y_train = y_train,\n                             y_test = y_test)\n\nmodel_scores"]}, {"cell_type": "markdown", "id": "64350552", "metadata": {}, "source": ["if we see in the above result Logistic Regression has higher value. "]}, {"cell_type": "markdown", "id": "09043989", "metadata": {}, "source": ["The above warning suggesting us an way to improve the logistic regression model"]}, {"cell_type": "markdown", "id": "50a17f4a", "metadata": {}, "source": ["## Model comparision"]}, {"cell_type": "code", "execution_count": 1, "id": "f746794c", "metadata": {}, "outputs": [], "source": ["model_compare = pd.DataFrame(model_scores, index = [\"accuracy\"])\nmodel_compare.T.plot.bar();"]}, {"cell_type": "markdown", "id": "75f9ca9f", "metadata": {}, "source": ["## Improving the model"]}, {"cell_type": "markdown", "id": "fe5ade12", "metadata": {}, "source": ["we are going to do the following:\n\n* Hyperparameter tuning\n* Feature importance\n* Confusion Matrix\n* Cross-validation\n* Precision (mean absolute error)\n* Recall (mean squared error)\n* F1 score (root mean squared error)\n* Classification report\n* ROC curve\n* Area Under the curve\n"]}, {"cell_type": "markdown", "id": "10f9fa24", "metadata": {}, "source": ["### Hyperparameter Tuning\n\n> KNN"]}, {"cell_type": "code", "execution_count": 1, "id": "9b265cde", "metadata": {}, "outputs": [], "source": ["# Tuning KNN\n\ntrain_score = []\ntest_score = []\n\n# Create a list of different values for n_neighbors\n\nneighbors = range(1,21)\n\n# Setup KNN instance\n\nknn = KNeighborsClassifier()\n\n# Loop through differnt n_neighbors\n\nfor i in neighbors:\n    knn.set_params(n_neighbors = i)\n    \n    # fit the algo\n    knn.fit(x_train,y_train)\n    \n    # Update the training score and test scores\n    \n    train_score.append(knn.score(x_train,y_train))\n    \n    test_score.append(knn.score(x_test,y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "154e16f2", "metadata": {}, "outputs": [], "source": ["train_score"]}, {"cell_type": "code", "execution_count": 1, "id": "ff84e6e8", "metadata": {}, "outputs": [], "source": ["test_score"]}, {"cell_type": "code", "execution_count": 1, "id": "0e0d22e4", "metadata": {}, "outputs": [], "source": ["plt.plot(neighbors, train_score, label = \"Train Score\")\nplt.plot(neighbors, test_score, label = \"Test Score\")\nplt.xticks(np.arange(1,21,1))\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Model Score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the test data: {max(test_score)*100:.2f}%\")"]}, {"cell_type": "markdown", "id": "a6e8fdf1", "metadata": {}, "source": ["The heighest score is 75.41%\n* [note] we can still try different range of n_neighbors int this case i tried some and stil didn't get anything to the mark"]}, {"cell_type": "markdown", "id": "4a359dd2", "metadata": {}, "source": ["Good bye KNN...."]}, {"cell_type": "markdown", "id": "2fb4b602", "metadata": {}, "source": ["## Hyperparameter with RandomizedSearchCV"]}, {"cell_type": "markdown", "id": "0331d539", "metadata": {}, "source": ["to know more about it : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"]}, {"cell_type": "markdown", "id": "86f61bf3", "metadata": {}, "source": ["> Logistic Regression\nAnd\n> RandomForest"]}, {"cell_type": "code", "execution_count": 1, "id": "0ffb14ba", "metadata": {}, "outputs": [], "source": ["# Create a hyperparameter grid for logostic regression\n\nlog_reg_grid = {\"C\" : np.logspace(-4, 4, 20),\n                \"solver\" : [\"liblinear\"]}\n\n# Create a hyperparameter for RandomForest Classifier\n\nrf_grid = {\"n_estimators\" : np.arange(10, 1000, 50),\n           \"max_depth\" : [None, 3, 5, 10],\n           \"min_samples_split\" : np.arange(2, 20, 2),\n           \"min_samples_leaf\" : np.arange(1, 20, 2)}"]}, {"cell_type": "code", "execution_count": 1, "id": "5a74f358", "metadata": {}, "outputs": [], "source": ["# Tune using RandomizedSearchCV\n\nnp.random.seed(42)\n\n# LogisticRegression\nrs_log_reg = RandomizedSearchCV(LogisticRegression(),\n                                param_distributions = log_reg_grid,\n                                cv = 5,\n                                n_iter = 20,\n                                verbose = True)\n# Fit the model\n\nrs_log_reg.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "31fc5823", "metadata": {}, "outputs": [], "source": ["# Check the best params\nrs_log_reg.best_params_"]}, {"cell_type": "code", "execution_count": 1, "id": "660fd990", "metadata": {}, "outputs": [], "source": ["rs_log_reg.score(x_test,y_test)"]}, {"cell_type": "markdown", "id": "25491235", "metadata": {}, "source": ["the model didnt improverd it remained the same, let leave it as it is for now"]}, {"cell_type": "markdown", "id": "70876020", "metadata": {}, "source": ["***RandomForestClassifier***"]}, {"cell_type": "code", "execution_count": 1, "id": "e5637e39", "metadata": {}, "outputs": [], "source": ["# Set the random seed\nnp.random.seed(42)\n\n#RandomForest\n\nrs_rf = RandomizedSearchCV(RandomForestClassifier(),\n                           param_distributions = rf_grid,\n                           cv = 5,\n                           n_iter = 20,\n                           verbose = True)\n\n# Fit the model\nrs_rf.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "6154daf2", "metadata": {}, "outputs": [], "source": ["# Best parameters\n\nrs_rf.best_params_"]}, {"cell_type": "code", "execution_count": 1, "id": "af04b47b", "metadata": {}, "outputs": [], "source": ["rs_rf.score(x_test,y_test)"]}, {"cell_type": "markdown", "id": "b354d15b", "metadata": {}, "source": ["The score has certainly increased by 0.32"]}, {"cell_type": "markdown", "id": "892c5079", "metadata": {}, "source": ["But still Logistic Regression holds upperhand here"]}, {"cell_type": "markdown", "id": "c690e38a", "metadata": {}, "source": ["bye bye RandomForestRegression..."]}, {"cell_type": "markdown", "id": "0f63ee96", "metadata": {}, "source": ["### Improving the Logistic model\n\nLet revisit what we did while improving the model\n* By hand - KNN eliminated\n* RandomizedSearchCv - RandomForestClassification eliminated\n* GridSearchCv - upcoming..."]}, {"cell_type": "markdown", "id": "a249103c", "metadata": {}, "source": ["## Tuning Hyperperameter using GridSearchCv\n> LogisticRegression\n"]}, {"cell_type": "markdown", "id": "950a411a", "metadata": {}, "source": ["to know more about GridSearchCv : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"]}, {"cell_type": "code", "execution_count": 1, "id": "315eef4d", "metadata": {}, "outputs": [], "source": ["# Set up hyperparameter\nlog_reg_grid = {\"C\" : np.logspace(-4, 4, 20),\n                \"solver\" : [\"liblinear\"]}\n\n# Set the grid \ngs_log_reg = GridSearchCV(LogisticRegression(),\n                          param_grid = log_reg_grid,\n                          cv = 5,\n                          verbose = True)\n\n# Fit the model\ngs_log_reg.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "e65e6460", "metadata": {}, "outputs": [], "source": ["# Check the best parameters\ngs_log_reg.best_params_"]}, {"cell_type": "code", "execution_count": 1, "id": "f28dbf46", "metadata": {}, "outputs": [], "source": ["# Evaluate\n\ngs_log_reg.score(x_test,y_test)"]}, {"cell_type": "markdown", "id": "1da2b139", "metadata": {}, "source": ["Still we did get the same as baseline and RandomizedSearchCV :\\"]}, {"cell_type": "markdown", "id": "c2f0491e", "metadata": {}, "source": ["## Evaluating the models beyond score\n* ROC curve & AUC score \n* Confusion matrix\n* Classification report\n    * Precision\n    * Recall\n    * F1 score"]}, {"cell_type": "markdown", "id": "94f6a055", "metadata": {}, "source": [" We have to make prediction inorder to compare the models"]}, {"cell_type": "code", "execution_count": 1, "id": "8b6e5637", "metadata": {}, "outputs": [], "source": ["y_pred = gs_log_reg.predict(x_test)\n\ny_pred"]}, {"cell_type": "markdown", "id": "2627acd9", "metadata": {}, "source": ["> ROC curve & AUC score\n\n* Check out this link : https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc#:~:text=An%20ROC%20curve%20"]}, {"cell_type": "markdown", "id": "2bd1efe4", "metadata": {}, "source": ["perfect model AUC score = 1"]}, {"cell_type": "code", "execution_count": 1, "id": "6c55a05f", "metadata": {}, "outputs": [], "source": ["plot_roc_curve(gs_log_reg, x_test, y_test);"]}, {"cell_type": "markdown", "id": "c53fac2c", "metadata": {}, "source": ["AUC score = 0.92"]}, {"cell_type": "markdown", "id": "9580fadb", "metadata": {}, "source": ["> Confusion matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "b46e321f", "metadata": {}, "outputs": [], "source": ["def plot_conf_mat(y_test,y_preds):\n    fig, ax = plt.subplots(figsize=(3,3))\n    ax = sns.heatmap(confusion_matrix(y_test,y_preds),\n                     annot = True,\n                     cbar = False)\n    \n    plt.xlabel(\"Predicted label\")\n    plt.ylabel(\"True label\")\n    \nplot_conf_mat(y_test,y_pred)"]}, {"cell_type": "markdown", "id": "8fb737e1", "metadata": {}, "source": ["> Classification report\n\n* Precision\n* Recall\n* F1 score"]}, {"cell_type": "code", "execution_count": 1, "id": "e5bb06a2", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test,y_pred))"]}, {"cell_type": "markdown", "id": "32f9cabe", "metadata": {}, "source": ["These are calculates only with single split"]}, {"cell_type": "markdown", "id": "3e49e930", "metadata": {}, "source": ["### Using cross validation\n> Classification report\n\n* Accuracy\n* Precision\n* Recall\n* F1 score"]}, {"cell_type": "code", "execution_count": 1, "id": "3e881f52", "metadata": {}, "outputs": [], "source": ["# Create a new classifier using best params\n\nclf  = LogisticRegression(C=0.23357214690901212,\n                          solver = \"liblinear\")"]}, {"cell_type": "code", "execution_count": 1, "id": "2e05f643", "metadata": {}, "outputs": [], "source": ["# Cross-validated Accuracy\n\ncv_acc = cross_val_score(clf,x,y,cv=5,scoring=\"accuracy\")\n\ncv_acc\n\nacc_mean = np.mean(cv_acc)\nacc_mean"]}, {"cell_type": "code", "execution_count": 1, "id": "c1d1a62b", "metadata": {}, "outputs": [], "source": ["# Cross-validated Precision\n\ncv_pre = cross_val_score(clf,x,y,cv=5,scoring=\"precision\")\n\ncv_pre\n\npre_mean = np.mean(cv_pre)\npre_mean"]}, {"cell_type": "code", "execution_count": 1, "id": "e211a3e1", "metadata": {}, "outputs": [], "source": ["# Cross-validated Recall\n\ncv_re = cross_val_score(clf,x,y,cv=5,scoring=\"recall\")\n\ncv_re\n\nre_mean = np.mean(cv_re)\nre_mean"]}, {"cell_type": "code", "execution_count": 1, "id": "388ec408", "metadata": {}, "outputs": [], "source": ["# Cross-validated F1 score\n\ncv_f1 = cross_val_score(clf,x,y,cv=5,scoring=\"f1\")\n\ncv_f1\n\nf1_mean = np.mean(cv_f1)\nf1_mean"]}, {"cell_type": "code", "execution_count": 1, "id": "9183e52e", "metadata": {}, "outputs": [], "source": ["# Visualizing cross validated matrix\n\ncv_metrics = pd.DataFrame({\"Accuracy\":acc_mean,\n                           \"Precision\":pre_mean,\n                           \"Recall\":re_mean,\n                           \"F1\":f1_mean},\n                            index = [0])\ncv_metrics.T.plot.bar(title = \"Crovalidated Classification Report\",legend = False);"]}, {"cell_type": "markdown", "id": "658c808f", "metadata": {}, "source": ["## Important Features"]}, {"cell_type": "markdown", "id": "64a6d67b", "metadata": {}, "source": ["> This is different for different models\n\nfor LogisticRegression"]}, {"cell_type": "code", "execution_count": 1, "id": "d329eff8", "metadata": {}, "outputs": [], "source": ["clf  = LogisticRegression(C=0.23357214690901212,\n                          solver = \"liblinear\")\n\n# fit the model\n\nclf.fit(x_train,y_train);"]}, {"cell_type": "code", "execution_count": 1, "id": "06f701fd", "metadata": {}, "outputs": [], "source": ["# Coefficient : how the attributes contribute for prediction\nclf.coef_"]}, {"cell_type": "code", "execution_count": 1, "id": "2e2f6130", "metadata": {}, "outputs": [], "source": ["# Match the coefficient to the columns\nfeature_dict = dict(zip(heart_disease.columns,list(clf.coef_[0])))\nfeature_dict"]}, {"cell_type": "code", "execution_count": 1, "id": "89f4888d", "metadata": {}, "outputs": [], "source": ["# Visualize it\nfeature_df = pd.DataFrame(feature_dict, index = [0])\nfeature_df.T.plot.bar(title=\"Feature Importance\",legend = False);"]}, {"cell_type": "markdown", "id": "9fa3b41b", "metadata": {}, "source": ["We can analyse the above graph and improve our dataset much more"]}, {"cell_type": "markdown", "id": "a07d69da", "metadata": {}, "source": ["# Conclusion\n* We got accuracy of 88.5% which is low in this case\n* We cannot practically implement it\n\n> Want we can do?\n\n* Try better model like CatBoost or XGBoost\n* Try to collect more data"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}