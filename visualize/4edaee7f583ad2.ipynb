{"cells": [{"cell_type": "code", "execution_count": 1, "id": "dc004f0c", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras"]}, {"cell_type": "code", "execution_count": 1, "id": "6caa0b37", "metadata": {}, "outputs": [], "source": ["N = 200 #Number of observations per class\nD = 2   #Number of features\nK = 3   #Number of classes\nX = np.zeros((N * K, D))\ny = np.zeros(N * K, dtype = 'uint8')\nfor j in range(K):\n    ix = range(N * j, N * (j + 1))\n    r = np.linspace(0, 1, N) \n    np.random.seed(j)\n    t = np.linspace(j * 4,(j + 1) * 5, N) + np.random.randn(N) * 0.25 \n    X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n    y[ix] = j\n\n#Plot Data\ncdict = {0: 'red', 1: 'blue', 2: 'green'}\nplt.figure(figsize = (8, 8))\nfor i in np.unique(y):\n    indices = np.where(y == i)\n    plt.scatter(x = X[indices, 0], y = X[indices, 1], c = cdict[i], \n                label = i, marker = \"o\", alpha = 0.7)\nplt.legend()"]}, {"cell_type": "code", "execution_count": 1, "id": "97d4576a", "metadata": {}, "outputs": [], "source": ["X.shape"]}, {"cell_type": "markdown", "id": "25d8cce0", "metadata": {}, "source": ["# Devide your dataset into train(80%) and test(20%).\n"]}, {"cell_type": "code", "execution_count": 1, "id": "df1e8340", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\nprint(f'The shape of X_train is: {X_train.shape}')\nprint(f'The shape of y_train is: {y_train.shape}')\nprint(f'The shape of X_test is: {X_test.shape}')\nprint(f'The shape of y_test is: {y_test.shape}')"]}, {"cell_type": "code", "execution_count": 1, "id": "f3a7ef95", "metadata": {}, "outputs": [], "source": ["pd.Series(y_train).value_counts()\n# It seems that in each category the distribution of data is balanced."]}, {"cell_type": "code", "execution_count": 1, "id": "c857a5a2", "metadata": {}, "outputs": [], "source": ["pd.Series(y_test).value_counts()\n# It seems that in each category the distribution of data is balanced."]}, {"cell_type": "code", "execution_count": 1, "id": "6caf9847", "metadata": {}, "outputs": [], "source": ["# Visualize the train and test dataset to see how data are distributed.\ncdict = {0: 'red', 1: 'blue', 2: 'green'}\nplt.figure(figsize = (8, 8))\nfor i in np.unique(y_train):\n    indices = np.where(y_train == i)\n    plt.scatter(x = X_train[indices, 0], y = X_train[indices, 1], c = cdict[i], \n                label = i, marker = \"o\", alpha = 0.7)\nplt.legend()\nplt.title('X_train', size = 20)"]}, {"cell_type": "code", "execution_count": 1, "id": "cd426592", "metadata": {}, "outputs": [], "source": ["# Visualize the train and test dataset to see how data are distributed.\ncdict = {0: 'red', 1: 'blue', 2: 'green'}\nplt.figure(figsize = (8, 8))\nfor i in np.unique(y_test):\n    indices = np.where(y_test == i)\n    plt.scatter(x = X_test[indices, 0], y = X_test[indices, 1], c = cdict[i], \n                label = i, marker = \"o\", alpha = 0.7)\nplt.legend()\nplt.title('X_test', size = 20)"]}, {"cell_type": "markdown", "id": "665e6da5", "metadata": {}, "source": ["### Q1: Create softmax regression to classify the observations on train dataset.\n###    Use the model to predict on test dataset. Report the accuracy of your model.\n###    Visualize your results."]}, {"cell_type": "markdown", "id": "a29d0b6f", "metadata": {}, "source": ["# Softmax Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "30189965", "metadata": {}, "outputs": [], "source": ["type(X_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "ef42a62a", "metadata": {}, "outputs": [], "source": ["features_train = tf.convert_to_tensor(X_train, dtype = tf.float32)\nfeatures_train"]}, {"cell_type": "code", "execution_count": 1, "id": "5b8f4376", "metadata": {}, "outputs": [], "source": ["response_train = tf.convert_to_tensor(y_train, dtype = tf.float32)\nresponse_train"]}, {"cell_type": "code", "execution_count": 1, "id": "338609fb", "metadata": {}, "outputs": [], "source": ["n_features = features_train.shape[1]\nn_outcomes = len(np.unique(response_train))\nprint(f'The Number of Features : {n_features}')\nprint(f'The Number of Outcomes : {n_outcomes}')\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a0a1e9f8", "metadata": {}, "outputs": [], "source": ["# One-hot Encoding for Categorical Variable\nresponse_one_hot = tf.one_hot(response_train.numpy(), depth = n_outcomes)\nresponse_one_hot"]}, {"cell_type": "code", "execution_count": 1, "id": "73aaf6c7", "metadata": {}, "outputs": [], "source": ["# Reading Data in Batch\ndef read_batch(batch_size, X, y):\n    sample_size = X.shape[0]\n    indices = list(range(sample_size))\n    np.random.shuffle(indices)           #read data at random\n    for i in range(0, sample_size, batch_size):\n        batch_indices = tf.constant(indices[i : min(i + batch_size, sample_size)])\n        yield tf.gather(X, batch_indices), tf.gather(y, batch_indices)\n        #use yield to iterate over a sequence, but not to store the entire sequence in memory"]}, {"cell_type": "code", "execution_count": 1, "id": "bcdc81d8", "metadata": {}, "outputs": [], "source": ["#Initialize Model Parameters\nw = tf.Variable(tf.random.normal(shape = (n_features, n_outcomes), mean = 0, stddev = 0.01))\nb = tf.Variable(tf.zeros(n_outcomes))"]}, {"cell_type": "code", "execution_count": 1, "id": "eab5e0b9", "metadata": {}, "outputs": [], "source": ["# Softmax Function\ndef softmax(X):\n    return tf.exp(X) / tf.reduce_sum(tf.exp(X), 1, keepdims = True) #reduction over rows"]}, {"cell_type": "code", "execution_count": 1, "id": "96cdc44d", "metadata": {}, "outputs": [], "source": ["# Prediction Function\ndef pred_func(w, b , X):\n    return softmax(tf.matmul(tf.reshape(X, (-1, w.shape[0])), w) + b)"]}, {"cell_type": "code", "execution_count": 1, "id": "a9543fb4", "metadata": {}, "outputs": [], "source": ["# Define the Optimization Algorithm\ndef sgd(params, grads, learning_rate, batch_size):\n    # Batch Stochastic Gradient Descent\n    for param, grad in zip(params, grads):\n        param.assign_sub(learning_rate * grad / batch_size)"]}, {"cell_type": "code", "execution_count": 1, "id": "67c0947e", "metadata": {}, "outputs": [], "source": ["batch_size = 30\nlearning_rate = 0.3\nnum_epochs = 100\nlosses = []\nfor epoch in range(num_epochs):\n    for X, y in read_batch(20, features_train, response_train):\n        #Compute Gradients and Update Parameters\n        with tf.GradientTape() as g:\n            #One-hot Encoding for Categorical Variable\n            y_one_hot = tf.one_hot(y.numpy(), depth = n_outcomes)\n            y_pred = pred_func(w, b, X)\n            loss   = tf.keras.losses.categorical_crossentropy(y_one_hot, y_pred)\n            dloss_w, dloss_b = g.gradient(loss, [w, b])\n        #Update parameters using their gradients\n        sgd([w, b], [dloss_w, dloss_b], learning_rate, batch_size)\n    train_l = tf.keras.losses.categorical_crossentropy(response_one_hot, pred_func(w, b, features_train))\n    losses.append(float(tf.reduce_mean(train_l)))\n    print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_l)): 0.4f}')"]}, {"cell_type": "code", "execution_count": 1, "id": "3708fac5", "metadata": {}, "outputs": [], "source": ["plt.plot(losses);"]}, {"cell_type": "code", "execution_count": 1, "id": "75f45f8e", "metadata": {}, "outputs": [], "source": ["#Prediction on Train \ny_pred_train = pred_func(w = w, b = b, X = features_train)\ny_pred_train"]}, {"cell_type": "code", "execution_count": 1, "id": "f1ed26c6", "metadata": {}, "outputs": [], "source": ["y_pred_train = np.argmax(y_pred_train, axis = 1)\ny_pred_train"]}, {"cell_type": "code", "execution_count": 1, "id": "f30c836d", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score, confusion_matrix\nprint(f'The accuracy is : {accuracy_score(y_pred_train, y_train)} \\n\\n The confusion matrix is :\\n\\n {confusion_matrix(y_pred_train, y_train)} ')"]}, {"cell_type": "markdown", "id": "e2f9f1f4", "metadata": {}, "source": ["## Prediction On Test"]}, {"cell_type": "code", "execution_count": 1, "id": "3415faa4", "metadata": {}, "outputs": [], "source": ["features_test = tf.convert_to_tensor(X_test, dtype = tf.float32)\nfeatures_test"]}, {"cell_type": "code", "execution_count": 1, "id": "ccea4612", "metadata": {}, "outputs": [], "source": ["response_test = tf.convert_to_tensor(y_test, dtype = tf.float32)\nresponse_test"]}, {"cell_type": "code", "execution_count": 1, "id": "4a2e0651", "metadata": {}, "outputs": [], "source": ["#Prediction on Test\ny_pred_test = pred_func(w = w, b = b, X = features_test)\ny_pred_test"]}, {"cell_type": "code", "execution_count": 1, "id": "47f75be0", "metadata": {}, "outputs": [], "source": ["y_pred_test = np.argmax(y_pred_test, axis = 1)\ny_pred_test"]}, {"cell_type": "code", "execution_count": 1, "id": "8c0f8cae", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score, confusion_matrix\nprint(f'The accuracy is : {accuracy_score(y_pred_test, y_test)} \\n\\n The confusion matrix is :\\n\\n {confusion_matrix(y_pred_test, y_test)} ')"]}, {"cell_type": "code", "execution_count": 1, "id": "e2c80773", "metadata": {}, "outputs": [], "source": ["#Plot Data\ncdict = {0: 'red', 1: 'blue', 2: 'green', 3: 'yellow'}\nplt.figure(figsize = (6, 6))\nfor i in np.unique(response_test):\n    indices = np.where(response_test == i)\n    plt.scatter(x = features_test.numpy()[indices, 0], y = features_test.numpy()[indices, 1], \n                c = cdict[i], label = i,\n                marker = \"o\", alpha = 0.7)\nplt.legend()\n\n#Plot Regions\nx1, x2 = np.meshgrid(np.linspace(features_test.numpy().min() - 1, features_test.numpy().max() + 1, 500), \n                     np.linspace(features_test.numpy().min() - 1, features_test.numpy().max() + 1, 500))\ngrids = np.array((x1.ravel(), x2.ravel())).T\ngrids = tf.convert_to_tensor(grids, dtype = tf.float32)\nregion_pred = pred_func(w = w, b = b, X = grids)\nregion_color = np.argmax(region_pred, axis = 1)\nregion_color = region_color.reshape(500, 500)\nplt.contourf(x1, x2, region_color, alpha = 0.1, levels = [0, 0.5, 1, 2, 3], \n             colors = ['red', 'blue', 'green', 'yellow'])"]}, {"cell_type": "markdown", "id": "2ad97144", "metadata": {}, "source": ["# Q2: Create a multi layer perceptron to classify the observations on train dataset.\n* **Use the model to predict on test dataset. Report the accuracy of your model.**\n* **Visualize your results.**"]}, {"cell_type": "markdown", "id": "0ca4bb6f", "metadata": {}, "source": ["# Multi-layer perceptron"]}, {"cell_type": "code", "execution_count": 1, "id": "20ea06f8", "metadata": {}, "outputs": [], "source": ["from keras import Sequential\nfrom keras.layers import Dense"]}, {"cell_type": "code", "execution_count": 1, "id": "3d26a447", "metadata": {}, "outputs": [], "source": ["#Scale Features\nfrom sklearn.preprocessing import StandardScaler\n#Initialize the scaler\nscaler = StandardScaler()\n# fit Scaler on features\nX_train = scaler.fit_transform(X_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "8e12a452", "metadata": {}, "outputs": [], "source": ["y_train = keras.utils.to_categorical(y_train)\ny_train"]}, {"cell_type": "code", "execution_count": 1, "id": "3da42b3e", "metadata": {}, "outputs": [], "source": ["model = Sequential()\nmodel.add(Dense(6, activation = 'tanh', input_shape = (2, )))\nmodel.add(Dense(6, activation = 'tanh'))\nmodel.add(Dense(6, activation = 'tanh'))\nmodel.add(Dense(6, activation = 'tanh'))\nmodel.add(Dense(3, activation = 'softmax'))\n\n#Configure the Model\nopt = keras.optimizers.RMSprop() \nmodel.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"]}, {"cell_type": "code", "execution_count": 1, "id": "3969f05e", "metadata": {}, "outputs": [], "source": ["#Train the Model\nhistory = model.fit(X_train, y_train, epochs = 500, batch_size = 32, verbose = 1, validation_split  = 0.2)"]}, {"cell_type": "code", "execution_count": 1, "id": "b9f68c9a", "metadata": {}, "outputs": [], "source": ["#Loss - Epochs\nplt.figure(figsize = (8, 6))\nplt.plot(model.history.history['loss'], label = 'train')\nplt.plot(model.history.history['val_loss'], alpha = 0.7, label = 'test')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc = 'upper left')\nplt.grid()"]}, {"cell_type": "code", "execution_count": 1, "id": "9f120c5b", "metadata": {}, "outputs": [], "source": ["#Loss - Epochs\nplt.figure(figsize = (8, 6))\nplt.plot(model.history.history['accuracy'], label = 'train')\nplt.plot(model.history.history['val_accuracy'], alpha = 0.7, label = 'test')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc = 'upper left')\nplt.grid()"]}, {"cell_type": "code", "execution_count": 1, "id": "9d4ecaf6", "metadata": {}, "outputs": [], "source": ["y_pred = model.predict(X_train)\ny_pred"]}, {"cell_type": "code", "execution_count": 1, "id": "ab74cc84", "metadata": {}, "outputs": [], "source": ["y_pred = np.argmax(y_pred, axis = 1)\ny_pred"]}, {"cell_type": "code", "execution_count": 1, "id": "af71631b", "metadata": {}, "outputs": [], "source": ["accuracy_score(y_pred, np.argmax(y_train, axis = 1))"]}, {"cell_type": "code", "execution_count": 1, "id": "9bc1149e", "metadata": {}, "outputs": [], "source": ["#Scale Features\nfrom sklearn.preprocessing import StandardScaler\n#Initialize the scaler\nscaler = StandardScaler()\n# fit Scaler on features\nX_test = scaler.fit_transform(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "2d4b6b03", "metadata": {}, "outputs": [], "source": ["y_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis = 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "4e1018cd", "metadata": {}, "outputs": [], "source": ["accuracy_score(y_pred, y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "639e474c", "metadata": {}, "outputs": [], "source": ["confusion_matrix(y_pred, y_test)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}