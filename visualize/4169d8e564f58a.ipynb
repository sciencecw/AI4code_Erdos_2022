{"cells": [{"cell_type": "code", "execution_count": 1, "id": "1c838062", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nimport string\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.metrics import accuracy_score # for evaluating results\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "d78e2910", "metadata": {}, "source": ["**Load data** "]}, {"cell_type": "code", "execution_count": 1, "id": "f6352b52", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "33b923a9", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "9eaaed2a", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "markdown", "id": "8aa45d58", "metadata": {}, "source": ["**Processing data**"]}, {"cell_type": "code", "execution_count": 1, "id": "e523bb18", "metadata": {}, "outputs": [], "source": ["# Load stop word\neng_stopwords = set(stopwords.words(\"english\"))"]}, {"cell_type": "code", "execution_count": 1, "id": "479f9f07", "metadata": {}, "outputs": [], "source": ["def processingData(train, test):\n    # Tokenize\n    train['question_text'] = train[\"question_text\"].apply(lambda x: \" \".join(word_tokenize(str(x))))\n    test['question_text'] = test[\"question_text\"].apply(lambda x: \" \".join(word_tokenize(str(x))))\n\n    # Remove punctuation\n    train['question_text'] = train[\"question_text\"].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n    test['question_text'] = test[\"question_text\"].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n\n    ## Remove stopwords in the text ##\n    train[\"question_text\"] = train[\"question_text\"].apply(lambda x: \" \".join([w for w in str(x).lower().split() if not w in eng_stopwords]))\n    test[\"question_text\"] = test[\"question_text\"].apply(lambda x: \" \".join([w for w in str(x).lower().split() if not w in eng_stopwords]))\n    \n    return train, test"]}, {"cell_type": "code", "execution_count": 1, "id": "f5e82c04", "metadata": {}, "outputs": [], "source": ["train, test = processingData(train, test)"]}, {"cell_type": "code", "execution_count": 1, "id": "7014431c", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "c918e5a1", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "markdown", "id": "bd29afc5", "metadata": {}, "source": ["**Extracting features from text**"]}, {"cell_type": "code", "execution_count": 1, "id": "c981ae08", "metadata": {}, "outputs": [], "source": ["train_question_list = train['question_text']\ntest_question_list = test['question_text']\n\nvectorizer  = CountVectorizer()\n\nx_train =  vectorizer.fit_transform(train_question_list)\nx_test =  vectorizer.transform(test_question_list)"]}, {"cell_type": "code", "execution_count": 1, "id": "1fbd113b", "metadata": {}, "outputs": [], "source": ["y_train_tfidf = np.array(train[\"target\"].tolist())"]}, {"cell_type": "code", "execution_count": 1, "id": "53bbde81", "metadata": {}, "outputs": [], "source": ["train_x, validate_x, train_y, validate_y = train_test_split(x_train, y_train_tfidf, test_size=0.3)"]}, {"cell_type": "markdown", "id": "afac2742", "metadata": {}, "source": ["**Training**"]}, {"cell_type": "code", "execution_count": 1, "id": "c6e09a67", "metadata": {}, "outputs": [], "source": ["clf = MultinomialNB()\nclf.fit(train_x, train_y)\ny_vad = clf.predict(validate_x)\nprint('accuracy = %.2f%%' % \\\n      (accuracy_score(validate_y, y_vad)*100))"]}, {"cell_type": "markdown", "id": "fc51ec9f", "metadata": {}, "source": ["**Prediction**"]}, {"cell_type": "code", "execution_count": 1, "id": "686f5a61", "metadata": {}, "outputs": [], "source": ["y_predict = clf.predict(x_test)\npredict = pd.DataFrame(data = y_predict, columns=['prediction'])\npredict = predict.astype(int)"]}, {"cell_type": "markdown", "id": "c0ef5d7f", "metadata": {}, "source": ["**Extracting result**"]}, {"cell_type": "code", "execution_count": 1, "id": "f11d86c1", "metadata": {}, "outputs": [], "source": ["id = test['qid']\nid_df = pd.DataFrame(id)\n# Join predicted into result dataframe and write result as a CSV file\nresult = id_df.join(predict)\nresult.to_csv(\"submission.csv\", index = False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}