{"cells": [{"cell_type": "code", "execution_count": 1, "id": "ddfae49e", "metadata": {}, "outputs": [], "source": ["DEGUB = False"]}, {"cell_type": "markdown", "id": "825e5b93", "metadata": {}, "source": ["## Libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "959ac13b", "metadata": {}, "outputs": [], "source": ["import os\nfrom logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer\n\n%matplotlib inline\ntqdm.pandas()"]}, {"cell_type": "code", "execution_count": 1, "id": "3de4926f", "metadata": {}, "outputs": [], "source": ["def get_logger(\n    filename=\"log\",\n    disable_stream_handler=False,\n    disable_file_handler=False\n):\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n\n    if not disable_stream_handler:\n        handler1 = StreamHandler()\n        handler1.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler1)\n\n    if not disable_file_handler:\n        handler2 = FileHandler(filename=f\"{filename}.log\")\n        handler2.setFormatter(Formatter(\"%(message)s\"))\n        logger.addHandler(handler2)\n\n    return logger"]}, {"cell_type": "markdown", "id": "1bbe0207", "metadata": {}, "source": ["## Loading"]}, {"cell_type": "code", "execution_count": 1, "id": "9d363a3c", "metadata": {}, "outputs": [], "source": ["logger = get_logger(\"log\")\n\nINPUT_DIR = \"../input/ailab-ml-training-2/\"\n\ntrain_df = pd.read_csv(os.path.join(INPUT_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(INPUT_DIR, \"test.csv\"))\n\npretrained_weights = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(pretrained_weights)\nbackbone = BertModel.from_pretrained(pretrained_weights)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]}, {"cell_type": "markdown", "id": "16a7cdfb", "metadata": {}, "source": ["## Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "f5ccd611", "metadata": {}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "39045ab2", "metadata": {}, "outputs": [], "source": ["train_df = train_df.fillna({\"item_description\": \"No description.\"})\ntest_df = test_df.fillna({\"item_description\": \"No description.\"})"]}, {"cell_type": "code", "execution_count": 1, "id": "4682976e", "metadata": {}, "outputs": [], "source": ["train_df[\"item_description_length\"] = train_df[\"item_description\"].progress_apply(lambda x: len(x.split()))\ntest_df[\"item_description_length\"] = test_df[\"item_description\"].progress_apply(lambda x: len(x.split()))\nprint(max(train_df[\"item_description_length\"].max(), test_df[\"item_description_length\"].max()))\nsns.distplot(train_df[\"item_description_length\"], kde=False, label=\"train\")\nsns.distplot(test_df[\"item_description_length\"], kde=False, label=\"test\")\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "0f595e89", "metadata": {}, "outputs": [], "source": ["train_df[\"price_log1p\"] = np.log1p(train_df[\"price\"])"]}, {"cell_type": "markdown", "id": "2f606c16", "metadata": {}, "source": ["## Dataset/Module"]}, {"cell_type": "code", "execution_count": 1, "id": "e822141c", "metadata": {}, "outputs": [], "source": ["class MercariDataset(Dataset):\n    def __init__(self, names, descriptions, prices, tokenizer, maxlen=512):\n        super().__init__()\n        self.names = names\n        self.descriptions = descriptions\n        self.prices = prices\n        self.tokenizer = tokenizer\n        self.maxlen = maxlen\n    \n    def __len__(self):\n        return len(self.names)\n    \n    def __getitem__(self, idx):\n        name = self.names[idx]\n        description = self.descriptions[idx]\n        \n        tokens = tokenizer.encode(name, description, max_length=self.maxlen, pad_to_max_length=True)\n        tokens = torch.tensor(tokens)\n        attn_mask = (tokens != 0).long()\n        price = torch.tensor(self.prices[idx])\n        \n        return tokens, attn_mask, price"]}, {"cell_type": "code", "execution_count": 1, "id": "2159ee3a", "metadata": {}, "outputs": [], "source": ["class MercariBert(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n        self.reg_fc = nn.Linear(768, 1, bias=True)\n    \n    def forward(self, x, mask):\n        x, _ = self.backbone(x, attention_mask=mask)\n        x = x[:, 0]\n        x = self.reg_fc(x)\n        return x"]}, {"cell_type": "markdown", "id": "a46988e4", "metadata": {}, "source": ["## Training"]}, {"cell_type": "code", "execution_count": 1, "id": "c9ea1f44", "metadata": {}, "outputs": [], "source": ["dev_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True)\ndev_df = dev_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\nlogger.info(f\"dev: {len(dev_df)}, val: {len(val_df)}\")"]}, {"cell_type": "code", "execution_count": 1, "id": "cc497c5b", "metadata": {}, "outputs": [], "source": ["dev_datasets = MercariDataset(dev_df[\"name\"], dev_df[\"item_description\"], dev_df[\"price_log1p\"],\n                              tokenizer=tokenizer, maxlen=128)\nval_datasets = MercariDataset(val_df[\"name\"], val_df[\"item_description\"], val_df[\"price_log1p\"],\n                              tokenizer=tokenizer, maxlen=128)\n\ndev_dataloader = DataLoader(dev_datasets, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_datasets, batch_size=32, shuffle=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "e9d70f86", "metadata": {}, "outputs": [], "source": ["model = MercariBert(backbone).to(DEVICE)\noptimizer = Adam(model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()"]}, {"cell_type": "code", "execution_count": 1, "id": "914e70d4", "metadata": {}, "outputs": [], "source": ["for epoch in tqdm(range(1)):\n    dev_losses = []\n    model.train()\n    for i, (x, mask, y) in enumerate(tqdm(dev_dataloader, leave=False)):\n        optimizer.zero_grad()\n        \n        x = x.to(dtype=torch.long, device=DEVICE)\n        mask = mask.to(dtype=torch.long, device=DEVICE)\n        y = y.to(dtype=torch.float32, device=DEVICE)\n        \n        y_pred = model(x, mask).view(-1)\n        loss = criterion(y_pred, y)\n        loss.backward()\n        optimizer.step()\n        \n        dev_losses.append(loss.item())\n        \n        if (i + 1) % 200 == 0:\n            logger.info(\"iter: {}/{}, moving loss - {:.5f}\".format(\n                i + 1, len(dev_dataloader), np.mean(dev_losses[-200:])\n            ))\n        \n        if DEGUB and (i + 1) >= 400:\n            break\n    \n    val_losses = []\n    model.eval()\n    for i, (x, mask, y) in enumerate(val_dataloader):\n        x = x.to(dtype=torch.long, device=DEVICE)\n        mask = mask.to(dtype=torch.long, device=DEVICE)\n        y = y.to(dtype=torch.float32, device=DEVICE)\n        \n        with torch.no_grad():\n            y_pred = model(x, mask).view(-1)\n            loss = criterion(y_pred, y)\n        \n        val_losses.append(loss.item())\n        \n        if DEGUB and (i + 1) >= 400:\n            break\n    \n    logger.info(\"epoch: {}, loss - {:.5f}, val_loss - {:.5f}\".format(\n        epoch + 1, np.mean(dev_losses), np.mean(val_losses)\n    ))"]}, {"cell_type": "markdown", "id": "77284203", "metadata": {}, "source": ["## Inference"]}, {"cell_type": "code", "execution_count": 1, "id": "8b891168", "metadata": {}, "outputs": [], "source": ["test_datasets = MercariDataset(test_df[\"name\"], test_df[\"item_description\"], test_df[\"shipping\"],\n                               tokenizer=tokenizer, maxlen=128)\ntest_dataloader = DataLoader(test_datasets, batch_size=32, shuffle=False)\n\ntest_preds = []\nmodel.eval()\nfor i, (x, mask, _) in enumerate(tqdm(test_dataloader)):\n    x = x.to(dtype=torch.long, device=DEVICE)\n    mask = mask.to(dtype=torch.long, device=DEVICE)\n    with torch.no_grad():\n        y_pred = model(x, mask).view(-1)\n    test_preds.append(y_pred.cpu().numpy())\n    if DEGUB and (i + 1) >= 400:\n        break\ntest_preds = np.concatenate(test_preds, axis=0)\n\ntest_preds = np.where(test_preds < 0.0, 0.0, test_preds)\ntest_preds = np.exp(test_preds) - 1"]}, {"cell_type": "code", "execution_count": 1, "id": "08320dc5", "metadata": {}, "outputs": [], "source": ["sub_df = pd.DataFrame()\nsub_df[\"test_id\"] = test_df[\"test_id\"]\nsub_df[\"price\"] = test_preds\nsub_df.to_csv(\"submission.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}