{"cells": [{"cell_type": "code", "execution_count": 1, "id": "a8a4365e", "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\nimport keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPool2D, UpSampling2D, GlobalMaxPool2D, GlobalAveragePooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import to_categorical, plot_model\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import NASNetMobile, Xception, DenseNet121, MobileNetV2, InceptionV3, InceptionResNetV2, vgg16, resnet50, inception_v3, xception, DenseNet201\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import CSVLogger\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import jaccard_score\n\nfrom scipy import stats\n\nimport seaborn as sns\n\nimport skimage\nfrom skimage.transform import rotate\n\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nimport numpy as np\nimport os\nimport cv2\nimport pandas as pd\n# import imutils\nimport random\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport pickle\nimport torch"]}, {"cell_type": "markdown", "id": "4659c7de", "metadata": {}, "source": ["# Load Clip Filename"]}, {"cell_type": "code", "execution_count": 1, "id": "2b0b1d5e", "metadata": {}, "outputs": [], "source": ["def get_video_filename(filenames):\n    date2clip = {}\n    for filename in filenames:\n        for path in os.listdir(filename):\n            if path == '.ipynb_checkpoints':\n                continue\n\n            path = filename+'/'+path\n            int_path = int(path[-18:-4])\n            paths = range(int_path-50, int_path+50)\n            for i in paths:\n                if str(i) in date2clip.keys():\n                    int_path_date2clip = int(date2clip[str(i)][-18:-4])\n                    if abs(i - int_path) < abs(i - int_path_date2clip):\n                        date2clip[str(i)] = path\n                else:\n                    date2clip[str(i)] = path\n\n    def clip(filename, date2clip):\n        try:\n            return date2clip[filename]\n        except:\n            return 'Error'\n        \n    return lambda x: clip(x, date2clip)"]}, {"cell_type": "markdown", "id": "7a9f72f8", "metadata": {}, "source": ["# Prepare Data"]}, {"cell_type": "code", "execution_count": 1, "id": "c4f52bf5", "metadata": {}, "outputs": [], "source": ["def get_data(condition):\n    df = pd.DataFrame({})\n    if condition == 'train':\n        for path in os.listdir('../input/super-ai-engineer-denso-lasi/train_csv'):\n            df = pd.concat([df, pd.read_csv('../input/super-ai-engineer-denso-lasi/train_csv/' + path)])\n    if condition == 'test':\n        df = pd.read_csv('../input/super-ai-engineer-denso-lasi/test.csv')\n\n    # Drop sth shit\n    df.drop(columns=['s_equipment_control'], inplace=True)\n    df.rename(columns={'Unnamed: 0' : 'Ids'}, inplace=True)\n\n    # Create file_datetime for finding filename in clip\n    df['file_datetime'] = df['d_datetime'].replace({'-':'', ':':'', ' ':''}, regex=True)\n\n    # Get video filename\n    video_filenames = ['../input/denso-videos/denso-video', '../input/densotest']\n    df['file_datetime'] = df['file_datetime'].apply(get_video_filename(video_filenames))\n    \n    df.index = df['Ids']\n    df.drop(columns='Ids', inplace=True)\n    \n    if condition == 'train':\n        df.drop(index=df.loc[df['has_actual_output'] == 'Corrupted Video'].index, inplace=True)\n        \n    return df"]}, {"cell_type": "code", "execution_count": 1, "id": "54f8a10e", "metadata": {}, "outputs": [], "source": ["train = get_data('train')\ntest = get_data('test')"]}, {"cell_type": "code", "execution_count": 1, "id": "e97b4b49", "metadata": {}, "outputs": [], "source": ["train"]}, {"cell_type": "code", "execution_count": 1, "id": "156d73c2", "metadata": {}, "outputs": [], "source": ["test"]}, {"cell_type": "code", "execution_count": 1, "id": "b8978f18", "metadata": {}, "outputs": [], "source": ["def get_image(df, condition='train'):\n    number = range(5)\n    file_datetime = df['file_datetime']\n    n_ct = df['n_ct']\n    cap = cv2.VideoCapture(file_datetime)\n    fps = 15\n    frames = []\n    \n    x_crop_start = 30\n    x_crop_end = 240\n    y_crop_start = 500\n    y_crop_end = 620\n    \n    for i in number:\n        ret, frame = cap.read()\n        if ret == False:\n            return 'Error'\n\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        frame = np.array(frame)\n        try:\n            if condition == 'test':\n                return frame[x_crop_start:x_crop_end, y_crop_start:y_crop_end, :]\n            \n            frames.append(frame[x_crop_start:x_crop_end, y_crop_start:y_crop_end, :])\n        except:\n            return 'Error'\n        \n    frames = np.array(frames)\n    return frames\n    \ndef get_image2df(df, condition='train'):\n    df['image'] = df.apply(lambda x: get_image(x, condition), axis=1)\n    df.drop(index=df.loc[df['image'] == 'Error'].index, inplace=True)\n    return df\n\ntrain = get_image2df(train)"]}, {"cell_type": "code", "execution_count": 1, "id": "7624c50c", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize = (50,100))\nrows = train.loc[train['has_actual_output'] == 'Yes']['has_actual_output'].index\nnumber = 5\nfor i, row in enumerate(tqdm(rows[:number])):\n    im = np.array(train.loc[row]['image'])\n    fig.add_subplot(1, number, i+1)\n    plt.imshow(im[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "d9a1ac75", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize = (50,100))\nrows = train.loc[train['has_actual_output'] == 'No']['has_actual_output'].index\nnumber = 5\nfor i, row in enumerate(tqdm(rows[:number])):\n    im = np.array(train.loc[row]['image'])\n    fig.add_subplot(1, number, i+1)\n    plt.imshow(im[0])"]}, {"cell_type": "markdown", "id": "4f18ef43", "metadata": {}, "source": ["# Washing Machine Training"]}, {"cell_type": "markdown", "id": "564f8d77", "metadata": {}, "source": ["# Model"]}, {"cell_type": "code", "execution_count": 1, "id": "6faa3791", "metadata": {}, "outputs": [], "source": ["im = np.array(train.loc[45049]['image'][0])\nx_resolution, y_resolution, _ = im.shape\nx_resolution, y_resolution"]}, {"cell_type": "code", "execution_count": 1, "id": "b82f3136", "metadata": {}, "outputs": [], "source": ["with tf.device('/device:GPU:0'):\n    def get_model():\n        inputs = Input(shape=(x_resolution, y_resolution, 3))\n        \n        x = Conv2D(16, kernel_size=(5,5), activation='relu')(inputs)\n        x = MaxPool2D(pool_size=2)(x)\n        x = BatchNormalization()(x)\n        \n        x = Conv2D(32, kernel_size=(5,5), activation='relu')(x)\n        x = MaxPool2D(pool_size=2)(x)\n        x = BatchNormalization()(x)\n        \n        x = Flatten()(x)\n        x = Dense(32)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(16)(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Dropout(0.2)(x)\n        \n        x = Dense(1)(x)\n        outputs = Activation('sigmoid')(x)\n\n        model = Model(inputs=inputs, outputs=outputs)\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n        return model\n    \n    get_model().summary()\nplot_model(get_model(),show_shapes=True)"]}, {"cell_type": "markdown", "id": "598b1e6c", "metadata": {}, "source": ["# Prepare Data For Training Model"]}, {"cell_type": "code", "execution_count": 1, "id": "2e902862", "metadata": {}, "outputs": [], "source": ["# X = np.array([i for i in train['image']])\n# y = train['has_actual_output'].replace({'No':0, 'Yes':1}, regex=True).to_numpy()\nX = []\ny = []\nfor i, out in zip(train['image'], train['has_actual_output'].replace({'No':0, 'Yes':1}, regex=True).to_numpy()):\n    for j in i:\n        X.append(j)\n        y.append(out)\n        \nX = np.array(X)/255.\ny = np.array(y)\nX.shape, y.shape"]}, {"cell_type": "markdown", "id": "d2b9d24a", "metadata": {}, "source": ["# Traning Process"]}, {"cell_type": "code", "execution_count": 1, "id": "21b584eb", "metadata": {}, "outputs": [], "source": ["X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\nbatch_size = 32\nearlystopping = 50\nbest_model = 'best_model.h5'\n\nEarlyStopper = EarlyStopping(patience=earlystopping, verbose=1, monitor='val_accuracy', mode='max')\nCheckpoint = ModelCheckpoint(best_model, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max')\n\nprint('Train Size :',X_train.shape[0])\nprint('Validation Size :',X_valid.shape[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "32c1c6ee", "metadata": {}, "outputs": [], "source": ["model = get_model()\n\nmodel.fit(X_train, y_train, \n         validation_data=(X_valid, y_valid),\n         batch_size=batch_size,\n         epochs=200,\n         verbose=1,\n         callbacks=[EarlyStopper, Checkpoint]\n        )"]}, {"cell_type": "code", "execution_count": 1, "id": "c608e525", "metadata": {}, "outputs": [], "source": ["model = load_model(best_model)\nloss_train, acc_train = model.evaluate(X_train, y_train, verbose=0)\nloss_valid, acc_valid = model.evaluate(X_valid, y_valid, verbose=0)\nloss_all, acc_all = model.evaluate(X, y, verbose=0)\nprint('Train Loss :', loss_train)\nprint('Train Accuracy :', acc_train*100)\nprint()\nprint('Valid Loss :', loss_valid)\nprint('Valid Accuracy :', acc_valid*100)\nprint()\nprint('All Loss :', loss_all)\nprint('All Accuracy :', acc_all*100)"]}, {"cell_type": "markdown", "id": "7821b4d5", "metadata": {}, "source": ["# Submission Model"]}, {"cell_type": "code", "execution_count": 1, "id": "0259740e", "metadata": {}, "outputs": [], "source": ["model_submission = get_model()\n\nmodel_submission.fit(X, y,\n         batch_size=batch_size,\n         epochs=100,\n         verbose=1\n        )"]}, {"cell_type": "code", "execution_count": 1, "id": "ed6a7d0c", "metadata": {}, "outputs": [], "source": ["loss_train, acc_train = model_submission.evaluate(X_train, y_train, verbose=0)\nloss_valid, acc_valid = model_submission.evaluate(X_valid, y_valid, verbose=0)\nloss_all, acc_all = model_submission.evaluate(X, y, verbose=0)\nprint('Train Loss :', loss_train)\nprint('Train Accuracy :', acc_train*100)\nprint()\nprint('Valid Loss :', loss_valid)\nprint('Valid Accuracy :', acc_valid*100)\nprint()\nprint('All Loss :', loss_all)\nprint('All Accuracy :', acc_all*100)"]}, {"cell_type": "markdown", "id": "a78a2879", "metadata": {}, "source": ["# Predict"]}, {"cell_type": "code", "execution_count": 1, "id": "b2f429cd", "metadata": {}, "outputs": [], "source": ["# 44845,48788 ---> Error\ntest = get_image2df(test, 'test')\nX_test = np.array([i for i in test['image']])/255.\nactual_output = ['No' if i[0] < 0.5 else 'Yes' for i in model_submission.predict(X_test)]\nactual_output[:20]"]}, {"cell_type": "code", "execution_count": 1, "id": "14d960cb", "metadata": {}, "outputs": [], "source": ["#Error\ndf_error = pd.DataFrame({'Ids':[44845,48788],\n                        'actual_output':['No','No']})\ndf_error"]}, {"cell_type": "code", "execution_count": 1, "id": "bd2c93a5", "metadata": {}, "outputs": [], "source": ["submission = pd.DataFrame({'Ids': test.index})\nsubmission['actual_output'] = actual_output\n\n# Appending Error Clip\nsubmission = submission.append(df_error, ignore_index=True)\n\nsubmission = submission.sort_values(['Ids'])\nsubmission.to_csv('actual_output.csv', index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "e3bd2511", "metadata": {}, "outputs": [], "source": ["import math\n\nfig = plt.figure(figsize = (50,100))\nsize = len(test.index)\nsize = int(math.sqrt(size))+1\nfor i, idx in enumerate(tqdm(test.index)):\n    im = np.array(test.loc[idx]['image'])\n    fig.add_subplot(size, size, i+1)\n    print_output = submission.loc[submission['Ids'] == idx]['actual_output'].to_numpy()[0]\n    plt.title(print_output, fontsize=70)\n    plt.imshow(im)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}