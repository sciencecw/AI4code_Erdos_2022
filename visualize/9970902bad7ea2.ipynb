{"cells": [{"cell_type": "code", "execution_count": 1, "id": "566876eb", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, plot_confusion_matrix\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "6b930a11", "metadata": {}, "source": ["# Importing dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "a743eab0", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"../input/glass/glass.csv\")\ndf.describe()"]}, {"cell_type": "markdown", "id": "2700f221", "metadata": {}, "source": ["# Dependent and Independent variables"]}, {"cell_type": "code", "execution_count": 1, "id": "0c5e0c71", "metadata": {}, "outputs": [], "source": ["X = df.iloc[:, 0:9]\ny = df.iloc[:, 9]"]}, {"cell_type": "markdown", "id": "c489853b", "metadata": {}, "source": ["# Analysing"]}, {"cell_type": "code", "execution_count": 1, "id": "c84106e5", "metadata": {}, "outputs": [], "source": ["correlation=df.corr()\nplt.figure(figsize=(10,10))\nsbn.heatmap(correlation,annot=True,cmap=plt.cm.Blues)"]}, {"cell_type": "markdown", "id": "dfae2ec5", "metadata": {}, "source": ["# Applying GridSearchCV to find the best hyperparameters"]}, {"cell_type": "code", "execution_count": 1, "id": "95aa5b98", "metadata": {}, "outputs": [], "source": ["model = RandomForestClassifier()\n# Applying GridSearchCV to find the best hyperparameters for doing random forest classification\nparameters = [{'n_estimators': [10, 20, 50]}]\nclf = GridSearchCV(model, parameters, cv=5, scoring=\"accuracy\")\nclf.fit(X, y)   \nprint(clf.best_params_)"]}, {"cell_type": "markdown", "id": "85d4ab57", "metadata": {}, "source": ["# Creating model using best parameters"]}, {"cell_type": "code", "execution_count": 1, "id": "b9f34ded", "metadata": {}, "outputs": [], "source": ["clf = RandomForestClassifier(n_estimators=50)\nclf.fit(X, y)"]}, {"cell_type": "markdown", "id": "ba50c6b1", "metadata": {}, "source": ["# Predicting and evaluating its accuracy"]}, {"cell_type": "code", "execution_count": 1, "id": "953f0b64", "metadata": {}, "outputs": [], "source": ["y_hat = clf.predict(X)\nprint(classification_report(y, y_hat))\nprint(plot_confusion_matrix(clf, X, y, cmap=plt.cm.Blues,\n                            display_labels=(y.unique())))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}