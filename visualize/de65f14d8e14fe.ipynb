{"cells": [{"cell_type": "code", "execution_count": 1, "id": "dba1a858", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom joblib import dump, load\nimport pickle\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss, brier_score_loss, precision_score, recall_score, f1_score\nfrom datetime import date\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.calibration import CalibratedClassifierCV, calibration_curve\nfrom sklearn.model_selection import train_test_split\n"]}, {"cell_type": "markdown", "id": "f0ac641e", "metadata": {}, "source": ["settings and hyperparameters"]}, {"cell_type": "code", "execution_count": 1, "id": "159aaa3f", "metadata": {}, "outputs": [], "source": ["\ndata_folder = '../input/lish-moa/'\noutput_folder = ''\n\n# fix the random seed \nxseed = 43\n\n# number of folds for cv\nnfolds = 5\n\n# number of components to retain from PCA decomposition\nnof_comp = 300\n\nmodel_name = 'svm'"]}, {"cell_type": "markdown", "id": "2f8dcdc2", "metadata": {}, "source": ["# Data"]}, {"cell_type": "code", "execution_count": 1, "id": "02f7c487", "metadata": {}, "outputs": [], "source": ["xtrain = pd.read_csv(data_folder + 'train_features.csv')\nxtest = pd.read_csv(data_folder + 'test_features.csv')\nytrain = pd.read_csv(data_folder + 'train_targets_scored.csv')"]}, {"cell_type": "markdown", "id": "695df7b1", "metadata": {}, "source": ["# FE"]}, {"cell_type": "code", "execution_count": 1, "id": "ed3bcf04", "metadata": {}, "outputs": [], "source": ["# due to small cardinality of all values, it's faster to handle categoricals that way,\n\nprint(set(xtrain['cp_time']), set(xtest['cp_time']) )\n\n# cp_time\nxtrain['cp_time_24'] = (xtrain['cp_time'] == 24) + 0\nxtrain['cp_time_48'] = (xtrain['cp_time'] == 48) + 0\nxtest['cp_time_24'] = (xtest['cp_time'] == 24) + 0\nxtest['cp_time_48'] = (xtest['cp_time'] == 48) + 0\nxtrain.drop('cp_time', axis = 1, inplace = True)\nxtest.drop('cp_time', axis = 1, inplace = True)\n\n# cp_dose\nprint(set(xtrain['cp_dose']), set(xtest['cp_dose']) )\nxtrain['cp_dose_D1'] = (xtrain['cp_dose'] == 'D1') + 0\nxtest['cp_dose_D1'] = (xtest['cp_dose'] == 'D1') + 0\nxtrain.drop('cp_dose', axis = 1, inplace = True)\nxtest.drop('cp_dose', axis = 1, inplace = True)\n\n# cp_type\nxtrain['cp_type_control'] = (xtrain['cp_type'] == 'ctl_vehicle') + 0\nxtest['cp_type_control'] = (xtest['cp_type'] == 'ctl_vehicle') + 0\nxtrain.drop('cp_type', axis = 1, inplace = True)\nxtest.drop('cp_type', axis = 1, inplace = True)"]}, {"cell_type": "markdown", "id": "476cc40b", "metadata": {}, "source": ["# Model"]}, {"cell_type": "code", "execution_count": 1, "id": "f415f9d9", "metadata": {}, "outputs": [], "source": ["# prepare split\nkf = KFold(n_splits = nfolds)\n\n# separation\nid_train = xtrain['sig_id']; id_test = xtest['sig_id']\nytrain.drop('sig_id', axis = 1, inplace = True) \nxtrain.drop('sig_id', axis = 1, inplace = True)\nxtest.drop('sig_id', axis = 1, inplace = True)\n\n# storage matrices for OOF / test predictions\nprval = np.zeros(ytrain.shape)\nprfull = np.zeros((xtest.shape[0], ytrain.shape[1]))"]}, {"cell_type": "code", "execution_count": 1, "id": "f8f13ddf", "metadata": {}, "outputs": [], "source": ["# base model definition throught sklearn Pipeline\npca = PCA(n_components = nof_comp)\nsvm0 = SVR(C = 0.1)\n\nbase_model = Pipeline(steps=[('pca', pca), ('svm', svm0)])\n\nmo_base = MultiOutputRegressor(base_model, n_jobs=-1)"]}, {"cell_type": "markdown", "id": "051e1da9", "metadata": {}, "source": ["Create OOF forecasts + test ones averaged across folds"]}, {"cell_type": "code", "execution_count": 1, "id": "f25deeb4", "metadata": {}, "outputs": [], "source": ["for (ff, (id0, id1)) in enumerate(kf.split(xtrain)):\n     \n    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n    y0, y1 = np.array(ytrain.loc[id0]), np.array(ytrain.loc[id1])\n    \n    # stupid fix for empty columns - LogisticRegression blows up otherwise \n    # (the problem occurs for two folds only, each time for a single column)\n    # yes, i know it's ugly\n    check_for_empty_cols = np.where(y0.sum(axis = 0) == 0)[0]\n    if len(check_for_empty_cols):\n        y0[0,check_for_empty_cols] = 1\n    \n    # fit model\n    mo_base.fit(x0,y0)\n    \n    prv = mo_base.predict(x1)\n    prf = mo_base.predict(xtest)\n    # generate the prediction\n    prval[id1,:] = prv\n    prfull += prf/nfolds\n    \n    \n    print('fold '+str(ff) + ': completed')"]}, {"cell_type": "markdown", "id": "d2b810f2", "metadata": {}, "source": ["# Postprocessing the probabilities"]}, {"cell_type": "markdown", "id": "8503aee4", "metadata": {}, "source": ["Platt scaling with default params"]}, {"cell_type": "code", "execution_count": 1, "id": "79bc8bff", "metadata": {}, "outputs": [], "source": ["column_list = ytrain.columns\n\nprval_cal = np.zeros(ytrain.shape)\nprfull_cal = np.zeros((xtest.shape[0], ytrain.shape[1]))\n\n\n\nfor (ff, (id0, id1)) in enumerate(kf.split(xtrain)):\n     \n    for ii in range(0, ytrain.shape[1]):\n        \n        xname = column_list[ii]\n        \n        x0, x1 = prval[id0,ii], prval[id1,ii]\n        y0, y1 = np.array(ytrain)[id0,ii], np.array(ytrain)[id1,ii]\n       \n        if sum(y0) == 0:\n            y0[0] = 1\n            \n        basemodel = LogisticRegression()        \n        basemodel.fit(x0.reshape(-1,1), y0)\n        prv = basemodel.predict_proba(x1.reshape(-1,1))[:,1]\n        prf = basemodel.predict_proba(np.array(prfull)[:,ii].reshape(-1,1))[:,1]\n        \n        prval_cal[id1, ii] = prv\n        prfull_cal[:, ii] += prf/nfolds\n\n    print(ff)"]}, {"cell_type": "code", "execution_count": 1, "id": "398fcd92", "metadata": {}, "outputs": [], "source": ["# compare performance pre- and post- calibration\nmetrics1 = []\nmetrics2 = []\n\n\nfor ii in range(0,ytrain.shape[1]):\n    loss1 = log_loss(np.array(ytrain)[:, ii], prval[:, ii])\n    metrics1.append(loss1)\n    loss2 = log_loss(np.array(ytrain)[:, ii], prval_cal[:, ii])\n    metrics2.append(loss2)\n    \nprint('raw: ' + str(np.mean(metrics1)) )\nprint('cal: ' + str(np.mean(metrics2)))"]}, {"cell_type": "markdown", "id": "ad2fced1", "metadata": {}, "source": ["# Eval and sub"]}, {"cell_type": "code", "execution_count": 1, "id": "64dd12eb", "metadata": {}, "outputs": [], "source": ["prval_cal = pd.DataFrame(prval_cal)\nprfull_cal = pd.DataFrame(prfull_cal)\nprval_cal.columns = ytrain.columns\nprfull_cal.columns = ytrain.columns\n\nprval_cal['sig_id'] = id_train\nprfull_cal['sig_id'] = id_test"]}, {"cell_type": "code", "execution_count": 1, "id": "18797876", "metadata": {}, "outputs": [], "source": ["metrics = []\nfor _target in ytrain.columns:\n    metrics.append(log_loss(ytrain.loc[:, _target], prval_cal.loc[:, _target]))\nprint(f'OOF Metric: {np.round(np.mean(metrics),4)}')"]}, {"cell_type": "code", "execution_count": 1, "id": "3b6479b5", "metadata": {}, "outputs": [], "source": ["xcols = list(ytrain.columns); xcols.insert(0, 'sig_id')\nprval_cal = prval_cal[xcols]; prfull_cal = prfull_cal[xcols]\n\n\ntodate = date.today().strftime(\"%d%m\")\nprint(todate)\n\n# files for combination\n# prval_cal.to_csv(output_folder + 'prval_'+model_name+'_'+todate+'.csv', index = False)\n# prfull_cal.to_csv(output_folder + 'prfull_'+model_name+'_'+todate+'.csv', index = False)\n# actual submission\nprfull_cal.to_csv(output_folder + 'submission.csv', index = False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}