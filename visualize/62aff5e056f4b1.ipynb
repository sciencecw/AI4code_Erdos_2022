{"cells": [{"cell_type": "markdown", "id": "265ed3f8", "metadata": {}, "source": ["# About this notebook\n\nThis is an introduction to how to build Light GBM, optuna for beginners using Titanic data.\n\n\u203b\u3000I have devised a way to improve the reproducibility of LGBM optuna.\n\n\u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u30c7\u30fc\u30bf\u3092\u7528\u3044\u305f\u521d\u5fc3\u8005\u306e\u305f\u3081\u306eLight GBM, optuna\u306e\u7d44\u307f\u65b9\u5165\u9580\u3067\u3059\u3002\n\n\n\u203b LGBM optuna\u306e\u518d\u73fe\u6027\u3082\u51fa\u3059\u3088\u3046\u306b\u5de5\u592b\u3057\u307e\u3057\u305f\u3002\n"]}, {"cell_type": "markdown", "id": "d7e25552", "metadata": {}, "source": ["# 1. Confirming the train/test data : \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\n"]}, {"cell_type": "code", "execution_count": 1, "id": "f9a9c4f2", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport random"]}, {"cell_type": "code", "execution_count": 1, "id": "8fee68f5", "metadata": {}, "outputs": [], "source": ["def fix_seed(seed):\n    # random\n    random.seed(seed)\n    # Numpy\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\nSEED = 42\nfix_seed(SEED)"]}, {"cell_type": "code", "execution_count": 1, "id": "42713473", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf"]}, {"cell_type": "code", "execution_count": 1, "id": "fc424797", "metadata": {}, "outputs": [], "source": ["test = pd.read_csv(\"../input/titanic/test.csv\")\ntest"]}, {"cell_type": "markdown", "id": "b5f12a03", "metadata": {}, "source": ["## About data\nsurvival\tSurvival\t0 = No, 1 = Yes\npclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\tSex\t\nAge\tAge in years\t\nsibsp\t# of siblings / spouses aboard the Titanic\t\nparch\t# of parents / children aboard the Titanic\t\nticket\tTicket number\t\nfare\tPassenger fare\t\ncabin\tCabin number\t\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n\n#########\u65e5\u672c\u8a9e#################\n\nsurvival\t\u751f\u6b7b\t0 = \u6b7b\u4ea1, 1 = \u751f\u5b58\npclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\t\u6027\u5225\t\nAge\t\u5e74\u9f62\t\nsibsp\t# of siblings / \u89aa\u65cf\u306e\u6570\t\nparch\t# of parents / \u5b50\u4f9b\u306e\u6570\t\nticket\tTicket number\u3000\u30c1\u30b1\u30c3\u30c8\u30ca\u30f3\u30d0\u30fc\t\nfare\tPassenger fare\t\u904b\u8cc3\ncabin\tCabin number\t\u90e8\u5c4b\u306e\u756a\u53f7\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\u3000\u4e57\u8239\u3057\u305f\u5834\u6240\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7b68097e", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "markdown", "id": "6723dd55", "metadata": {}, "source": ["#### There are 891 rows. There are NaN data in Age, Cabin, Embarked.\n#### \u5168\u90e8\u3067891\u884c\u3042\u3063\u3066\u3001Age,Cabin,Embarked\u306b\u306fnull\u30c7\u30fc\u30bf\u306f\u306a\u3044\u304c\u3001NaN\u30c7\u30fc\u30bf\u304c\u3042\u308a\u305d\u3046\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "c5232e1f", "metadata": {}, "outputs": [], "source": ["df.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "977268ea", "metadata": {}, "outputs": [], "source": ["df.nunique()"]}, {"cell_type": "markdown", "id": "ef643bea", "metadata": {}, "source": ["# 2 label encoding\n#### Automatically convert strings to numbers. In the case of neural networks, you shouldn't do it without significant differences, but LGBM is irrelevant.\n#### \u6587\u5b57\u5217\u3092\u6570\u5b57\u306b\u81ea\u52d5\u5909\u63db. \n#### \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5834\u5408\u306f\u3001\u6709\u610f\u5dee\u304c\u306a\u3044\u3068\u3084\u3063\u3066\u306f\u3044\u3051\u306a\u3044\u304c\u3001LGBM\u306f\u95a2\u4fc2\u306a\u3057(Categorical feature\u3067\u53d6\u308a\u6271\u3046)"]}, {"cell_type": "code", "execution_count": 1, "id": "dea22fbe", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import LabelEncoder"]}, {"cell_type": "code", "execution_count": 1, "id": "42e9c809", "metadata": {}, "outputs": [], "source": ["le=LabelEncoder()\n\nle.fit(df[\"Sex\"])\ndf[\"Sex\"] = le.transform(df[\"Sex\"])\ntest[\"Sex\"] = le.transform(test[\"Sex\"])"]}, {"cell_type": "markdown", "id": "4c98aebe", "metadata": {}, "source": ["*  Nan data can be used with LGBM, but it must be float type.\n*  Embarked contains a character string and nan, so when label encoding, first replace na with fillna and then label encode.\n\n##### \u65e5\u672c\u8a9e\n*  Nan\u30c7\u30fc\u30bf\u306f\u3001LGBM\u3067\u4f7f\u7528\u3067\u304d\u308b\u304c\u3001float\u578b\u306b\u3057\u306a\u3044\u3068\u3044\u3051\u306a\u3044\u3002\n*  Embarked\u306f\u6587\u5b57\u5217\u3068\u3001nan\u304c\u5165\u3063\u3066\u3044\u308b\u305f\u3081\u3001label encode\u3059\u308b\u3068\u304d\u306f\u3001fillna\u3067\u307e\u305a\u306f\u3001na\u3092\u7f6e\u63db\u3057\u305f\u5f8c\u3001label encoding\u3059\u308b "]}, {"cell_type": "code", "execution_count": 1, "id": "76f82110", "metadata": {}, "outputs": [], "source": ["df[\"Embarked\"] = df[\"Embarked\"].fillna(\"NoData\")"]}, {"cell_type": "code", "execution_count": 1, "id": "8e3df993", "metadata": {}, "outputs": [], "source": ["le2=LabelEncoder()\nle2.fit(df[\"Embarked\"])\ndf[\"Embarked\"] = le2.transform(df[\"Embarked\"])\ntest[\"Embarked\"] = le2.transform(test[\"Embarked\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "1dd970d7", "metadata": {}, "outputs": [], "source": ["train = df.copy()"]}, {"cell_type": "markdown", "id": "4f9143ff", "metadata": {}, "source": ["# 3. Kfold\n#### Prepare training data and verification data in 5 combinations.\n#### \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u30925\u3064\u306e\u7d44\u307f\u5408\u308f\u305b\u3067\u6e96\u5099\u3059\u308b\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "6ddf8ed8", "metadata": {}, "outputs": [], "source": ["from sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold"]}, {"cell_type": "code", "execution_count": 1, "id": "7d3ab55a", "metadata": {}, "outputs": [], "source": ["folds = train.copy()\nFold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[\"Survived\"])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nprint(folds.groupby(['fold', \"Survived\"]).size())"]}, {"cell_type": "code", "execution_count": 1, "id": "9d5f6966", "metadata": {}, "outputs": [], "source": ["folds"]}, {"cell_type": "markdown", "id": "bc97514f", "metadata": {}, "source": ["## 3.1 : 1-fold separation for example of modeling & inference"]}, {"cell_type": "markdown", "id": "4f86eafb", "metadata": {}, "source": ["## for practice, fold0 is defined as validation, fold1-4 are defined as train\n## \u7df4\u7fd2\u306e\u305f\u3081\u306b\u3001\u307e\u305a\u3001fold0\u3092\u691c\u8a3c\u30c7\u30fc\u30bf\u3001fold1-4\u3092\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u3057\u307e\u3059\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "4370fae4", "metadata": {}, "outputs": [], "source": ["p_train = folds[folds[\"fold\"] != 0]\np_val = folds[folds[\"fold\"] == 0]"]}, {"cell_type": "code", "execution_count": 1, "id": "54af0193", "metadata": {}, "outputs": [], "source": ["p_train"]}, {"cell_type": "code", "execution_count": 1, "id": "84bdc59c", "metadata": {}, "outputs": [], "source": ["# An error will occur later, so reassign the index.\n# \u5f8c\u307b\u3069\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067\u3001index\u3092\u632f\u308a\u306a\u304a\u3059\u3002\n\np_train = p_train.reset_index(drop=True)\np_val = p_val.reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "a6738f49", "metadata": {}, "outputs": [], "source": ["p_train"]}, {"cell_type": "markdown", "id": "3052aca0", "metadata": {}, "source": ["# 4.Light GBM"]}, {"cell_type": "code", "execution_count": 1, "id": "c0c85edc", "metadata": {}, "outputs": [], "source": ["import lightgbm as lgb"]}, {"cell_type": "code", "execution_count": 1, "id": "7b56807a", "metadata": {}, "outputs": [], "source": ["fix_seed(SEED) # for repetability"]}, {"cell_type": "markdown", "id": "fe4f84f1", "metadata": {}, "source": ["## 4.1 Defining features and target\n##     \u7279\u5fb4\u91cf\u3068\u30e9\u30d9\u30eb(\u30bf\u30fc\u30b2\u30c3\u30c8)\u3092\u5b9a\u7fa9\u3057\u307e\u3059"]}, {"cell_type": "code", "execution_count": 1, "id": "a09d84e0", "metadata": {}, "outputs": [], "source": ["# defining the feature columns and the target\n\nFEATURES = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Embarked\"]\nTARGET = \"Survived\""]}, {"cell_type": "code", "execution_count": 1, "id": "45f93d4e", "metadata": {}, "outputs": [], "source": ["p_train[FEATURES]"]}, {"cell_type": "markdown", "id": "69f903f4", "metadata": {}, "source": ["Meaningful as continuous data: Pclass, Age, SibSp, Parch\nCategorical feature: Embarked\n\nSince it is 0,1, it doesn't matter which one Sex (In the case of LGBM, the result does not change regardless of which one you put in experience)\n\nThe categorical feature is automatically determined by the basic default, but if you do not want it, you define it yourself.\n\n\n\u4e00\u5ea6\u6574\u7406\u3002\n\n\u9023\u7d9a\u30c7\u30fc\u30bf\u3068\u3057\u3066\u610f\u5473\u304c\u3042\u308b\u3082\u306e : Pclass, Age, SibSp, Parch\n\u610f\u5473\u304c\u3042\u308b\u304b\u308f\u304b\u3089\u306a\u3044\u3082\u306e(categorical feature) : Embarked\n\n0,1 \u306a\u306e\u3067\u3001\u3069\u3061\u3089\u3067\u3082\u3088\u3044\u3082\u306e Sex ( LGBM\u306e\u5834\u5408\u3001\u7d4c\u9a13\u4e0a\u3069\u3061\u3089\u306b\u5165\u308c\u3066\u3082\u7d50\u679c\u5909\u308f\u3089\u306a\u3044)\n\ncategorical feature\u306f\u57fa\u672cdefault\u3067\u81ea\u52d5\u5224\u5b9a\u3057\u3066\u304f\u308c\u308b\u304c\u3001\u3055\u308c\u305f\u304f\u306a\u3044\u5834\u5408\u306f\u81ea\u5206\u3067\u5b9a\u7fa9\u3059\u308b\u3002\n\n\n\u307e\u305f\u3001categorical feature\u306f0\u304b\u3089\u306e\u9023\u7d9a\u3059\u308b\u6574\u6570\u304c\u597d\u307e\u3057\u3044\u3002\u3068LGBM\u306e\u8aac\u660e\u30da\u30fc\u30b8\u306b\u66f8\u3044\u3066\u3042\u308b\n"]}, {"cell_type": "markdown", "id": "11b95816", "metadata": {}, "source": ["## 4.2 Making Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "9ac4c09e", "metadata": {}, "outputs": [], "source": ["lgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\nlgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])"]}, {"cell_type": "markdown", "id": "92d6e3b8", "metadata": {}, "source": ["## 4.3 Setting parameter"]}, {"cell_type": "code", "execution_count": 1, "id": "3fdfed9c", "metadata": {}, "outputs": [], "source": ["# example of parameters\nlgbm_params = {\n    'objective': 'binary', # Binary classification : 2\u5024\u5206\u985e\u3067\u306f\u3053\u308c\u3092\u4f7f\u3046\n    'seed': 42, # random seed : \u3053\u308c\u3092\u56fa\u5b9a\u3059\u308b\u3068\u3001\u518d\u73fe\u6027\u304c\u51fa\u308b\n    'metric': 'auc', \n#    'learning_rate': 0.01,\n#    'max_bin': 800, # depth\n#    'num_leaves': 80, # leaves,\n    \"verbose\":-1,\n    \"deterministic\":True\n}"]}, {"cell_type": "markdown", "id": "05adb38b", "metadata": {}, "source": ["## 4.4 Modeling"]}, {"cell_type": "code", "execution_count": 1, "id": "594ac8b2", "metadata": {}, "outputs": [], "source": ["train[FEATURES].head(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "15aa9e1b", "metadata": {}, "outputs": [], "source": ["cat_list = ['Embarked']\n\n\nmodel = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                  verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n                  num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n                  early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n                  categorical_feature = cat_list # manual categorical feature setting\n                 \n                 )"]}, {"cell_type": "markdown", "id": "7acafff3", "metadata": {}, "source": ["## 4.5 Saving model and loading model method"]}, {"cell_type": "code", "execution_count": 1, "id": "6e68dd6f", "metadata": {}, "outputs": [], "source": ["import pickle\n\nmodel_name = \"LGBMmodel.bin\"\n\n# saving model\npickle.dump(model, open(model_name, 'wb'))\n\n# loading model\nmodel = pickle.load(open(model_name, 'rb'))\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ae1eea05", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "id": "ed262bec", "metadata": {}, "source": ["## 4.6 Show importance features"]}, {"cell_type": "code", "execution_count": 1, "id": "7c9ecb20", "metadata": {}, "outputs": [], "source": ["# model.save_model(f'model.txt')\nlgb.plot_importance(model, importance_type='gain')\nplt.show()"]}, {"cell_type": "markdown", "id": "78f4c369", "metadata": {}, "source": ["## 4.7 Show ROC curve and calculating accuracy"]}, {"cell_type": "code", "execution_count": 1, "id": "5d1230e9", "metadata": {}, "outputs": [], "source": ["# predicting validation value\noof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)"]}, {"cell_type": "code", "execution_count": 1, "id": "ad614941", "metadata": {}, "outputs": [], "source": ["oof_pred[:3]"]}, {"cell_type": "code", "execution_count": 1, "id": "41757395", "metadata": {}, "outputs": [], "source": ["# Calculating AUC (Area Under the Curve)\nfrom sklearn import metrics\nfpr, tpr, thresholds = metrics.roc_curve(p_val[TARGET], oof_pred)\nauc = metrics.auc(fpr, tpr)\nprint(auc)\n\n# Ploting the ROC curve\nplt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)"]}, {"cell_type": "markdown", "id": "22fbb9b9", "metadata": {}, "source": ["## 4.8 Scoring : Accuracy"]}, {"cell_type": "code", "execution_count": 1, "id": "ca243ca2", "metadata": {}, "outputs": [], "source": ["oof_pred"]}, {"cell_type": "code", "execution_count": 1, "id": "8b147bc4", "metadata": {}, "outputs": [], "source": ["oof_pred2 = np.where(oof_pred>=0.5,1,0)"]}, {"cell_type": "code", "execution_count": 1, "id": "4f39c22d", "metadata": {}, "outputs": [], "source": ["accuracy_score(p_val[TARGET], oof_pred2)"]}, {"cell_type": "markdown", "id": "d393ca6c", "metadata": {}, "source": ["# 5.inference for test data"]}, {"cell_type": "markdown", "id": "89342c9d", "metadata": {}, "source": ["## 5.1 loading model"]}, {"cell_type": "code", "execution_count": 1, "id": "dc1051e4", "metadata": {}, "outputs": [], "source": ["model = pickle.load(open(model_name, 'rb'))"]}, {"cell_type": "code", "execution_count": 1, "id": "8e85aa89", "metadata": {}, "outputs": [], "source": ["# confirming submission file\n\nsubmission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\nsubmission"]}, {"cell_type": "code", "execution_count": 1, "id": "c44063e9", "metadata": {}, "outputs": [], "source": ["test"]}, {"cell_type": "code", "execution_count": 1, "id": "e27722a6", "metadata": {}, "outputs": [], "source": ["test_X = test[FEATURES]\ntest_X "]}, {"cell_type": "code", "execution_count": 1, "id": "18820ff4", "metadata": {}, "outputs": [], "source": ["# predicting for test_X\npreds = model.predict(test_X[FEATURES])"]}, {"cell_type": "code", "execution_count": 1, "id": "f5f36bcd", "metadata": {}, "outputs": [], "source": ["preds2 = np.where(preds>=0.5,1,0)"]}, {"cell_type": "code", "execution_count": 1, "id": "e7bd99f5", "metadata": {}, "outputs": [], "source": ["preds2[:3]"]}, {"cell_type": "code", "execution_count": 1, "id": "41acaf5b", "metadata": {}, "outputs": [], "source": ["submission"]}, {"cell_type": "code", "execution_count": 1, "id": "b0e980f8", "metadata": {}, "outputs": [], "source": ["submission[\"Survived\"] = preds2"]}, {"cell_type": "code", "execution_count": 1, "id": "faecdd89", "metadata": {}, "outputs": [], "source": ["submission.to_csv(\"submission1.csv\",index = False)"]}, {"cell_type": "markdown", "id": "f72aadf8", "metadata": {}, "source": ["# 6. Application : Kfold"]}, {"cell_type": "markdown", "id": "3464ee9e", "metadata": {}, "source": ["## 6.1 Step1 : Combine from the chapter3.1 to 5 in one cell\n\n3.1\u304b\u30895\u30921\u3064\u306e\u30bb\u30eb\u306b\u307e\u3068\u3081\u308b"]}, {"cell_type": "code", "execution_count": 1, "id": "640f3e38", "metadata": {}, "outputs": [], "source": ["fix_seed(SEED) # for repetability\n\np_train = folds[folds[\"fold\"] != 0]\np_val = folds[folds[\"fold\"] == 0]\n\np_train = p_train.reset_index(drop=True)\np_val = p_val.reset_index(drop=True)\n\nlgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\nlgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])\n\ncat_list = ['Embarked']\n\n\nmodel = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                  verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n                  num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n                  early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n                  categorical_feature = cat_list, # manual categorical feature setting\n                 \n                 )\n\nimport pickle\n\nmodel_name = \"LGBMmodel.bin\"\n\n# saving model\npickle.dump(model, open(model_name, 'wb'))\n\n# loading model\nmodel = pickle.load(open(model_name, 'rb'))\n\n# predicting validation value\noof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\noof_pred2 = np.where(oof_pred>=0.5,1,0)\n\naccuracy_score(p_val[TARGET], oof_pred2)\n\n# predicting for test_X\npreds = model.predict(test_X[FEATURES])\n\npreds2 = np.where(preds>=0.5,1,0)"]}, {"cell_type": "markdown", "id": "07356a88", "metadata": {}, "source": ["## 6.2 Step2 : Turn around 5 times\n\nfor\u6587\u30675\u500b\u5206\u56de\u3059"]}, {"cell_type": "code", "execution_count": 1, "id": "6c08e72b", "metadata": {}, "outputs": [], "source": ["scores = []\nallpreds = []\n\nallvaliddf = pd.DataFrame()\n\n\nfor fold in range(5):\n    \n    fix_seed(SEED) # for repetability\n\n    p_train = folds[folds[\"fold\"] != fold]\n    p_val = folds[folds[\"fold\"] == fold]\n\n    p_train = p_train.reset_index(drop=True)\n    p_val = p_val.reset_index(drop=True)\n\n    lgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\n    lgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])\n\n    cat_list = ['Embarked']\n\n\n    model = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                      verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n                      num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n                      early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n                      categorical_feature = cat_list, # manual categorical feature setting\n                      \n                     )\n\n    import pickle\n\n    model_name = f\"LGBMmodel{fold}.bin\"\n\n    # saving model\n    pickle.dump(model, open(model_name, 'wb'))\n\n    # loading model\n    model = pickle.load(open(model_name, 'rb'))\n\n    # predicting validation value\n    oof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\n    oof_pred2 = np.where(oof_pred>=0.5,1,0)\n\n    scores.append(accuracy_score(p_val[TARGET], oof_pred2))\n\n    # predicting for test_X\n    preds = model.predict(test_X[FEATURES])\n\n    #preds2 = np.where(preds>=0.5,1,0)\n    \n    allpreds.append(preds)\n    \n    # out of fold : oof\n    p_val[\"preds\"] = oof_pred2\n    \n    allvaliddf = pd.concat([allvaliddf,p_val])\n    \n    "]}, {"cell_type": "code", "execution_count": 1, "id": "bee732e1", "metadata": {}, "outputs": [], "source": ["scores"]}, {"cell_type": "markdown", "id": "044265d9", "metadata": {}, "source": ["### cv\u306e\u8868\u73fe\u306e\u4ed5\u65b9\u306f2\u3064\u3042\u308b : score\u306e\u5e73\u5747\u3001out of fold : oof \u306e\u30b9\u30b3\u30a2"]}, {"cell_type": "code", "execution_count": 1, "id": "765fe5fc", "metadata": {}, "outputs": [], "source": ["np.mean(scores)"]}, {"cell_type": "code", "execution_count": 1, "id": "ec81ba87", "metadata": {}, "outputs": [], "source": ["allvaliddf"]}, {"cell_type": "code", "execution_count": 1, "id": "ed2198a5", "metadata": {}, "outputs": [], "source": ["accuracy_score(allvaliddf[TARGET],allvaliddf[\"preds\"])"]}, {"cell_type": "markdown", "id": "d63c9e98", "metadata": {}, "source": ["# 7. inference"]}, {"cell_type": "code", "execution_count": 1, "id": "16fa910c", "metadata": {}, "outputs": [], "source": ["allpreds"]}, {"cell_type": "code", "execution_count": 1, "id": "f58122d5", "metadata": {}, "outputs": [], "source": ["allpreds = np.mean(allpreds,axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "82267be5", "metadata": {}, "outputs": [], "source": ["allpreds"]}, {"cell_type": "code", "execution_count": 1, "id": "6b7c1f8f", "metadata": {}, "outputs": [], "source": ["allpreds2 = np.where(allpreds>=0.5,1,0)"]}, {"cell_type": "code", "execution_count": 1, "id": "26b7fcf6", "metadata": {}, "outputs": [], "source": ["submission.head(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "bf520afd", "metadata": {}, "outputs": [], "source": ["submission[\"Survived\"] = allpreds2"]}, {"cell_type": "code", "execution_count": 1, "id": "a14216e6", "metadata": {}, "outputs": [], "source": ["submission.to_csv(\"submission2.csv\",index=False)"]}, {"cell_type": "markdown", "id": "4d44a1c4", "metadata": {}, "source": ["# 8. Optuna : Optimization of hyper parameters of Light GBM"]}, {"cell_type": "markdown", "id": "9f78e5d6", "metadata": {}, "source": ["## In order to get repeatablity, we must use optuna_seed. It can be optuna version > 2.8. So update."]}, {"cell_type": "code", "execution_count": 1, "id": "80a4d90c", "metadata": {}, "outputs": [], "source": ["!pip install -U optuna"]}, {"cell_type": "code", "execution_count": 1, "id": "b7aad5d5", "metadata": {}, "outputs": [], "source": ["import optuna.integration.lightgbm as lgbo"]}, {"cell_type": "markdown", "id": "1f43a195", "metadata": {}, "source": ["## After setting parameters, change lgb.train to optuna version\n\nparameter\u3092\u8a2d\u5b9a\u3057\u3066\u3001model\u8a2d\u5b9a\u306e\u3068\u3053\u308d\u3092\u5909\u3048\u308b\u3060\u3051\u3067\u3059\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "6491e3a3", "metadata": {}, "outputs": [], "source": ["lgbm_params = {\n    'objective': 'binary', # Binary classification : 2\u5024\u5206\u985e\u3067\u306f\u3053\u308c\u3092\u4f7f\u3046\n    \"seed\":42,\n    'metric': \"auc\",\n    \"verbose\":-1,\n\"deterministic\":True}\n\n    "]}, {"cell_type": "markdown", "id": "b063e9de", "metadata": {}, "source": ["## 8.1 Let's do only fold. We just changed the model in Chapter 6.1 to the optuna version.\n\n* You can do it just by changing lgb to lgbo, but it is not reproducible, so it seems to be done by this method now.\n\n\u307e\u305a\u306f1\u3064\u3060\u3051\u3084\u308b. 6.1\u7ae0\u306emodel\u3092optuna\u7248\u306b\u5909\u3048\u305f\u3060\u3051\u3067\u3059\u3002\n\n* lgb\u3092lgbo\u306b\u5909\u3048\u308b\u3060\u3051\u3067\u3082\u3067\u304d\u307e\u3059\u304c\u3001\u518d\u73fe\u6027\u304c\u3042\u308a\u307e\u305b\u3093\u306e\u3067\u3001\u3053\u306e\u65b9\u6cd5\u3067\u4eca\u306f\u3084\u308b\u307f\u305f\u3044\u3067\u3059\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "85af20f1", "metadata": {}, "outputs": [], "source": ["fix_seed(SEED) # for repetability\n\np_train = folds[folds[\"fold\"] != 0]\np_val = folds[folds[\"fold\"] == 0]\n\np_train = p_train.reset_index(drop=True)\np_val = p_val.reset_index(drop=True)\n\nlgbo_train = lgbo.Dataset(p_train[FEATURES], p_train[TARGET])\nlgbo_eval = lgbo.Dataset(p_val[FEATURES], p_val[TARGET])\n\ncat_list = ['Embarked']\n\n# For repeatability, change this part\nbooster = lgbo.LightGBMTuner(\n    params = lgbm_params, \n    train_set = lgbo_train,\n    valid_sets=lgbo_eval,\n    optuna_seed=42, # new\n    verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n    num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n    early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n    categorical_feature = cat_list, # manual categorical feature setting\n    )\n\nbooster.run()\n\n# get best model\nmodel = booster.get_best_booster()\n\nimport pickle\n\nmodel_name = \"lgboMmodel.bin\"\n\n# saving model\npickle.dump(model, open(model_name, 'wb'))\n\n# loading model\nmodel = pickle.load(open(model_name, 'rb'))\n\n# predicting validation value\noof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\noof_pred2 = np.where(oof_pred>=0.5,1,0)\n\naccuracy_score(p_val[TARGET], oof_pred2)\n\n# predicting for test_X\npreds = model.predict(test_X[FEATURES])\n\npreds2 = np.where(preds>=0.5,1,0)"]}, {"cell_type": "code", "execution_count": 1, "id": "f0ccc523", "metadata": {}, "outputs": [], "source": ["accuracy_score(p_val[TARGET], oof_pred2)"]}, {"cell_type": "code", "execution_count": 1, "id": "50e32a32", "metadata": {}, "outputs": [], "source": ["submission[\"Survived\"] = preds2"]}, {"cell_type": "code", "execution_count": 1, "id": "1898dc11", "metadata": {}, "outputs": [], "source": ["submission.to_csv(\"submission3.csv\",index=False)"]}, {"cell_type": "markdown", "id": "b674035e", "metadata": {}, "source": ["## 8.2 Kfold"]}, {"cell_type": "code", "execution_count": 1, "id": "b1a858a5", "metadata": {}, "outputs": [], "source": ["scores = []\nallpreds = []\n\nmetric_scores = []\n\nallvaliddf = pd.DataFrame()\n\n\nfor fold in range(5):\n    \n    fix_seed(SEED) # for repetability\n\n    p_train = folds[folds[\"fold\"] != fold]\n    p_val = folds[folds[\"fold\"] == fold]\n\n    p_train = p_train.reset_index(drop=True)\n    p_val = p_val.reset_index(drop=True)\n\n    lgbo_train = lgbo.Dataset(p_train[FEATURES], p_train[TARGET])\n    lgbo_eval = lgbo.Dataset(p_val[FEATURES], p_val[TARGET])\n\n    cat_list = ['Embarked']\n\n    \"\"\"\n    model = lgbo.train(lgbm_params, lgbo_train, valid_sets=lgbo_eval,\n                      verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n                      num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n                      early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n                      categorical_feature = cat_list,# manual categorical feature setting\n                      \n                     )\n    \"\"\"\n    \n    # For repeatability, change this part\n    booster = lgbo.LightGBMTuner(\n        params = lgbm_params, \n        train_set = lgbo_train,\n        valid_sets=lgbo_eval,\n        optuna_seed=42, # new\n        verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n        num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n        early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n        categorical_feature = cat_list, # manual categorical feature setting\n    \n    )\n\n    booster.run()\n\n    metric_scores.append(booster.best_score)\n\n\n    # get best model\n    model = booster.get_best_booster()\n    \n\n    import pickle\n\n    model_name = \"lgboMmodel.bin\"\n\n    # saving model\n    pickle.dump(model, open(model_name, 'wb'))\n\n    # loading model\n    model = pickle.load(open(model_name, 'rb'))\n\n    # predicting validation value\n    oof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\n    oof_pred2 = np.where(oof_pred>=0.5,1,0)\n\n    scores.append(accuracy_score(p_val[TARGET], oof_pred2))\n\n    # predicting for test_X\n    preds = model.predict(test_X[FEATURES])\n\n    #preds2 = np.where(preds>=0.5,1,0)\n    \n    allpreds.append(preds)\n    \n    # out of fold : oof\n    p_val[\"preds\"] = oof_pred2\n    \n    allvaliddf = pd.concat([allvaliddf,p_val])\n    \n    "]}, {"cell_type": "code", "execution_count": 1, "id": "0ed3e75f", "metadata": {}, "outputs": [], "source": ["metric_scores"]}, {"cell_type": "code", "execution_count": 1, "id": "6b11bee8", "metadata": {}, "outputs": [], "source": ["np.mean(metric_scores)"]}, {"cell_type": "code", "execution_count": 1, "id": "3c476d9c", "metadata": {}, "outputs": [], "source": ["scores"]}, {"cell_type": "code", "execution_count": 1, "id": "23daffd7", "metadata": {}, "outputs": [], "source": ["np.mean(scores)"]}, {"cell_type": "code", "execution_count": 1, "id": "30c2b1e0", "metadata": {}, "outputs": [], "source": ["accuracy_score(allvaliddf[TARGET],allvaliddf[\"preds\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "74d57c72", "metadata": {}, "outputs": [], "source": ["allpreds = np.mean(allpreds,axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "4b286770", "metadata": {}, "outputs": [], "source": ["allpreds2 = np.where(allpreds>0.5,1,0)"]}, {"cell_type": "code", "execution_count": 1, "id": "cd2bfc78", "metadata": {}, "outputs": [], "source": ["submission[\"Survived\"] = allpreds2"]}, {"cell_type": "code", "execution_count": 1, "id": "8a97fc8b", "metadata": {}, "outputs": [], "source": ["submission"]}, {"cell_type": "code", "execution_count": 1, "id": "7b29fc60", "metadata": {}, "outputs": [], "source": ["submission.to_csv(\"submission4.csv\",index=False)"]}, {"cell_type": "markdown", "id": "4a65f3e6", "metadata": {}, "source": ["![image.png](attachment:2d070816-bb47-4d80-afd3-3309b9de97e2.png)"]}, {"cell_type": "markdown", "id": "b558dded", "metadata": {}, "source": ["## 5 kfold without optuna is the best LB score. optuna may overfit.\n\n5 kfold\u306eoptuna\u304c\u4e00\u756a\u826f\u3044\u30b9\u30b3\u30a2\u306b\u306a\u308a\u307e\u3057\u305f\u3002optuna\u306f\u904e\u5b66\u7fd2\u3057\u3066\u3044\u308b\u306e\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002"]}, {"cell_type": "markdown", "id": "94c8997f", "metadata": {}, "source": ["# 9. Appendix : LGBM using custom metric"]}, {"cell_type": "markdown", "id": "107f30eb", "metadata": {}, "source": ["## 9.1 Custom Metric LGBM without optuna : fold 0, Submission 5"]}, {"cell_type": "code", "execution_count": 1, "id": "54d88269", "metadata": {}, "outputs": [], "source": ["def feval_accuracy(y_pred, lgb_train):\n    \n    y_true = lgb_train.get_label()\n    \n    y_pred = np.where(y_pred>=0.5,1,0)\n    score = accuracy_score(y_true, y_pred)\n    \n    \n    return 'Accuracy', score, True"]}, {"cell_type": "code", "execution_count": 1, "id": "fb91ebf5", "metadata": {}, "outputs": [], "source": ["lgbm_params = {\n    'objective': 'binary', \n    'seed': 42, \n    'metric': 'None', # Change here \n    \"verbose\":-1,\n    \"deterministic\":True\n}"]}, {"cell_type": "code", "execution_count": 1, "id": "790b449f", "metadata": {}, "outputs": [], "source": ["fix_seed(SEED) # for repetability\n\np_train = folds[folds[\"fold\"] != 0]\np_val = folds[folds[\"fold\"] == 0]\n\np_train = p_train.reset_index(drop=True)\np_val = p_val.reset_index(drop=True)\n\nlgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\nlgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])\n\ncat_list = ['Embarked']\n\n\nmodel = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                  verbose_eval=50,  \n                  num_boost_round=1000,  \n                  early_stopping_rounds=100, \n                  categorical_feature = cat_list, \n                 feval = feval_accuracy # add here\n                 )\n\nimport pickle\n\nmodel_name = \"LGBMmodel.bin\"\n\n# saving model\npickle.dump(model, open(model_name, 'wb'))\n\n# loading model\nmodel = pickle.load(open(model_name, 'rb'))\n\n# predicting validation value\noof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\noof_pred2 = np.where(oof_pred>=0.5,1,0)\n\naccuracy_score(p_val[TARGET], oof_pred2)\n\n# predicting for test_X\npreds = model.predict(test_X[FEATURES])\n\npreds2 = np.where(preds>=0.5,1,0)"]}, {"cell_type": "markdown", "id": "15aeaf3a", "metadata": {}, "source": ["### 0.826 \u2192 0.849\u306b\u4e0a\u6607\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "c01a5522", "metadata": {}, "outputs": [], "source": ["submission[\"Survived\"] = preds2\nsubmission.to_csv(\"submission5.csv\",index=False)"]}, {"cell_type": "markdown", "id": "23900cf5", "metadata": {}, "source": ["## 9.2 Custom Metric LGBM without optuna : 5 kfold , Submission 6"]}, {"cell_type": "code", "execution_count": 1, "id": "d9d7ad65", "metadata": {}, "outputs": [], "source": ["scores = []\nallpreds = []\n\nallvaliddf = pd.DataFrame()\n\n\nfor fold in range(5):\n    \n    fix_seed(SEED) # for repetability\n\n    p_train = folds[folds[\"fold\"] != fold]\n    p_val = folds[folds[\"fold\"] == fold]\n\n    p_train = p_train.reset_index(drop=True)\n    p_val = p_val.reset_index(drop=True)\n\n    lgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\n    lgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])\n\n    cat_list = ['Embarked']\n\n\n    model = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                      verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n                      num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n                      early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n                      categorical_feature = cat_list, # manual categorical feature setting\n                      feval = feval_accuracy # add here\n                     )\n\n    import pickle\n\n    model_name = f\"LGBMmodel{fold}.bin\"\n\n    # saving model\n    pickle.dump(model, open(model_name, 'wb'))\n\n    # loading model\n    model = pickle.load(open(model_name, 'rb'))\n\n    # predicting validation value\n    oof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\n    oof_pred2 = np.where(oof_pred>=0.5,1,0)\n\n    scores.append(accuracy_score(p_val[TARGET], oof_pred2))\n\n    # predicting for test_X\n    preds = model.predict(test_X[FEATURES])\n\n    #preds2 = np.where(preds>=0.5,1,0)\n    \n    allpreds.append(preds)\n    \n    # out of fold : oof\n    p_val[\"preds\"] = oof_pred2\n    \n    allvaliddf = pd.concat([allvaliddf,p_val])\n    \n    "]}, {"cell_type": "code", "execution_count": 1, "id": "a8513a25", "metadata": {}, "outputs": [], "source": ["scores"]}, {"cell_type": "code", "execution_count": 1, "id": "691f837e", "metadata": {}, "outputs": [], "source": ["np.mean(scores)"]}, {"cell_type": "markdown", "id": "abbcf5b4", "metadata": {}, "source": ["# 0.824 \u2192 0.835\u306b\u4e0a\u6607"]}, {"cell_type": "code", "execution_count": 1, "id": "696d1155", "metadata": {}, "outputs": [], "source": ["allpreds = np.mean(allpreds,axis=0)\nallpreds2 = np.where(allpreds>=0.5,1,0)\nsubmission[\"Survived\"] = allpreds2\nsubmission.to_csv(\"submission6.csv\",index=False)"]}, {"cell_type": "markdown", "id": "6a12f2ac", "metadata": {}, "source": ["## 9.2 Custom Metric Optuna with LGBM : fold = 0 , Submission 7\n\n\u203b Optunalightgbmtuner\u3057\u304boptuna\u306eseed\u56fa\u5b9a\u3067\u304d\u307e\u305b\u3093\u304c\u3001custom metric\u304c\u4f7f\u3048\u307e\u305b\u3093\u3067\u3057\u305f\u3002\u305d\u306e\u305f\u3081\u3001\u901a\u5e38\u7248\u3067\u3059\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "fa758dd0", "metadata": {}, "outputs": [], "source": ["import optuna"]}, {"cell_type": "code", "execution_count": 1, "id": "9b0e507b", "metadata": {}, "outputs": [], "source": ["def objective_fold(num):\n    \n    \n    def objective(trial):\n\n\n        for fold in range(5):\n            \n            if fold != num:\n                continue\n                \n\n            fix_seed(SEED) # for repetability\n\n            p_train = folds[folds[\"fold\"] != fold]\n            p_val = folds[folds[\"fold\"] == fold]\n\n            p_train = p_train.reset_index(drop=True)\n            p_val = p_val.reset_index(drop=True)\n\n            lgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\n            lgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])\n\n            cat_list = ['Embarked']\n\n\n\n\n        #==== \u6700\u9069\u5316\u3057\u305f\u3044\u30d1\u30e9\u30e1\u30fc\u30bf ====\n        lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-8, 10.0)\n        lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-8, 10.0)\n\n        learning_rate = trial.suggest_uniform('learning_rate', 0, 1.0)\n\n        feature_fraction = trial.suggest_uniform('feature_fraction', 0, 1.0)\n\n        bagging_fraction = trial.suggest_uniform('bagging_fraction', 0, 1.0)\n        bagging_freq = trial.suggest_int('bagging_freq', 5, 500)\n\n        num_leaves = trial.suggest_int('num_leaves', 5, 1000)\n        num_iterations = trial.suggest_int('num_iterations', 5, 1000)\n\n        min_child_samples = trial.suggest_int('min_child_samples', 5, 500)\n        min_child_weight = trial.suggest_int('min_child_weight', 5, 500)\n\n        max_depth = trial.suggest_int('max_depth', 5, 100)\n\n        #==== \u5b9a\u7fa9\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf ====\n\n        lgbm_params = {\n        'objective': 'binary', \n        'seed': 42, \n        'metric': 'None', # Change here \n        \"lambda_l1\": lambda_l1,\n                  \"lambda_l2\": lambda_l2,\n                  \"learning_rate\": learning_rate,\n                  \"feature_fraction\": feature_fraction,\n                  \"bagging_fraction\": bagging_fraction,\n                  \"bagging_freq\": bagging_freq,\n                  \"num_leaves\": num_leaves,\n                  \"num_iterations\": num_iterations,\n                  \"min_child_samples\": min_child_samples,\n                  \"min_child_weight\": min_child_weight,\n                  \"max_depth\": max_depth,\n                  \"verbosity\": -1,\n            \"deterministic\":True\n        }\n\n\n\n        model = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                              verbose_eval=50,  # Learning result output every 50 iterations : 50\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6bce\u306b\u5b66\u7fd2\u7d50\u679c\u51fa\u529b\n                              num_boost_round=1000,  # Specify the maximum number of iterations : \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u6307\u5b9a\n                              early_stopping_rounds=100, # Early stopping number : early stopping\u3092\u63a1\u7528\u3059\u308biteration\u56de\u6570\n                              categorical_feature = cat_list, # manual categorical feature setting\n                              feval = feval_accuracy # add here\n                             )\n\n\n\n        oof_pred = model.predict(p_val[FEATURES])\n        oof_pred2 = np.where(oof_pred>=0.5,1,0)\n\n\n        score = accuracy_score(p_val[TARGET], oof_pred2)\n        return score\n    \n    return objective"]}, {"cell_type": "code", "execution_count": 1, "id": "eede03d1", "metadata": {}, "outputs": [], "source": ["study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=42))\nstudy.optimize(objective_fold(0), n_trials=100)"]}, {"cell_type": "code", "execution_count": 1, "id": "c2a25aea", "metadata": {}, "outputs": [], "source": ["trial = study.best_trial\nprint(trial.params)\n\nlgbm_params = {\n    'objective': 'binary', \n    'seed': 42, \n    'metric': 'None', # Change here \n    \"verbose\":-1,\n    \"deterministic\":True\n}\nlgbm_params.update(**lgbm_params,**trial.params)\nlgbm_params"]}, {"cell_type": "markdown", "id": "fca5addb", "metadata": {}, "source": ["### 9.2.1 Inference"]}, {"cell_type": "code", "execution_count": 1, "id": "4d7c9228", "metadata": {}, "outputs": [], "source": ["fix_seed(SEED) # for repetability\n\np_train = folds[folds[\"fold\"] != 0]\np_val = folds[folds[\"fold\"] == 0]\n\np_train = p_train.reset_index(drop=True)\np_val = p_val.reset_index(drop=True)\n\nlgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\nlgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])\n\ncat_list = ['Embarked']\n\n\nmodel = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                  verbose_eval=50,  \n                  num_boost_round=1000,  \n                  early_stopping_rounds=100, \n                  categorical_feature = cat_list, \n                 feval = feval_accuracy # add here\n                 )\n\nimport pickle\n\nmodel_name = \"LGBMmodel.bin\"\n\n# saving model\npickle.dump(model, open(model_name, 'wb'))\n\n# loading model\nmodel = pickle.load(open(model_name, 'rb'))\n\n# predicting validation value\noof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\noof_pred2 = np.where(oof_pred>=0.5,1,0)\n\naccuracy_score(p_val[TARGET], oof_pred2)\n\n# predicting for test_X\npreds = model.predict(test_X[FEATURES])\n\npreds2 = np.where(preds>=0.5,1,0)"]}, {"cell_type": "code", "execution_count": 1, "id": "3f00ac77", "metadata": {}, "outputs": [], "source": ["#allpreds = np.mean(allpreds,axis=0)\nsubmission[\"Survived\"] = preds2\nsubmission.to_csv(\"submission7.csv\",index=False)"]}, {"cell_type": "markdown", "id": "5ee90f0d", "metadata": {}, "source": ["## 9.3 Kfold with custom metric LGBM each fold optuna"]}, {"cell_type": "code", "execution_count": 1, "id": "3d57a1d8", "metadata": {}, "outputs": [], "source": ["scores = []\nallpreds = []\n\nallvaliddf = pd.DataFrame()\n\nfor fold in range(5):\n    \n\n\n    study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=42))\n    study.optimize(objective_fold(fold), n_trials=100)\n\n    trial = study.best_trial\n    print(trial.params)\n\n    lgbm_params = {\n        'objective': 'binary', \n        'seed': 42, \n        'metric': 'None', # Change here \n        \"verbose\":-1,\n        \"deterministic\":True\n    }\n    lgbm_params.update(**lgbm_params,**trial.params)\n    lgbm_params\n\n    fix_seed(SEED) # for repetability\n\n    p_train = folds[folds[\"fold\"] != 0]\n    p_val = folds[folds[\"fold\"] == 0]\n\n    p_train = p_train.reset_index(drop=True)\n    p_val = p_val.reset_index(drop=True)\n\n    lgb_train = lgb.Dataset(p_train[FEATURES], p_train[TARGET])\n    lgb_eval = lgb.Dataset(p_val[FEATURES], p_val[TARGET])\n\n    cat_list = ['Embarked']\n\n\n    model = lgb.train(lgbm_params, lgb_train, valid_sets=lgb_eval,\n                      verbose_eval=50,  \n                      num_boost_round=1000,  \n                      early_stopping_rounds=100, \n                      categorical_feature = cat_list, \n                     feval = feval_accuracy # add here\n                     )\n\n    import pickle\n\n    model_name = \"LGBMmodel.bin\"\n\n    # saving model\n    pickle.dump(model, open(model_name, 'wb'))\n\n    # loading model\n    model = pickle.load(open(model_name, 'rb'))\n\n    # predicting validation value\n    oof_pred = model.predict(p_val[FEATURES], num_iteration=model.best_iteration)\n\n    oof_pred2 = np.where(oof_pred>=0.5,1,0)\n\n    scores.append(accuracy_score(p_val[TARGET], oof_pred2))\n\n    # predicting for test_X\n    preds = model.predict(test_X[FEATURES])\n    \n    #preds2 = np.where(preds>=0.5,1,0)\n    \n    allpreds.append(preds)\n    \n    # out of fold : oof\n    p_val[\"preds\"] = oof_pred2\n    \n    allvaliddf = pd.concat([allvaliddf,p_val])\n    \n"]}, {"cell_type": "code", "execution_count": 1, "id": "f7e4c3a0", "metadata": {}, "outputs": [], "source": ["scores"]}, {"cell_type": "code", "execution_count": 1, "id": "16905daf", "metadata": {}, "outputs": [], "source": ["np.mean(scores)"]}, {"cell_type": "markdown", "id": "ab1405d3", "metadata": {}, "source": ["### 0.835 \u2192 0.849 \u306b\u4e0a\u6607"]}, {"cell_type": "code", "execution_count": 1, "id": "b7fc213d", "metadata": {}, "outputs": [], "source": ["accuracy_score(allvaliddf[TARGET],allvaliddf[\"preds\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "98e546eb", "metadata": {}, "outputs": [], "source": ["allpreds = np.mean(allpreds,axis=0)\nallpreds2 = np.where(allpreds>=0.5,1,0)\nsubmission[\"Survived\"] = allpreds2\nsubmission.to_csv(\"submission8.csv\",index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}