{"cells": [{"cell_type": "markdown", "id": "987d06a4", "metadata": {}, "source": ["# Chest Xray pneumonia, study with CNN"]}, {"cell_type": "markdown", "id": "ad7af9f7", "metadata": {}, "source": ["I tried to study, Chest Xray pneumonia with CNN."]}, {"cell_type": "code", "execution_count": 1, "id": "25565334", "metadata": {}, "outputs": [], "source": ["# Basic library\nimport numpy as np \nimport pandas as pd \nimport os\nimport glob\n\n# Data preprocessing\nimport cv2 # Open cv\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Machine learning library\nimport keras\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, Activation, Input\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Validation\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"]}, {"cell_type": "markdown", "id": "0610becb", "metadata": {}, "source": ["## dataset loading & create dataframe"]}, {"cell_type": "code", "execution_count": 1, "id": "e2206cb9", "metadata": {}, "outputs": [], "source": ["print(\"train\",os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train\"))\nprint(\"val\",os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train\"))\nprint(\"test\",os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train\"))"]}, {"cell_type": "code", "execution_count": 1, "id": "aea08e7a", "metadata": {}, "outputs": [], "source": ["# train_data_set\n# Normal\ntrain_data_nor = pd.DataFrame({})\ntrain_data_nor[\"data_id\"] = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train/NORMAL\")\ntrain_data_nor[\"flg\"] = 0\n\n# Pneumonia\ntrain_data_pne = pd.DataFrame({})\ntrain_data_pne[\"data_id\"] = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA\")\ntrain_data_pne[\"flg\"] = 1"]}, {"cell_type": "code", "execution_count": 1, "id": "2b716b80", "metadata": {}, "outputs": [], "source": ["# val_data_set\n# Normal\nval_data_nor = pd.DataFrame({})\nval_data_nor[\"data_id\"] = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/val/NORMAL\")\nval_data_nor[\"flg\"] = 0\n\n# Pneumonia\nval_data_pne = pd.DataFrame({})\nval_data_pne[\"data_id\"] = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA\")\nval_data_pne[\"flg\"] = 1"]}, {"cell_type": "code", "execution_count": 1, "id": "fab983bc", "metadata": {}, "outputs": [], "source": ["# test_data_set\n# Normal\ntest_data_nor = pd.DataFrame({})\ntest_data_nor[\"data_id\"] = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/test/NORMAL\")\ntest_data_nor[\"flg\"] = 0\n\n# Pneumonia\ntest_data_pne = pd.DataFrame({})\ntest_data_pne[\"data_id\"] = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA\")\ntest_data_pne[\"flg\"] = 1"]}, {"cell_type": "code", "execution_count": 1, "id": "62fd4e72", "metadata": {}, "outputs": [], "source": ["# data shape\nprint(\"train data normal:{}\".format(train_data_nor.shape), \"train_data_pneumonia:{}\".format(train_data_pne.shape))\nprint(\"val data normal:{}\".format(val_data_nor.shape), \"val_data_pneumonia:{}\".format(val_data_pne.shape))\nprint(\"test data normal:{}\".format(test_data_nor.shape), \"test_data_pneumonia:{}\".format(test_data_pne.shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "0beccd06", "metadata": {}, "outputs": [], "source": ["# Combine data frame\ntrain_data = pd.concat([train_data_nor, train_data_pne])\nval_data = pd.concat([val_data_nor, val_data_pne])\ntest_data = pd.concat([test_data_nor, test_data_pne])\n\n# data shape\nprint(\"train data:{}\".format(train_data.shape))\nprint(\"val data:{}\".format(val_data.shape))\nprint(\"test data:{}\".format(test_data.shape))"]}, {"cell_type": "markdown", "id": "622b6827", "metadata": {}, "source": ["Image data loading, This time, I decide the data size=64\u00d764."]}, {"cell_type": "code", "execution_count": 1, "id": "0d164896", "metadata": {}, "outputs": [], "source": ["# data size\nsize = 128\n\n# train_data_nor\ntrain_image_nor = []\n\n# loading\nfor _id in train_data_nor[\"data_id\"]:\n    path = \"../input/chest-xray-pneumonia/chest_xray/train/NORMAL/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    train_image_nor.append(image)"]}, {"cell_type": "code", "execution_count": 1, "id": "5ed3750f", "metadata": {}, "outputs": [], "source": ["# train_data_pne\ntrain_image_pne = []\n\n# loading\nfor _id in train_data_pne[\"data_id\"]:\n    path = \"../input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    train_image_pne.append(image)"]}, {"cell_type": "code", "execution_count": 1, "id": "7d98aef9", "metadata": {}, "outputs": [], "source": ["# val_data_nor\nval_image_nor = []\n\n# loading\nfor _id in val_data_nor[\"data_id\"]:\n    path = \"../input/chest-xray-pneumonia/chest_xray/val/NORMAL/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    val_image_nor.append(image)"]}, {"cell_type": "code", "execution_count": 1, "id": "4a88f4f5", "metadata": {}, "outputs": [], "source": ["# val_data_pne\nval_image_pne = []\n\n# loading\nfor _id in val_data_pne[\"data_id\"]:\n    path = \"../input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    val_image_nor.append(image)"]}, {"cell_type": "code", "execution_count": 1, "id": "59ccd2a6", "metadata": {}, "outputs": [], "source": ["# test_data_nor\ntest_image_nor = []\n\n# loading\nfor _id in test_data_nor[\"data_id\"]:\n    path = \"../input/chest-xray-pneumonia/chest_xray/test/NORMAL/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    test_image_nor.append(image)"]}, {"cell_type": "code", "execution_count": 1, "id": "ebfd6a05", "metadata": {}, "outputs": [], "source": ["# test_data_pne\ntest_image_pne = []\n\n# loading\nfor _id in test_data_pne[\"data_id\"]:\n    path = \"../input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    test_image_pne.append(image)"]}, {"cell_type": "markdown", "id": "084b67c0", "metadata": {}, "source": ["### image data check"]}, {"cell_type": "code", "execution_count": 1, "id": "cf213965", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(4, 4, figsize=(20,20))\n\nfor i in range(4):\n    ax[0,i].imshow(train_image_nor[i])\n    ax[0,i].set_title(\"train_image_normal\")\n    \n    ax[1,i].imshow(train_image_pne[i])\n    ax[1,i].set_title(\"train_image_pneumonia\")\n    \n    ax[2,i].imshow(test_image_nor[i])\n    ax[2,i].set_title(\"test_image_normal\")\n    \n    ax[3,i].imshow(test_image_pne[i])\n    ax[3,i].set_title(\"test_image_pneumonia\")"]}, {"cell_type": "markdown", "id": "8092f457", "metadata": {}, "source": ["Combine list data"]}, {"cell_type": "code", "execution_count": 1, "id": "5b9c7fab", "metadata": {}, "outputs": [], "source": ["train_image = train_image_nor + train_image_pne\nval_image = val_image_nor + val_image_pne\ntest_image = test_image_nor + test_image_pne"]}, {"cell_type": "markdown", "id": "49a28d82", "metadata": {}, "source": ["# Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "0757fbf6", "metadata": {}, "outputs": [], "source": ["# Training data\n# data dimension\nX_train = np.ndarray(shape=(len(train_image), size, size, 3), dtype=np.float32)\n\n# change to np.ndarray\ni = 0\n\nfor image in train_image:\n    X_train[i] = train_image[i]\n    i=i+1\n    \n# Scaling\nX_train = X_train/255\n\n# Checking dimension\nprint(\"Train shape:{}\".format(X_train.shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "f1dfec5f", "metadata": {}, "outputs": [], "source": ["# Val data\n# data dimension\nX_val = np.ndarray(shape=(len(val_image), size, size, 3), dtype=np.float32)\n\n# change to np.ndarray\ni = 0\n\nfor image in val_image:\n    X_val[i] = val_image[i]\n    i=i+1\n    \n# Scaling\nX_val = X_val/255\n\n# Checking dimension\nprint(\"val shape:{}\".format(X_val.shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "5fee2593", "metadata": {}, "outputs": [], "source": ["# Test data\n# data dimension\nX_Test = np.ndarray(shape=(len(test_image), size, size, 3), dtype=np.float32)\n\n# change to np.ndarray\ni = 0\n\nfor image in test_image:\n    X_Test[i] = test_image[i]\n    i=i+1\n    \n# Scaling\nX_Test = X_Test/255\n\n# Checking dimension\nprint(\"Test shape:{}\".format(X_Test.shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "ca987fb6", "metadata": {}, "outputs": [], "source": ["# train target data\ny_train = train_data[\"flg\"]\n\n# change to np.array\ny_train = np.array(y_train.values)\nprint(\"y_train shape:{}\".format(y_train.shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "f081b230", "metadata": {}, "outputs": [], "source": ["# val target data\ny_val = val_data[\"flg\"]\n\n# change to np.array\ny_val = np.array(y_val.values)\nprint(\"y_val shape:{}\".format(y_val.shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "6eda0295", "metadata": {}, "outputs": [], "source": ["# test target data\ny_test = test_data[\"flg\"]\n\n# change to np.array\ny_test = np.array(y_test.values)\nprint(\"y shape:{}\".format(y_test.shape))"]}, {"cell_type": "markdown", "id": "2af15940", "metadata": {}, "source": ["## Difinition CNN model"]}, {"cell_type": "code", "execution_count": 1, "id": "22c6d84c", "metadata": {}, "outputs": [], "source": ["def define_model():\n    model = Sequential()\n    # 1st layer block\n    model.add(BatchNormalization(input_shape=(size, size, 3)))\n    model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # 2nd layer block\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # 3rd layer block\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # 4th layer block\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # Flatten\n    model.add(Flatten())\n    \n    # Dense layer\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(2, activation='softmax'))\n    \n    # model\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer=Adam(lr=0.0001, decay=0.000001),\n                  metrics=[\"accuracy\"])\n    return model"]}, {"cell_type": "markdown", "id": "04c5dc94", "metadata": {}, "source": ["## Fitting model"]}, {"cell_type": "code", "execution_count": 1, "id": "4224b731", "metadata": {}, "outputs": [], "source": ["# Data augmentation\ndatagen = ImageDataGenerator(rotation_range=15, \n                             width_shift_range=0.2, \n                             height_shift_range=0.2,\n                             horizontal_flip=True)\n\ndatagen.fit(X_train)\n\n# Model check point\nmc = ModelCheckpoint(\"cnn_model_01.h5\",\n                     monitor='val_loss',\n                     save_best_only=True,\n                     verbose=1)\n\nes = EarlyStopping(monitor='val_loss',\n                   patience=5)"]}, {"cell_type": "code", "execution_count": 1, "id": "bbb3954a", "metadata": {}, "outputs": [], "source": ["# Calculation\nmodel = define_model()\n\n# Training\nbatch_size= 12\nepochs = 100\nvalid_samples = 100\ntrain_samples = len(X_train) - valid_samples\n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n                    steps_per_epoch = train_samples / batch_size,\n                    epochs = epochs,\n                    callbacks = [mc, es],\n                    validation_data = datagen.flow(X_val, y_val, batch_size=batch_size),\n                    validation_steps = valid_samples / batch_size )"]}, {"cell_type": "markdown", "id": "10e4b614", "metadata": {}, "source": ["## Evaluation training"]}, {"cell_type": "code", "execution_count": 1, "id": "d4367b5a", "metadata": {}, "outputs": [], "source": ["train_loss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nplt.figure(figsize=(8, 4))\nplt.plot(range(len(train_loss)), train_loss, label='train_loss')\nplt.plot(range(len(val_loss)), val_loss, label='valid_loss')\nplt.xlabel('epoch', fontsize=16)\nplt.ylabel('loss', fontsize=16)\nplt.yscale(\"log\")\nplt.legend(fontsize=16)\nplt.show()\n\ntrain_loss = history.history[\"accuracy\"]\nval_loss = history.history[\"val_accuracy\"]\n\nplt.figure(figsize=(8, 4))\nplt.plot(range(len(train_loss)), train_loss, label='accuracy')\nplt.plot(range(len(val_loss)), val_loss, label='val_accuracy')\nplt.xlabel('epoch', fontsize=16)\nplt.ylabel('accuracy', fontsize=16)\nplt.legend(fontsize=16)\nplt.show()"]}, {"cell_type": "markdown", "id": "ae269b08", "metadata": {}, "source": ["# Test data prediction"]}, {"cell_type": "code", "execution_count": 1, "id": "ea6d9808", "metadata": {}, "outputs": [], "source": ["# Loading best model\nmodel = load_model('cnn_model_01.h5')\n\n# Best model accuracy and loss\nevaluation = model.evaluate(X_Test, y_test)\nprint('test_loss:%.3f' % evaluation[0])\nprint('test_accuracy:%.3f' % evaluation[1])"]}, {"cell_type": "code", "execution_count": 1, "id": "69c7d8de", "metadata": {}, "outputs": [], "source": ["# predict label\ny_pred = model.predict_classes(X_Test)\n\n# Confusion matrix\ncnf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n\n# Visualization\nfig, ax = plt.subplots(figsize=(6, 6))\nax.matshow(cnf_matrix, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cnf_matrix.shape[0]): \n    for j in range(cnf_matrix.shape[1]): \n        ax.text(x=j, y=i, s=cnf_matrix[i,j], va='center', ha='center')\nplt.xlabel(\"predicted label\")\nplt.ylabel(\"true label\")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "807feb36", "metadata": {}, "outputs": [], "source": ["print(\"accuracy = %.3f\" % accuracy_score(y_true=y_test, y_pred=y_pred))\nprint(\"precision = %.3f\" % precision_score(y_true=y_test, y_pred=y_pred))\nprint(\"recall = %.3f\" % recall_score(y_true=y_test, y_pred=y_pred))\nprint(\"f1_score = %.3f\" % f1_score(y_true=y_test, y_pred=y_pred))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}