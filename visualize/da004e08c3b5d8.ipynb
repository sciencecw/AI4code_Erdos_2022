{"cells": [{"cell_type": "markdown", "id": "dea06a29", "metadata": {}, "source": ["This Kernel's goal is to highlight a real business problem and to propose a modular way of thinking to build an efficient Search Engine."]}, {"cell_type": "code", "execution_count": 1, "id": "0a0e3b93", "metadata": {}, "outputs": [], "source": ["from IPython.display import Image"]}, {"cell_type": "markdown", "id": "1a8d67e6", "metadata": {}, "source": ["I have been surfing [Kaggle job page](https://www.kaggle.com/jobs) to explore the latest they have in the field of data science and machine learning field and to learn what new skills I need to be focusing on for the future.\n\nSince I\u2019m interested in NLP I jumped right in to the search box and started typing \u201cNLP software engineer\u201d and I got a \u201cNo Jobs to show\u201d message!"]}, {"cell_type": "code", "execution_count": 1, "id": "77c3d557", "metadata": {}, "outputs": [], "source": ["Image(\"../input/search-results-examples-images/kagglesearchengine-20190412t113812z-001/kaggleSearchEngine/kse-1.png\")"]}, {"cell_type": "markdown", "id": "b1340e29", "metadata": {}, "source": ["I was sure that there are few jobs that match my search!\n\nI tried to search only with \u201cNLP\u201d and the surprise was that it showed couple as a results!"]}, {"cell_type": "code", "execution_count": 1, "id": "f874a932", "metadata": {}, "outputs": [], "source": ["Image(\"../input/search-results-examples-images/kagglesearchengine-20190412t113812z-001/kaggleSearchEngine/kse-2.png\")"]}, {"cell_type": "markdown", "id": "2db8a626", "metadata": {}, "source": ["I tried to do more search queries in aim to understand how the search actually works on Kaggle's website.\nI tried \u201cNLP engineer\u201d and I had one result.."]}, {"cell_type": "code", "execution_count": 1, "id": "959418f7", "metadata": {}, "outputs": [], "source": ["Image(\"../input/search-results-examples-images/kagglesearchengine-20190412t113812z-001/kaggleSearchEngine/kse-3.png\")"]}, {"cell_type": "markdown", "id": "0678afa5", "metadata": {}, "source": ["Now let's try to do search with the same keywords but in different order. In our case I tried \u201cengineer NLP\u201d, again the result was \u201cNo Jobs to show\u201d!"]}, {"cell_type": "code", "execution_count": 1, "id": "d2e56bc8", "metadata": {}, "outputs": [], "source": ["Image(\"../input/search-results-examples-images/kagglesearchengine-20190412t113812z-001/kaggleSearchEngine/kse-4.png\")"]}, {"cell_type": "markdown", "id": "e27d26c7", "metadata": {}, "source": ["**From the business point of view**, this is considered a failing point because I send the user to a dead-end and his journey mostly will end up with a bad experience.\n\nTo proceed, we need to understand why this has happened and how to use NLP to build a search engine that can be reliable and capable to return related results which will help improve the user experience as well.\n\nFrom the test cases above we can guess what is the function behind the search. The search function is built to return the Exact Match from the jobs description.\n\nSQL example:\n```sql\nselect * from kaggleJobs where description regexp '[[:<:]]search keywords[[:>:]]';\n```\nPython example:\n```python\nif \"search keywords\" in description:\n    print(\"Find 2 Jobs!\")\nelse:\n    print(\"No Jobs to show\")\n```\n\nThis will check only if the exact search text is found in the jobs description. But this will not work all the time as we saw before."]}, {"cell_type": "markdown", "id": "7cc29a66", "metadata": {}, "source": ["**How NLP Can Help to Solve This Real Business Problem?**\n\nIn this notebook we\u2019ll explain how use NLP to propose a simple and basic search engine that could handle multi cases to find the most related search results.\n\n**Corpus & Reading in the data**\n\nThe first step is to acquire the data. For that, I collected all the open jobs on Kaggle. Let\u2019s load and browse the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "d435cca3", "metadata": {}, "outputs": [], "source": ["import pandas as pd\ndata = pd.read_csv('../input/jobs-list/kaggleJobs.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "0cafa060", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "markdown", "id": "6571c727", "metadata": {}, "source": ["As we see from the dataset, the only colums that contains textual content about the jobs are\n* **result__companyName:** contain company name\n* **result__content:** contain job description\n* **result__name:** contain job title\n\nWe'll select these three columns and ignore the rest for now."]}, {"cell_type": "code", "execution_count": 1, "id": "4fdff84a", "metadata": {}, "outputs": [], "source": ["searchData = data[['result__companyName', 'result__content', 'result__name']]"]}, {"cell_type": "markdown", "id": "b98ac1b2", "metadata": {}, "source": ["**Pre-processing the raw text**\n\nNow we need to clean the data where it came as a raw HTML. Also, we may remove the punctuations as well."]}, {"cell_type": "code", "execution_count": 1, "id": "7e2cb5d3", "metadata": {}, "outputs": [], "source": ["import re\nimport string\n\ndef cleanHtml(raw_html):\n    tags = r'<.*?>|/|\\\\.|-|,'\n    cleanHtml = re.sub(tags, ' ', raw_html)\n    cleantext = cleanHtml.translate(str.maketrans('', '', string.punctuation))\n    return cleantext"]}, {"cell_type": "code", "execution_count": 1, "id": "7d961fbd", "metadata": {}, "outputs": [], "source": ["searchData['result__content__clean'] = searchData['result__content'].apply(lambda rawHtml: cleanHtml(rawHtml))"]}, {"cell_type": "markdown", "id": "5963c671", "metadata": {}, "source": ["**Data Transformation**\n\nAfter the initial preprocessing phase, we need to transform text into a meaningful vector of numbers.\nWe are going to use TF-IDF approach. Term Frequency-Inverse Document Frequency, or TF-IDF for short, is an approach to rescale the frequency of words by how often they appear in all documents so that the scores for frequent words like \u201cthe\u201d that are also frequent across all documents are penalized [1].\n\nWe'll use TFidfVectorizer from sklearn to convert our corpus into a matrix of TF-IDF features."]}, {"cell_type": "code", "execution_count": 1, "id": "d274455f", "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(analyzer='word',min_df=0.0005,stop_words='english')\n\ntfidfMatrix = vectorizer.fit_transform(searchData['result__companyName']+\" \"+searchData['result__content__clean']+\" \"+searchData['result__name'])"]}, {"cell_type": "markdown", "id": "d989e0ea", "metadata": {}, "source": ["**Cosine similarity**\n\nTF-IDF is a transformation applied to texts to get two real-valued vectors in vector space. We can then obtain the cosine similarity of any pair of vectors by taking their dot product and dividing that by the product of their norms. \n\nThat's it!\n\nNow we can apply search queries. Let's try one of the quieres that failed to return results such as \"engineer NLP\"\n\nWe'll transfor the query text to document-term matrix. Then we'll measure the cosine similarity between the queryTFIDF and our original TFIDF matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "b5f823c8", "metadata": {}, "outputs": [], "source": ["queryText = \"engineer NLP\"\nqueryTFIDF = vectorizer.transform([queryText])"]}, {"cell_type": "code", "execution_count": 1, "id": "ec9d7c43", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics.pairwise import cosine_similarity\ndef sim():\n    similarityMatrix = cosine_similarity(queryTFIDF, tfidfMatrix).flatten()\n    sortedResultsIndices = similarityMatrix.argsort()[:-11:-1]\n    return [sortedResultsIndices[idx] for idx, val in enumerate(similarityMatrix[sortedResultsIndices]) if val>0]\n\ndata.iloc[sim(),[4, 5, 16, 23]]"]}, {"cell_type": "markdown", "id": "18481de3", "metadata": {}, "source": ["**Hooray we have results!**\n\nWe can tell that the first two jobs are the most related to our search keywords so it works fine!\n\n**But**, we still have more to do to make our engine reliable. To do that we need to handle incomplete words and the misspelling issues.\n\n**Jaro\u2013Winkler distance**\n\nThe Jaro\u2013Winkler distance is a string metric measuring an edit distance between two sequences. We are going to use Jaro\u2013Winkler to correct misspelling and to predict incomplete words based on the content of our corpus."]}, {"cell_type": "code", "execution_count": 1, "id": "21756c6a", "metadata": {}, "outputs": [], "source": ["# To use jaro_winkler_similarity make sure that you have NLTK v3.4\n# You can check nltk version by running following lines:\n# import nltk\n# print('The nltk version is {}.'.format(nltk.__version__))\n\n!pip install -U nltk==3.4"]}, {"cell_type": "code", "execution_count": 1, "id": "5be2bab8", "metadata": {}, "outputs": [], "source": ["from nltk.metrics.distance import jaro_winkler_similarity as jaro\ndef jaro_winkler(word):\n    jaroDis = [round(jaro(x, word.lower(), p=0.1, max_l=10), 3) for x in vectorizer.get_feature_names()]\n    indices = [index for index, value in sorted(enumerate(jaroDis), reverse=True, key=lambda x: x[1])]\n    return [vectorizer.get_feature_names()[i] for i in indices[0:3]]"]}, {"cell_type": "markdown", "id": "70e57665", "metadata": {}, "source": ["Let's intentionally misspell both words in \"engineer NLP\""]}, {"cell_type": "code", "execution_count": 1, "id": "beab5b78", "metadata": {}, "outputs": [], "source": ["queryText = \"enginner NLD\"\nqueryTextCheck = \" \".join([\" \".join(jaro_winkler(w)) for w in queryText.split()])\nqueryTFIDF = vectorizer.transform([queryTextCheck])\ndata.iloc[sim(),[4, 5, 16, 23]]"]}, {"cell_type": "markdown", "id": "316cbeb8", "metadata": {}, "source": ["That's nice! we still have a relevant results even with an input with typos/Improper Inputs\n\n**Future work**\n\nThis is a basic engine that need to be optimized on many levels.\n\nWe may need to apply more preprocessing and cleaning such as Stemming and\\or Lemmatization.\n\nAlso we may optimize the TfidfVectorizer by using n-gram and optimize other parameters.\n\nWe may optimize the p & l values for Jaro Winkler algorithm\n\nLast but not least, we may start to think if we need to add extra layers to understand the context of the text, synonyms\\antonyms and more ..."]}, {"cell_type": "markdown", "id": "3bb75165", "metadata": {}, "source": ["Finally, to bring our work to the life, I deployed all the work done up to a server so **YOU CAN TRY IT YOURSELF**\n> Please note that some links may be out-of date"]}, {"cell_type": "code", "execution_count": 1, "id": "5e939d3a", "metadata": {}, "outputs": [], "source": ["from IPython.display import HTML\nHTML('<iframe src=https://kaggle-search-engine-demo.herokuapp.com/ width=600 height=350></iframe>')"]}, {"cell_type": "markdown", "id": "0fb589ed", "metadata": {}, "source": ["Thank you"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}