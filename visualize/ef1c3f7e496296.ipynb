{"cells": [{"cell_type": "markdown", "id": "c4b98edb", "metadata": {}, "source": ["* ***User***: [@manishshah120](https://www.kaggle.com/manishshah120)\n* ***LinkedIn***: https://www.linkedin.com/in/manishshah120/\n* ***GitHub***: https://github.com/ManishShah120\n* ***Twitter***: https://twitter.com/ManishShah120\n\n> *This Notebook was created while undergoing a course \"[Deep Learning with PyTorch: Zero to GANs](https://jovian.ml/forum/t/start-here-welcome-to-deep-learning-with-pytorch-zero-to-gans/1622)\" from \"jovian.ml\" in collaboratoin with \"freecodecamp.org\"*"]}, {"cell_type": "markdown", "id": "bdacc5f5", "metadata": {}, "source": ["# **Classifying CIFAR10 images using a ResNet and Regularization techniques in PyTorch**\n\n### **Training an image classifier from scratch to over 90% accuracy in less than 5 minutes on a single GPU**\n\nPart 6 of \"PyTorch: Zero to GANs\""]}, {"cell_type": "markdown", "id": "c222e8e9", "metadata": {}, "source": ["#### In this tutorial, we'll use the following techniques to achieve over 90% accuracy in less than 5 minutes:\n\n- Data normalization\n- Data augmentation\n- Residual connections\n- Batch normalization\n- Learning rate scheduling\n- Weight Decay\n- Gradient clipping\n- Adam optimizer"]}, {"cell_type": "markdown", "id": "1d814fe5", "metadata": {}, "source": ["## **Imports**"]}, {"cell_type": "code", "execution_count": 1, "id": "407b07c6", "metadata": {}, "outputs": [], "source": ["import os\nimport torch\nimport torchvision\nimport tarfile\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "2af58107", "metadata": {}, "outputs": [], "source": ["project_name='013predictingimagesofcifar10dtstwithresnetregularizationtechniques-lec-5'"]}, {"cell_type": "markdown", "id": "215140d7", "metadata": {}, "source": ["### Preparing the Data"]}, {"cell_type": "code", "execution_count": 1, "id": "ea418d29", "metadata": {}, "outputs": [], "source": ["# Dowload the dataset\ndataset_url = \"http://files.fast.ai/data/cifar10.tgz\"\ndownload_url(dataset_url, '.')\n\n# Extract from archive\nwith tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n    tar.extractall(path='./data')\n    \n# Look into the data directory\ndata_dir = './data/cifar10'\nprint(os.listdir(data_dir))\nclasses = os.listdir(data_dir + \"/train\")\nprint(classes)"]}, {"cell_type": "markdown", "id": "d037ec69", "metadata": {}, "source": ["There are a few important changes we'll make while creating the PyTorch datasets:\n\n1. **Use test set for validation**: Instead of setting aside a fraction (e.g. 10%) of the data from the training set for validation, we'll simply use the test set as our validation set. This just gives a little more data to train with. In general, once you have picked the best model architecture & hypeparameters using a fixed validation set, it is a good idea to retrain the same model on the entire dataset just to give it a small final boost in performance.\n2. **Channel-wise data normalization**: We will normalize the image tensors by subtracting the mean and dividing by the standard deviation across each channel. As a result, the mean of the data across each channel is 0, and standard deviation is 1. Normalizing the data prevents the values from any one channel from disproportionately affecting the losses and gradients while training, simply by having a higher or wider range of values that others.\n3. **Randomized data augmentations**: We will apply randomly chosen transformations while loading images from the training dataset. Specifically, we will pad each image by 4 pixels, and then take a random crop of size 32 x 32 pixels, and then flip the image horizontally with a 50% probability. Since the transformation will be applied randomly and dynamically each time a particular image is loaded, the model sees slightly different images in each epoch of training, which allows it generalize better.\n\n![image](https://imgaug.readthedocs.io/en/latest/_images/cropandpad_percent.jpg)"]}, {"cell_type": "code", "execution_count": 1, "id": "be01aa4a", "metadata": {}, "outputs": [], "source": ["# Data transforms (normalization & data augmentation)\nstats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))    # Channel wise means and s.d.\n\ntrain_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'), \n                         tt.RandomHorizontalFlip(), \n                         tt.ToTensor(), \n                         tt.Normalize(*stats,inplace=True)]\n                        )\n\nvalid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])"]}, {"cell_type": "code", "execution_count": 1, "id": "c369c003", "metadata": {}, "outputs": [], "source": ["# PyTorch datasets\ntrain_ds = ImageFolder(data_dir+'/train', train_tfms)\nvalid_ds = ImageFolder(data_dir+'/test', valid_tfms)"]}, {"cell_type": "markdown", "id": "b79a875a", "metadata": {}, "source": ["## **Data Loaders**"]}, {"cell_type": "code", "execution_count": 1, "id": "27ead266", "metadata": {}, "outputs": [], "source": ["batch_size = 400"]}, {"cell_type": "code", "execution_count": 1, "id": "2535c7e9", "metadata": {}, "outputs": [], "source": ["# PyTorch data loaders\ntrain_dl = DataLoader(\n                    train_ds, \n                    batch_size, \n                    shuffle=True, \n                    num_workers=3, \n                    pin_memory=True \n                     )\nvalid_dl = DataLoader(\n                    valid_ds, \n                    batch_size*2, \n                    num_workers=3, \n                    pin_memory=True \n                     )"]}, {"cell_type": "code", "execution_count": 1, "id": "4a57f383", "metadata": {}, "outputs": [], "source": ["def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n        break"]}, {"cell_type": "code", "execution_count": 1, "id": "fb3f1995", "metadata": {}, "outputs": [], "source": ["show_batch(train_dl)"]}, {"cell_type": "markdown", "id": "25f5f5b8", "metadata": {}, "source": ["The colors seem out of place because of the normalization. Note that normalization is also applied during inference. If you look closely, you can see the cropping and reflection padding in some of the images. Horizontal flip is a bit difficult to detect from visual inspection."]}, {"cell_type": "code", "execution_count": 1, "id": "ee35e125", "metadata": {}, "outputs": [], "source": ["def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)"]}, {"cell_type": "code", "execution_count": 1, "id": "be618924", "metadata": {}, "outputs": [], "source": ["device = get_default_device()\ndevice"]}, {"cell_type": "markdown", "id": "7bba35f2", "metadata": {}, "source": ["We can now wrap our training and validation data loaders using `DeviceDataLoader` for automatically transferring batches of data to the GPU (if available)."]}, {"cell_type": "code", "execution_count": 1, "id": "241cb1db", "metadata": {}, "outputs": [], "source": ["train_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)"]}, {"cell_type": "markdown", "id": "8ca79659", "metadata": {}, "source": ["### **Model with Residual Blocks and Batch Normalization**\n\nOne of the key changes to our CNN model this time is the addition of the resudial block, which adds the original input back to the output feature map obtained by passing the input through one or more convolutional layers.\n\n![images](https://miro.medium.com/max/1140/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)"]}, {"cell_type": "markdown", "id": "ab71205e", "metadata": {}, "source": ["Here is a very simply Residual block:"]}, {"cell_type": "code", "execution_count": 1, "id": "2c6b8083", "metadata": {}, "outputs": [], "source": ["class SimpleResidualBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.relu1(out)\n        out = self.conv2(out)\n        return self.relu2(out) + x # ReLU can be applied before or after adding the input"]}, {"cell_type": "code", "execution_count": 1, "id": "8722ff37", "metadata": {}, "outputs": [], "source": ["simple_resnet = to_device(SimpleResidualBlock(), device)\n\nfor images, labels in train_dl:\n    out = simple_resnet(images)\n    print(out.shape)\n    break\n    \ndel simple_resnet, images, labels\ntorch.cuda.empty_cache()"]}, {"cell_type": "markdown", "id": "39c45758", "metadata": {}, "source": ["This seeming small change produces a drastic improvement in the performance of the model. Also, after each convolutional layer, we'll add a batch normalization layer, which normalizes the outputs of the previous layer."]}, {"cell_type": "markdown", "id": "e9634a3e", "metadata": {}, "source": ["We will use the ResNet9 architecture, as described in [this blog series](https://www.myrtle.ai/2018/09/24/how_to_train_your_resnet/) :"]}, {"cell_type": "code", "execution_count": 1, "id": "203ca546", "metadata": {}, "outputs": [], "source": ["def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"]}, {"cell_type": "code", "execution_count": 1, "id": "b85b41f1", "metadata": {}, "outputs": [], "source": ["def conv_block(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n              nn.BatchNorm2d(out_channels), \n              nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n\nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n                                                    #3 x 32 x 32\n        self.conv1 = conv_block(in_channels, 64)    #64 x 32 x32\n        self.conv2 = conv_block(64, 128, pool=True) #128 x 16 x 16\n        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))   # 128 x16 x 16\n        \n        self.conv3 = conv_block(128, 256, pool=True)    #256 x 8 x 8\n        self.conv4 = conv_block(256, 512, pool=True)    #512 x 4 x 4\n        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))   #512 x 4 x 4\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),  # 512 x 1 x 1\n                                        nn.Flatten(),     # 512 x \n                                        nn.Linear(512, num_classes)) # 10\n        \n    def forward(self, xb):\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out"]}, {"cell_type": "code", "execution_count": 1, "id": "29201e60", "metadata": {}, "outputs": [], "source": ["model = to_device(ResNet9(3, 10), device)\nmodel"]}, {"cell_type": "markdown", "id": "9ac8fb32", "metadata": {}, "source": ["## **Training the model**\nBefore we train the model, we're going to make a bunch of small but important improvements to our fit function:\n\n- **Learning rate scheduling**: Instead of using a fixed learning rate, we will use a learning rate scheduler, which will change the learning rate after every batch of training. There are many strategies for varying the learning rate during training, and the one we'll use is called the \"**One Cycle Learning Rate Policy**\", which involves starting with a low learning rate, gradually increasing it batch-by-batch to a high learning rate for about 30% of epochs, then gradually decreasing it to a very low value for the remaining epochs. Learn more: https://sgugger.github.io/the-1cycle-policy.html\n\n- **Weight decay**: We also use weight decay, which is yet another regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function.Learn more: https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab\n\n- **Gradient clipping**: Apart from the layer weights and outputs, it also helpful to limit the values of gradients to a small range to prevent undesirable changes in parameters due to large gradient values. This simple yet effective technique is called gradient clipping. Learn more: https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48"]}, {"cell_type": "markdown", "id": "affe4e16", "metadata": {}, "source": ["Let's define a `fit_one_cycle` function to incorporate these changes. We'll also record the learning rate used for each batch."]}, {"cell_type": "code", "execution_count": 1, "id": "53065b68", "metadata": {}, "outputs": [], "source": ["@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history"]}, {"cell_type": "code", "execution_count": 1, "id": "4f9142a4", "metadata": {}, "outputs": [], "source": ["history = [evaluate(model, valid_dl)]\nhistory"]}, {"cell_type": "code", "execution_count": 1, "id": "01b6dfb9", "metadata": {}, "outputs": [], "source": ["epochs = 10\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam"]}, {"cell_type": "code", "execution_count": 1, "id": "29384c63", "metadata": {}, "outputs": [], "source": ["%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)     "]}, {"cell_type": "code", "execution_count": 1, "id": "c8078d01", "metadata": {}, "outputs": [], "source": ["epochs = 10\nmax_lr = 0.001\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam"]}, {"cell_type": "code", "execution_count": 1, "id": "e87a5b3b", "metadata": {}, "outputs": [], "source": ["%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func) "]}, {"cell_type": "code", "execution_count": 1, "id": "7c75ed78", "metadata": {}, "outputs": [], "source": ["train_time='10min 16s'"]}, {"cell_type": "markdown", "id": "a5ce7a8f", "metadata": {}, "source": ["Our model trained to over 90% accuracy in just 5 minutes! Try playing around with the data augmentations, network architecture & hyperparameters to achive the following results:\n\n1. 94% accuracy in under 10 minutes (easy)\n2. 90% accuracy in under 2.5 minutes (intermediate)\n3. 94% accuracy in under 5 minutes (hard)\n\nLet's plot the valdation set accuracies to study how the model improves over time."]}, {"cell_type": "markdown", "id": "54caca34", "metadata": {}, "source": ["## **Plotting Functions**"]}, {"cell_type": "code", "execution_count": 1, "id": "ba0ac3a4", "metadata": {}, "outputs": [], "source": ["def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');"]}, {"cell_type": "code", "execution_count": 1, "id": "e7594002", "metadata": {}, "outputs": [], "source": ["plot_accuracies(history)"]}, {"cell_type": "code", "execution_count": 1, "id": "9d35f406", "metadata": {}, "outputs": [], "source": ["plot_losses(history)"]}, {"cell_type": "markdown", "id": "c154e6b2", "metadata": {}, "source": ["It's clear from the trend that our model isn't overfitting to the training data just yet. \n\nFinally, let's visualize how the learning rate changed over time, batch-by-batch over all the epochs."]}, {"cell_type": "code", "execution_count": 1, "id": "68ddf5cc", "metadata": {}, "outputs": [], "source": ["def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');"]}, {"cell_type": "code", "execution_count": 1, "id": "5a14e2e6", "metadata": {}, "outputs": [], "source": ["plot_lrs(history)"]}, {"cell_type": "markdown", "id": "7d64866e", "metadata": {}, "source": ["## Saving and Commiting\n\nLet's save the weights of the model, record the hyperparameters, and commit our experiment to Jovian. As you try different ideas, make sure to record every experiment so you can look back and analyze the results."]}, {"cell_type": "code", "execution_count": 1, "id": "df49cb48", "metadata": {}, "outputs": [], "source": ["torch.save(model.state_dict(), 'cifar10-resnet9.pth')"]}, {"cell_type": "code", "execution_count": 1, "id": "eeddbfd8", "metadata": {}, "outputs": [], "source": ["# Jovian doesn't work with colab Do this task when on kaggle\n!pip install jovian --upgrade --quiet\nimport jovian"]}, {"cell_type": "code", "execution_count": 1, "id": "dbbfbe6a", "metadata": {}, "outputs": [], "source": ["jovian.reset()\njovian.log_hyperparams(arch='resnet9', \n                       epochs=epochs, \n                       lr=max_lr, \n                       scheduler='one-cycle', \n                       weight_decay=weight_decay, \n                       grad_clip=grad_clip,\n                       opt=opt_func.__name__)"]}, {"cell_type": "code", "execution_count": 1, "id": "61ef3d22", "metadata": {}, "outputs": [], "source": ["jovian.log_metrics(val_loss=history[-1]['val_loss'], \n                   val_acc=history[-1]['val_acc'],\n                   train_loss=history[-1]['train_loss'],\n                   time=train_time)"]}, {"cell_type": "code", "execution_count": 1, "id": "152dac68", "metadata": {}, "outputs": [], "source": ["jovian.commit(project=project_name, environment=None, outputs=['cifar10-resnet9.pth'], is_cli=True)"]}, {"cell_type": "markdown", "id": "19fb328f", "metadata": {}, "source": ["## **Summary and Further Reading**\n\nHere's a summary of the different techniques used in this tutorial to improve our model performance and reduce the training time:\n\n- Data normalization: We normalized the image tensors by subtracting the mean and dividing by the standard deviation of pixels across each channel. Normalizing the data prevents the pixel values from any one channel from disproportionately affecting the losses and gradients. [Learn more](https://medium.com/@ml_kid/what-is-transform-and-transform-normalize-lesson-4-neural-networks-in-pytorch-ca97842336bd)\n\n- Data augmentation: We applied random transformations while loading images from the training dataset. Specifically, we will pad each image by 4 pixels, and then take a random crop of size 32 x 32 pixels, and then flip the image horizontally with a 50% probability. [Learn more](https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/)\n\n- Residual connections: One of the key changes to our CNN model was the addition of the resudial block, which adds the original input back to the output feature map obtained by passing the input through one or more convolutional layers. We used the ResNet9 architecture [Learn more](https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec).\n\n- Batch normalization: After each convolutional layer, we added a batch normalization layer, which normalizes the outputs of the previous layer. This is somewhat similar to data normalization, except it's applied to the outputs of a layer, and the mean and standard deviation are learned parameters. [Learn more](https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd)\n\n- Learning rate scheduling: Instead of using a fixed learning rate, we will use a learning rate scheduler, which will change the learning rate after every batch of training. There are [many strategies](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) for varying the learning rate during training, and we used the \"One Cycle Learning Rate Policy\". [Learn more](https://sgugger.github.io/the-1cycle-policy.html)\n\n- Weight Decay: We added weight decay to the optimizer, yet another regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function. [Learn more](https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab)\n\n- Gradient clipping: We also added gradient clippint, which helps limit the values of gradients to a small range to prevent undesirable changes in model parameters due to large gradient values during training. [Learn more.](https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48#63e0)\n\n- Adam optimizer: Instead of SGD (stochastic gradient descent), we used the Adam optimizer which uses techniques like momentum and adaptive learning rates for faster training. There are many other optimizers to choose froma and experiment with. [Learn more](https://ruder.io/optimizing-gradient-descent/index.html).\n\nAs an exercise, you should try applying each technique independently and see how much each one affects the performance and training time. As you try different experiments, you will start to cultivate the intuition for picking the right architectures, data augmentation & regularization techniques."]}, {"cell_type": "markdown", "id": "9059fe81", "metadata": {}, "source": ["# **THE END**"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}