{"cells": [{"cell_type": "markdown", "id": "a936b1c2", "metadata": {}, "source": ["# Inputting & Importing"]}, {"cell_type": "code", "execution_count": 1, "id": "f14883b6", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib\nimport re\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom IPython.display import Markdown, display\nimport random"]}, {"cell_type": "code", "execution_count": 1, "id": "c69ac630", "metadata": {}, "outputs": [], "source": ["%config Completer.use_jedi = False\nsns.set(rc={'figure.figsize':(18,10)})\nsns.set_style({'axes.facecolor':'white', 'grid.color': '.8', 'font.family':'Times New Roman'})\n\n# Colors\ncyan = '#00FFD1'\nred = '#FF007D'\nprussian = '#0075FF'\ngreen = '#EEF622'\nyellow = '#FFF338'\nviolet = '#9B65FF'\norange = '#FFA500'\nblue = '#00EBFF'\nvermillion = '#FF6900'\nred2 = '#FF2626'\nseagreen = '#28FFBF'\ngreen2 = '#FAFF00'\nnavyblue = '#04009A'\ndarkgreen = '#206A5D'\nlightgreen = '#CCF6C8'\npink = '#F35588'\nmauve = '#BAABDA'\nlightblue = '#1CC5DC'\nmustard = '#FDB827'\ndeeppurple = '#723881'\n\ncolor_list = [cyan,red,prussian,green,violet,orange,yellow,blue,vermillion,red2,seagreen,green2,navyblue,darkgreen,lightgreen,pink,mauve,lightblue,mustard,deeppurple]\nplt.rcParams['axes.prop_cycle'] = plt.cycler(color=color_list)"]}, {"cell_type": "code", "execution_count": 1, "id": "a93d22ab", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "54e51bba", "metadata": {}, "outputs": [], "source": ["def printmd(string):\n    display(Markdown(string))"]}, {"cell_type": "code", "execution_count": 1, "id": "b4c10bb3", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "a4e3bc20", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d52aa311", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "43d9d05e", "metadata": {}, "outputs": [], "source": ["train.shape, test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "818c8be6", "metadata": {}, "outputs": [], "source": ["# To analyse presence of any disparities and/or major factors\nsurvived_df = train[train['Survived']==1]\ndeceased_df = train[train['Survived']==0]"]}, {"cell_type": "markdown", "id": "12eb37d8", "metadata": {}, "source": ["# Data Preprocessing"]}, {"cell_type": "markdown", "id": "3aa6079c", "metadata": {}, "source": ["## Missing Values"]}, {"cell_type": "code", "execution_count": 1, "id": "0cea309f", "metadata": {}, "outputs": [], "source": ["train.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "1e1cdcf4", "metadata": {}, "outputs": [], "source": ["test.isnull().sum()"]}, {"cell_type": "markdown", "id": "346079f8", "metadata": {}, "source": ["- 20% **Age** values are missing in *Train Data*, 20% in *Test Data* as well\n- 0.2% **Embarked** values are missing \n- 77% **Cabin** values are missing in *Train Data* -> ***might delete later but keeping for EDA insight***\n- **Fare** has just 1 missing value in *Test Data*"]}, {"cell_type": "markdown", "id": "b0ac5793", "metadata": {}, "source": ["### Cabin"]}, {"cell_type": "code", "execution_count": 1, "id": "b1d415aa", "metadata": {}, "outputs": [], "source": ["# train = train.drop(['Cabin'],axis=1)\n# test = test.drop(['Cabin'],axis=1)"]}, {"cell_type": "markdown", "id": "2341b946", "metadata": {}, "source": ["### Age"]}, {"cell_type": "code", "execution_count": 1, "id": "08bc1d5f", "metadata": {}, "outputs": [], "source": ["# 20% Age values are missing\ntrain['Age'].isnull().sum() "]}, {"cell_type": "code", "execution_count": 1, "id": "0dae5d47", "metadata": {}, "outputs": [], "source": ["sns.displot(data=train['Age'],kde=True,height=6.5,color=random.choice(color_list));"]}, {"cell_type": "code", "execution_count": 1, "id": "d31ede46", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12,7))\nsns.kdeplot(survived_df['Age'],label = 'Survived', shade = True, color=cyan)\nsns.kdeplot(deceased_df['Age'],label = 'Deceased', shade = True, color=red)\nplt.title('Age')\nplt.xlabel('Age of Passengers')"]}, {"cell_type": "code", "execution_count": 1, "id": "c13f007e", "metadata": {}, "outputs": [], "source": ["train['Age'] = train['Age'].fillna(train['Age'].mean())\ntest['Age'] = test['Age'].fillna(train['Age'].mean())"]}, {"cell_type": "markdown", "id": "787d9e18", "metadata": {}, "source": ["### Embarked"]}, {"cell_type": "code", "execution_count": 1, "id": "09439f40", "metadata": {}, "outputs": [], "source": ["# 0.2% Embarked values are missing\ntrain['Embarked'].isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "373db1cb", "metadata": {}, "outputs": [], "source": ["train['Embarked'].value_counts()"]}, {"cell_type": "markdown", "id": "a456c55e", "metadata": {}, "source": ["* **S** or *Southampton* is the **Mode**"]}, {"cell_type": "code", "execution_count": 1, "id": "22c5dbe1", "metadata": {}, "outputs": [], "source": ["train['Embarked'] = train['Embarked'].fillna('S')"]}, {"cell_type": "markdown", "id": "845373de", "metadata": {}, "source": ["### Fare"]}, {"cell_type": "code", "execution_count": 1, "id": "6901ff6a", "metadata": {}, "outputs": [], "source": ["train.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "b4d2e99e", "metadata": {}, "outputs": [], "source": ["sns.displot(train['Fare'],bins=20,color=random.choice(color_list));"]}, {"cell_type": "code", "execution_count": 1, "id": "d836efd0", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12,7))\nsns.kdeplot(survived_df['Fare'],label = 'Survived', shade = True, color=cyan)\nsns.kdeplot(deceased_df['Fare'],label = 'Deceased', shade = True, color=red)\nplt.title('Fare')\nplt.xlabel('Fare of Passengers')"]}, {"cell_type": "code", "execution_count": 1, "id": "333bf1e0", "metadata": {}, "outputs": [], "source": ["test['Fare'] = test['Fare'].fillna(train['Fare'].mode()[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "685bd552", "metadata": {}, "outputs": [], "source": ["train.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "fdcfe771", "metadata": {}, "outputs": [], "source": ["test.isnull().sum()"]}, {"cell_type": "markdown", "id": "6691d094", "metadata": {}, "source": ["### Cabin"]}, {"cell_type": "code", "execution_count": 1, "id": "0425f9c9", "metadata": {}, "outputs": [], "source": ["train['Cabin'].isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "950115a1", "metadata": {}, "outputs": [], "source": ["nonNullCabin = train[~train['Cabin'].isnull()] # non null Cabin values"]}, {"cell_type": "code", "execution_count": 1, "id": "57a0c43a", "metadata": {}, "outputs": [], "source": [" # Non null cabin values that Survived\nlen(nonNullCabin[nonNullCabin['Survived']==1])"]}, {"cell_type": "code", "execution_count": 1, "id": "b35ee8d8", "metadata": {}, "outputs": [], "source": [" # Non null cabin values that didn't  # Non null cabin values that Survive\nlen(nonNullCabin[nonNullCabin['Survived']==0])"]}, {"cell_type": "code", "execution_count": 1, "id": "0ff119ab", "metadata": {}, "outputs": [], "source": ["survived_cabins = list(nonNullCabin[nonNullCabin['Survived']==1]['Cabin'].value_counts().index)\ndeceased_cabins = list(nonNullCabin[nonNullCabin['Survived']==0]['Cabin'].value_counts().index)"]}, {"cell_type": "code", "execution_count": 1, "id": "1a647e17", "metadata": {}, "outputs": [], "source": ["# Common Cabins\nc=0\nfor x in survived_cabins:\n    if(x in deceased_cabins):\n        c=c+1\nprint(c)"]}, {"cell_type": "code", "execution_count": 1, "id": "b8394b10", "metadata": {}, "outputs": [], "source": ["print(survived_cabins)"]}, {"cell_type": "code", "execution_count": 1, "id": "c3f03d00", "metadata": {}, "outputs": [], "source": ["print(deceased_cabins)"]}, {"cell_type": "markdown", "id": "6835d2bd", "metadata": {}, "source": ["### SibSp and Parch"]}, {"cell_type": "code", "execution_count": 1, "id": "5004769f", "metadata": {}, "outputs": [], "source": ["train['Family'] = train['SibSp']+train['Parch']\ntest['Family'] = test['SibSp']+test['Parch']\n# train=train.drop(['SibSp','Parch'],axis=1)\n# test=test.drop(['SibSp','Parch'],axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "a897bdfa", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "id": "b5221b46", "metadata": {}, "source": ["# **Exploratory Data Analysis**"]}, {"cell_type": "markdown", "id": "d5523cd1", "metadata": {}, "source": ["## **Ticket**"]}, {"cell_type": "markdown", "id": "d89ec634", "metadata": {}, "source": ["Here, I'll be creating new Dataframes (Test and Train each) to analyse the frequent occuring Ticket types and analayse each of those ticket groups individually"]}, {"cell_type": "code", "execution_count": 1, "id": "7d0854d3", "metadata": {}, "outputs": [], "source": ["Ticket_temp_train = train['Ticket'].value_counts()\nTicket_temp_test = test['Ticket'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "12aee370", "metadata": {}, "outputs": [], "source": ["Ticket_temp_train_df = pd.DataFrame({'ticket':Ticket_temp_train.index,'freq':Ticket_temp_train.values})\nTicket_temp_test_df = pd.DataFrame({'ticket':Ticket_temp_test.index,'freq':Ticket_temp_test.values})"]}, {"cell_type": "code", "execution_count": 1, "id": "d7958cc9", "metadata": {}, "outputs": [], "source": ["Ticket_temp_train_df.head(8)"]}, {"cell_type": "code", "execution_count": 1, "id": "c1a4d79e", "metadata": {}, "outputs": [], "source": ["train.set_index('PassengerId',inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "bf44f13f", "metadata": {}, "outputs": [], "source": ["train.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "417123f5", "metadata": {}, "outputs": [], "source": ["train = train[['Survived','Name','Sex','Ticket','Age','Fare','Pclass','Embarked','Cabin','Family','SibSp', 'Parch']]"]}, {"cell_type": "code", "execution_count": 1, "id": "9514d393", "metadata": {}, "outputs": [], "source": ["# This function creates a mechanism for us to parse different ranges of frequency (from the 'freq' column of the above\n# newly created DataFrames) and obatin individual Tables for Analysis\n\n\ndef analyse_tickets(freq_to_stop_at,dataframe):\n    flag = 'none'\n    for i in range(0,len(Ticket_temp_train_df.iloc[:,:])): # iterating a number range\n        \n        ticket_name = Ticket_temp_train_df.iloc[i,0]\n        ticket_freq = Ticket_temp_train_df.iloc[i,1]\n\n        if(flag != ticket_freq and ticket_freq != freq_to_stop_at-1):\n            flag=ticket_freq\n            printmd('---')\n            printmd('### **Ticket frequency:** **%d**'%(ticket_freq))\n            print('\\n')\n            \n    \n        if (ticket_freq!=freq_to_stop_at-1):\n            printmd(' #### *Ticket Name:* **%s**'%(ticket_name))\n            display(dataframe.loc[dataframe['Ticket']==ticket_name])\n            print('\\n\\n')# End of one group\n        \n        else:\n            break\nprint('\\n')\nprintmd('---')"]}, {"cell_type": "markdown", "id": "016432b5", "metadata": {}, "source": ["#### **Among the following Table groups below, Please pay attention to:**\n* How many **survived** in a group?\n* Whether they're in the same family via **Family**and **Name**? (For details on family demographic, see **SipSp** and **ParCh**)\n* The port they **Embarked** from\n* Their **Age** demographic\n* Whether they're in the same **cabin**. "]}, {"cell_type": "code", "execution_count": 1, "id": "5844f786", "metadata": {}, "outputs": [], "source": ["analyse_tickets(2,train) ## Enter frequency to stop at and dataframe to work with. For ex: (6,train)"]}, {"cell_type": "markdown", "id": "159edb26", "metadata": {}, "source": ["#### **Observations**\n* Some people have more than one **cabin**. Almost all of these people belong to the 1st **Class**.\n* Some people not from the same **family** are in the same **cabin**.\n* Should I **age** categorize?\n* There are hardly any **cabin** names for both 2nd and 3rd **Class** passengers.\n* 3rd **class** passengers usually have **cabins** in F and G (for the data that is present).\n* Passengers on the same **ticket** are mostly in the same **cabin** and belong to the same **class**.\n* Among couples (in the same cabin) from all **classes**, it was common to see **only women** surviving in a lot of cases.\n\nInteresting read for the side: Berth numbers were given for some passengers. Odd for lower berths and even for upper berths. [source](https://www.encyclopedia-titanica.org/cabins.html)"]}, {"cell_type": "markdown", "id": "7b642460", "metadata": {}, "source": ["#### Getting Ticket prefix values"]}, {"cell_type": "code", "execution_count": 1, "id": "3139b98b", "metadata": {}, "outputs": [], "source": ["train.loc[1,'Ticket']"]}, {"cell_type": "code", "execution_count": 1, "id": "cca52ed9", "metadata": {}, "outputs": [], "source": ["train"]}, {"cell_type": "code", "execution_count": 1, "id": "11b15bc7", "metadata": {}, "outputs": [], "source": ["# c = -1\n# tick_1 = {}\n# for i in range(0,len(train['Ticket'])):\n#     c=c+1\n#     match = re.search('^[a-zA-Z]+',train.iloc[i,3])\n#     if (match):\n#         tick_1[c] = match.group()"]}, {"cell_type": "code", "execution_count": 1, "id": "918940a8", "metadata": {}, "outputs": [], "source": ["# tick1_s = pd.Series(tick_1)\n# tick1_s.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "9d3ec23b", "metadata": {}, "outputs": [], "source": ["tick_prefix_train = []\nfor i in range(0,len(train['Ticket'])):\n    match = re.search('^[a-zA-Z]+',train.iloc[i,3])\n    if (match):\n        tick_prefix_train.append(match.group())\n    else:\n        tick_prefix_train.append('Null')\n        \n        \ntick_prefix_test = []\nfor i in range(0,len(test['Ticket'])):\n    match = re.search('^[a-zA-Z]+',test.iloc[i,7])\n    if (match):\n        tick_prefix_test.append(match.group())\n    else:\n        tick_prefix_test.append('Null')"]}, {"cell_type": "code", "execution_count": 1, "id": "45134d52", "metadata": {}, "outputs": [], "source": ["train['Ticket_prefix'] = tick_prefix_train\ntest['Ticket_prefix'] = tick_prefix_test"]}, {"cell_type": "code", "execution_count": 1, "id": "470d62ef", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "5bbbab41", "metadata": {}, "outputs": [], "source": ["Ticket_pre_df = pd.DataFrame({'prefix':train['Ticket_prefix'].value_counts().index, 'freq':train['Ticket_prefix'].value_counts().values})\nTicket_pre_df.head(15)"]}, {"cell_type": "code", "execution_count": 1, "id": "89fbde69", "metadata": {}, "outputs": [], "source": ["def analyse_prefix(freq_to_stop_at,dataframe):\n    # booll - enter True if you want null too\n    flag = 'none'\n    for i in range(1,len(Ticket_pre_df)): # iterating a number range\n        ticket_name = Ticket_pre_df.iloc[i,0]\n        ticket_freq = Ticket_pre_df.iloc[i,1]\n\n        if(flag != ticket_freq):\n            flag=ticket_freq\n            printmd('---')\n            printmd('### Ticket frequency: **%d**'%(int(ticket_freq)))\n            \n    \n        if (ticket_freq!=freq_to_stop_at-1):\n            printmd(' #### *Ticket Name:* **%s**'%(ticket_name))\n            display(dataframe.loc[dataframe['Ticket_prefix']==ticket_name])\n            print('\\n\\n')# End of one number\n        \n        else:\n            break"]}, {"cell_type": "code", "execution_count": 1, "id": "a19c41d8", "metadata": {}, "outputs": [], "source": ["analyse_prefix(11,train) # first arg doesn't work here ##change"]}, {"cell_type": "markdown", "id": "1bdffff0", "metadata": {}, "source": ["**Grouping all unique tickets to a common value**"]}, {"cell_type": "code", "execution_count": 1, "id": "61a4d616", "metadata": {}, "outputs": [], "source": ["for i in range(0,len(Ticket_temp_train_df.iloc[:,:])):\n    if (Ticket_temp_train_df.loc[i,'freq'] == 1):\n        train['Ticket'] = train['Ticket'].replace([ Ticket_temp_train_df.loc[i,'ticket'] ],'UniqueTicketPrefix')\n        \nfor i in range(0,len(Ticket_temp_test_df.iloc[:,:])):\n    if (Ticket_temp_test_df.loc[i,'freq'] == 1):\n        test['Ticket'] = test['Ticket'].replace([ Ticket_temp_test_df.loc[i,'ticket'] ],'UniqueTicketPrefix')"]}, {"cell_type": "code", "execution_count": 1, "id": "ca515e1f", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "1ff44af1", "metadata": {}, "outputs": [], "source": ["train['Ticket'].value_counts()"]}, {"cell_type": "markdown", "id": "1b901261", "metadata": {}, "source": ["### Name"]}, {"cell_type": "code", "execution_count": 1, "id": "404304ce", "metadata": {}, "outputs": [], "source": ["name_titles_train = []\nfor i in range(0,len(train['Name'])):\n    title = (train.iloc[i,1].split(', ')[1]).split(' ')[0]\n    name_titles_train.append(title)\n\n\nname_titles_test = []\nfor i in range(0,len(test['Name'])):\n    title = (test.iloc[i,2].split(', ')[1]).split(' ')[0]\n    name_titles_test.append(title)"]}, {"cell_type": "code", "execution_count": 1, "id": "f88e4301", "metadata": {}, "outputs": [], "source": ["train['Title'] = name_titles_train\ntest['Title'] = name_titles_test"]}, {"cell_type": "code", "execution_count": 1, "id": "e5dcc7cb", "metadata": {}, "outputs": [], "source": ["train = train.drop(['Name'],axis=1)\ntest = test.drop(['Name'],axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "697e9169", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "5970fb0b", "metadata": {}, "outputs": [], "source": ["train['Title'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "9fedc1d6", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(25,17))\nsns.countplot(x='Title',hue='Survived',data=train)"]}, {"cell_type": "markdown", "id": "66982c01", "metadata": {}, "source": ["# Categorical Encoding"]}, {"cell_type": "code", "execution_count": 1, "id": "d107a93c", "metadata": {}, "outputs": [], "source": ["train.head(7)"]}, {"cell_type": "code", "execution_count": 1, "id": "6e1f30bc", "metadata": {}, "outputs": [], "source": ["# Categories\n\nfor i in (1,2,5,6,7,11,12):\n    c = train.columns[i]\n    printmd('### %s'%(c))\n    display(train[c].value_counts())\n    print(' ')"]}, {"cell_type": "markdown", "id": "77d5b2ba", "metadata": {}, "source": ["## Mean Encoding for **Ticket**, **Ticket_prefix** and **Title** columns"]}, {"cell_type": "code", "execution_count": 1, "id": "afb4e5b6", "metadata": {}, "outputs": [], "source": ["def Mean_Encoding(column_name):\n    new_smooth_name = column_name+'_smean_encod'\n    \n    mean = train['Survived'].mean()\n    agg= train.groupby(column_name)['Survived'].agg(['count','mean'])\n    counts = agg['count']\n    means = agg['mean']\n    weight = 100\n    smooth = (counts*means + weight*mean)/(counts+weight)\n    \n    train.loc[:,new_smooth_name] = train[column_name].map(smooth)\n    test.loc[:,new_smooth_name] = test[column_name].map(smooth)    \n    "]}, {"cell_type": "code", "execution_count": 1, "id": "9ee3e708", "metadata": {}, "outputs": [], "source": ["Mean_Encoding('Ticket')"]}, {"cell_type": "code", "execution_count": 1, "id": "441ddc4f", "metadata": {}, "outputs": [], "source": ["Mean_Encoding('Ticket_prefix')"]}, {"cell_type": "code", "execution_count": 1, "id": "1d871f68", "metadata": {}, "outputs": [], "source": ["Mean_Encoding('Title')"]}, {"cell_type": "code", "execution_count": 1, "id": "859a1b26", "metadata": {}, "outputs": [], "source": ["test.isnull().sum()"]}, {"cell_type": "markdown", "id": "e27b5071", "metadata": {}, "source": ["This means, there are new uniue values in the test dataset which weren't mapped to the smooth values we have here"]}, {"cell_type": "markdown", "id": "afdc71d9", "metadata": {}, "source": ["### Missing values after mean Encoding"]}, {"cell_type": "code", "execution_count": 1, "id": "d887a03c", "metadata": {}, "outputs": [], "source": ["sns.displot(data=train['Ticket_smean_encod'],kde=True,height=6.5,color=random.choice(color_list));"]}, {"cell_type": "code", "execution_count": 1, "id": "0229e92a", "metadata": {}, "outputs": [], "source": ["sns.displot(data=train['Ticket_prefix_smean_encod'],kde=True,height=6.5,color=random.choice(color_list));"]}, {"cell_type": "code", "execution_count": 1, "id": "2781f030", "metadata": {}, "outputs": [], "source": ["sns.displot(data=train['Title_smean_encod'],kde=True,height=6.5,color=random.choice(color_list));"]}, {"cell_type": "code", "execution_count": 1, "id": "bed0cd91", "metadata": {}, "outputs": [], "source": ["test['Ticket_smean_encod'] = test['Ticket_smean_encod'].fillna(train['Ticket_smean_encod'].mean())\ntest['Ticket_prefix_smean_encod'] = test['Ticket_prefix_smean_encod'].fillna(train['Ticket_prefix_smean_encod'].mean())\ntest['Title_smean_encod'] = test['Title_smean_encod'].fillna(train['Title_smean_encod'].mean())"]}, {"cell_type": "code", "execution_count": 1, "id": "800d16e3", "metadata": {}, "outputs": [], "source": ["test.isnull().sum()"]}, {"cell_type": "markdown", "id": "4bb1fbb6", "metadata": {}, "source": ["## One Hot Encoding for **Sex**, **Embarked** and **Pclass** columns"]}, {"cell_type": "code", "execution_count": 1, "id": "b3bcb155", "metadata": {}, "outputs": [], "source": ["# Sex\n\ntrain['Sex_female'] = pd.get_dummies(train.Sex, prefix='Sex')['Sex_female']\ntrain['Sex_male'] = pd.get_dummies(train.Sex, prefix='Sex')['Sex_male']\ntest['Sex_female'] = pd.get_dummies(test.Sex, prefix='Sex')['Sex_female']\ntest['Sex_male'] = pd.get_dummies(test.Sex, prefix='Sex')['Sex_male']"]}, {"cell_type": "code", "execution_count": 1, "id": "3cc4119b", "metadata": {}, "outputs": [], "source": ["# Pclass\n\ntrain['Pclass_1'] = pd.get_dummies(train.Pclass, prefix='Pclass')['Pclass_1']\ntrain['Pclass_2'] = pd.get_dummies(train.Pclass, prefix='Pclass')['Pclass_2']\ntrain['Pclass_3'] = pd.get_dummies(train.Pclass, prefix='Pclass')['Pclass_3']\n\ntest['Pclass_1'] = pd.get_dummies(test.Pclass, prefix='Pclass')['Pclass_1']\ntest['Pclass_2'] = pd.get_dummies(test.Pclass, prefix='Pclass')['Pclass_2']\ntest['Pclass_3'] = pd.get_dummies(test.Pclass, prefix='Pclass')['Pclass_3']"]}, {"cell_type": "code", "execution_count": 1, "id": "314e64e6", "metadata": {}, "outputs": [], "source": ["# Embarked\n\ntrain['Embarked_C'] = pd.get_dummies(train.Embarked, prefix='Embarked')['Embarked_C']\ntrain['Embarked_Q'] = pd.get_dummies(train.Embarked, prefix='Embarked')['Embarked_Q']\ntrain['Embarked_S'] = pd.get_dummies(train.Embarked, prefix='Embarked')['Embarked_S']\n\ntest['Embarked_C'] = pd.get_dummies(test.Embarked, prefix='Embarked')['Embarked_C']\ntest['Embarked_Q'] = pd.get_dummies(test.Embarked, prefix='Embarked')['Embarked_Q']\ntest['Embarked_S'] = pd.get_dummies(test.Embarked, prefix='Embarked')['Embarked_S']"]}, {"cell_type": "code", "execution_count": 1, "id": "9a176131", "metadata": {}, "outputs": [], "source": ["train.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "ba8c4ad5", "metadata": {}, "outputs": [], "source": ["df_train = train[['Age','Fare','Ticket_prefix_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n       'Embarked_Q','Survived']] # omitted extra dummy variables\ndf_test = test[['Age','Fare','Ticket_prefix_smean_encod','Sex_female','Pclass_1','Pclass_2','Embarked_C',\n       'Embarked_Q']] # omitted extra dummy variables"]}, {"cell_type": "markdown", "id": "cfda0210", "metadata": {}, "source": ["# Correlation"]}, {"cell_type": "code", "execution_count": 1, "id": "74096468", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(18,16)) \nmy_c = sns.diverging_palette(20, 220, as_cmap=True)\nmask = np.triu(df_train.corr())\nsns.heatmap(df_train.corr(),cmap='BrBG',linewidths=1.5,ax=ax,annot=True,center=0,square=True,mask=mask)\nplt.title('Correlation',fontsize=30);"]}, {"cell_type": "code", "execution_count": 1, "id": "cfcc33f6", "metadata": {}, "outputs": [], "source": ["train.head()"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}