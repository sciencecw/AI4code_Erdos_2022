{"cells": [{"cell_type": "code", "execution_count": 1, "id": "dbab7926", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "aeced548", "metadata": {}, "source": ["# LOADING THE DATASETS"]}, {"cell_type": "code", "execution_count": 1, "id": "ee45d687", "metadata": {}, "outputs": [], "source": ["train_img=pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest=pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "097e6287", "metadata": {}, "outputs": [], "source": ["train_img.tail(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "6382807e", "metadata": {}, "outputs": [], "source": ["Y=train_img['label']"]}, {"cell_type": "code", "execution_count": 1, "id": "4d15ff5b", "metadata": {}, "outputs": [], "source": ["X=train_img.drop(labels='label',axis=1)\nX"]}, {"cell_type": "code", "execution_count": 1, "id": "6e34dca1", "metadata": {}, "outputs": [], "source": ["Y"]}, {"cell_type": "code", "execution_count": 1, "id": "09f92de7", "metadata": {}, "outputs": [], "source": ["g = sns.countplot(Y)\n\nY.value_counts()"]}, {"cell_type": "markdown", "id": "f5e9e7c8", "metadata": {}, "source": ["# CHECKING FOR NULL VALUES"]}, {"cell_type": "code", "execution_count": 1, "id": "a2d38e80", "metadata": {}, "outputs": [], "source": ["X.isnull().any().describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "43462b09", "metadata": {}, "outputs": [], "source": ["test.isnull().any().describe()"]}, {"cell_type": "markdown", "id": "81d1b79b", "metadata": {}, "source": ["So there are no null values.\n"]}, {"cell_type": "markdown", "id": "9a298b9d", "metadata": {}, "source": ["#     # NORMALISING THE PIXEL VALUES"]}, {"cell_type": "code", "execution_count": 1, "id": "2160d6e3", "metadata": {}, "outputs": [], "source": ["X = X/ 255.0\ntest= test / 255.0"]}, {"cell_type": "code", "execution_count": 1, "id": "2517d1c7", "metadata": {}, "outputs": [], "source": ["X"]}, {"cell_type": "markdown", "id": "2f2d4e65", "metadata": {}, "source": ["# Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n\n# Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices."]}, {"cell_type": "markdown", "id": "515f9ad4", "metadata": {}, "source": ["# If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a shape of [-1] flattens into 1-D. At most one component of shape can be -1."]}, {"cell_type": "code", "execution_count": 1, "id": "3e15f9b3", "metadata": {}, "outputs": [], "source": ["X = X.values.reshape(-1,28,28,1)\ntest= test.values.reshape(-1,28,28,1)"]}, {"cell_type": "code", "execution_count": 1, "id": "2926cb51", "metadata": {}, "outputs": [], "source": ["X"]}, {"cell_type": "code", "execution_count": 1, "id": "88444d93", "metadata": {}, "outputs": [], "source": ["Y"]}, {"cell_type": "markdown", "id": "347db4ab", "metadata": {}, "source": ["# SPLITTING THE DATASET"]}, {"cell_type": "code", "execution_count": 1, "id": "caca5e74", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D"]}, {"cell_type": "code", "execution_count": 1, "id": "224ce633", "metadata": {}, "outputs": [], "source": ["x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.1,random_state=42)"]}, {"cell_type": "code", "execution_count": 1, "id": "2b5f8953", "metadata": {}, "outputs": [], "source": ["x_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "0a9848ee", "metadata": {}, "outputs": [], "source": ["x_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "d10efc27", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras import datasets, layers, models"]}, {"cell_type": "code", "execution_count": 1, "id": "e6a70190", "metadata": {}, "outputs": [], "source": ["from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization"]}, {"cell_type": "markdown", "id": "6d8b1de2", "metadata": {}, "source": ["# CNN MODEL"]}, {"cell_type": "code", "execution_count": 1, "id": "d6ac3a42", "metadata": {}, "outputs": [], "source": ["model = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n                 input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))"]}, {"cell_type": "code", "execution_count": 1, "id": "9bc629a8", "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "643822c9", "metadata": {}, "outputs": [], "source": ["model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=25)"]}, {"cell_type": "code", "execution_count": 1, "id": "d03ae42d", "metadata": {}, "outputs": [], "source": ["test_loss, test_acc = model.evaluate(x_test, y_test)"]}, {"cell_type": "markdown", "id": "7a44daa9", "metadata": {}, "source": ["# TEST ACCURACY"]}, {"cell_type": "code", "execution_count": 1, "id": "69e3b5b7", "metadata": {}, "outputs": [], "source": ["print(test_acc)"]}, {"cell_type": "code", "execution_count": 1, "id": "a82e7be9", "metadata": {}, "outputs": [], "source": ["print(test_loss)"]}, {"cell_type": "code", "execution_count": 1, "id": "eb592aa8", "metadata": {}, "outputs": [], "source": ["test"]}, {"cell_type": "code", "execution_count": 1, "id": "7c16ba0d", "metadata": {}, "outputs": [], "source": ["results=model.predict(test)"]}, {"cell_type": "code", "execution_count": 1, "id": "9391d17b", "metadata": {}, "outputs": [], "source": ["results.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "2a34e853", "metadata": {}, "outputs": [], "source": ["results"]}, {"cell_type": "code", "execution_count": 1, "id": "9bf56a9b", "metadata": {}, "outputs": [], "source": ["classes= model.predict_classes(test)\nclasses"]}, {"cell_type": "code", "execution_count": 1, "id": "f7275a97", "metadata": {}, "outputs": [], "source": ["results = pd.Series(classes,name=\"Label\")"]}, {"cell_type": "markdown", "id": "a506f649", "metadata": {}, "source": ["# SUBMISSION"]}, {"cell_type": "code", "execution_count": 1, "id": "5238d8e1", "metadata": {}, "outputs": [], "source": ["submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission"]}, {"cell_type": "code", "execution_count": 1, "id": "eb0d21f8", "metadata": {}, "outputs": [], "source": ["submission.to_csv(\"submit5.csv\",index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}