{"cells": [{"cell_type": "code", "execution_count": 1, "id": "ce7c71d5", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport re "]}, {"cell_type": "code", "execution_count": 1, "id": "f793fca9", "metadata": {}, "outputs": [], "source": ["train_data = pd.read_csv('../input/nlp-getting-started/train.csv')\ntest_data  =pd.read_csv('../input/nlp-getting-started/test.csv')\ntrain_data.head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "71225896", "metadata": {}, "outputs": [], "source": ["train_data.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "a714119c", "metadata": {}, "outputs": [], "source": ["train_data['text'][0]"]}, {"cell_type": "markdown", "id": "04204c52", "metadata": {}, "source": ["# text preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "c06a72d6", "metadata": {}, "outputs": [], "source": ["import re\ndef  clean_text(df, text_field, new_text_field_name):\n    df[new_text_field_name] = df[text_field].str.lower()\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n    # remove numbers\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n    \n    return df\ndata_clean = clean_text(train_data, 'text', 'text_clean')\ndata_clean.head()"]}, {"cell_type": "markdown", "id": "1e10bbb3", "metadata": {}, "source": ["# Removing stopwords"]}, {"cell_type": "code", "execution_count": 1, "id": "6683f363", "metadata": {}, "outputs": [], "source": ["import nltk.corpus\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\ndata_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\ndata_clean.head()"]}, {"cell_type": "markdown", "id": "cf5b0c11", "metadata": {}, "source": ["# text tokenization"]}, {"cell_type": "code", "execution_count": 1, "id": "5f859477", "metadata": {}, "outputs": [], "source": ["import nltk \nnltk.download('punkt')\nfrom nltk.tokenize import sent_tokenize, word_tokenize\ndata_clean['text_tokens'] = data_clean['text_clean'].apply(lambda x: word_tokenize(x))\ndata_clean.head()"]}, {"cell_type": "markdown", "id": "77bfac9d", "metadata": {}, "source": ["# Stemming words with NLTK"]}, {"cell_type": "code", "execution_count": 1, "id": "80ca73d7", "metadata": {}, "outputs": [], "source": ["from nltk.stem import PorterStemmer \nfrom nltk.tokenize import word_tokenize\ndef word_stemmer(text):\n    stem_text = [PorterStemmer().stem(i) for i in text]\n    return stem_text\ndata_clean['text_clean_tokens'] = data_clean['text_tokens'].apply(lambda x: word_stemmer(x))\ndata_clean.head()"]}, {"cell_type": "markdown", "id": "46415fb3", "metadata": {}, "source": ["# text lemmatisation"]}, {"cell_type": "code", "execution_count": 1, "id": "23f4ef6b", "metadata": {}, "outputs": [], "source": ["nltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\ndef word_lemmatizer(text):\n    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n    return lem_text\ndata_clean['text_clean_tokens'] = data_clean['text_tokens'].apply(lambda x: word_lemmatizer(x))\ndata_clean.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "407cc29c", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data_clean['text_clean'],data_clean['target'],random_state = 0)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\npipeline_sgd = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf',  TfidfTransformer()),\n    ('lr', LogisticRegression()),\n])\nmodel = pipeline_sgd.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "7a73e440", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import classification_report\ny_predict = model.predict(X_test)\nprint(classification_report(y_test, y_predict))"]}, {"cell_type": "code", "execution_count": 1, "id": "0686a666", "metadata": {}, "outputs": [], "source": ["#Confusion Matrix Visualisation\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model, X_test, y_test) \nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "d896e10f", "metadata": {}, "outputs": [], "source": ["test_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "27b9c12e", "metadata": {}, "outputs": [], "source": ["submission_test_clean = test_data.copy()\nsubmission_test_clean = clean_text(submission_test_clean, \"text\",\"text_clean\")\nsubmission_test_clean['text_clean'] = submission_test_clean['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\nsubmission_test_clean.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "b9cc5e1f", "metadata": {}, "outputs": [], "source": ["submission_test_pred = model.predict(submission_test_clean['text_clean'])"]}, {"cell_type": "code", "execution_count": 1, "id": "da48f77a", "metadata": {}, "outputs": [], "source": ["id_col = test_data['id']\nsubmission_df_kaggle = pd.DataFrame({\"id\": id_col,\"target\": submission_test_pred})\nsubmission_df_kaggle.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "17bf5c4f", "metadata": {}, "outputs": [], "source": ["submission_df_kaggle.to_csv(\"submission.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}