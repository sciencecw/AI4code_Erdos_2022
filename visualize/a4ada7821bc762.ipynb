{"cells": [{"cell_type": "markdown", "id": "f6c3501a", "metadata": {}, "source": ["# 1. Preparation"]}, {"cell_type": "code", "execution_count": 1, "id": "794b83da", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport random\nimport cv2"]}, {"cell_type": "code", "execution_count": 1, "id": "02dbd400", "metadata": {}, "outputs": [], "source": ["## Declare Directory\ntrain_dir = \"../input/face-mask-12k-images-dataset/Face Mask Dataset/Train\"\nval_dir = \"../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation\"\ntest_dir = \"../input/face-mask-12k-images-dataset/Face Mask Dataset/Test\"\n\nclasses = [\"With Mask\", \"Without Mask\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "e90b0a1d", "metadata": {}, "outputs": [], "source": ["n = 5\n## Check Image\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"/WithMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"/WithMask/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"With Mask\")\nplt.show()   \n\nplt.figure(figsize=(15, n))\nfor i in range(n):\n    # read image\n    sample = random.choice(os.listdir(train_dir + \"/WithoutMask\"))\n    # print(\"filename:\", sample)\n    img_dir = train_dir + \"/WithoutMask/\" + sample\n    img = cv2.imread(img_dir)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # plot image\n    plt.subplot(1, n, 1+i)\n    plt.imshow(img)\n    plt.xlabel(\"Without Mask\")\nplt.show()   "]}, {"cell_type": "code", "execution_count": 1, "id": "96befee8", "metadata": {}, "outputs": [], "source": ["## Data Augmentation \nfrom keras.preprocessing.image import ImageDataGenerator"]}, {"cell_type": "code", "execution_count": 1, "id": "e77a9086", "metadata": {}, "outputs": [], "source": ["# Dataset Loader\ntrain_datagen = ImageDataGenerator(\n                                rescale=1./255,\n                                rotation_range=0.2,\n                                #width_shift_range=0.1,\n                                #height_shift_range=0.1,\n                                shear_range=0.2,\n                                #zoom_range=0.09,\n                                horizontal_flip=True,\n                                vertical_flip=False,\n                                #validation_split=0.1\n                                )\n\nval_datagen = ImageDataGenerator(rescale=1./255)"]}, {"cell_type": "code", "execution_count": 1, "id": "c978d8fd", "metadata": {}, "outputs": [], "source": ["# Image Generator Config\ntarget_size = (150, 150)\nbatch_size = 16\n\n# Load Dataset\ntrain_dataset = train_datagen.flow_from_directory(train_dir,\n                                                  target_size=target_size,\n                                                  batch_size=batch_size,\n                                                  class_mode=\"categorical\",\n                                                  shuffle=True)\n\nval_dataset = val_datagen.flow_from_directory(val_dir,\n                                              target_size=target_size,\n                                              batch_size=batch_size,\n                                              class_mode=\"categorical\",\n                                              shuffle=False)"]}, {"cell_type": "markdown", "id": "0d6bf3a5", "metadata": {}, "source": ["# 2. Deep Learning Model"]}, {"cell_type": "code", "execution_count": 1, "id": "9335b4d3", "metadata": {}, "outputs": [], "source": ["# Import\nimport keras\nfrom keras import layers\nfrom keras.applications import MobileNetV2\n\n# Initiate Baseline Model\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))"]}, {"cell_type": "code", "execution_count": 1, "id": "c5682997", "metadata": {}, "outputs": [], "source": ["# Freezing Layer\nfor layer in base_model.layers:\n    layer.trainable = False"]}, {"cell_type": "code", "execution_count": 1, "id": "817363b6", "metadata": {}, "outputs": [], "source": ["model = keras.Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2, activation=\"softmax\"))"]}, {"cell_type": "code", "execution_count": 1, "id": "c62ad407", "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "1c60a96b", "metadata": {}, "outputs": [], "source": ["## Setting backprop of model (how this model learning)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics =\"accuracy\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4cf54c0f", "metadata": {}, "outputs": [], "source": ["# Training\nEPOCHS = 10\nhistory = model.fit_generator(train_dataset,\n                               steps_per_epoch=len(train_dataset)//train_dataset.batch_size,\n                               validation_data=val_dataset, \n                               validation_steps=len(val_dataset)//val_dataset.batch_size,\n                               epochs=EPOCHS, \n                               )"]}, {"cell_type": "markdown", "id": "975758af", "metadata": {}, "source": ["# 3. Reviewing Model"]}, {"cell_type": "code", "execution_count": 1, "id": "1af77607", "metadata": {}, "outputs": [], "source": ["## Review Our Model\nimport matplotlib.gridspec as gridspec\n\nfig = plt.figure(figsize=(14,5))\ngrid = gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\nfig.add_subplot(grid[0])\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nfig.add_subplot(grid[1])\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n\n#plt.savefig(\"Training_result.jpg\",dpi=300)"]}, {"cell_type": "code", "execution_count": 1, "id": "f2ddc9f3", "metadata": {}, "outputs": [], "source": ["# Load Test Dataset\ntest_dataset = val_datagen.flow_from_directory(test_dir,\n                                            target_size=target_size,\n                                            batch_size=1,\n                                            class_mode=None,\n                                            shuffle=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "b8d3e754", "metadata": {}, "outputs": [], "source": ["probabilities = model.predict_generator(test_dataset)"]}, {"cell_type": "code", "execution_count": 1, "id": "4c891627", "metadata": {}, "outputs": [], "source": ["y_pred = probabilities.argmax(axis=-1)\ny_test = test_dataset.classes"]}, {"cell_type": "code", "execution_count": 1, "id": "2576984a", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, accuracy_score\nimport seaborn as sns"]}, {"cell_type": "code", "execution_count": 1, "id": "3b27975c", "metadata": {}, "outputs": [], "source": ["print(\"Accuracy Score of Model:\", accuracy_score(y_pred,y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "37c91723", "metadata": {}, "outputs": [], "source": ["labels = [\"No Mask\",\"Mask\"]\n\nfig, ax = plt.subplots(figsize=(8,7))\nsns.heatmap(confusion_matrix(y_test,y_pred),xticklabels=labels, ax=ax,\n                                       yticklabels=labels, annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 20})\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nplt.title(\"Confusion matrix\",fontsize=30)"]}, {"cell_type": "markdown", "id": "b7993caf", "metadata": {}, "source": ["# Test with Visualization"]}, {"cell_type": "code", "execution_count": 1, "id": "af0e7d08", "metadata": {}, "outputs": [], "source": ["import glob\nimport random"]}, {"cell_type": "code", "execution_count": 1, "id": "957cb475", "metadata": {}, "outputs": [], "source": ["def preprocessing_img(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150, 150))\n    img = np.array(img)\n    img = np.expand_dims(img, axis=0)\n    img = img/255\n    return img\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7bb0b223", "metadata": {}, "outputs": [], "source": ["random_test_img = random.choice(glob.glob(test_dir+\"/*/*\"))\nprint(random_test_img)\nimg_test = cv2.imread(random_test_img)\nimg_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\nplt.imshow(img_test)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "523fc031", "metadata": {}, "outputs": [], "source": ["img_test = preprocessing_img(img_test)\nresult = model.predict(img_test)\nscore = np.max(result)\npredicted_class = classes[np.argmax(result)]\nprint(predicted_class)\nprint(\"Confident: \", score)"]}, {"cell_type": "markdown", "id": "add47c74", "metadata": {}, "source": ["# Save Model"]}, {"cell_type": "code", "execution_count": 1, "id": "59a77eec", "metadata": {}, "outputs": [], "source": ["model.save(\"face-masked-detection.h5\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}