{"cells": [{"cell_type": "markdown", "id": "b7f25492", "metadata": {}, "source": ["Importing packages"]}, {"cell_type": "code", "execution_count": 1, "id": "011eae63", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\n\nimport seaborn as sns\n\n\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\npaths = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "a2ebd250", "metadata": {}, "source": ["Loading Dataset\n\ndata = pd.read_csv(paths[0])\ndata.info()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0bbc14e1", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv(paths[0])\ndata.info()\n"]}, {"cell_type": "markdown", "id": "b8f32930", "metadata": {}, "source": ["Check for null value"]}, {"cell_type": "code", "execution_count": 1, "id": "db946667", "metadata": {}, "outputs": [], "source": ["data.isnull().values.any()\n\n"]}, {"cell_type": "markdown", "id": "3fffad2c", "metadata": {}, "source": ["Column names"]}, {"cell_type": "code", "execution_count": 1, "id": "1d734a29", "metadata": {}, "outputs": [], "source": ["data.columns\n"]}, {"cell_type": "markdown", "id": "a3a07e82", "metadata": {}, "source": ["statistical data"]}, {"cell_type": "code", "execution_count": 1, "id": "2660eabd", "metadata": {}, "outputs": [], "source": ["data.describe()"]}, {"cell_type": "markdown", "id": "f6d80f33", "metadata": {}, "source": ["first 5 row"]}, {"cell_type": "code", "execution_count": 1, "id": "3c78cb32", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "markdown", "id": "299bdd9d", "metadata": {}, "source": ["no of unique datatypes"]}, {"cell_type": "code", "execution_count": 1, "id": "387bd246", "metadata": {}, "outputs": [], "source": ["\n\ndata.nunique()\n\n\n"]}, {"cell_type": "markdown", "id": "20155d2c", "metadata": {}, "source": ["normalization interms os chool"]}, {"cell_type": "code", "execution_count": 1, "id": "83a886ac", "metadata": {}, "outputs": [], "source": ["data.school.value_counts(normalize=True)"]}, {"cell_type": "markdown", "id": "a70fca63", "metadata": {}, "source": ["normalization in terms of sex"]}, {"cell_type": "code", "execution_count": 1, "id": "83be7ffd", "metadata": {}, "outputs": [], "source": ["data.sex.value_counts(normalize=True)"]}, {"cell_type": "markdown", "id": "0ad602a1", "metadata": {}, "source": ["visualizing graph for male and female count"]}, {"cell_type": "code", "execution_count": 1, "id": "f11d3e76", "metadata": {}, "outputs": [], "source": ["sns.set(rc={'figure.figsize':(8,6)})\nsns.countplot(x=\"school\", hue =\"sex\", data=data)"]}, {"cell_type": "markdown", "id": "3e07f7a6", "metadata": {}, "source": ["Visualizing graph for age"]}, {"cell_type": "code", "execution_count": 1, "id": "8304ddce", "metadata": {}, "outputs": [], "source": ["sns.countplot(data.age)"]}, {"cell_type": "markdown", "id": "5def19f7", "metadata": {}, "source": ["replacing the attribute value to integer and change its type"]}, {"cell_type": "code", "execution_count": 1, "id": "2cd947ea", "metadata": {}, "outputs": [], "source": ["data['internet'] = data['internet'].replace({'no': 0, 'yes': 1}).astype(int)\ndata['romantic'] = data['romantic'].replace({'no': 0, 'yes': 1}).astype(int)\ndata['school'] = data['school'].replace({'GP': 0, 'MS': 1}).astype(int)\ndata['sex'] = data['sex'].replace({'M': 0, 'F': 1})\ndata['address'] = data['address'].replace({'R': 0, 'U': 1})\ndata['famsize'] = data['famsize'].replace({'LE3': 0, 'GT3': 1})\ndata['Pstatus'] = data['Pstatus'].replace({'A': 0, 'T': 1})\ndata['Mjob'] = data['Mjob'].replace({'at_home': 0, 'health': 1, 'other': 2, 'services': 3, 'teacher': 4})\ndata['Fjob'] = data['Fjob'].replace({'at_home': 0, 'health': 1, 'other': 2, 'services': 3, 'teacher': 4}).astype(int)\ndata['reason'] = data['reason'].replace({'course': 0, 'other': 1, 'home': 2, 'reputation': 3}).astype(int)\ndata['guardian'] = data['guardian'].replace({'mother': 0, 'father': 1, 'other': 2}).astype(int)\ndata['schoolsup'] = data['schoolsup'].replace({'no': 0, 'yes': 1}).astype(int)\ndata['famsup'] = data['famsup'].replace({'no': 0, 'yes': 1}).astype(int)\ndata['paid'] = data['paid'].replace({'no': 0, 'yes': 1}).astype(int)\ndata['activities'] = data['activities'].replace({'no': 0, 'yes': 1}).astype(int)\ndata['nursery'] = data['nursery'].replace({'no': 0, 'yes': 1}).astype(int)\ndata['higher'] = data['higher'].replace({'no': 0, 'yes': 1}).astype(int)\n\ndata.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "0280f633", "metadata": {}, "outputs": [], "source": ["data.columns\n"]}, {"cell_type": "markdown", "id": "6b7b4bc1", "metadata": {}, "source": ["calculate avg of grade and assign grade to find op"]}, {"cell_type": "code", "execution_count": 1, "id": "f7dfb224", "metadata": {}, "outputs": [], "source": ["data['GAvg'] = (data['G1'] + data['G2'] + data['G3']) / 3\ndef grade_assign(df):\n    # Create a list to store the data\n    grades = []\n\n    # For each row in the column,\n    for row in df['GAvg']:\n        # if more than a value,\n        if row >= (0.9 * df['GAvg'].max()):\n            # Append a letter grade\n            grades.append('A')\n        # else, if more than a value,\n        elif row >= (0.7 * df['GAvg'].max()):\n            # Append a letter grade\n            grades.append('B')\n        # else, if more than a value,\n        elif row < (0.7 * df['GAvg'].max()):\n            # Append a letter grade\n            grades.append('C')   \n    # Create a column from the list\n    df['grades'] = grades\n    return df"]}, {"cell_type": "markdown", "id": "c4b53f33", "metadata": {}, "source": ["again display new attribute values for 5 rows"]}, {"cell_type": "code", "execution_count": 1, "id": "a808ecd7", "metadata": {}, "outputs": [], "source": ["data = grade_assign(data)\ndata.head()"]}, {"cell_type": "markdown", "id": "111e146b", "metadata": {}, "source": ["splitting into train and test set"]}, {"cell_type": "code", "execution_count": 1, "id": "3bb3c63a", "metadata": {}, "outputs": [], "source": ["\nX = data.drop(['grades','famsize'], axis=1)\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndata['grades'] = le.fit_transform(data['grades'])\ny=data['grades']"]}, {"cell_type": "code", "execution_count": 1, "id": "bed54abc", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=100)\n"]}, {"cell_type": "markdown", "id": "9d86163f", "metadata": {}, "source": ["Build LR model"]}, {"cell_type": "code", "execution_count": 1, "id": "be4b3e09", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\nReg = LinearRegression()\nReg.fit(X_train, y_train)\n"]}, {"cell_type": "markdown", "id": "a7dc9bc6", "metadata": {}, "source": ["predicting op"]}, {"cell_type": "code", "execution_count": 1, "id": "e5b326d5", "metadata": {}, "outputs": [], "source": ["y_pred = Reg.predict(X_test)\nprint(y_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "ee427b8f", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\ncount_misclassified = (y_test != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))\naccuracy_score(y_pred.round(),y_test,normalize = False)\n"]}, {"cell_type": "markdown", "id": "7b740857", "metadata": {}, "source": ["Building Decision Tree"]}, {"cell_type": "code", "execution_count": 1, "id": "a5591e8f", "metadata": {}, "outputs": [], "source": ["dtree = tree.DecisionTreeClassifier(max_depth=5, criterion='entropy', random_state=42)\ndtree.fit(X_train,y_train)"]}, {"cell_type": "markdown", "id": "e5be7c33", "metadata": {}, "source": ["visualizing graph into list"]}, {"cell_type": "code", "execution_count": 1, "id": "0bf09460", "metadata": {}, "outputs": [], "source": ["import graphviz\nfrom sklearn.tree import export_text\n\nfeature_names = X.columns\ndot_data = tree.export_graphviz(dtree, out_file=None, feature_names=X.columns,class_names=['unacc', 'acc', 'good', 'vgood'], filled=True, rounded=True, special_characters=True)  \ngraph = graphviz.Source(dot_data)  \nprint(graph)\nr = export_text(dtree, feature_names=X.columns.tolist())\nprint(r)"]}, {"cell_type": "markdown", "id": "196e8a4d", "metadata": {}, "source": ["predicting accuracy of decisiontree"]}, {"cell_type": "code", "execution_count": 1, "id": "2542e607", "metadata": {}, "outputs": [], "source": ["predictions = dtree.predict(X_test)\n\n\naccuracy_score(y_true = y_test, y_pred = predictions)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}