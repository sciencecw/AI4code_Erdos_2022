{"cells": [{"cell_type": "markdown", "id": "36a097a4", "metadata": {}, "source": ["<img style=\"float: left;\" src=\"http://3.bp.blogspot.com/-cRW46iETTJw/VPIc1vbEWWI/AAAAAAAAAUU/3Hdq70uDl6U/s1600/il%2Bmare%2Bdi%2Bghiaccio%2B(1).jpg\" width=\"700px\"/>"]}, {"cell_type": "markdown", "id": "46403e9b", "metadata": {}, "source": ["***The Sea of Ice - Caspar David Friedrich - 1824***"]}, {"cell_type": "markdown", "id": "41918d57", "metadata": {}, "source": ["## ***Titanic***\n\n- EDA\n- Classification Pipeline\n- RandomGridCV\n- ANN"]}, {"cell_type": "code", "execution_count": 1, "id": "d149350d", "metadata": {}, "outputs": [], "source": ["import warnings  \nwarnings.filterwarnings('ignore')\nimport os\nimport numpy as np\nimport pandas as pd\nimport math \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import export_graphviz \nfrom sklearn.metrics import roc_curve, auc \nfrom sklearn.metrics import classification_report \nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"]}, {"cell_type": "code", "execution_count": 1, "id": "9d9b1b4e", "metadata": {}, "outputs": [], "source": ["dataset = pd.read_csv('/kaggle/input/titanic/train.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "382c1ec9", "metadata": {}, "outputs": [], "source": ["dataset.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "9582e0f2", "metadata": {}, "outputs": [], "source": ["dataset.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True) \n"]}, {"cell_type": "code", "execution_count": 1, "id": "3773b58c", "metadata": {}, "outputs": [], "source": ["dataset.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "cd5b4600", "metadata": {}, "outputs": [], "source": ["dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")\n\ndataset.isnull().sum()"]}, {"cell_type": "markdown", "id": "70267cc0", "metadata": {}, "source": ["***Survived***"]}, {"cell_type": "code", "execution_count": 1, "id": "352419e2", "metadata": {}, "outputs": [], "source": ["sns.countplot(x='Survived', hue='Sex', data=dataset)"]}, {"cell_type": "markdown", "id": "7ccf84b8", "metadata": {}, "source": ["***SibSp***"]}, {"cell_type": "code", "execution_count": 1, "id": "bb84399c", "metadata": {}, "outputs": [], "source": ["sns.countplot(x='SibSp', hue='Survived', data=dataset)"]}, {"cell_type": "markdown", "id": "0f04099b", "metadata": {}, "source": ["***Parch***"]}, {"cell_type": "code", "execution_count": 1, "id": "d9495903", "metadata": {}, "outputs": [], "source": ["sns.countplot('Parch' , hue = 'Survived' , data = dataset)"]}, {"cell_type": "markdown", "id": "1564f629", "metadata": {}, "source": ["***Embarked***"]}, {"cell_type": "code", "execution_count": 1, "id": "16e6fcdf", "metadata": {}, "outputs": [], "source": ["sns.countplot(x='Embarked', hue='Survived', data=dataset)"]}, {"cell_type": "markdown", "id": "7212481a", "metadata": {}, "source": ["***Pclass***"]}, {"cell_type": "code", "execution_count": 1, "id": "490b7e9a", "metadata": {}, "outputs": [], "source": ["sns.countplot(x='Pclass', hue='Survived', data=dataset)"]}, {"cell_type": "code", "execution_count": 1, "id": "1aba22cf", "metadata": {}, "outputs": [], "source": ["dataset = pd.get_dummies(dataset)"]}, {"cell_type": "code", "execution_count": 1, "id": "b4e68e52", "metadata": {}, "outputs": [], "source": ["y = dataset['Survived'].values \n\nX = dataset.drop(['Survived'],axis=1)                 \n"]}, {"cell_type": "code", "execution_count": 1, "id": "de58eaf9", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "addd4539", "metadata": {}, "outputs": [], "source": ["\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\n\n\nclassifiers =  [\n       ['Logistic Regression Classifier :', LogisticRegression()] ,\n       ['Decision Tree Classifier :', DecisionTreeClassifier()] ,\n       ['Random Forest Classifier :', RandomForestClassifier()] ,\n       ['Gradient Boosting Classifier :', GradientBoostingClassifier()] ,\n       ['AdaBoost Classifier :', AdaBoostClassifier()] ,\n       ['XGB Classifier :', XGBClassifier()] ,\n       ['Extra Tree Classifier :', ExtraTreesClassifier()] ,\n       ['K-Neighbors Classifier :', KNeighborsClassifier()] ,  \n       ['Naive Bayes :' , GaussianNB()] ,\n       ]\n\n\nconfusion_tab = []\n\nfor name,model in classifiers:    \n\n    model = model\n    \n    model.fit(X_train,y_train)\n    \n    y_pred = model.predict(X_test)\n        \n\n    print('-----------------------------------')\n    print(name)\n    print('Accuracy Score ', accuracy_score( y_test, y_pred))\n    print(\"f1_score: \",f1_score( y_test, y_pred))\n    print(\"precision_score: \", precision_score( y_test, y_pred))\n    print(\"recall_score: \", recall_score( y_test, y_pred))\n    print(\"ROC AUC: \", roc_auc_score( y_test, y_pred))\n    print('---------------------------------')\n    confusion = confusion_matrix( y_test, y_pred)\n    confusion_tab.append(confusion)    \n    plt.subplot(2,2,1)\n    plt.title(name)\n    sns.heatmap(confusion, annot=True , cmap=\"Blues\" , fmt=\"d\" , cbar=False , annot_kws = {\"size\": 24})\n    plt.show()\n\n"]}, {"cell_type": "markdown", "id": "e9c5bd7d", "metadata": {}, "source": ["Best Model  --> ExtraTreeClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "8cf4bbc0", "metadata": {}, "outputs": [], "source": ["n_estimators = [int(x) for x in np.linspace(start = 1, stop = 100, num = 10 )]  \nmax_depth = [int(x) for x in np.linspace(1, 100, num = 10)] \nmax_depth.append(None)\n\nmin_samples_split = [2, 5, 10]     \nmin_samples_leaf = [1, 2, 4]       \nmax_features = ['auto', 'sqrt' , 'log2']    \nbootstrap = [True, False]         \nrandom_state = [42]                \n\n\n\n\n\nparam_distributions = dict(n_estimators = n_estimators,\n                   max_depth = max_depth, \n                   min_samples_split = min_samples_split,\n                   min_samples_leaf = min_samples_leaf,\n                   max_features = max_features, \n                   bootstrap = bootstrap,\n                   random_state = random_state ,\n                   )\n\n\n\n\nestimator = ExtraTreesClassifier()     \n\n                         \nfrom sklearn.model_selection import RandomizedSearchCV\n\n\n\n\nRandomCV = RandomizedSearchCV(estimator=estimator,          \n                            param_distributions=param_distributions,\n                            n_iter = 50,\n                            cv = 10,\n                            scoring = 'precision',\n                            verbose=1, \n                            n_jobs=-1,\n                            )\n\n\n\nhyper_model = RandomCV.fit(X_train, y_train)\n\nprint('Best Score: ', hyper_model.best_score_)  \nprint('Best Params: ', hyper_model.best_params_)"]}, {"cell_type": "code", "execution_count": 1, "id": "5ae1f0aa", "metadata": {}, "outputs": [], "source": ["hyper_model.best_estimator_.fit(X_train,y_train) \n\ny_pred_hyper = hyper_model.best_estimator_.predict(X_test) \n\n\nprint('Accuracy Score ', accuracy_score( y_test, y_pred_hyper))\nprint(\"f1_score: \",f1_score( y_test, y_pred_hyper))\nprint(\"precision_score: \", precision_score( y_test, y_pred_hyper))\nprint(\"recall_score: \", recall_score( y_test, y_pred_hyper))\nprint(\"ROC AUC: \", roc_auc_score( y_test, y_pred_hyper))\n\nconfusion_hyper = confusion_matrix(y_test ,y_pred_hyper )\n\nplt.subplot(2,3,1)\nplt.title(\"Hyper Model Confusion Matrix\")\nsns.heatmap(confusion_hyper,annot=True,fmt=\"d\",cbar=False, annot_kws={\"size\": 24})"]}, {"cell_type": "markdown", "id": "3f11f906", "metadata": {}, "source": ["# ***ANN***"]}, {"cell_type": "code", "execution_count": 1, "id": "41f0dbdc", "metadata": {}, "outputs": [], "source": ["import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nclassifier = Sequential()\n\nclassifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n\nclassifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n\nclassifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n\nclassifier.fit(X_train, y_train, batch_size = 1, epochs = 200)  "]}, {"cell_type": "code", "execution_count": 1, "id": "f4c49d3e", "metadata": {}, "outputs": [], "source": ["y_pred_ANN = classifier.predict(X_test)\n\ny_pred_ANN = [1 if each > 0.5 else 0 for each in y_pred_ANN]\ny_pred_ANN = np.array(y_pred_ANN)\n\n  \nprint('Accuracy Score ', accuracy_score( y_test, y_pred_ANN))\nprint(\"f1_score: \",f1_score( y_test, y_pred_ANN))\nprint(\"precision_score: \", precision_score( y_test, y_pred_ANN))\nprint(\"recall_score: \", recall_score( y_test, y_pred_ANN))\nprint(\"ROC AUC: \", roc_auc_score( y_test, y_pred_ANN))\n\nconfusion_ANN = confusion_matrix(y_test, y_pred_ANN)   \n\nplt.subplot(2,3,1)\nplt.title(\"ANN Confusion Matrix\")\nsns.heatmap(confusion_ANN,annot=True,fmt=\"d\",cbar=False, annot_kws={\"size\": 24})"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}