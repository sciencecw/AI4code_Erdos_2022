{"cells": [{"cell_type": "markdown", "id": "8bbc784d", "metadata": {}, "source": ["# 3d-printer-data-classification\n\nIn that software page, we applied some algorithms from machine learning to the data of 3D printers (classification) and we got results in the test data that have reached completion.."]}, {"cell_type": "code", "execution_count": 1, "id": "22d79b81", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder"]}, {"cell_type": "code", "execution_count": 1, "id": "d7267e41", "metadata": {}, "outputs": [], "source": ["data=pd.read_csv(\"../input/3dprinter/data.csv\",sep=\",\")"]}, {"cell_type": "code", "execution_count": 1, "id": "ec259447", "metadata": {}, "outputs": [], "source": ["data"]}, {"cell_type": "code", "execution_count": 1, "id": "aa80fbf4", "metadata": {}, "outputs": [], "source": ["data.shape"]}, {"cell_type": "markdown", "id": "c9a321d0", "metadata": {}, "source": ["We have very little data, so it is not likely that we will use neural networks in this process, but we will try, my friend."]}, {"cell_type": "code", "execution_count": 1, "id": "6395291a", "metadata": {}, "outputs": [], "source": ["# The data is small, but it is beautiful.\ndata.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "61ac94f0", "metadata": {}, "outputs": [], "source": ["# We note that the data we have has a different type of data than the digital type, so we will convert it.\ndata.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "bb1c5289", "metadata": {}, "outputs": [], "source": ["list(data.columns)"]}, {"cell_type": "code", "execution_count": 1, "id": "24a1c80d", "metadata": {}, "outputs": [], "source": ["#Now we will convert the two data types, to the numbers data type.\ndata_2=data.copy()\nobj=LabelEncoder()\ndata_2[\"infill_pattern\"] = obj.fit_transform(data[\"infill_pattern\"])\ndata_2[\"material\"] = obj.fit_transform(data[\"material\"])\n# And then we notice that change / transformation."]}, {"cell_type": "code", "execution_count": 1, "id": "1e04092a", "metadata": {}, "outputs": [], "source": ["data_2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "f19e4ee5", "metadata": {}, "outputs": [], "source": ["# Now it is our turn to extract the rewards and unique characteristics of each column.\nfor i in data.columns:\n  print(i, data[i].unique())"]}, {"cell_type": "code", "execution_count": 1, "id": "309daa57", "metadata": {}, "outputs": [], "source": ["# Here is another formula that we can extract the advantages for each column.\n#for column in data.columns:\n #   print(\"{} : {}\".format(column,data[column].unique()))"]}, {"cell_type": "code", "execution_count": 1, "id": "0f0bb664", "metadata": {}, "outputs": [], "source": ["#Note that the number 3 in the code indicates the number of digits after the decimal point for each cell.\ncorrelation = data_2.corr()\ncorrelation.style.background_gradient(cmap='coolwarm').set_precision(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "2b3f0c13", "metadata": {}, "outputs": [], "source": ["# Now we will separate the goal from the rest of the features.\ntarget_data= data_2[\"material\"].values\nfeature_data= data_2.drop([\"material\",\"print_speed\",\"infill_pattern\",\"bed_temperature\",\"layer_height\"],axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "4c64e167", "metadata": {}, "outputs": [], "source": ["target_data"]}, {"cell_type": "code", "execution_count": 1, "id": "b824341f", "metadata": {}, "outputs": [], "source": ["feature_data"]}, {"cell_type": "code", "execution_count": 1, "id": "1a2a941f", "metadata": {}, "outputs": [], "source": ["# Now I will do the process of smoothing the data.\n#Import Libraries\nfrom sklearn.preprocessing import StandardScaler\n#Standard Scaler for Data\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(feature_data)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "9d8d3b04", "metadata": {}, "outputs": [], "source": ["# Now I will do the partitioning of the data.\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X,target_data,test_size = 0.1,random_state=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "d0d9ae74", "metadata": {}, "outputs": [], "source": ["print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"]}, {"cell_type": "markdown", "id": "57cccc08", "metadata": {}, "source": ["We note that the amount of data used in the test is very small because \n\n---\n\nthe data is very few, of course."]}, {"cell_type": "markdown", "id": "575dc99c", "metadata": {}, "source": ["# Now I will build our own model."]}, {"cell_type": "code", "execution_count": 1, "id": "053ef03e", "metadata": {}, "outputs": [], "source": ["# This algorithm is for prediction.\n#Import Libraries\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import confusion_matrix\nDecisionTreeRegressorModel=DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=3,min_samples_split=2,\n                                   min_samples_leaf=1,min_weight_fraction_leaf=0.0, max_features=None,\n                                   random_state=None, max_leaf_nodes=5\n                                  )"]}, {"cell_type": "code", "execution_count": 1, "id": "a6ad387f", "metadata": {}, "outputs": [], "source": ["DecisionTreeRegressorModel.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "1e3f1ff5", "metadata": {}, "outputs": [], "source": ["#Calculating Details\nprint('DecisionTreeRegressor Train Score is : ' , DecisionTreeRegressorModel.score(x_train, y_train))\nprint('DecisionTreeRegressor Test Score is : ' , DecisionTreeRegressorModel.score(x_test, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "fa3b6dd2", "metadata": {}, "outputs": [], "source": ["#Calculating Prediction\ny_pred = DecisionTreeRegressorModel.predict(x_test)\nprint('Predicted Value for DecisionTreeRegressorModel is : ' , y_pred[:10])\n#Here we are working on printing the data that we have put to the test\nprint(\"test values :\" , y_test[:10] )"]}, {"cell_type": "code", "execution_count": 1, "id": "2d31381a", "metadata": {}, "outputs": [], "source": ["# This algorithm is for classification.\n#Import Libraries\nfrom sklearn.tree import DecisionTreeClassifier\nDecisionTreeClassifierModel =DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=3,min_samples_split=2,\n                                    min_samples_leaf=1,min_weight_fraction_leaf=0.0,max_features=None,\n                                    random_state=0, max_leaf_nodes=5)"]}, {"cell_type": "code", "execution_count": 1, "id": "1a2e6d5b", "metadata": {}, "outputs": [], "source": ["DecisionTreeClassifierModel.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "68bba6e5", "metadata": {}, "outputs": [], "source": ["#Calculating Details\nprint('DecisionTreeClassifierModel Train Score is : ' , DecisionTreeClassifierModel.score(x_train, y_train))\nprint('DecisionTreeClassifierModel Test Score is : ' , DecisionTreeClassifierModel.score(x_test, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "090dba5e", "metadata": {}, "outputs": [], "source": ["print('DecisionTreeClassifierModel Classes are : ' , DecisionTreeClassifierModel.classes_)\nprint('DecisionTreeClassifierModel feature importances are : ' , DecisionTreeClassifierModel.feature_importances_)"]}, {"cell_type": "code", "execution_count": 1, "id": "972b473d", "metadata": {}, "outputs": [], "source": ["#Calculating Prediction\ny_pred = DecisionTreeClassifierModel.predict(x_test)\n# Now we calculate the probability of choosing the output for any division\ny_pred_prob = DecisionTreeClassifierModel.predict_proba(x_test)\nprint('Predicted Value for DecisionTreeClassifierModel is : ' , y_pred[:10])\n# These are the values that we categorized.\nprint(\"test values :\" ,y_test[:10] )\nprint('Prediction Probabilities Value for DecisionTreeClassifierModel is : ' , y_pred_prob[:10])\n"]}, {"cell_type": "code", "execution_count": 1, "id": "595b6baf", "metadata": {}, "outputs": [], "source": ["#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()"]}, {"cell_type": "markdown", "id": "1497fadd", "metadata": {}, "source": ["In the end, I obtained the accuracy of the test results, which reached the full percentage."]}, {"cell_type": "markdown", "id": "b5139665", "metadata": {}, "source": ["Now the use of neural networks in this process is a luxury to some extent.\nTherefore, I will not use neural networks, although I can do so by reducing the size of the network and reducing the number of layers in it, and it will also be of the type of hollow networks."]}, {"cell_type": "markdown", "id": "e8d62caf", "metadata": {}, "source": ["Now we're somewhat done with that software page.\nThank you very much for\nhttps://www.kaggle.com/parag46/kernel8c0883347d\n# And you too, thank you very much."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}