{"cells": [{"cell_type": "markdown", "id": "4caaf9fa", "metadata": {}, "source": ["# Importing Libraries and Loading datasets"]}, {"cell_type": "code", "execution_count": 1, "id": "eaeca1fe", "metadata": {}, "outputs": [], "source": ["import gc\nimport numpy as np\nimport pandas as pd\n\n# Plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Encoding\nfrom sklearn.preprocessing import LabelEncoder\n\n# Scaling\nfrom sklearn.preprocessing import RobustScaler\n\n# Neural Network\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\n\n# Cross-Validation\nfrom sklearn.model_selection import StratifiedKFold\n\n# Scoring\nfrom sklearn.metrics import accuracy_score"]}, {"cell_type": "code", "execution_count": 1, "id": "e467f4e3", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-dec-2021/test.csv\")"]}, {"cell_type": "markdown", "id": "4a0f1190", "metadata": {}, "source": ["# Explore Data"]}, {"cell_type": "code", "execution_count": 1, "id": "d273e769", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "47830a15", "metadata": {}, "outputs": [], "source": ["train.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "02d02838", "metadata": {}, "outputs": [], "source": ["print(\"Columns: \\n{0}\".format(list(train.columns)))"]}, {"cell_type": "markdown", "id": "11f2986f", "metadata": {}, "source": ["# Pseudo Labeling\n\nCredits to [remekkinas](https://www.kaggle.com/remekkinas) for his notebook [TPS-12 NN (TPU) + Pseudolabeling](https://www.kaggle.com/remekkinas/tps-12-nn-tpu-pseudolabeling-0-95690) and his dataset [TPS-12 - Pseudolabels](https://www.kaggle.com/remekkinas/tps12-pseudolabels)."]}, {"cell_type": "code", "execution_count": 1, "id": "4ede3a91", "metadata": {}, "outputs": [], "source": ["pseudo = pd.read_csv(\"../input/tps12-pseudolabels/tps12-pseudolabels_v2.csv\")\ntrain = pd.concat([train, pseudo], axis=0)\ntrain.reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "365e14c3", "metadata": {}, "outputs": [], "source": ["del pseudo\ngc.collect()"]}, {"cell_type": "markdown", "id": "802cdd25", "metadata": {}, "source": ["# Basic Data Check"]}, {"cell_type": "code", "execution_count": 1, "id": "5d72d152", "metadata": {}, "outputs": [], "source": ["print('Train data shape:', train.shape)\nprint('Test data shape:', test.shape)"]}, {"cell_type": "markdown", "id": "0d85ed19", "metadata": {}, "source": ["## Missing values"]}, {"cell_type": "code", "execution_count": 1, "id": "d2a0a8b1", "metadata": {}, "outputs": [], "source": ["missing_values_train = train.isna().any().sum()\nprint('Missing values in train data: {0}'.format(missing_values_train[missing_values_train > 0]))\n\nmissing_values_test = test.isna().any().sum()\nprint('Missing values in test data: {0}'.format(missing_values_test[missing_values_test > 0]))"]}, {"cell_type": "markdown", "id": "c7e286a9", "metadata": {}, "source": ["## Duplicates"]}, {"cell_type": "code", "execution_count": 1, "id": "39589518", "metadata": {}, "outputs": [], "source": ["duplicates_train = train.duplicated().sum()\nprint('Duplicates in train data: {0}'.format(duplicates_train))\n\nduplicates_test = test.duplicated().sum()\nprint('Duplicates in test data: {0}'.format(duplicates_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "a804038a", "metadata": {}, "outputs": [], "source": ["del missing_values_train\ndel missing_values_test\ndel duplicates_train\ndel duplicates_test\ngc.collect()"]}, {"cell_type": "markdown", "id": "b87b2cc2", "metadata": {}, "source": ["# Features"]}, {"cell_type": "markdown", "id": "8c3e9f85", "metadata": {}, "source": ["## Categorical Features"]}, {"cell_type": "code", "execution_count": 1, "id": "06fb3d22", "metadata": {}, "outputs": [], "source": ["categorical_features = train.columns[11:-1:]\nprint(\"Categorical Columns: \\n{0}\".format(list(categorical_features)))"]}, {"cell_type": "markdown", "id": "46623dfc", "metadata": {}, "source": ["## Numerical Features"]}, {"cell_type": "code", "execution_count": 1, "id": "f3bdd96c", "metadata": {}, "outputs": [], "source": ["numerical_features = train.columns[1:11]\nprint(\"Numerical Columns: \\n{0}\".format(list(train.columns[1:11])))\ntrain[numerical_features].describe()"]}, {"cell_type": "markdown", "id": "bca355b7", "metadata": {}, "source": ["## Target Distribution"]}, {"cell_type": "code", "execution_count": 1, "id": "57ad5730", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 6))\nplt.title('Target distribution')\nax = sns.countplot(x=train['Cover_Type'], data=train)"]}, {"cell_type": "markdown", "id": "4a5c41e1", "metadata": {}, "source": ["## Dropping rows and columns"]}, {"cell_type": "code", "execution_count": 1, "id": "171e5156", "metadata": {}, "outputs": [], "source": ["cType5 = train[train['Cover_Type'] == 5].index\nprint(\"Number of rows with Cover_Type = 5: {0}\".format(len(cType5)))"]}, {"cell_type": "code", "execution_count": 1, "id": "efbd7ef6", "metadata": {}, "outputs": [], "source": ["print(\"Unique values in Soil_Type7 column train data: {0}\".format(train['Soil_Type7'].unique()))\nprint(\"Unique values in Soil_Type15 column train data: {0}\".format(train['Soil_Type15'].unique()))\n\nprint(\"Unique values in Soil_Type7 column test data: {0}\".format(test['Soil_Type7'].unique()))\nprint(\"Unique values in Soil_Type15 column test data: {0}\".format(test['Soil_Type15'].unique()))"]}, {"cell_type": "code", "execution_count": 1, "id": "f310844e", "metadata": {}, "outputs": [], "source": ["# Dropping the row Cover_Type = 5,\n# causes problems during kfold (least populated class)\n# Also, it appears there is no label 5 in test data, \n# Check out, https://www.kaggle.com/baekseungyun/tps-dec-there-is-no-label-5-in-test-data\ntrain.drop(cType5, axis=0, inplace=True)\n\n# Dropping columns Soil_Type7 and Soil_Type15, they are zero\ntrain.drop(['Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)\ntest.drop(['Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "10ccf5e5", "metadata": {}, "outputs": [], "source": ["del categorical_features\ndel cType5\ndel ax\ngc.collect()"]}, {"cell_type": "markdown", "id": "769f5d8e", "metadata": {}, "source": ["# Feature Engineering\n\nCredits to [chryzal](https://www.kaggle.com/chryzal) for his notebook [\ud83e\udd47Features Engineering For You \ud83e\udd47](https://www.kaggle.com/chryzal/features-engineering-for-you)."]}, {"cell_type": "markdown", "id": "ee4676af", "metadata": {}, "source": ["## Encoding labels"]}, {"cell_type": "code", "execution_count": 1, "id": "4bf8e48c", "metadata": {}, "outputs": [], "source": ["encoder = LabelEncoder()\ntrain[\"Cover_Type\"] = encoder.fit_transform(train[\"Cover_Type\"])"]}, {"cell_type": "markdown", "id": "49764548", "metadata": {}, "source": ["## Arrange the range of `Aspect` column\n\nSets the `Aspect` columns' value range to 0 to 359."]}, {"cell_type": "code", "execution_count": 1, "id": "9d8b71bc", "metadata": {}, "outputs": [], "source": ["for data in [train, test]:\n    data[\"Aspect\"][data[\"Aspect\"] < 0] += 360\n    data[\"Aspect\"][data[\"Aspect\"] > 359] -= 360"]}, {"cell_type": "markdown", "id": "7d5030e9", "metadata": {}, "source": ["## Arrange the range of `Hillshade` columns\n\nSets the `Hillshade` columns' value range to 0 to 255."]}, {"cell_type": "code", "execution_count": 1, "id": "4e4eec24", "metadata": {}, "outputs": [], "source": ["for data in [train, test]:\n    data.loc[data[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n    data.loc[data[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n    data.loc[data[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n    data.loc[data[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n    data.loc[data[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n    data.loc[data[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255"]}, {"cell_type": "markdown", "id": "97d3e0c4", "metadata": {}, "source": ["## Creating distance based features"]}, {"cell_type": "code", "execution_count": 1, "id": "3eeacfad", "metadata": {}, "outputs": [], "source": ["for data in [train, test]:\n    # Manhhattan distance to Hydrology\n    data[\"Manhhattan_Distance_To_Hydrology\"] = np.abs(data[\"Horizontal_Distance_To_Hydrology\"]) + np.abs(data[\"Vertical_Distance_To_Hydrology\"])\n    # Euclidean distance to Hydrology\n    data[\"Euclidean_Distance_To_Hydrology\"] = (data[\"Horizontal_Distance_To_Hydrology\"]**2 + data[\"Vertical_Distance_To_Hydrology\"]**2)**0.5"]}, {"cell_type": "markdown", "id": "550b62d4", "metadata": {}, "source": ["## Creating new features\n\nCreating the following new features:  \n* Sum of all the soil types\n* Sum of all the wilderness area types"]}, {"cell_type": "code", "execution_count": 1, "id": "9d7b9723", "metadata": {}, "outputs": [], "source": ["features_Hillshade = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\nsoil_features = [x for x in train.columns if x.startswith(\"Soil_Type\")]\nwilderness_features = [x for x in train.columns if x.startswith(\"Wilderness_Area\")]\n\nfor data in [train, test]:\n    # Thanks @mpwolke : https://www.kaggle.com/mpwolke/tooezy-where-are-you-no-camping-here\n    data[\"Soil_Count\"] = data[soil_features].apply(sum, axis=1)\n    \n    # Thanks @yannbarthelemy : https://www.kaggle.com/yannbarthelemy/tps-december-first-simple-feature-engineering\n    data[\"Wilderness_Area_Count\"] = data[wilderness_features].apply(sum, axis=1)\n    data[\"Hillshade_mean\"] = data[features_Hillshade].mean(axis=1)\n    data['amp_Hillshade'] = data[features_Hillshade].max(axis=1) - data[features_Hillshade].min(axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "afd9f4cb", "metadata": {}, "outputs": [], "source": ["cols = test.columns\nfor data in [train, test]:\n    data['sum_na'] = data.isna().sum(axis = 1)\n    data['mean'] = data[cols].mean(axis=1)\n    data['min'] = data[cols].min(axis=1)\n    data['max'] = data[cols].max(axis=1)"]}, {"cell_type": "markdown", "id": "2083b332", "metadata": {}, "source": ["## Scaling features"]}, {"cell_type": "code", "execution_count": 1, "id": "939253ad", "metadata": {}, "outputs": [], "source": ["new_features = [\n    \"Manhhattan_Distance_To_Hydrology\",\n    \"Euclidean_Distance_To_Hydrology\",\n    \"Soil_Count\",\n    \"Wilderness_Area_Count\",\n    \"Hillshade_mean\",\n    \"amp_Hillshade\",\n    \"sum_na\",\n    \"mean\",\n    \"min\",\n    \"max\"\n]\nfeatures = np.concatenate((new_features, numerical_features))\n\nscaler = RobustScaler()\ntrain[features] = scaler.fit_transform(train[features])\ntest[features] = scaler.transform(test[features])"]}, {"cell_type": "code", "execution_count": 1, "id": "82e34909", "metadata": {}, "outputs": [], "source": ["del wilderness_features\ndel features_Hillshade\ndel numerical_features\ndel soil_features\ndel new_features\ndel features\ndel scaler\ndel cols\ngc.collect()"]}, {"cell_type": "markdown", "id": "15376725", "metadata": {}, "source": ["# Reduce memory usage\n\nThis code snippet is taken from https://www.kaggle.com/desalegngeb/december-2021-tps-eda-models  \nOriginally https://www.kaggle.com/c/tabular-playground-series-oct-2021/discussion/275854"]}, {"cell_type": "code", "execution_count": 1, "id": "0a56edfd", "metadata": {}, "outputs": [], "source": ["# This code snippet is taken from https://www.kaggle.com/desalegngeb/december-2021-tps-eda-models\n# Originally https://www.kaggle.com/c/tabular-playground-series-oct-2021/discussion/275854\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)"]}, {"cell_type": "markdown", "id": "95c8d0bd", "metadata": {}, "source": ["# Modelling"]}, {"cell_type": "code", "execution_count": 1, "id": "f01b094c", "metadata": {}, "outputs": [], "source": ["UNITS = train[\"Cover_Type\"].nunique()\nTEST_ID = test.Id.copy()"]}, {"cell_type": "code", "execution_count": 1, "id": "9e543f58", "metadata": {}, "outputs": [], "source": ["# Get train data without the target and ids\nX = train.drop(['Id', 'Cover_Type'], axis=1).copy()\n# Get the target\ny = train.Cover_Type.copy()\n# Get the test data without ids\ntest_X = test.drop(['Id'], axis=1).copy()"]}, {"cell_type": "code", "execution_count": 1, "id": "5a5fdadb", "metadata": {}, "outputs": [], "source": ["del train\ndel test\ngc.collect()"]}, {"cell_type": "markdown", "id": "c8248f58", "metadata": {}, "source": ["## Callbacks"]}, {"cell_type": "code", "execution_count": 1, "id": "1c0dbcec", "metadata": {}, "outputs": [], "source": ["# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\nearly_stopping = callbacks.EarlyStopping(\n    monitor=\"val_accuracy\",     # Quantity to be monitored\n    patience=20,                # How many epochs to wait before stopping\n    restore_best_weights=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "0dcb8f3e", "metadata": {}, "outputs": [], "source": ["# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\nreduce_lr = callbacks.ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.5,                # Factor by which the learning rate will be reduced\n    patience=5)                # Number of epochs with no improvement"]}, {"cell_type": "code", "execution_count": 1, "id": "21f97904", "metadata": {}, "outputs": [], "source": ["CALLBACKS = [early_stopping, reduce_lr]"]}, {"cell_type": "markdown", "id": "d544e06c", "metadata": {}, "source": ["## Model"]}, {"cell_type": "code", "execution_count": 1, "id": "d8e28bc5", "metadata": {}, "outputs": [], "source": ["# Credits to https://www.kaggle.com/samuelcortinhas/tps-dec-feat-eng-pseudolab-clean-version\nN_SPLITS = 8\nEPOCHS = 100\nBATCH_SIZE = 250"]}, {"cell_type": "code", "execution_count": 1, "id": "307e5efd", "metadata": {}, "outputs": [], "source": ["# Credits to https://www.kaggle.com/chryzal/features-engineering-for-you\n# Credits to https://www.kaggle.com/samuelcortinhas/tps-dec-feat-eng-pseudolab-clean-version\nmodel = keras.Sequential([\n    layers.Dense(units=256, kernel_initializer=\"lecun_normal\", activation=\"selu\", input_shape=[X.shape[1]]),\n    layers.BatchNormalization(),\n    layers.Dense(units=256, kernel_initializer=\"lecun_normal\", activation=\"selu\"),\n    layers.BatchNormalization(),\n    layers.Dense(units=128, kernel_initializer=\"lecun_normal\", activation=\"selu\"),\n    layers.BatchNormalization(),\n    layers.Dense(units=64, kernel_initializer=\"lecun_normal\", activation=\"selu\"),\n    layers.BatchNormalization(),\n    layers.Dense(units=UNITS, activation=\"softmax\")])"]}, {"cell_type": "code", "execution_count": 1, "id": "13d15f8c", "metadata": {}, "outputs": [], "source": ["model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'])"]}, {"cell_type": "markdown", "id": "9b6b60e2", "metadata": {}, "source": ["## Training"]}, {"cell_type": "code", "execution_count": 1, "id": "2ea9b0ff", "metadata": {}, "outputs": [], "source": ["fold = 1\nscores = []\ntest_predictions = np.zeros((1, 1))\ncv = StratifiedKFold(n_splits=N_SPLITS, random_state=48, shuffle=True)\nfor train_idx, test_idx in cv.split(X, y):\n    train_X, val_X = X.iloc[train_idx], X.iloc[test_idx]\n    train_y, val_y = y.iloc[train_idx], y.iloc[test_idx]\n\n    model.fit(\n        train_X, train_y,\n        validation_data=(val_X, val_y),\n        batch_size=BATCH_SIZE,\n        epochs=EPOCHS,\n        callbacks=CALLBACKS,        # Put your callbacks in a list\n        verbose=0)                  # Turn off training log\n\n    predictions = np.argmax(model.predict(val_X), axis=1)\n    score = accuracy_score(val_y, predictions)\n    scores.append(score)\n    print(f\"Fold {fold} \\t\\t Accuracy: {score}\")\n\n    # Get the average values from each fold to the prediction\n    test_predictions = test_predictions + model.predict(test_X)\n    fold += 1\nprint('Overall Accuracy: ', np.mean(scores))"]}, {"cell_type": "markdown", "id": "bdd02030", "metadata": {}, "source": ["# Submission"]}, {"cell_type": "code", "execution_count": 1, "id": "203a4ff8", "metadata": {}, "outputs": [], "source": ["test_predictions = np.argmax(test_predictions, axis=1)\ntest_predictions = encoder.inverse_transform(test_predictions)\noutput = pd.DataFrame({'Id': TEST_ID, 'Cover_Type': test_predictions})\noutput.to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}