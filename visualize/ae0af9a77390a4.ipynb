{"cells": [{"cell_type": "markdown", "id": "84551f78", "metadata": {}, "source": ["# Machine Learning Visualization 3"]}, {"cell_type": "markdown", "id": "6a6c17d9", "metadata": {}, "source": ["## Live Variational Autoencoder (VAE)"]}, {"cell_type": "code", "execution_count": 1, "id": "f21fd3b7", "metadata": {}, "outputs": [], "source": ["!pip install livelossplot"]}, {"cell_type": "code", "execution_count": 1, "id": "82e1b5b5", "metadata": {}, "outputs": [], "source": ["import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nimport numpy as np\nfrom livelossplot import PlotLosses\nimport imageio\nimport glob"]}, {"cell_type": "code", "execution_count": 1, "id": "bbf2e50c", "metadata": {}, "outputs": [], "source": ["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]}, {"cell_type": "code", "execution_count": 1, "id": "231f5f66", "metadata": {}, "outputs": [], "source": ["batch_size, image_dim = 256, 784\nemb_dim, enc_hidden_units = 2, 512\ndec_hidden_units, dec_hidden_units2 = 256, 512"]}, {"cell_type": "markdown", "id": "96779080", "metadata": {}, "source": ["## MNIST"]}, {"cell_type": "code", "execution_count": 1, "id": "248c027c", "metadata": {}, "outputs": [], "source": ["train_set = torchvision.datasets.MNIST(\n    root= './data/MNIST',\n    train= True,\n    download= True,\n    transform= transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Lambda(lambda x: x.view(image_dim))\n    ])\n)\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_set, batch_size = batch_size\n)\n\nvalid_set = torchvision.datasets.MNIST(\n    root= './data/MNIST',\n    train= False,\n    download= True,\n    transform= transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Lambda(lambda x: x.view(image_dim))\n    ])\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    valid_set, batch_size = batch_size\n)"]}, {"cell_type": "code", "execution_count": 1, "id": "5505856d", "metadata": {}, "outputs": [], "source": ["class Encoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n        self.fc3 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = F.relu(out)\n        mu = self.fc2(out)\n        log_sigma = self.fc3(out)\n        return mu, log_sigma\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, hidden_dim, hidden_dim2, input_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(output_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim2)\n        self.fc3 = nn.Linear(hidden_dim2, input_dim)\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = F.relu(out)\n        out = self.fc2(out)\n        out = F.relu(out)\n        out = self.fc3(out)\n        out = out.sigmoid()\n        return out\n    \ndef sampling(mu, log_sigma):\n    eps = torch.randn(mu.shape[0], mu.shape[1])\n    return mu + torch.exp(log_sigma / 2) * eps\n\nclass VAE(nn.Module):\n        def __init__(self, enc, dec):\n            super().__init__()\n            self.enc = enc\n            self.dec = dec\n\n        def forward(self, x):\n            mu, log_sigma = model.enc(inp)\n            z = sampling(mu, log_sigma)\n            out = model.dec(z)\n            return out, z[0], z[1]"]}, {"cell_type": "code", "execution_count": 1, "id": "80df77cf", "metadata": {}, "outputs": [], "source": ["epochs = 8\ndataloaders = {'train': train_loader, 'val': valid_loader}\nenc = Encoder(image_dim, enc_hidden_units, emb_dim)\ndec = Decoder(emb_dim, dec_hidden_units, dec_hidden_units2, image_dim)\nmodel = VAE(enc, dec).to(device)\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\nliveloss = PlotLosses()\n\nfor epoch in range(epochs):\n    logs = {}\n    for phase in ['train', 'val']:\n        losses = []\n        \n        if phase == 'train':\n            model.train()\n        else:\n            model.eval()\n        \n        for i, (inp, _) in enumerate(dataloaders[phase]):\n            out, z_mu, z_var = model(inp)\n            rec = F.binary_cross_entropy(out, inp, reduction='sum') / inp.shape[0]\n            kl = -0.5*torch.mean(1+z_var-z_mu.pow(2)-torch.exp(z_mu))\n            loss = rec + kl\n            losses.append(loss.item())\n        \n            if phase == 'train':\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        prefix = ''\n        if phase == 'val':\n            prefix = 'val_'\n\n        logs[prefix + 'loss'] = np.mean(losses)\n\n    liveloss.update(logs)\n    liveloss.send()"]}, {"cell_type": "code", "execution_count": 1, "id": "f88b822f", "metadata": {}, "outputs": [], "source": ["# Creating a manifold of samples\n\n# Setting number of samples (18*18) and size of images in manifold as default\ndef manifold(model, it='', n=18, size=28): \n    result = torch.zeros((size * n, size * n))\n\n    # Defyining grid space\n    s, s2 = torch.linspace(-7, 7, n), torch.linspace(7, -7, n)\n    grid_x, grid_y = torch.std(s)*s, torch.std(s2)*s2 \n\n    for i, y_ex in enumerate(grid_x):\n        for j, x_ex in enumerate(grid_y):\n            z_sample = torch.repeat_interleave(torch.tensor([[x_ex, y_ex]]), \n                                               repeats=batch_size, dim=0)\n            x_dec = model.dec(z_sample)\n            element = x_dec[0].reshape(size, size).detach()\n            result[i * size: (i + 1) * size, j * size: (j + 1) * size] = element\n\n    plt.figure(figsize=(12, 12))\n    plt.title(\"VAE Samples\", fontsize=20)\n    plt.xlabel(\"X\", fontsize=18)\n    plt.ylabel(\"Y\", fontsize=18)\n    plt.imshow(result, cmap='Greys')\n    plt.savefig('VAE'+str(it)+'.png', format='png', dpi=300)\n    plt.show()  \n    \nmanifold(model)"]}, {"cell_type": "code", "execution_count": 1, "id": "60c559e6", "metadata": {}, "outputs": [], "source": ["def latent_space(model, train_set, it=''):\n    x_latent = model.enc(train_set.data.reshape(-1, 28*28).float())\n    plt.figure(figsize=(10, 7))\n    plt.scatter(x_latent[0][:,0].detach().numpy(), x_latent[1][:,1].detach().numpy(), c=train_set.targets)\n    plt.colorbar()\n    plt.title(\"VAE Latent Space\", fontsize=20)\n    plt.xlabel(\"X\", fontsize=18)\n    plt.ylabel(\"Y\", fontsize=18)\n    plt.savefig('VAE_space'+str(it)+'.png', format='png', dpi=200)\n    plt.show()\n    \nlatent_space(model, train_set)"]}, {"cell_type": "code", "execution_count": 1, "id": "485e755c", "metadata": {}, "outputs": [], "source": ["epochs = 8\ndataloaders = {'train': train_loader, 'val': valid_loader}\nenc = Encoder(image_dim, enc_hidden_units, emb_dim)\ndec = Decoder(emb_dim, dec_hidden_units, dec_hidden_units2, image_dim)\nmodel = VAE(enc, dec).to(device)\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\nliveloss = PlotLosses()\n\nfor epoch in range(epochs):\n    logs = {}\n    for phase in ['train', 'val']:\n        losses = []\n        \n        if phase == 'train':\n            model.train()\n        else:\n            model.eval()\n        \n        for i, (inp, _) in enumerate(dataloaders[phase]):\n            out, z_mu, z_var = model(inp)\n            rec = F.binary_cross_entropy(out, inp, reduction='sum') / inp.shape[0]\n            kl = -0.5*torch.mean(1+z_var-z_mu.pow(2)-torch.exp(z_mu))\n            loss = rec + kl\n            losses.append(loss.item())\n        \n            if phase == 'train':\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n        prefix = ''\n        if phase == 'val':\n            prefix = 'val_'\n            latent_space(model, train_set, epoch)\n            manifold(model, epoch)\n\n        logs[prefix + 'loss'] = np.mean(losses)\n\n    liveloss.update(logs)\n    liveloss.send()"]}, {"cell_type": "code", "execution_count": 1, "id": "f820fc14", "metadata": {}, "outputs": [], "source": ["filenames = glob.glob('./VAE_space*.png')\n\nimages = []\nfor filename in filenames:\n    images.append(imageio.imread(filename))\nkargs = {'duration': 1}\nimageio.mimsave('space.gif', images, **kargs)"]}, {"cell_type": "code", "execution_count": 1, "id": "e756179b", "metadata": {}, "outputs": [], "source": ["filenames = glob.glob('./VAE*.png')\n\nimages = []\nfor filename in filenames:\n    images.append(imageio.imread(filename))\nkargs = {'duration': 1}\nimageio.mimsave('manifold.gif', images, **kargs)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}