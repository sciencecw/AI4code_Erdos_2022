{"cells": [{"cell_type": "code", "execution_count": 1, "id": "f99e9b55", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "dcd18ccf", "metadata": {}, "source": ["# Load dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "844e2dcb", "metadata": {}, "outputs": [], "source": ["gender = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "4e93f2fc", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "id": "1b3acbd9", "metadata": {}, "source": ["# Cleaning data"]}, {"cell_type": "code", "execution_count": 1, "id": "c388c4d8", "metadata": {}, "outputs": [], "source": ["def CLEAN(train):\n    print(train.groupby(train['Age'].isnull()).median())\n\n    print(train.groupby('Pclass')['Age'].describe())\n\n    for i,j in enumerate(train['Age'].isnull()):\n        if train.loc[i,['Pclass']].values ==1:\n            train.loc[i,['Age']] =train.loc[i,['Age']].fillna(38.233441)\n        elif train.loc[i,['Pclass']].values ==2:\n            train.loc[i,['Age']] =train.loc[i,['Age']].fillna(29.877630)\n        else:\n            train.loc[i,['Age']] =train.loc[i,['Age']].fillna(25.140620)\n\n\n    train.groupby(train['Cabin'].isnull()).mean()\n    train['Cabin'] = np.where(train['Cabin'].isnull(),0,1)\n\n    train['title']= train['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip() )\n    li = ['Dr','Master','Miss','Mr','Mrs']\n\n    train['title'] = train['title'].apply(lambda x : x if x in li else 'Other')\n\n    train = train.drop(['Name','Ticket','PassengerId'],axis=1)\n\n    print(train.head())\n\n    from sklearn.preprocessing import LabelEncoder\n    li = ['Sex','Embarked','title']\n\n    train = train.dropna()\n\n    for i in li:\n      train[i] = LabelEncoder().fit_transform(train[i])\n\n    train['family'] = train['SibSp']+train['Parch']\n    train = train.drop(['SibSp','Parch'],axis=1)\n    \n    return train\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "1fd91578", "metadata": {}, "outputs": [], "source": ["train = CLEAN(train)"]}, {"cell_type": "code", "execution_count": 1, "id": "0ab6e1ba", "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "a302fd19", "metadata": {}, "outputs": [], "source": ["support = SVC(kernel='linear',random_state= 42)\nrandom = RandomForestClassifier(random_state=42)"]}, {"cell_type": "code", "execution_count": 1, "id": "c3723a48", "metadata": {}, "outputs": [], "source": ["model = [support,random]"]}, {"cell_type": "code", "execution_count": 1, "id": "f17d321a", "metadata": {}, "outputs": [], "source": ["test = pd.merge(test,gender,on='PassengerId')"]}, {"cell_type": "code", "execution_count": 1, "id": "ebc4fcff", "metadata": {}, "outputs": [], "source": ["feature = train.drop('Survived',axis=1)\nlabel = train['Survived']\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "00709164", "metadata": {}, "outputs": [], "source": ["test = CLEAN(test)"]}, {"cell_type": "code", "execution_count": 1, "id": "9d71578e", "metadata": {}, "outputs": [], "source": ["testf = test.drop('Survived',axis=1)\ntestl = test['Survived']\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "d38b17e1", "metadata": {}, "outputs": [], "source": ["def fitAndScore(feature,label,testf,testl):\n    for i in model:\n        i.fit(feature,label)\n\n    acc = []\n    for i in model:\n        acc.append(i.score(testf,testl))\n    print(acc)"]}, {"cell_type": "code", "execution_count": 1, "id": "d23d53fe", "metadata": {}, "outputs": [], "source": ["from imblearn.combine import SMOTEENN\nos = SMOTEENN(random_state=42)\nfeature,label = os.fit_resample(feature,label)"]}, {"cell_type": "code", "execution_count": 1, "id": "d2c2fb07", "metadata": {}, "outputs": [], "source": ["fitAndScore(feature,label,testf,testl)"]}, {"cell_type": "markdown", "id": "79307ef1", "metadata": {}, "source": ["# Delete outliers"]}, {"cell_type": "code", "execution_count": 1, "id": "81789b6b", "metadata": {}, "outputs": [], "source": ["def remove(data):\n  Q1 = np.percentile(data, 25, interpolation = 'midpoint')\n  \n# Third quartile (Q3)\n  Q3 = np.percentile(data, 75, interpolation = 'midpoint')\n  iqr = Q3 - Q1\n  percentile25 = data.quantile(0.25)\n  percentile75 = data.quantile(0.75)\n\n  upper_limit = percentile75 + 1.5 * iqr\n  lower_limit = percentile25 - 1.5 * iqr\n  data = np.where(\n    data > upper_limit,upper_limit,\n    np.where(\n        data < lower_limit,\n        lower_limit,\n        data\n    )\n  )\n  return data\n\n#train[train['discount_percent'] > upper_limit]\n#train[train['discount_percent'] < lower_limit]\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a715126f", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,10))\nfor i in enumerate(train.columns):\n  plt.subplot(3,5,i[0]+1)\n  sns.boxplot(train[i[1]])\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7cc96e0a", "metadata": {}, "outputs": [], "source": ["for i in ['Age','Fare']:\n    train[i] = remove(train[i])\n    test[i] = remove(test[i])"]}, {"cell_type": "code", "execution_count": 1, "id": "021e2386", "metadata": {}, "outputs": [], "source": ["feature = train.drop('Survived',axis=1)\nlabel = train['Survived']\n\ntestf = test.drop('Survived',axis=1)\ntestl = test['Survived']\n\nfrom imblearn.combine import SMOTEENN\nos = SMOTEENN(random_state=42)\nfeature,label = os.fit_resample(feature,label)"]}, {"cell_type": "code", "execution_count": 1, "id": "6b313a17", "metadata": {}, "outputs": [], "source": ["fitAndScore(feature,label,testf,testl)"]}, {"cell_type": "markdown", "id": "56356287", "metadata": {}, "source": ["# Transform"]}, {"cell_type": "code", "execution_count": 1, "id": "c90483d4", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,10))\nfor i in enumerate(train.columns):\n  plt.subplot(3,4,i[0]+1)\n  sns.distplot(train[i[1]])"]}, {"cell_type": "code", "execution_count": 1, "id": "d6054b04", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,10))\nfor i in enumerate(test.columns):\n  plt.subplot(3,4,i[0]+1)\n  sns.distplot(test[i[1]])"]}, {"cell_type": "code", "execution_count": 1, "id": "be1c0f1a", "metadata": {}, "outputs": [], "source": ["li = ['Age','Fare','family']\nfrom sklearn.preprocessing import  StandardScaler\n\nfor i in li:\n  train[i] = StandardScaler().fit_transform(train[[i]])\n  testf[i] = StandardScaler().fit_transform(testf[[i]])"]}, {"cell_type": "code", "execution_count": 1, "id": "1e0de8c9", "metadata": {}, "outputs": [], "source": ["feature = train.drop('Survived',axis=1)\nlabel = train['Survived']\n\nfrom imblearn.combine import SMOTEENN\nos = SMOTEENN(random_state=42)\nfeature,label = os.fit_resample(feature,label)"]}, {"cell_type": "code", "execution_count": 1, "id": "61aaeb44", "metadata": {}, "outputs": [], "source": ["fitAndScore(feature,label,testf,testl)"]}, {"cell_type": "markdown", "id": "31bed63c", "metadata": {}, "source": ["# GridSearchCV"]}, {"cell_type": "code", "execution_count": 1, "id": "e44375a1", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import GridSearchCV\n\nparams = {\n    'criterion':['gini','entropy'],\n    'n_estimators':[x**2 for x in range(3,10)],\n    'n_jobs':[-1,None],\n    'random_state':[1,42,None],\n    'max_depth': [3,5,None]\n}\n\ncv = GridSearchCV(random,params,cv=5)\ncv.fit(feature,label)\n#print(cv._best_params,cv._best_result)\n\nprint(cv.best_params_,cv.best_score_)\n\nbestmodel = cv.best_estimator_\nbestmodel.score(testf,testl)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}