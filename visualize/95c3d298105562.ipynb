{"cells": [{"cell_type": "markdown", "id": "dc0b884a", "metadata": {}, "source": ["# IBM HR Analytics"]}, {"cell_type": "markdown", "id": "5f638fd6", "metadata": {}, "source": ["## Dataset: [IBM HR Analytics Attrition Dataset](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset)"]}, {"cell_type": "markdown", "id": "5c058787", "metadata": {}, "source": ["### Import all the necessary header files as follows:"]}, {"cell_type": "markdown", "id": "5ef46b01", "metadata": {}, "source": ["**pandas** : An open source library used for data manipulation, cleaning, analysis and visualization. <br>\n**numpy** : A library used to manipulate multi-dimensional data in the form of numpy arrays with useful in-built functions. <br>\n**matplotlib** : A library used for plotting and visualization of data. <br>\n**seaborn** : A library based on matplotlib which is used for plotting of data. <br>\n**sklearn.metrics** : A library used to calculate the accuracy, precision and recall. <br>\n**sklearn.preprocessing** : A library used to encode and onehotencode categorical variables. <br>"]}, {"cell_type": "code", "execution_count": 1, "id": "fcb90ec6", "metadata": {}, "outputs": [], "source": ["# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import metrics"]}, {"cell_type": "markdown", "id": "9e88ba77", "metadata": {}, "source": ["### Read the data from the dataset using the read_csv() function from the pandas library."]}, {"cell_type": "code", "execution_count": 1, "id": "22e98c91", "metadata": {}, "outputs": [], "source": ["# Importing the dataset\ndata = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")"]}, {"cell_type": "markdown", "id": "80a53e97", "metadata": {}, "source": ["### Inspecting and cleaning the data"]}, {"cell_type": "code", "execution_count": 1, "id": "7d7c1f0f", "metadata": {}, "outputs": [], "source": ["# Printing the 1st 5 columns\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "ceea503e", "metadata": {}, "outputs": [], "source": ["# Printing the dimenions of data\ndata.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "2acdbb04", "metadata": {}, "outputs": [], "source": ["# Viewing the column heading\ndata.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "427d2c62", "metadata": {}, "outputs": [], "source": ["# Inspecting the target variable\ndata.Attrition.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "227a39a0", "metadata": {}, "outputs": [], "source": ["data.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "b3fc4de8", "metadata": {}, "outputs": [], "source": ["# Identifying the unique number of values in the dataset\ndata.nunique()"]}, {"cell_type": "code", "execution_count": 1, "id": "b5bd2f11", "metadata": {}, "outputs": [], "source": ["# Checking if any NULL values are present in the dataset\ndata.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "52139c05", "metadata": {}, "outputs": [], "source": ["# See rows with missing values\ndata[data.isnull().any(axis=1)]"]}, {"cell_type": "code", "execution_count": 1, "id": "8f46959d", "metadata": {}, "outputs": [], "source": ["# Viewing the data statistics\ndata.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "c72f5d51", "metadata": {}, "outputs": [], "source": ["# Here the value for columns, Over18, StandardHours and EmployeeCount are same for all rows, we can eliminate these columns\ndata.drop(['EmployeeCount','StandardHours','Over18','EmployeeNumber'],axis=1, inplace=True)"]}, {"cell_type": "markdown", "id": "73d829b3", "metadata": {}, "source": ["### Data Visualization"]}, {"cell_type": "code", "execution_count": 1, "id": "a1de0957", "metadata": {}, "outputs": [], "source": ["# Plotting a boxplot to study the distribution of features\nfig,ax = plt.subplots(1,3, figsize=(20,5))               \nplt.suptitle(\"Distribution of various factors\", fontsize=20)\nsns.boxplot(data['DailyRate'], ax = ax[0]) \nsns.boxplot(data['MonthlyIncome'], ax = ax[1]) \nsns.boxplot(data['DistanceFromHome'], ax = ax[2])  \nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "0ba8c5be", "metadata": {}, "outputs": [], "source": ["# Finding out the correlation between the features\ncorr = data.corr()\ncorr.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "dca138f2", "metadata": {}, "outputs": [], "source": ["# Plotting the heatmap of correlation between features\nplt.figure(figsize=(20,20))\nsns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')"]}, {"cell_type": "code", "execution_count": 1, "id": "1b98cd30", "metadata": {}, "outputs": [], "source": ["# Check for multicollinearity using correlation plot\nf,ax = plt.subplots(figsize=(10,10))\nsns.heatmap(data[['DailyRate','HourlyRate','MonthlyIncome','MonthlyRate']].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "fadacffd", "metadata": {}, "outputs": [], "source": ["# Plotting countplots for the categorical variables\nfig,ax = plt.subplots(2,3, figsize=(20,20))            \nplt.suptitle(\"Distribution of various factors\", fontsize=20)\nsns.countplot(data['Attrition'], ax = ax[0,0]) \nsns.countplot(data['BusinessTravel'], ax = ax[0,1]) \nsns.countplot(data['Department'], ax = ax[0,2]) \nsns.countplot(data['EducationField'], ax = ax[1,0])\nsns.countplot(data['Gender'], ax = ax[1,1])  \nsns.countplot(data['OverTime'], ax = ax[1,2]) \nplt.xticks(rotation=20)\nplt.subplots_adjust(bottom=0.4)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "9dbe37e5", "metadata": {}, "outputs": [], "source": ["# Combine levels in a categorical variable by seeing their distribution\nJobRoleCrossTab = pd.crosstab(data['JobRole'], data['Attrition'], margins=True)\nJobRoleCrossTab"]}, {"cell_type": "code", "execution_count": 1, "id": "b9f0860d", "metadata": {}, "outputs": [], "source": ["JobRoleCrossTab.div(JobRoleCrossTab[\"All\"], axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "f01a2f1f", "metadata": {}, "outputs": [], "source": ["# Combining job roles with high similarities together\ndata['JobRole'].replace(['Human Resources','Laboratory Technician'],value= 'HR-LT',inplace = True)\ndata['JobRole'].replace(['Research Scientist','Sales Executive'],value= 'RS-SE',inplace = True)\ndata['JobRole'].replace(['Healthcare Representative','Manufacturing Director'],value= 'HE-MD',inplace = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "1edfb657", "metadata": {}, "outputs": [], "source": ["# Encoding Yes / No values in Attrition column to 1 / 0\ndata.Attrition.replace([\"Yes\",\"No\"],[1,0],inplace=True)\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "60930199", "metadata": {}, "outputs": [], "source": ["# One hot encoding for categorical variables\nfinal_data = pd.get_dummies(data)\nfinal_data.head().T"]}, {"cell_type": "code", "execution_count": 1, "id": "9236cf27", "metadata": {}, "outputs": [], "source": ["final_data.shape"]}, {"cell_type": "markdown", "id": "610a931e", "metadata": {}, "source": ["#### Once the data is cleaned, we split the data into training set and test set to prepare it for our machine learning model in a suitable proportion."]}, {"cell_type": "code", "execution_count": 1, "id": "ae29b1d8", "metadata": {}, "outputs": [], "source": ["# Spliting target variable and independent variables\nX = final_data.drop(['Attrition'], axis = 1)\ny = final_data['Attrition']"]}, {"cell_type": "code", "execution_count": 1, "id": "a80f63d6", "metadata": {}, "outputs": [], "source": ["# Splitting the data into training set and testset\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 0, stratify=y)"]}, {"cell_type": "code", "execution_count": 1, "id": "ae17e884", "metadata": {}, "outputs": [], "source": ["y_train.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "9285782a", "metadata": {}, "outputs": [], "source": ["# Checking distribtution of Target varaible in training set\ny_train.value_counts()[1]/(y_train.value_counts()[0]+y_train.value_counts()[1])*100"]}, {"cell_type": "code", "execution_count": 1, "id": "c6f3b17c", "metadata": {}, "outputs": [], "source": ["y_test.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "b4467d45", "metadata": {}, "outputs": [], "source": ["# Checking distribtution of Target varaible in test set\ny_test.value_counts()[1]/(y_test.value_counts()[0]+y_test.value_counts()[1])*100"]}, {"cell_type": "markdown", "id": "f856a583", "metadata": {}, "source": ["### Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "7b6638b8", "metadata": {}, "outputs": [], "source": ["# Logistic Regression\n\n# Import library for LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\n\n# Create a Logistic regression classifier\nlogreg = LogisticRegression()\n\n# Train the model using the training sets \nlogreg.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "0771f9df", "metadata": {}, "outputs": [], "source": ["# Prediction on test data\ny_pred = logreg.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "e212e229", "metadata": {}, "outputs": [], "source": ["# Calculating the accuracy, precision and the recall\nacc_logreg = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_logreg )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )"]}, {"cell_type": "code", "execution_count": 1, "id": "5155ba88", "metadata": {}, "outputs": [], "source": ["# Create confusion matrix function to find out sensitivity and specificity\nfrom sklearn.metrics import auc,confusion_matrix\ndef draw_cm(actual, predicted):\n    cm = confusion_matrix( actual, predicted, [1,0]).T\n    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels = [\"Yes\",\"No\"] , yticklabels = [\"Yes\",\"No\"] )\n    plt.ylabel('Predicted')\n    plt.xlabel('Actual')\n    plt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "4b6eaf2d", "metadata": {}, "outputs": [], "source": ["# Confusion matrix \ndraw_cm(y_test, y_pred)"]}, {"cell_type": "markdown", "id": "08da5c78", "metadata": {}, "source": ["### Gaussian Naive Bayes"]}, {"cell_type": "code", "execution_count": 1, "id": "4cf71b41", "metadata": {}, "outputs": [], "source": ["# Gaussian Naive Bayes\n\n# Import library of Gaussian Naive Bayes model\nfrom sklearn.naive_bayes import GaussianNB\n\n# Create a Gaussian Classifier\nmodel = GaussianNB()\n\n# Train the model using the training sets \nmodel.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "fbe4e7d8", "metadata": {}, "outputs": [], "source": ["# Prediction on test set\ny_pred = model.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "aaa670f9", "metadata": {}, "outputs": [], "source": ["# Calculating the accuracy, precision and the recall\nacc_nb = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_nb )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )"]}, {"cell_type": "code", "execution_count": 1, "id": "1de536e0", "metadata": {}, "outputs": [], "source": ["# Confusion matrix \ndraw_cm(y_test, y_pred)"]}, {"cell_type": "markdown", "id": "52cc9aa5", "metadata": {}, "source": ["### Decision Tree Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "93e35b63", "metadata": {}, "outputs": [], "source": ["# Decision Tree Classifier\n\n# Import Decision tree classifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create a Decision tree classifier model\nclf = DecisionTreeClassifier(criterion = \"gini\" , min_samples_split = 100, min_samples_leaf = 10, max_depth = 50)\n\n# Train the model using the training sets \nclf.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "6f2ee64b", "metadata": {}, "outputs": [], "source": ["# Model prediction on train data\ny_pred = clf.predict(X_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "20fad566", "metadata": {}, "outputs": [], "source": ["# Finding the variable with more importance\nfeature_importance = pd.DataFrame([X_train.columns, clf.tree_.compute_feature_importances()])\nfeature_importance = feature_importance.T.sort_values(by = 1, ascending=False)[1:10]"]}, {"cell_type": "code", "execution_count": 1, "id": "fa83366e", "metadata": {}, "outputs": [], "source": ["sns.barplot(x=feature_importance[1], y=feature_importance[0])\n# Add labels to the graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "bb9a0e92", "metadata": {}, "outputs": [], "source": ["# Prediction on test set\ny_pred = clf.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "2c933587", "metadata": {}, "outputs": [], "source": ["# Confusion matrix\ndraw_cm(y_test, y_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "20e8fb18", "metadata": {}, "outputs": [], "source": ["# Calculating the accuracy, precision and the recall\nacc_dt = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_dt )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )"]}, {"cell_type": "markdown", "id": "6f867ab8", "metadata": {}, "source": ["### Random Forest Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "c039504c", "metadata": {}, "outputs": [], "source": ["# Random Forest Classifier\n\n# Import library of RandomForestClassifier model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Create a Random Forest Classifier\nrf = RandomForestClassifier()\n\n# Train the model using the training sets \nrf.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "32e9fdba", "metadata": {}, "outputs": [], "source": ["# Finding the variable with more importance\nfeature_imp = pd.Series(rf.feature_importances_,index= X_train.columns).sort_values(ascending=False)\n# Creating a bar plot\nfeature_imp=feature_imp[0:10,]\nsns.barplot(x=feature_imp, y=feature_imp.index)\n# Add labels to the graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "d5e7aac7", "metadata": {}, "outputs": [], "source": ["# Prediction on test data\ny_pred = rf.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "901aa6cf", "metadata": {}, "outputs": [], "source": ["# Confusion metrix\ndraw_cm(y_test, y_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "b598673e", "metadata": {}, "outputs": [], "source": ["# Calculating the accuracy, precision and the recall\nacc_rf = round( metrics.accuracy_score(y_test, y_pred) * 100 , 2 )\nprint( 'Total Accuracy : ', acc_rf )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100 , 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )"]}, {"cell_type": "markdown", "id": "4fc45044", "metadata": {}, "source": ["### Support Vector Machine Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "c01c0c87", "metadata": {}, "outputs": [], "source": ["# SVM Classifier\n\n# Creating scaled set to be used in model to improve the results\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "4be2b753", "metadata": {}, "outputs": [], "source": ["# Import Library of Support Vector Machine model\nfrom sklearn import svm\n\n# Create a Support Vector Classifier\nsvc = svm.SVC()\n\n# Train the model using the training sets \nsvc.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "3d19cccc", "metadata": {}, "outputs": [], "source": ["# Prediction on test data\ny_pred = svc.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "1ca7afa3", "metadata": {}, "outputs": [], "source": ["# Confusion Matrix\ndraw_cm(y_test, y_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "987c5428", "metadata": {}, "outputs": [], "source": ["# Calculating the accuracy, precision and the recall\nacc_svm = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Total Accuracy : ', acc_svm )\nprint( 'Precision : ', round( metrics.precision_score(y_test, y_pred) * 100, 2 ) )\nprint( 'Recall : ', round( metrics.recall_score(y_test, y_pred) * 100, 2 ) )"]}, {"cell_type": "markdown", "id": "0b2c676d", "metadata": {}, "source": ["## Evaluation and comparision of all the models"]}, {"cell_type": "code", "execution_count": 1, "id": "bfb4dfe6", "metadata": {}, "outputs": [], "source": ["models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines'],\n    'Score': [acc_logreg, acc_nb, acc_dt, acc_rf, acc_svm]})\nmodels.sort_values(by='Score', ascending=False)"]}, {"cell_type": "markdown", "id": "f7f7fdd9", "metadata": {}, "source": ["## Hence we can see that the Logistic Regression works the best for this dataset. "]}, {"cell_type": "markdown", "id": "3110ac08", "metadata": {}, "source": ["### Please upvote if you found this kernel useful! :) <br>\n### Any sort of feedback is appreciated!"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}