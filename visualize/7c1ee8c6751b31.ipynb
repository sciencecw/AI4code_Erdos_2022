{"cells": [{"cell_type": "markdown", "id": "f184de0e", "metadata": {}, "source": ["So what exactly is this assignment? This is a simple classification task with a minor hiccup: how exactly should the inputs be vectorized? \n\nThis will be a public kernel, so feel free to offer suggestions/yell at me if you're reading this"]}, {"cell_type": "code", "execution_count": 1, "id": "8fcb905f", "metadata": {}, "outputs": [], "source": ["#Getting the basic libraries set up\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Machine learning-specific\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom collections import Counter\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\ny_train = pd.read_csv('../input/y_train.csv')\nx_train = pd.read_csv('../input/X_train.csv')\nx_test = pd.read_csv('../input/X_test.csv')\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "41722c89", "metadata": {}, "source": ["First things first, let's get the inputs and outputs set up.\n\nFor outputs, this is a pretty simple use of label encoding.\n\nFor inputs, this implementation crafts a couple of features from each measurement series: mean, stdev, and range. I suspect that the feature selection is the first thing that needs to be improved to make an accurate model, but I'm not entirely sure what else to add"]}, {"cell_type": "code", "execution_count": 1, "id": "0b0fc7f4", "metadata": {}, "outputs": [], "source": ["#Function for setting up training & testing data\ndef processor(input,out_name,num_samples):\n    #Input should be an input csv turned into a data frame\n    #out_name is a string ending in .csvorientations = [\"or_x_mean\",\"or_x_std\",\"or_x_range\",\"or_y_mean\",\"or_y_std\",\"or_y_range\",\"or_z_mean\",\"or_z_std\",\"or_z_range\",\"or_w_mean\",\"or_w_std\",\"or_w_range\"]\n    orientations = [\"or_x_mean\",\"or_x_std\",\"or_x_range\",\"or_y_mean\",\"or_y_std\",\"or_y_range\",\"or_z_mean\",\"or_z_std\",\"or_z_range\",\"or_w_mean\",\"or_w_std\",\"or_w_range\"]\n    ang_vels = [\"an_x_mean\",\"an_x_std\",\"an_x_range\",\"an_y_mean\",\"an_y_std\",\"an_y_range\",\"an_z_mean\",\"an_z_std\",\"an_z_range\"]\n    accels = [\"acc_x_mean\",\"acc_x_std\",\"acc_x_range\",\"acc_y_mean\",\"acc_y_std\",\"acc_y_range\",\"acc_z_mean\",\"acc_z_std\",\"acc_z_range\"]\n    columns = orientations + ang_vels+accels\n    processed = pd.DataFrame(index = range(0,num_samples+1), columns = columns)\n    #What you are about to see is an affront to good code, but I'm not entire sure how to make this manageable\n    for i in range(0,num_samples+1):\n        curr = input.loc[input[\"series_id\"]==i]\n        \n        or_x_mean = np.mean(curr[\"orientation_X\"])\n        processed[\"or_x_mean\"][i] = or_x_mean\n        or_x_std = np.std(curr[\"orientation_X\"])\n        processed[\"or_x_std\"][i] = or_x_std\n        or_x_range = max(curr[\"orientation_X\"])-min(curr[\"orientation_X\"])\n        processed[\"or_x_range\"][i] = or_x_range\n        \n        \n        or_y_mean = np.mean(curr[\"orientation_Y\"])\n        processed[\"or_y_mean\"][i] = or_y_mean\n        or_y_std = np.std(curr[\"orientation_Y\"])\n        processed[\"or_y_std\"][i] = or_y_std\n        or_y_range = max(curr[\"orientation_Y\"])-min(curr[\"orientation_Y\"])\n        processed[\"or_y_range\"][i] = or_y_range\n        \n        or_z_mean = np.mean(curr[\"orientation_Z\"])\n        processed[\"or_z_mean\"][i] = or_z_mean\n        or_z_std = np.std(curr[\"orientation_Z\"])\n        processed[\"or_z_std\"][i] = or_z_std\n        or_z_range = max(curr[\"orientation_Z\"])-min(curr[\"orientation_Z\"])\n        processed[\"or_z_range\"][i] = or_z_range\n        \n        or_w_mean = np.mean(curr[\"orientation_W\"])\n        processed[\"or_w_mean\"][i] = or_z_mean\n        or_w_std = np.std(curr[\"orientation_W\"])\n        processed[\"or_w_std\"][i] = or_z_std\n        or_w_range = max(curr[\"orientation_W\"])-min(curr[\"orientation_W\"])\n        processed[\"or_w_range\"][i] = or_z_range\n        \n        an_x_mean = np.mean(curr[\"angular_velocity_X\"])\n        processed[\"an_x_mean\"][i] = an_x_mean\n        an_x_std = np.std(curr[\"angular_velocity_X\"])\n        processed[\"an_x_std\"][i] = an_x_std\n        an_x_range = max(curr[\"angular_velocity_X\"])-min(curr[\"angular_velocity_X\"])\n        processed[\"an_x_range\"][i] = an_x_range\n        \n        \n        an_y_mean = np.mean(curr[\"angular_velocity_Y\"])\n        processed[\"an_y_mean\"][i] = an_y_mean\n        an_y_std = np.std(curr[\"angular_velocity_Y\"])\n        processed[\"an_y_std\"][i] = an_y_std\n        an_y_range = max(curr[\"angular_velocity_Y\"])-min(curr[\"angular_velocity_Y\"])\n        processed[\"an_y_range\"][i] = an_y_range\n        \n        an_z_mean = np.mean(curr[\"angular_velocity_Z\"])\n        processed[\"an_z_mean\"][i] = an_z_mean\n        an_z_std = np.std(curr[\"angular_velocity_Z\"])\n        processed[\"an_z_std\"][i] = an_z_std\n        an_z_range = max(curr[\"angular_velocity_Z\"])-min(curr[\"angular_velocity_Z\"])\n        processed[\"an_z_range\"][i] = an_z_range\n        \n        acc_x_mean = np.mean(curr[\"linear_acceleration_X\"])\n        processed[\"acc_x_mean\"][i] = acc_x_mean\n        acc_x_std = np.std(curr[\"linear_acceleration_X\"])\n        processed[\"acc_x_std\"][i] = acc_x_std\n        acc_x_range = max(curr[\"linear_acceleration_X\"])-min(curr[\"linear_acceleration_X\"])\n        processed[\"acc_x_range\"][i] = acc_x_range\n        \n        acc_y_mean = np.mean(curr[\"linear_acceleration_Y\"])\n        processed[\"acc_y_mean\"][i] = acc_y_mean\n        acc_y_std = np.std(curr[\"linear_acceleration_Y\"])\n        processed[\"acc_y_std\"][i] = acc_y_std\n        acc_y_range = max(curr[\"linear_acceleration_Y\"])-min(curr[\"linear_acceleration_Y\"])\n        processed[\"acc_y_range\"][i] = acc_y_range\n        \n        acc_z_mean = np.mean(curr[\"linear_acceleration_Z\"])\n        processed[\"acc_z_mean\"][i] = acc_z_mean\n        acc_z_std = np.std(curr[\"linear_acceleration_Z\"])\n        processed[\"acc_z_std\"][i] = acc_z_std\n        acc_z_range = max(curr[\"linear_acceleration_Z\"])-min(curr[\"linear_acceleration_Z\"])\n        processed[\"acc_z_range\"][i] = acc_z_range\n        \n    processed.to_csv(out_name)\n    return processed"]}, {"cell_type": "markdown", "id": "32128176", "metadata": {}, "source": ["Now the first payoff- Building the trainining dataframes"]}, {"cell_type": "code", "execution_count": 1, "id": "f30c1d49", "metadata": {}, "outputs": [], "source": ["train = processor(x_train,'training_processed.csv',3809)\ntest = processor(x_test,'testing_processed.csv',3815)\n\nle = preprocessing.LabelEncoder()\ny_train = le.fit_transform(y_train['surface'])"]}, {"cell_type": "markdown", "id": "f11d0737", "metadata": {}, "source": ["With this taken care of, we can get to building the actual model\nThis is another place where I think improvements can be made in shaping the model. This is my first idea for doing this"]}, {"cell_type": "markdown", "id": "d8de4977", "metadata": {}, "source": ["X = train.values\n\nmodel = keras.Sequential([\n\nkeras.layers.Dense(25, activation=tf.nn.relu),\nkeras.layers.BatchNormalization(), #Absolutely no idea if this will do anything, throwing data science at the wall and seeing what sticks\nkeras.layers.Dense(25, activation=tf.nn.relu),\nkeras.layers.Dense(9, activation=tf.nn.softmax)\n])\n\nstop = keras.callbacks.EarlyStopping(monitor='loss')\ncallbacks = [stop]\n\nmodel.compile(optimizer='adam', \nloss='sparse_categorical_crossentropy',\nmetrics=['accuracy'])\n\n\nmodel.fit(X, y_train, epochs=1000,batch_size = 32)\nmodel.save_weights('attempt.hd5')"]}, {"cell_type": "markdown", "id": "44e7b0eb", "metadata": {}, "source": ["...But what if we did this another way? Time for me to find out what random forests are"]}, {"cell_type": "markdown", "id": "55732cdc", "metadata": {}, "source": ["X = train.values\n\nclf = RandomForestClassifier(n_estimators = 200)\n\nclf.fit(X,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "d55e6a3a", "metadata": {}, "outputs": [], "source": ["#You know what, lets try this XGBoost thing they've been talking about\nmodel = XGBClassifier(n_estimators = 2000)\nX = train.values\nmodel.fit(X,y_train,early_stopping_rounds=5,eval_set = [(X,y_train)]) #Too laxy to split r/n,just seeing if this works\n\n\npredictions = model.predict(test.values)\npredictions = le.inverse_transform(predictions)\n\nindexes = range(0,3816)\ncolumns = [\"series_id\",\"surface\"]\nsubmission = pd.DataFrame(index = indexes, columns = columns)\nsubmission[\"series_id\"]= range(0,3816)\nsubmission[\"surface\"]=predictions\n\nsubmission.to_csv('predictions.csv', index = False)"]}, {"cell_type": "markdown", "id": "5504120d", "metadata": {}, "source": ["Now we apply the model to the test set"]}, {"cell_type": "markdown", "id": "df40ed25", "metadata": {}, "source": ["#This is the predictions using the NN implementation\npredictions = model.predict(test)\nindexes = range(0,3816)\ntrue_predictions = np.zeros((3816,)) #Ask Mike about this one\n\n#convert the number arrays to actual surfaces\nfor i in range(len(predictions)):\n    true_predictions[i]= np.argmax(predictions[i])\n\ntrue_predictions = true_predictions.astype(int)\ntrue_predictions = le.inverse_transform(true_predictions)  \n    \ncolumns = [\"series_id\",\"surface\"]\nsubmission = pd.DataFrame(index = indexes, columns = columns)\n\nsubmission[\"series_id\"]= range(0,3816)\nsubmission[\"surface\"]=true_predictions\n\nsubmission.to_csv('predictions.csv', index = False)"]}, {"cell_type": "markdown", "id": "9bd38e63", "metadata": {}, "source": ["#Random forest implementation\n\npredictions=clf.predict(test.values)\n\npredictions = le.inverse_transform(predictions)\n\nindexes = range(0,3816)\ncolumns = [\"series_id\",\"surface\"]\nsubmission = pd.DataFrame(index = indexes, columns = columns)\nsubmission[\"series_id\"]= range(0,3816)\nsubmission[\"surface\"]=predictions\n\nsubmission.to_csv('predictions.csv', index = False)"]}, {"cell_type": "markdown", "id": "7711ce0d", "metadata": {}, "source": ["#Random forest implementation\n\npredictions=clf.predict(test.values)\n\npredictions = le.inverse_transform(predictions)\n\nindexes = range(0,3816)\ncolumns = [\"series_id\",\"surface\"]\nsubmission = pd.DataFrame(index = indexes, columns = columns)\nsubmission[\"series_id\"]= range(0,3816)\nsubmission[\"surface\"]=predictions\n\nsubmission.to_csv('predictions.csv', index = False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}