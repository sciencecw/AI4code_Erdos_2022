{"cells": [{"cell_type": "markdown", "id": "45a5d29e", "metadata": {}, "source": ["# Objective\n\nThe objective for this dataset is **to build a predictive model** that could best classify and predict if a patient would contract a heart disease based on associated health variables.\n\nWithout further ado, let's explore how we could accomplish the objective."]}, {"cell_type": "markdown", "id": "df05a0f1", "metadata": {}, "source": ["# Import Dependencies/Libraries & Datasets\n\nFirst, we import our dependencies and libraries. I like to put all my libaries in one cell at the start so that I could detect any of the libraries that I'm missing. Of course, I could always go back and run the cell again after I add the necessary missing library.\n\nThen, we add our dataset and save it as a variable in Pandas Dataframe."]}, {"cell_type": "code", "execution_count": 1, "id": "34c70c20", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.neural_network import MLPClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\") ## Telling Python to do not show any warnings for clean throughput"]}, {"cell_type": "code", "execution_count": 1, "id": "da5b330c", "metadata": {}, "outputs": [], "source": ["## Loading csv data to Pandas DataFrame\ndf = pd.read_csv('../input/heart-disease-uci/heart.csv')"]}, {"cell_type": "markdown", "id": "2ee23249", "metadata": {}, "source": ["# Exploratory Data Analysis\n\nNow that we have imported our dataset, let's take a look at a few characteristics of the dataframe, as well as the the insights we could find on the features and target variables."]}, {"cell_type": "code", "execution_count": 1, "id": "1918fa7f", "metadata": {}, "outputs": [], "source": ["df.head(5)"]}, {"cell_type": "code", "execution_count": 1, "id": "0ea6ced4", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "markdown", "id": "aaedaa7c", "metadata": {}, "source": ["We have **13 features** and **one target (0 and 1)** variables, with a total row of **303**. \n\nThere's also **no null values** in all of the columns, with all of the datapoints being integer or float datatypes. It's safe to say that we have a clean and pretty straightfoward dataset."]}, {"cell_type": "markdown", "id": "a099fa7c", "metadata": {}, "source": ["## Finding early insights "]}, {"cell_type": "code", "execution_count": 1, "id": "745c298e", "metadata": {}, "outputs": [], "source": ["df['age'].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "c4e197bb", "metadata": {}, "outputs": [], "source": ["df['sex'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "a9f7f9d1", "metadata": {}, "outputs": [], "source": ["df['target'].value_counts()\n\n## 1 --> Defective heart\n## 0 --> Healthy heart"]}, {"cell_type": "markdown", "id": "5a4421cf", "metadata": {}, "source": ["1. 50% of the patients are at least 55 years old\n2. We have quite an imbalance proportion of male and female patients, with male being about 2 times the number of female patients\n3. Since the distribution of our target variable is about the same AND more than 30 samples, we have a normal standard distribution and thus, we don't need to perform pre-processing steps for our model building"]}, {"cell_type": "markdown", "id": "4795c0be", "metadata": {}, "source": ["## Exploring The Variables"]}, {"cell_type": "code", "execution_count": 1, "id": "745eda15", "metadata": {}, "outputs": [], "source": ["# Assign target column to the variable tar\ntar = df[\"target\"] \n\n# Assign nummerical columns to the variable num (all columns in data DF - target column)\nfeature = list(set(df.columns)-set(tar))"]}, {"cell_type": "code", "execution_count": 1, "id": "834e7476", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(25,25))\nfor i in range(0,len(feature)):\n    plt.subplot(4, 4, i+1)\n    sns.boxplot(y = df[feature[i]], x = df['target'], data=df)"]}, {"cell_type": "markdown", "id": "44fd7ca1", "metadata": {}, "source": ["Given that the datapoints for Patients with No heart disease overlapped with those with a heart disease, we could say that **there is no significant difference** between the two class in all of our feature variables. "]}, {"cell_type": "code", "execution_count": 1, "id": "d28cb7dc", "metadata": {}, "outputs": [], "source": ["# This is a neat and easiest way to visualize the correlation between the variables\n\ncorr_matrix = df.corr()\nplt.figure(figsize=(20,20))\nsns.heatmap(corr_matrix, cmap=\"PiYG\", annot=True, square=False, fmt=\".2g\")\nplt.title(\"Data: Correlations between Variables\")"]}, {"cell_type": "markdown", "id": "8a1acc74", "metadata": {}, "source": ["Note that since we do not have a highly correlated features, **we don't need to perform PCA** as a pre-processing steps in our model building to remove the highly-correlated variables."]}, {"cell_type": "markdown", "id": "db025b91", "metadata": {}, "source": ["# Splitting the Features & Target variables, Scale X and y\n\nNow, we split our features and targets into X and y for our model building process. To make it more interesting, I use StandardScaler() on X_train and X_test to remove the mean and scale each variable to their unit variance. \n\nBecause why not, right? Let's see if we could have a better model with a scaled sets."]}, {"cell_type": "code", "execution_count": 1, "id": "8f5f8076", "metadata": {}, "outputs": [], "source": ["X = df.drop(columns = 'target', axis = 1)\ny = df['target']"]}, {"cell_type": "code", "execution_count": 1, "id": "9c123cfc", "metadata": {}, "outputs": [], "source": ["# Stratify: So that the target class will be evenly distributed to train & test set i.e. not all 0 will be assigned to train/test and vice versa\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)"]}, {"cell_type": "code", "execution_count": 1, "id": "4baa95e4", "metadata": {}, "outputs": [], "source": ["# Let's check the row number of our split sets compared to the original one\n\n(X.shape, X_train.shape, X_test.shape)"]}, {"cell_type": "markdown", "id": "d8904337", "metadata": {}, "source": ["## Scale the X_train & X_test"]}, {"cell_type": "code", "execution_count": 1, "id": "d9a897da", "metadata": {}, "outputs": [], "source": ["## Fit & Transform Standard scaler on X_train & X_test\n\nstd = StandardScaler()\n\nX_train_sc = std.fit(X_train).transform(X_train)\nX_test_sc = std.transform(X_test)"]}, {"cell_type": "markdown", "id": "a7661a7a", "metadata": {}, "source": ["# Model Building: Without Scaler\n\nWe'll use 4 models: kNN, Logistic Regression, Random Forest Classifier, and MultiLayer Perceptron Classifier.\n\nWe'll also use Receiver Operating Characteristics-Area Under Curve (ROC_AUC) as our metric score as it measures **how well predictions** are ranked, rather than the absolute values.\n\nTo simplify the steps in searching for the best parameters for each models, we'll use **GridSearchCV** function to loop through predefined hyperparameters and fit the estimator on the training set.\n\nFor each of the model, we'll also print out the **Classification Report and Confusion Matrix** to see the models' Precision and Recall score on a bird's eye view. "]}, {"cell_type": "markdown", "id": "d4324c1d", "metadata": {}, "source": ["### k-nearest neighbours Classifier (kNN)"]}, {"cell_type": "code", "execution_count": 1, "id": "d3d560a0", "metadata": {}, "outputs": [], "source": ["param_grid_knn = {'n_neighbors': np.arange(1, 20),\n              'p': [1,2],\n              'weights': ['uniform','distance']}\n\ngrid_knn = GridSearchCV(KNeighborsClassifier(), \n                    param_grid_knn, scoring='roc_auc',\n                    cv=5)\n\ngrid_knn.fit(X_train, y_train)\n\nprint(\"KNN Best Parameters: \", grid_knn.best_params_)\n\nmodel_knn = grid_knn.best_estimator_\nprint(\"KNN Best Score: \", grid_knn.best_score_)\n\nmodel_knn.fit(X_train, y_train)\ny_pred_knn = model_knn.predict(X_test)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_knn))\nconfusion_matrix(y_test, y_pred_knn)"]}, {"cell_type": "markdown", "id": "073eb0bf", "metadata": {}, "source": ["Whoa! Note the 75% of the score given by this kNN model"]}, {"cell_type": "markdown", "id": "a783ab43", "metadata": {}, "source": ["### Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "9954e9a3", "metadata": {}, "outputs": [], "source": ["param_grid_lr = {'C': [0.001,0.01,0.1,1,10,100],\n             'penalty': ['none','l2'],\n             'fit_intercept':[True,False],\n                'solver':['newton-cg','lbfgs','sag','saga']}\n\ngrid_lr = GridSearchCV(LogisticRegression(), \n                    param_grid_lr, scoring='roc_auc',\n                    cv=5)\n\ngrid_lr.fit(X_train, y_train)\n\nprint(\"LR Best Parameters: \", grid_lr.best_params_)\n\nmodel_lr = grid_lr.best_estimator_\nprint(\"LR Best Score: \", grid_lr.best_score_)\n\nmodel_lr.fit(X_train, y_train)\ny_pred_lr = model_lr.predict(X_test)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_lr))\nconfusion_matrix(y_test, y_pred_lr)"]}, {"cell_type": "markdown", "id": "45cdc956", "metadata": {}, "source": ["### Random Forest"]}, {"cell_type": "code", "execution_count": 1, "id": "cb084fd5", "metadata": {}, "outputs": [], "source": ["param_grid_rf = {'max_depth': np.arange(1, 20),\n                'n_estimators':[1,10,20,50,100]}\n\ngrid_rf = GridSearchCV(RandomForestClassifier(), \n                    param_grid_rf, scoring='roc_auc',\n                    cv=5)\n\ngrid_rf.fit(X_train, y_train)\n\nprint(\"RF Best Parameters: \", grid_rf.best_params_)\n\nmodel_rf = grid_rf.best_estimator_\nprint(\"RF Best Score: \", grid_rf.best_score_)\n\nmodel_rf.fit(X_train,y_train)\ny_pred_rf = model_rf.predict(X_test)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_rf))\nconfusion_matrix(y_test, y_pred_rf)"]}, {"cell_type": "markdown", "id": "8acea61f", "metadata": {}, "source": ["### MultiLayer Perceptron"]}, {"cell_type": "code", "execution_count": 1, "id": "b610f00a", "metadata": {}, "outputs": [], "source": ["param_grid_mlp = {'hidden_layer_sizes': [(20),(20,20),(20,20,20)],\n    'activation': ['logistic', 'relu'],\n    'solver': ['adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive']}\n\ngrid_mlp = GridSearchCV(MLPClassifier(),\n                        param_grid_mlp,\n                        scoring='roc_auc',\n                        cv=5)\n\ngrid_mlp.fit(X_train, y_train)\n\nprint(\"MLP Best Parameters: \", grid_mlp.best_params_)\n\nmodel_mlp = grid_mlp.best_estimator_\nprint(\"MLP Best Score: \", grid_mlp.best_score_)\n\nmodel_mlp.fit(X_train,y_train)\ny_pred_mlp = model_mlp.predict(X_test)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_mlp))\nconfusion_matrix(y_test, y_pred_mlp)"]}, {"cell_type": "markdown", "id": "38556711", "metadata": {}, "source": ["# Model Training: With StandardScaler()"]}, {"cell_type": "markdown", "id": "093bdafd", "metadata": {}, "source": ["### k-nearest neighbour (kNN)"]}, {"cell_type": "code", "execution_count": 1, "id": "01b4e269", "metadata": {}, "outputs": [], "source": ["param_grid_knn_sc = {'n_neighbors': np.arange(1, 20),\n              'p': [1,2],\n              'weights': ['uniform','distance']}\n\ngrid_knn_sc = GridSearchCV(KNeighborsClassifier(), \n                    param_grid_knn_sc, scoring='roc_auc',\n                    cv=5)\n\ngrid_knn_sc.fit(X_train_sc, y_train)\n\nprint(\"KNN Best Parameters: \", grid_knn_sc.best_params_)\n\nmodel_knn_sc = grid_knn_sc.best_estimator_\nprint(\"KNN Best Score: \", grid_knn_sc.best_score_)\n\nmodel_knn_sc.fit(X_train_sc,y_train)\ny_pred_knn_sc = model_knn_sc.predict(X_test_sc)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_knn_sc))\nconfusion_matrix(y_test, y_pred_knn_sc)"]}, {"cell_type": "markdown", "id": "f26301cb", "metadata": {}, "source": ["Hey! Looks like our kNN model's score **improves** when we use Scaled set."]}, {"cell_type": "markdown", "id": "6aef8d01", "metadata": {}, "source": ["### Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "b671e57b", "metadata": {}, "outputs": [], "source": ["param_grid_lr_sc = {'C': [0.001,0.01,0.1,1,10,100],\n             'penalty': ['none','l2'],\n             'fit_intercept':[True,False],\n                'solver':['newton-cg','lbfgs','sag','saga']}\n\ngrid_lr_sc = GridSearchCV(LogisticRegression(), \n                    param_grid_lr_sc, scoring='roc_auc',\n                    cv=5)\n\ngrid_lr_sc.fit(X_train_sc, y_train)\n\nprint(\"LR Best Parameters: \", grid_lr_sc.best_params_)\n\nmodel_lr_sc = grid_lr_sc.best_estimator_\nprint(\"LR Best Score: \", grid_lr_sc.best_score_)\n\nmodel_lr_sc.fit(X_train_sc,y_train)\ny_pred_lr_sc = model_lr_sc.predict(X_test_sc)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_lr_sc))\nconfusion_matrix(y_test, y_pred_lr_sc)"]}, {"cell_type": "markdown", "id": "47190f48", "metadata": {}, "source": ["### Random Forest"]}, {"cell_type": "code", "execution_count": 1, "id": "badf09e2", "metadata": {}, "outputs": [], "source": ["param_grid_rf_sc_sc = {'max_depth': np.arange(1, 20),\n                'n_estimators':[1,10,20,50,100]}\n\ngrid_rf_sc = GridSearchCV(RandomForestClassifier(), \n                    param_grid_rf_sc_sc, scoring='roc_auc',\n                    cv=5)\n\ngrid_rf_sc.fit(X_train_sc, y_train)\n\nprint(\"RF Best Parameters: \", grid_rf_sc.best_params_)\n\nmodel_rf_sc = grid_rf_sc.best_estimator_\nprint(\"RF Best Score: \", grid_rf_sc.best_score_)\n\nmodel_rf_sc.fit(X_train_sc,y_train)\ny_pred_rf_sc = model_rf_sc.predict(X_test_sc)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_rf_sc))\nconfusion_matrix(y_test, y_pred_rf_sc)"]}, {"cell_type": "markdown", "id": "4d8b3112", "metadata": {}, "source": ["### MultiLayer Perceptron"]}, {"cell_type": "code", "execution_count": 1, "id": "2ccec2b4", "metadata": {}, "outputs": [], "source": ["param_grid_mlp_sc_sc = {'hidden_layer_sizes': [(20),(20,20),(20,20,20)],\n    'activation': ['logistic', 'relu'],\n    'solver': ['adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive']}\n\ngrid_mlp_sc = GridSearchCV(MLPClassifier(),\n                        param_grid_mlp_sc_sc,\n                        scoring='roc_auc',\n                        cv=5)\n\ngrid_mlp_sc.fit(X_train_sc, y_train)\n\nprint(\"MLP Best Parameters: \", grid_mlp_sc.best_params_)\n\nmodel_mlp_sc = grid_mlp_sc.best_estimator_\nprint(\"MLP Best Score: \", grid_mlp_sc.best_score_)\n\nmodel_mlp_sc.fit(X_train_sc,y_train)\ny_pred_mlp_sc = model_mlp_sc.predict(X_test_sc)\n\nprint('classification_report:\\n',classification_report(y_test, y_pred_mlp_sc))\nconfusion_matrix(y_test, y_pred_mlp_sc)"]}, {"cell_type": "markdown", "id": "9f9f945d", "metadata": {}, "source": ["Note that when we use the Scaled set, the models' scores are either enhanced or stay about the same. No harm done, right :)"]}, {"cell_type": "markdown", "id": "a855aac5", "metadata": {}, "source": ["# Conclusion\n\n**Best Model:** Random Forest without StandardScaler\n\n**Reason:**\n* We have an **excellent roc_auc score**. Our model is able to distinguish the patients with heart disease and those who don\u2019t above 90% of the time.\n\n* We have **a higher Precision & Recall score** amongst all our models, which means if we choose those scores as our metrics, Random Forest will generate a better score overall.\n\n* The **misclassified portions** (False Negative and False Positive) of datapoints in Random Forest without Scaling in the Classification Matrix is **lower than the others**. In regard to disease classification, we would want to try and avoid a misclassification as much as we could.\n\n* The model gives out the **highest True Positive and True Negative portions** amongst all the models. Back to our objective, this model would be the best to classify and predict patients with a heart disease and those that truly do not have a heart disease."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}