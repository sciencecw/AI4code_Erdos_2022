{"cells": [{"cell_type": "markdown", "id": "44de5679", "metadata": {}, "source": ["## My previous works:\n\n1. https://www.kaggle.com/ivangavrilove88/acc-0-94\n2. https://www.kaggle.com/ivangavrilove88/bin-acc-0-96\n\n\n## What I have improved:\n\n1. Changed quality metrics\n2. Fixed date imbalance\n2. Grid Search"]}, {"cell_type": "markdown", "id": "1be8abee", "metadata": {}, "source": ["# Import Libs"]}, {"cell_type": "code", "execution_count": 1, "id": "2fdf7789", "metadata": {}, "outputs": [], "source": ["# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport missingno as msno\nimport pandas_profiling as pdp\n\n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)\n\n#import the necessary modelling algos.\n\n#classifiaction.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb\nfrom sklearn.ensemble import AdaBoostClassifier\n\n#model selection\nfrom sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n#preprocessing\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n\n#evaluation metrics\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score"]}, {"cell_type": "markdown", "id": "f76a557d", "metadata": {}, "source": ["# Data loading and overview"]}, {"cell_type": "code", "execution_count": 1, "id": "1a0ffa53", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('../input/fetal-health-classification/fetal_health.csv')\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "b52de967", "metadata": {}, "outputs": [], "source": ["df.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "1c7a5b11", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "be9f2844", "metadata": {}, "outputs": [], "source": ["df.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "ccbd74f3", "metadata": {}, "outputs": [], "source": ["sns.countplot(data = df, x = 'fetal_health')"]}, {"cell_type": "markdown", "id": "be707f71", "metadata": {}, "source": ["### Dividing fetal_health as normally and carefully for binary classification"]}, {"cell_type": "code", "execution_count": 1, "id": "66a8a9d9", "metadata": {}, "outputs": [], "source": ["bins = (0, 1.0, 3.0)\nbin_names = ['Normally', 'Carefully']\ndf['fetal_health'] = pd.cut(df['fetal_health'], bins = bins, labels = bin_names)"]}, {"cell_type": "code", "execution_count": 1, "id": "fb18b91d", "metadata": {}, "outputs": [], "source": ["\nsns.countplot(data = df, x = 'fetal_health')"]}, {"cell_type": "code", "execution_count": 1, "id": "de148a77", "metadata": {}, "outputs": [], "source": ["replace_values = {'Normally': 0,\n                 'Carefully': 1}\n\ndf = df.replace({'fetal_health': replace_values})"]}, {"cell_type": "code", "execution_count": 1, "id": "c4f617b7", "metadata": {}, "outputs": [], "source": ["X = df.drop('fetal_health', axis = 1)\ny = df.fetal_health"]}, {"cell_type": "markdown", "id": "522288c1", "metadata": {}, "source": ["# OverSampling"]}, {"cell_type": "code", "execution_count": 1, "id": "a42febf6", "metadata": {}, "outputs": [], "source": ["from imblearn.over_sampling import SMOTE\n\nsm = SMOTE()\nX_res, y_res = sm.fit_resample(X, y)\n\nprint(\"Before OverSampling, counts of label '1': {}\".format(sum(y==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y==0)))\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_res==0)))"]}, {"cell_type": "code", "execution_count": 1, "id": "54fc2155", "metadata": {}, "outputs": [], "source": ["sns.countplot(x = y_res, data = df)"]}, {"cell_type": "markdown", "id": "57d553b4", "metadata": {}, "source": ["# Modeling"]}, {"cell_type": "code", "execution_count": 1, "id": "ba065b20", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, random_state = 42)"]}, {"cell_type": "markdown", "id": "f0e00d31", "metadata": {}, "source": ["## Decision Tree"]}, {"cell_type": "code", "execution_count": 1, "id": "acca2675", "metadata": {}, "outputs": [], "source": ["%%time\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\ndtc_pred = dtc.predict(X_test)\nprint(confusion_matrix(dtc_pred, y_test))\nprint('-----')\nprint(classification_report(dtc_pred, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "2626d796", "metadata": {}, "outputs": [], "source": ["%%time\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint(confusion_matrix(rf_pred, y_test))\nprint('-----')\nprint(classification_report(rf_pred, y_test))"]}, {"cell_type": "markdown", "id": "a4996ff1", "metadata": {}, "source": ["## Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "a766cddc", "metadata": {}, "outputs": [], "source": ["lr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)\nprint(confusion_matrix(lr_pred, y_test))\nprint('-----')\nprint(classification_report(lr_pred, y_test))"]}, {"cell_type": "markdown", "id": "49f1eae1", "metadata": {}, "source": ["## SVC"]}, {"cell_type": "code", "execution_count": 1, "id": "8edafa94", "metadata": {}, "outputs": [], "source": ["svc = SVC()\nsvc.fit(X_train, y_train)\nsvc_pred = svc.predict(X_test)\nprint(confusion_matrix(svc_pred, y_test))\nprint('-----')\nprint(classification_report(svc_pred, y_test))"]}, {"cell_type": "markdown", "id": "49579c89", "metadata": {}, "source": ["## KNN"]}, {"cell_type": "code", "execution_count": 1, "id": "84e901d2", "metadata": {}, "outputs": [], "source": ["knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nprint(confusion_matrix(knn_pred, y_test))\nprint('-----')\nprint(classification_report(knn_pred, y_test))"]}, {"cell_type": "markdown", "id": "e928e2a0", "metadata": {}, "source": ["# Grid Search"]}, {"cell_type": "code", "execution_count": 1, "id": "6abafbdd", "metadata": {}, "outputs": [], "source": ["cross_valid_scores = {}"]}, {"cell_type": "markdown", "id": "ee13d5ca", "metadata": {}, "source": ["## Decision Tree"]}, {"cell_type": "code", "execution_count": 1, "id": "cabba17c", "metadata": {}, "outputs": [], "source": ["%%time\nparameters = {\n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_dtc = DecisionTreeClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_dtc = GridSearchCV(\n    model_dtc, \n    parameters, \n    cv=5,\n)\n\nmodel_dtc.fit(X_train, y_train)\nmodel_dtc_pred = model_dtc.predict(X_test)\nprint(classification_report(model_dtc_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_dtc.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \\\n    f'{model_dtc.best_score_:.3f}'\n)\ncross_valid_scores['desicion_tree'] = model_dtc.best_score_\nprint('-----')"]}, {"cell_type": "markdown", "id": "8cfa62bf", "metadata": {}, "source": ["## Random Forest"]}, {"cell_type": "code", "execution_count": 1, "id": "a6f95c90", "metadata": {}, "outputs": [], "source": ["%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25], \n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_rf = RandomForestClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_rf = GridSearchCV(\n    model_rf, \n    parameters, \n    cv=5,\n)\n\nmodel_rf.fit(X_train, y_train)\nmodel_rf_pred = model_rf.predict(X_test)\nprint(classification_report(model_rf_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_rf.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_rf.best_score_:.3f}'\n)\ncross_valid_scores['random_forest'] = model_rf.best_score_\nprint('-----')"]}, {"cell_type": "markdown", "id": "ea4482a9", "metadata": {}, "source": ["## XGBoost"]}, {"cell_type": "code", "execution_count": 1, "id": "5d88de7e", "metadata": {}, "outputs": [], "source": ["%%time\nparameters = {\n    'max_depth': [3, 5, 7, 9], \n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\n\nmodel_xgb = xgb.XGBClassifier(\n    random_state=42, verbosity = 0\n)\n\nmodel_xgb = GridSearchCV(\n    model_xgb, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_xgb.fit(X_train, y_train)\nmodel_xgb_pred = model_xgb.predict(X_test)\nprint(classification_report(model_xgb_pred, y_test))\n\n\nprint('-----')\nprint(f'Best parameters {model_xgb.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_xgb.best_score_:.3f}'\n)\ncross_valid_scores['xgboost'] = model_xgb.best_score_\nprint('-----')"]}, {"cell_type": "markdown", "id": "47dcf849", "metadata": {}, "source": ["## LightGBM"]}, {"cell_type": "code", "execution_count": 1, "id": "c75b810a", "metadata": {}, "outputs": [], "source": ["%%time\nparameters = {\n    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'num_leaves': [7, 15, 31],\n}\n\nmodel_lgbm = lgbm.LGBMClassifier(\n    random_state=42,\n    class_weight='balanced',\n)\n\nmodel_lgbm = GridSearchCV(\n    model_lgbm, \n    parameters, \n    cv=5)\n\nmodel_lgbm.fit(X_train, y_train)\nmodel_lgbm_pred = model_lgbm.predict(X_test)\nprint(classification_report(model_lgbm_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_lgbm.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_lgbm.best_score_:.3f}'\n)\ncross_valid_scores['lightgbm'] = model_lgbm.best_score_\nprint('-----')"]}, {"cell_type": "markdown", "id": "311b3280", "metadata": {}, "source": ["## Adaboost"]}, {"cell_type": "code", "execution_count": 1, "id": "6bef4ab0", "metadata": {}, "outputs": [], "source": ["%%time\nparameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25, 50, 75, 100], \n    \"learning_rate\": [0.001, 0.01, 0.1, 1.],\n}\n\nmodel_adaboost = AdaBoostClassifier(\n    random_state=42,\n)\n\nmodel_adaboost = GridSearchCV(\n    model_adaboost, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_adaboost.fit(X_train, y_train)\nmodel_adaboost_pred = model_adaboost.predict(X_test)\nprint(classification_report(model_adaboost_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_adaboost.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: '+ \\\n    f'{model_adaboost.best_score_:.3f}'\n)\ncross_valid_scores['ada_boost'] = model_adaboost.best_score_\nprint('-----')"]}, {"cell_type": "markdown", "id": "1df4944d", "metadata": {}, "source": ["## Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "4ba89bd8", "metadata": {}, "outputs": [], "source": ["%%time\nparameters = {\n    \"C\": [0.001, 0.01, 0.1, 1.],\n    \"penalty\": [\"l1\", \"l2\"]\n}\n\nmodel_lr = LogisticRegression(\n    random_state=42,\n    class_weight=\"balanced\",\n    solver=\"liblinear\",\n)\n\nmodel_lr = GridSearchCV(\n    model_lr, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_lr.fit(X_train, y_train)\nmodel_lr_pred = model_lr.predict(X_test)\nprint(classification_report(model_lr_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_lr.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_lr.best_score_:.3f}'\n)\ncross_valid_scores['logistic_regression'] = model_lr.best_score_\nprint('-----')"]}, {"cell_type": "markdown", "id": "61a40808", "metadata": {}, "source": ["## KNN"]}, {"cell_type": "code", "execution_count": 1, "id": "c44af65d", "metadata": {}, "outputs": [], "source": ["%%time\nparameters = {\n    \"weights\": [\"uniform\", \"distance\"],\n}\n\nmodel_k_neighbors = KNeighborsClassifier(\n)\n\nmodel_k_neighbors = GridSearchCV(\n    model_k_neighbors, \n    parameters, \n    cv=5,\n    scoring='accuracy',\n)\n\nmodel_k_neighbors.fit(X_train, y_train)\nmodel_k_neighbors_pred = model_k_neighbors.predict(X_test)\nprint(classification_report(model_k_neighbors_pred, y_test))\n\nprint('-----')\nprint(f'Best parameters {model_k_neighbors.best_params_}')\nprint(\n    f'Mean cross-validated accuracy score of the best_estimator: ' + \n    f'{model_k_neighbors.best_score_:.3f}'\n)\ncross_valid_scores['k_neighbors'] = model_k_neighbors.best_score_\nprint('-----')"]}, {"cell_type": "markdown", "id": "7fc19537", "metadata": {}, "source": ["# Thanks for watching!\n\n# If you liked my work then upvoted of write your opinion"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}