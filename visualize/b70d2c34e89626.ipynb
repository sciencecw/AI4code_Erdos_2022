{"cells": [{"cell_type": "markdown", "id": "a97ff30a", "metadata": {}, "source": ["# ChAII Starter Code: EDA + Baseline\nMy first proper competition with text and QnA. The plan you ask? ... well its simple \n<img src=\"https://media.giphy.com/media/l3V0x0469o9iWA2He/giphy.gif\">\n- Learn along the way\n- Getting better at EDA\n- Explore different tricks in the Text/NLP domain\n- Train some fancy models (well, why not :D)\n- Try to get a decent leaderboard finish (nothing fancy, haven't participated actively in any competition so far)"]}, {"cell_type": "markdown", "id": "0a694486", "metadata": {}, "source": ["## It's Raining Imports here!!!"]}, {"cell_type": "code", "execution_count": 1, "id": "fea591e7", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n"]}, {"cell_type": "markdown", "id": "087644e7", "metadata": {}, "source": ["## Loading The Data"]}, {"cell_type": "code", "execution_count": 1, "id": "24a80b09", "metadata": {}, "outputs": [], "source": ["df_train = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/train.csv')\ndf_test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\ndf_sub = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/sample_submission.csv')"]}, {"cell_type": "markdown", "id": "1042f98d", "metadata": {}, "source": ["## Let us get to the Exploration, Shall we?\n<img src=\"https://media.giphy.com/media/xT9C25UNTwfZuk85WP/giphy.gif\" width=\"500\" class=\"center\">"]}, {"cell_type": "code", "execution_count": 1, "id": "50a99b49", "metadata": {}, "outputs": [], "source": ["df_train.head(15)"]}, {"cell_type": "code", "execution_count": 1, "id": "77afffbb", "metadata": {}, "outputs": [], "source": ["print(f\"Total samples in train set: {len(df_train)}\")\nprint(f\"Total samples in test set: {len(df_test)}\")\nprint(f\"Total samples for submission: {len(df_sub)}\")"]}, {"cell_type": "code", "execution_count": 1, "id": "908cbc1c", "metadata": {}, "outputs": [], "source": ["df_train.info()"]}, {"cell_type": "markdown", "id": "f8ccb57e", "metadata": {}, "source": ["## Language metrics"]}, {"cell_type": "code", "execution_count": 1, "id": "03358920", "metadata": {}, "outputs": [], "source": ["# Train Language splits\nprint(\"LANGUAGE SPLIT FOR TRAIN SET\")\nprint(df_train['language'].value_counts())\nprint(\"\\n\")\n# Test Language Split\nprint(\"LANGUAGE SPLIT FOR TEST SET\")\nprint(df_test['language'].value_counts())\n"]}, {"cell_type": "code", "execution_count": 1, "id": "59586149", "metadata": {}, "outputs": [], "source": ["# For Train Set\ndf_train['language'].value_counts().plot.bar()\nplt.title('Train Language Split')"]}, {"cell_type": "markdown", "id": "0f0982c3", "metadata": {}, "source": ["## Language-wise Word and Character plots"]}, {"cell_type": "code", "execution_count": 1, "id": "b1712a7d", "metadata": {}, "outputs": [], "source": ["# spliting the dataframe into language specific dataframes\ndf_train_hindi = df_train[df_train['language']=='hindi']\ndf_train_tamil = df_train[df_train['language']=='tamil']"]}, {"cell_type": "markdown", "id": "73359b84", "metadata": {}, "source": ["### Question Word Length"]}, {"cell_type": "code", "execution_count": 1, "id": "5d7986e1", "metadata": {}, "outputs": [], "source": ["# For Hindi\ndf_train_hindi['question'].apply(lambda x: len(x.split())).plot(kind='hist')\nplt.title('Question Word Count for Hindi')"]}, {"cell_type": "code", "execution_count": 1, "id": "ccb9d7a4", "metadata": {}, "outputs": [], "source": ["# For Tamil\ndf_train_tamil['question'].apply(lambda x: len(x.split())).plot(kind='hist')\nplt.title('Question Word Count for Tamil')"]}, {"cell_type": "markdown", "id": "89d7ffa1", "metadata": {}, "source": ["### Question Char Length"]}, {"cell_type": "code", "execution_count": 1, "id": "bfc06ab5", "metadata": {}, "outputs": [], "source": ["# For Hindi\ndf_train_hindi['question'].apply(lambda x: len(x)).plot(kind='hist')\nplt.title('Question Char Count for Hindi')"]}, {"cell_type": "code", "execution_count": 1, "id": "2a6440b8", "metadata": {}, "outputs": [], "source": ["# For Tamil\ndf_train_tamil['question'].apply(lambda x: len(x)).plot(kind='hist')\nplt.title('Question Char Count for Tamil')"]}, {"cell_type": "markdown", "id": "3ad474a9", "metadata": {}, "source": ["### Context Word Length"]}, {"cell_type": "code", "execution_count": 1, "id": "e59a24fa", "metadata": {}, "outputs": [], "source": ["# For Hindi\ndf_train_hindi['context'].apply(lambda x: len(x.split())).plot(kind='hist')\nplt.title('Context Word Count for Hindi')"]}, {"cell_type": "code", "execution_count": 1, "id": "469585a5", "metadata": {}, "outputs": [], "source": ["# For Tamil\ndf_train_tamil['context'].apply(lambda x: len(x.split())).plot(kind='hist')\nplt.title('Context Word Count for Tamil')"]}, {"cell_type": "markdown", "id": "3778ddff", "metadata": {}, "source": ["### Context Char Length"]}, {"cell_type": "code", "execution_count": 1, "id": "604d7bfc", "metadata": {}, "outputs": [], "source": ["# For Hindi\ndf_train_hindi['context'].apply(lambda x: len(x)).plot(kind='hist')\nplt.xscale('log')\nplt.title('Context Char count for Hindi')\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3b0e8ac7", "metadata": {}, "outputs": [], "source": ["# For Tamil\ndf_train_tamil['context'].apply(lambda x: len(x)).plot(kind='hist')\nplt.xscale('log')\nplt.title('Context Char count for Tamil')\n"]}, {"cell_type": "markdown", "id": "d45dc247", "metadata": {}, "source": ["## Full Train Set Level Stats for Words and Characters"]}, {"cell_type": "markdown", "id": "8f0056cc", "metadata": {}, "source": ["### Word and Char stats for Questions"]}, {"cell_type": "code", "execution_count": 1, "id": "71f68781", "metadata": {}, "outputs": [], "source": ["# For Full Train Set Question : Word Level\ndf_train['question'].apply(lambda x: len(x.split())).plot(kind='hist')\nplt.title('Question word count in words for Full Train Set')"]}, {"cell_type": "code", "execution_count": 1, "id": "0452babc", "metadata": {}, "outputs": [], "source": ["# For Full Train Set Question : Char level\ndf_train['question'].apply(lambda x: len(x)).plot(kind='hist')\nplt.title('Question Char count for Full Train Set')"]}, {"cell_type": "markdown", "id": "ea0dbb63", "metadata": {}, "source": ["### Words and Char Stats for Context"]}, {"cell_type": "code", "execution_count": 1, "id": "4f6fb1b1", "metadata": {}, "outputs": [], "source": ["# For Full Set Train Context : Word Level\ndf_train['context'].apply(lambda x: len(x.split())).plot(kind='hist')\nplt.title('Context word count for Full Train Set')"]}, {"cell_type": "code", "execution_count": 1, "id": "352ab538", "metadata": {}, "outputs": [], "source": ["# For Full Set Train Context : Char level\ndf_train['context'].apply(lambda x: len(x)).plot(kind='hist')\nplt.xscale('log')\nplt.title('Context char count for Full Train Set')"]}, {"cell_type": "markdown", "id": "9e5fa978", "metadata": {}, "source": ["**More EDA in upcoming versions, this seems to be okay for now**"]}, {"cell_type": "markdown", "id": "eee3b3cc", "metadata": {}, "source": ["# Baseline Model"]}, {"cell_type": "markdown", "id": "c365d495", "metadata": {}, "source": ["Since this is the very first version, we will keep it simple and evolve it as the competition proceeds.\n\nFor now Sticking to the pipeline from the transformers library and later will enhance the solution. This mean unfortunately no finetuning or training in this one lads.\n\n<img src=\"https://media.giphy.com/media/7CiWMPL8IZFwq0DLxy/giphy-downsized.gif\">"]}, {"cell_type": "code", "execution_count": 1, "id": "9b68e15b", "metadata": {}, "outputs": [], "source": ["from transformers import pipeline"]}, {"cell_type": "code", "execution_count": 1, "id": "400dbf00", "metadata": {}, "outputs": [], "source": ["model_name = \"../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2\"\nbatch_size = 16"]}, {"cell_type": "code", "execution_count": 1, "id": "a0db83d2", "metadata": {}, "outputs": [], "source": ["pip1 = pipeline('question-answering', model=model_name, tokenizer=model_name, device=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "165eaf33", "metadata": {}, "outputs": [], "source": ["predictions = []\nfor que,cont in df_test[['question','context']].to_numpy():\n    ans = pip1(context=cont, question=que)\n    print(ans)\n    predictions.append(ans['answer'])"]}, {"cell_type": "code", "execution_count": 1, "id": "4b305039", "metadata": {}, "outputs": [], "source": ["submission_df = pd.DataFrame(data={\"id\": df_test[\"id\"], \"PredictionString\": predictions})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)\n\nsubmission_df"]}, {"cell_type": "markdown", "id": "b2c65f38", "metadata": {}, "source": ["So For the baseline using transformers pipeline, In the future iterations of the kernel we have the following targets:\n- Advanced EDA\n- Beating the above baseline\n\n<img src=\"https://media.giphy.com/media/u5BzptR1OTZ04/giphy.gif\" width='500'>"]}, {"cell_type": "markdown", "id": "e3a01e6a", "metadata": {}, "source": ["Watch this space for more updates, lets see how it goes.\n\n**If you like it so far, consider upvoting \ud83d\ude04** \n\n<img src=\"https://media.giphy.com/media/eunrMjB8lBUKeL1fqD/giphy-downsized.gif\">"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}