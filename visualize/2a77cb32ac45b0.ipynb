{"cells": [{"cell_type": "markdown", "id": "b6c8c9f0", "metadata": {}, "source": ["# Find keywords using Word2Vec\n\nThis notebook shows how to learn word vectors from the corpus and then identify keywords based on nearest neighbors.\n\n## Read the data"]}, {"cell_type": "code", "execution_count": 1, "id": "9d57d089", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport json\nimport os\n\ntitles = []\nabstracts = []\ntexts = []\nfor dirname, _, filenames in os.walk(\"/kaggle/input/CORD-19-research-challenge/\"):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n        if file.split(\".\")[-1] == \"json\":\n            with open(file,\"r\")as f:\n                doc = json.load(f)\n                titles.append(doc[\"metadata\"][\"title\"])\n                abstracts.append(\" \".join([item[\"text\"] for item in doc[\"abstract\"]]))\n                texts.append(\" \".join([item[\"text\"] for item in doc[\"body_text\"]]))"]}, {"cell_type": "markdown", "id": "59e57e6e", "metadata": {}, "source": ["## Learn the word vectors\n\nWe split the texts into sentences, clean them, merge phrases and train the word vectors using Skip-Gram with negative sampling."]}, {"cell_type": "code", "execution_count": 1, "id": "a58f0911", "metadata": {}, "outputs": [], "source": ["from nltk.tokenize import sent_tokenize\nfrom gensim.utils import simple_preprocess\nfrom gensim.sklearn_api.phrases import PhrasesTransformer\nfrom gensim.models import Word2Vec\n\nsentences = []\nfor text in texts:\n    sentences += [simple_preprocess(sentence) for sentence in sent_tokenize(text)]\nbigrams = PhrasesTransformer(min_count=20, threshold=100)\nmodel = Word2Vec(bigrams.fit_transform(sentences), \n                 size=100, \n                 window=10, \n                 min_count=10,\n                 sg=1,\n                 negative=5,\n                 max_final_vocab=30000, \n                 workers=4, \n                 iter=4)"]}, {"cell_type": "markdown", "id": "02800dc6", "metadata": {}, "source": ["## Visualize the nearest neighbors\n\nWe identify the 5 nearest neighbors for \"transmission\", \"incubation\" and \"genetics\", project there representations on a plan via PCA and plot them."]}, {"cell_type": "code", "execution_count": 1, "id": "b2971faa", "metadata": {}, "outputs": [], "source": ["from sklearn.decomposition import TruncatedSVD\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nmain_keywords = [\"transmission\", \"incubation\", \"genetics\"]\nvectors = []\nkeywords = []\nfor k in main_keywords:\n    vectors.append(model.wv[k])\n    keywords.append(k)\n    for w, s in model.wv.most_similar(positive=k, topn=5):\n        vectors.append(model.wv[w])\n        keywords.append(w)\nsvd = TruncatedSVD(n_components=2)\nX = svd.fit_transform(vectors)\nplt.figure(figsize=(15, 10))\ncolors = [\"red\", \"blue\", \"green\"]\nfor i in range(3):\n    plt.scatter(X[i*6:(i+1)*6,0], X[i*6:(i+1)*6,1], c=colors[i])\ni = 0\nfor keyword in keywords:\n    plt.annotate(keywords[i], (X[i,0], X[i,1]))\n    i += 1 "]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}