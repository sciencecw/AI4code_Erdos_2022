{"cells": [{"cell_type": "code", "execution_count": 1, "id": "255a40dd", "metadata": {}, "outputs": [], "source": ["#importing the necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn"]}, {"cell_type": "code", "execution_count": 1, "id": "6339fd6f", "metadata": {}, "outputs": [], "source": ["data_place = pd.read_csv(\"../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\ndata_place.head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "c8ebbf6b", "metadata": {}, "outputs": [], "source": ["#Details about the data\ndata_place.info()\n#Totally there are 14 variables and we can remove the serial number variable as it is not important"]}, {"cell_type": "code", "execution_count": 1, "id": "04638467", "metadata": {}, "outputs": [], "source": ["data_place.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "71cd01ff", "metadata": {}, "outputs": [], "source": ["# now checking the missing value imputation\ndata_place.isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "3f8b4a4a", "metadata": {}, "outputs": [], "source": ["#We can fill the salary missing values as zero because the students who are not placed has givven as missing values\ndata_place[\"salary\"]=data_place[\"salary\"].fillna(0.0)\ndata_place.isna().sum()"]}, {"cell_type": "markdown", "id": "e4f752a6", "metadata": {}, "source": ["# EDA and VISUALISATION"]}, {"cell_type": "code", "execution_count": 1, "id": "9620073f", "metadata": {}, "outputs": [], "source": ["data_place.drop(\"sl_no\",axis=1,inplace=True)\ndata_place.describe()"]}, {"cell_type": "markdown", "id": "9880c054", "metadata": {}, "source": ["# Univariate analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "fe74b300", "metadata": {}, "outputs": [], "source": ["data_place.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)"]}, {"cell_type": "code", "execution_count": 1, "id": "1b0ee454", "metadata": {}, "outputs": [], "source": ["data_place.skew()# there is no problem of skewness"]}, {"cell_type": "markdown", "id": "25d70027", "metadata": {}, "source": ["# Bi-variate and multi-variate analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "18a7f93d", "metadata": {}, "outputs": [], "source": ["data_place.dtypes"]}, {"cell_type": "markdown", "id": "2a2ac5d6", "metadata": {}, "source": ["# GENDER VS SALARY"]}, {"cell_type": "code", "execution_count": 1, "id": "5b3be4a6", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"gender\",\"salary\",data=data_place)#we can say that the salary for male is more compared to the female"]}, {"cell_type": "markdown", "id": "57117100", "metadata": {}, "source": ["# BASED ON DIFFERENT CATEGORICAL VARIABLES SEEING THE STATUS OF THE CANDIDATES"]}, {"cell_type": "code", "execution_count": 1, "id": "62267095", "metadata": {}, "outputs": [], "source": ["\nprint(data_place.groupby('status')['gender'].value_counts(normalize=True))\nprint(\"\\n\")\nprint(data_place.groupby('status')['ssc_b'].value_counts(normalize=True))\nprint(\"\\n\")\nprint(data_place.groupby('status')['hsc_b'].value_counts(normalize=True))\nprint(\"\\n\")\nprint(data_place.groupby('status')['hsc_s'].value_counts(normalize=True))\nprint(\"\\n\")\nprint(data_place.groupby('status')['degree_t'].value_counts(normalize=True))\nprint(\"\\n\")\nprint(data_place.groupby('status')['workex'].value_counts(normalize=True))\nprint(\"\\n\")\nprint(data_place.groupby('status')['specialisation'].value_counts(normalize=True))"]}, {"cell_type": "markdown", "id": "28ac50e6", "metadata": {}, "source": ["# NOTE:\n\n1) GENDER: we can say that male students are placed more than females but in non-placed status also male has high ratio\n\n2) SSC_B and HSC_B: we can say that this fetaure may not be important\n"]}, {"cell_type": "markdown", "id": "32b364fd", "metadata": {}, "source": ["# GENDER vs STATUS"]}, {"cell_type": "code", "execution_count": 1, "id": "bc418578", "metadata": {}, "outputs": [], "source": ["sns.countplot(\"gender\", hue=\"status\", data=data_place)\nplt.show()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5de940ba", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"gender\",\"salary\",hue=\"status\",data=data_place)\n#male candidates got high paid jobs than females"]}, {"cell_type": "code", "execution_count": 1, "id": "e7b4281a", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize =(18,6))\nsns.boxplot(\"salary\", \"gender\", data=data_place)\nplt.show()"]}, {"cell_type": "markdown", "id": "db19120b", "metadata": {}, "source": ["So we have more samples of male than female and male are getting high paid jobs compared to the female"]}, {"cell_type": "markdown", "id": "b83933b8", "metadata": {}, "source": ["# Feature: ssc_p (Secondary Education percentage), ssc_b (Board Of Education)"]}, {"cell_type": "code", "execution_count": 1, "id": "a1ba993d", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"ssc_p\",\"status\",data=data_place)\n#We can say that on an average if a person takes above 50 percent in ssc he may get placed"]}, {"cell_type": "code", "execution_count": 1, "id": "67459755", "metadata": {}, "outputs": [], "source": ["sns.countplot(\"ssc_b\",hue=\"status\",data=data_place)\n# we can say that the students in central board are placed more but the ssc education doesnt much effect the placement"]}, {"cell_type": "code", "execution_count": 1, "id": "e4ceae28", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize =(18,6))\nsns.boxplot(\"salary\", \"ssc_b\", data=data_place)\nplt.show()\n# the students studied in central board are got high paid salaries"]}, {"cell_type": "code", "execution_count": 1, "id": "245687bf", "metadata": {}, "outputs": [], "source": ["sns.lineplot(\"ssc_p\", \"salary\", hue=\"ssc_b\", data=data_place)\nplt.show()\n#From this plot we can say that the candidates from central board with\n# ssc percentage with an average of 60 are getting highest paid job"]}, {"cell_type": "markdown", "id": "4a8c0a40", "metadata": {}, "source": ["# Feature: hsc_p (Higher Secondary Education percentage), hsc_b (Board Of Education), hsc_s (Specialization in Higher Secondary Education)"]}, {"cell_type": "code", "execution_count": 1, "id": "4a0970d8", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"hsc_p\",\"status\",data=data_place)\n# we can say that on an average if student gets 50 percentage, there is possibility of getting placed"]}, {"cell_type": "code", "execution_count": 1, "id": "8cbfd4db", "metadata": {}, "outputs": [], "source": ["sns.countplot(\"hsc_b\", hue=\"status\", data=data_place)\nplt.show()\n#In HSC other board students are placed more"]}, {"cell_type": "code", "execution_count": 1, "id": "6598c124", "metadata": {}, "outputs": [], "source": ["sns.boxplot(\"salary\", \"hsc_b\", data=data_place)\n# The salary for central board candidates are high"]}, {"cell_type": "code", "execution_count": 1, "id": "b73da2a4", "metadata": {}, "outputs": [], "source": ["sns.countplot(\"hsc_s\", hue=\"status\", data=data_place)\nplt.show()\n#Arts students placed ratio is low"]}, {"cell_type": "code", "execution_count": 1, "id": "4a0b03ac", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize =(18,6))\nsns.boxplot(\"salary\", \"hsc_b\", data=data_place)\nplt.show()\n# Salary for Central board candidates are high"]}, {"cell_type": "code", "execution_count": 1, "id": "b74f439b", "metadata": {}, "outputs": [], "source": ["sns.lineplot(\"hsc_p\", \"salary\", hue=\"hsc_b\", data=data_place)\nplt.show()\n# A candidate from HSC central board with 60 percentage are getting highest paid job "]}, {"cell_type": "code", "execution_count": 1, "id": "59c9cd78", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize =(18,6))\nsns.boxplot(\"salary\", \"hsc_s\", data=data_place)\nplt.show()\n#The salary for the science students in HSC is more"]}, {"cell_type": "markdown", "id": "b06dfef0", "metadata": {}, "source": ["# Degree percentage and Degree Specialisation"]}, {"cell_type": "code", "execution_count": 1, "id": "dcdd287b", "metadata": {}, "outputs": [], "source": ["#Kernel-Density Plot\nsns.kdeplot(data_place.degree_p[ data_place.status==\"Placed\"])\nsns.kdeplot(data_place.degree_p[ data_place.status==\"Not Placed\"])\nplt.legend([\"Placed\", \"Not Placed\"])\nplt.xlabel(\"Under Graduate Percentage\")\nplt.show()\n# the placed rate will be high if the degree percentage is around 55 percentage"]}, {"cell_type": "code", "execution_count": 1, "id": "95fda4ae", "metadata": {}, "outputs": [], "source": ["sns.countplot(\"degree_t\", hue=\"status\", data=data_place)\nplt.show()\n#commerce&Mmt students are more placed"]}, {"cell_type": "code", "execution_count": 1, "id": "f81e2734", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize =(18,6))\nsns.boxplot(\"salary\", \"degree_t\", data=data_place)\nplt.show()\n# we can say that the students in Sci-tech get high paid jobs but Comm&mgmt students are getting good jobs"]}, {"cell_type": "code", "execution_count": 1, "id": "a5042923", "metadata": {}, "outputs": [], "source": ["sns.countplot(\"workex\",hue=\"status\",data=data_place)\n#So the students with experience are getting placed and their chance of not getting place is less"]}, {"cell_type": "code", "execution_count": 1, "id": "7cb72e3f", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"salary\",\"workex\",data=data_place)\n#Workexperinced candidates are getting high paid jobs"]}, {"cell_type": "markdown", "id": "5131be4a", "metadata": {}, "source": ["# EMPLOYABILITY TEST PERCENTAGE"]}, {"cell_type": "code", "execution_count": 1, "id": "5203711c", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"etest_p\",\"status\",data=data_place)\n#So this feature doesnt effect placement"]}, {"cell_type": "code", "execution_count": 1, "id": "4713139b", "metadata": {}, "outputs": [], "source": ["sns.lineplot(\"etest_p\",\"salary\",data=data_place)\n# so this doesnt effect the salary also"]}, {"cell_type": "markdown", "id": "ff57c4dc", "metadata": {}, "source": ["# POST GRADUATE SPECIALISATION "]}, {"cell_type": "code", "execution_count": 1, "id": "ff6d76db", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"specialisation\",\"salary\",hue=\"status\",data=data_place)\n#mkt and finance students are getting highly paid  jobs"]}, {"cell_type": "code", "execution_count": 1, "id": "2ddd3038", "metadata": {}, "outputs": [], "source": ["sns.countplot(\"specialisation\",hue=\"status\",data=data_place)\n#Market and finance candidates are getting placed more"]}, {"cell_type": "markdown", "id": "613e7f9f", "metadata": {}, "source": ["# MBA percantage"]}, {"cell_type": "code", "execution_count": 1, "id": "a062a5c3", "metadata": {}, "outputs": [], "source": ["sns.barplot(\"mba_p\",\"status\",data=data_place)\n#this doesnt effect status"]}, {"cell_type": "code", "execution_count": 1, "id": "cbaf63d6", "metadata": {}, "outputs": [], "source": ["sns.lineplot('mba_p',\"salary\",data=data_place)\n#doesnt effect salary "]}, {"cell_type": "markdown", "id": "866d3639", "metadata": {}, "source": ["# FEATURE SELECTION:\n The feature which is not important are \nsalary, hsc_b and ssc_b"]}, {"cell_type": "code", "execution_count": 1, "id": "ab459574", "metadata": {}, "outputs": [], "source": ["data_new = data_place.drop([\"hsc_b\",\"ssc_b\",\"salary\"],axis=1)\ndata_new.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "1a1d46ee", "metadata": {}, "outputs": [], "source": ["data_new[\"gender\"].value_counts()"]}, {"cell_type": "markdown", "id": "265548c8", "metadata": {}, "source": ["# ENCODING"]}, {"cell_type": "code", "execution_count": 1, "id": "64482fad", "metadata": {}, "outputs": [], "source": ["data_new.loc[data_new['gender']=='M','gender']= 0\n\ndata_new.loc[data_new['gender']=='F','gender']= 1\n\ndata_new[\"gender\"] = data_new[\"gender\"].astype(int)\n\n\ndata_new[\"hsc_s\"] = data_new.hsc_s.map({\"Commerce\":0,\"Science\":1,\"Arts\":2})\ndata_new[\"degree_t\"] = data_new.degree_t.map({\"Comm&Mgmt\":0,\"Sci&Tech\":1, \"Others\":2})\ndata_new[\"workex\"] = data_new.workex.map({\"No\":0, \"Yes\":1})\ndata_new[\"status\"] = data_new.status.map({\"Not Placed\":0, \"Placed\":1})\ndata_new[\"specialisation\"] = data_new.specialisation.map({\"Mkt&HR\":0, \"Mkt&Fin\":1})"]}, {"cell_type": "code", "execution_count": 1, "id": "aa1d86e2", "metadata": {}, "outputs": [], "source": ["data_new.dtypes"]}, {"cell_type": "markdown", "id": "15f0d785", "metadata": {}, "source": ["# Analysing which model will be best for this data-set"]}, {"cell_type": "code", "execution_count": 1, "id": "c4900d70", "metadata": {}, "outputs": [], "source": ["#importing the necessary libraries\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, fbeta_score, confusion_matrix, accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#LDA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n#NAIVE_BAYES MODEL\nfrom sklearn.naive_bayes import GaussianNB\n\n#SVC \nfrom sklearn.svm import SVC\n\n#XGBOOST\nfrom xgboost import XGBClassifier\nimport pandas as pd"]}, {"cell_type": "code", "execution_count": 1, "id": "b28f75f4", "metadata": {}, "outputs": [], "source": ["data_new.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "0106f418", "metadata": {}, "outputs": [], "source": ["cor=data_new.corr()\nplt.figure(figsize=(14,6))\nsns.heatmap(cor,annot=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "5cba3331", "metadata": {}, "outputs": [], "source": ["#from correlation plot we can remove the hsc_s and degree_t\ndata_new.drop([\"hsc_s\",\"degree_t\"],axis=1,inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "baf46fb0", "metadata": {}, "outputs": [], "source": ["x = data_new.drop(\"status\", axis =1).values#independent variable\n\ny = data_new[\"status\"].values #dependant variable\n#train and test data split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 42)\n\nprint(x_train.shape, x_test.shape)\n#NOTE:\n#.values will store the values in the form of array\n#if you not give x will store the values in series"]}, {"cell_type": "code", "execution_count": 1, "id": "c1649e5e", "metadata": {}, "outputs": [], "source": ["#to feed the random state\nseed = 42\n\n#prepare models\nmodels = []\nmodels.append((\"LR\", LogisticRegression()))\nmodels.append((\"LDA\", LinearDiscriminantAnalysis()))\nmodels.append((\"KNN\", KNeighborsClassifier()))\nmodels.append((\"CART\", DecisionTreeClassifier()))\nmodels.append((\"NB\", GaussianNB()))\nmodels.append((\"RF\", RandomForestClassifier()))\nmodels.append((\"SVM\", SVC(gamma = 'auto')))\nmodels.append((\"XGB\", XGBClassifier()))\n#appending all the models with their names"]}, {"cell_type": "code", "execution_count": 1, "id": "11c8f993", "metadata": {}, "outputs": [], "source": ["import warnings \nwarnings.filterwarnings(\"ignore\")# to avoid the warnings in our data-set\nresult = []\nnames = []\nscoring = 'recall'\nseed = 42\n\nfor name, model in models:\n    kfold = KFold(n_splits = 5, random_state =seed)# 5 split of data (value of k)\n    cv_results = cross_val_score(model, x_train, y_train, cv = kfold, scoring = scoring)\n    result.append(cv_results)\n    names.append(name)\n    msg = (name, cv_results.mean(), cv_results.std())\n    print(msg)"]}, {"cell_type": "code", "execution_count": 1, "id": "bfc5120a", "metadata": {}, "outputs": [], "source": ["#boxplot results for choosing our algorithm\nimport matplotlib.pyplot as plt\nfig = plt.figure(figsize = (8,4))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(1,1,1)\nplt.boxplot(result)\nax.set_xticklabels(names)\nplt.show()"]}, {"cell_type": "markdown", "id": "912c0eaf", "metadata": {}, "source": ["#FOR recall the best model is NAIVEBAYES"]}, {"cell_type": "code", "execution_count": 1, "id": "f6e06001", "metadata": {}, "outputs": [], "source": ["#precion\nimport warnings \nwarnings.filterwarnings(\"ignore\")# to avoid the warnings in our data-set\nresult1 = []\nnames = []\nscoring = 'precision'\nseed = 42\n\nfor name, model in models:\n    kfold = KFold(n_splits = 5, random_state =seed)# 5 split of data (value of k)\n    cv_results = cross_val_score(model, x_train, y_train, cv = kfold, scoring = scoring)\n    result1.append(cv_results)\n    names.append(name)\n    msg1 = (name, cv_results.mean(), cv_results.std())\n    print(msg1)\n#first one is mean value of a model, next one is the std deviation"]}, {"cell_type": "code", "execution_count": 1, "id": "57800776", "metadata": {}, "outputs": [], "source": ["#boxplot results for choosing our algorithm\nfig = plt.figure(figsize = (8,4))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(1,1,1)\nplt.boxplot(result1)\nax.set_xticklabels(names)\nplt.show()"]}, {"cell_type": "markdown", "id": "e83b4a2d", "metadata": {}, "source": ["#For precision is DECISION-TREE"]}, {"cell_type": "code", "execution_count": 1, "id": "da12f73e", "metadata": {}, "outputs": [], "source": ["# default scoring is a accuracy\nimport warnings \nwarnings.filterwarnings(\"ignore\")# to avoid the warnings in our data-set\nresult2 = []\nnames = []\nseed = 42\n\nfor name, model in models:\n    kfold = KFold(n_splits = 5, random_state =seed)# 5 split of data (value of k)\n    cv_results = cross_val_score(model, x_train, y_train, cv = kfold)\n    result2.append(cv_results)\n    names.append(name)\n    msg1 = (name, cv_results.mean(), cv_results.std())\n    print(msg1)\n#first one is mean value of a model, next one is the std deviation"]}, {"cell_type": "code", "execution_count": 1, "id": "ec595d4d", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize = (8,4))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(1,1,1)\nplt.boxplot(result2)\nax.set_xticklabels(names)\nplt.show()"]}, {"cell_type": "markdown", "id": "92a2bce0", "metadata": {}, "source": ["#For accuracy the best model is Random-forest"]}, {"cell_type": "markdown", "id": "43431090", "metadata": {}, "source": ["# DECISION TREE"]}, {"cell_type": "code", "execution_count": 1, "id": "72851756", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(criterion='entropy')\ndtree.fit(x_train, y_train)\ny_pred = dtree.predict(x_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "9aa992c1", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test,y_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "7d127e6b", "metadata": {}, "outputs": [], "source": ["#Using Random Forest Algorithm\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(x_train, y_train)\ny_pred = random_forest.predict(x_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "55d072fb", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test,y_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "bf3e5df7", "metadata": {}, "outputs": [], "source": ["# creating confusion matrix heatmap\n\nconf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred))\nfig = plt.figure(figsize=(10,7))\nsns.heatmap(conf_mat, annot=True, annot_kws={\"size\": 16}, fmt='g')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()"]}, {"cell_type": "markdown", "id": "09f8af49", "metadata": {}, "source": ["# ETS Method"]}, {"cell_type": "code", "execution_count": 1, "id": "ddfdc34e", "metadata": {}, "outputs": [], "source": ["\nfrom sklearn.ensemble import ExtraTreesClassifier\nx2= data_new.drop(\"status\",axis=1)\ny= data_new[\"status\"]\n\nmodel = ExtraTreesClassifier(n_estimators =5, criterion = 'entropy')\n\nmodel.fit(x2,y)\n\nfi = model.feature_importances_\n\nprint(fi)"]}, {"cell_type": "code", "execution_count": 1, "id": "9a4abc89", "metadata": {}, "outputs": [], "source": ["fi_df = pd.DataFrame({'fi':fi, \"feature\":x2.columns})\nfi_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "6b875b95", "metadata": {}, "outputs": [], "source": ["fi_df.sort_values([\"fi\"],ascending = False)"]}, {"cell_type": "code", "execution_count": 1, "id": "b3f908f9", "metadata": {}, "outputs": [], "source": ["x2_col = fi_df[fi_df[\"fi\"]>0.05]\nx2_col"]}, {"cell_type": "code", "execution_count": 1, "id": "715a8254", "metadata": {}, "outputs": [], "source": ["#now we are going to extract only these features\nx2 = x2[x2_col[\"feature\"]]\nx2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "916d37c3", "metadata": {}, "outputs": [], "source": ["#now with these values of x and y we are going to build the model\nfrom sklearn.preprocessing import MinMaxScaler\n\nstd_data = MinMaxScaler()\nstd_data = std_data.fit_transform(x2)\nstd_data = pd.DataFrame(std_data, columns =x2.columns)\nstd_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "0c2d19e6", "metadata": {}, "outputs": [], "source": ["x_train, x_test, y_train, y_test = train_test_split(std_data,y, test_size = 0.25, random_state = 100)\nmodel1 = RandomForestClassifier().fit(x_train,y_train)\n\ny_pred = model1.predict(x_test)\n\nprint(classification_report(y_test,y_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "d9bc9b10", "metadata": {}, "outputs": [], "source": ["# creating confusion matrix heatmap\n\nconf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred))\nfig = plt.figure(figsize=(10,7))\nsns.heatmap(conf_mat, annot=True, annot_kws={\"size\": 16}, fmt='g')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()"]}, {"cell_type": "markdown", "id": "5abaf3b5", "metadata": {}, "source": ["# HYPER-PARAMETER TUNING"]}, {"cell_type": "code", "execution_count": 1, "id": "b2206f66", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import RandomizedSearchCV\n#no of trees in randomforest\n#n_estimators = [100,200,500]\n\n#no of features to consider at every split\nmax_features = ['auto','sqrt']\n\n#max number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10,110,11)]\n\n#minimum no of samples required at each node\nmin_samples_leaf = [1,2,4]\n\n\nrandom_grid = {'max_features':max_features,'max_depth':max_depth,'min_samples_leaf':min_samples_leaf}\n\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator=rf,param_distributions = random_grid, n_iter= 100, cv=3,verbose=1,n_jobs=2,random_state=11)\n\nrf_random.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "49ad9682", "metadata": {}, "outputs": [], "source": ["rf_random.best_estimator_"]}, {"cell_type": "code", "execution_count": 1, "id": "34081603", "metadata": {}, "outputs": [], "source": ["newmod = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=4, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=42,\n                       verbose=0, warm_start=False).fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "7a2280ff", "metadata": {}, "outputs": [], "source": ["y_pred = newmod.predict(x_test)\nprint(classification_report(y_test,y_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "8f20e52a", "metadata": {}, "outputs": [], "source": ["data_n= data_place\ndata_n.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "be03f65c", "metadata": {}, "outputs": [], "source": ["data_n[\"gender\"] = data_n.gender.map({\"M\":0,\"F\":1})\ndata_n[\"ssc_b\"] = data_n.ssc_b.map({\"Others\":0,\"Central\":1})\ndata_n[\"hsc_b\"] = data_n.hsc_b.map({\"Others\":0,\"Central\":1})\ndata_n[\"hsc_s\"] = data_n.hsc_s.map({\"Commerce\":0,\"Science\":1,\"Arts\":2})\ndata_n[\"degree_t\"] = data_n.degree_t.map({\"Comm&Mgmt\":0,\"Sci&Tech\":1, \"Others\":2})\ndata_n[\"workex\"] = data_n.workex.map({\"No\":0, \"Yes\":1})\ndata_n[\"status\"] = data_n.status.map({\"Not Placed\":0, \"Placed\":1})\ndata_n[\"specialisation\"] = data_n.specialisation.map({\"Mkt&HR\":0, \"Mkt&Fin\":1})\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0cfdd692", "metadata": {}, "outputs": [], "source": ["cor=data_n.corr()\nplt.figure(figsize=(14,6))\nsns.heatmap(cor,annot=True)"]}, {"cell_type": "markdown", "id": "34b88375", "metadata": {}, "source": ["# BASED ON THE CORRELATION AND PREVIOUS STEPS WE HAVE SELECTED THE IMPORTANT FEATURES"]}, {"cell_type": "code", "execution_count": 1, "id": "e27067e6", "metadata": {}, "outputs": [], "source": ["# Seperating Features and Target\nX = data_n[[ 'ssc_p', 'hsc_p', 'hsc_s', 'degree_p',  'workex','etest_p', 'specialisation', 'mba_p',]]\ny = data_n['status']"]}, {"cell_type": "code", "execution_count": 1, "id": "9e4e45ac", "metadata": {}, "outputs": [], "source": ["# Let us now split the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify =y)"]}, {"cell_type": "code", "execution_count": 1, "id": "62fa0540", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import make_scorer, accuracy_score,precision_score\nfrom sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nrandomForestFinalModel = RandomForestClassifier(n_estimators=200,criterion='gini',\n max_depth= 4 ,\n max_features= 'auto',random_state=42)\nrandomForestFinalModel.fit(X_train, y_train)\npredictions_rf = randomForestFinalModel.predict(X_test)\n\nprint(classification_report(y_test,predictions_rf))"]}, {"cell_type": "code", "execution_count": 1, "id": "afa028a2", "metadata": {}, "outputs": [], "source": ["conf_mat = pd.DataFrame(confusion_matrix(y_test, predictions_rf))\nfig = plt.figure(figsize=(10,7))\nsns.heatmap(conf_mat, annot=True, annot_kws={\"size\": 16}, fmt='g')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()"]}, {"cell_type": "markdown", "id": "82371ea9", "metadata": {}, "source": ["# KNN CLASSIFICATION"]}, {"cell_type": "code", "execution_count": 1, "id": "de890e5f", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import cross_val_score\n\ndf = pd.read_csv(\"../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\ndf.head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "02713be2", "metadata": {}, "outputs": [], "source": ["df[\"salary\"]=df[\"salary\"].fillna(0.0)\ndf.isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "cc2363a4", "metadata": {}, "outputs": [], "source": ["X1 = df.drop(['status',\"salary\"], axis = 1)\ny1 = df.status\n\nfrom sklearn.preprocessing import LabelEncoder\nencoder=LabelEncoder()\n\n#placed as 1, not placed as 0\ny1 = encoder.fit_transform(y1)\nX1 = pd.get_dummies(X1)"]}, {"cell_type": "code", "execution_count": 1, "id": "40ed12c4", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X1, y1, test_size= 0.3, random_state=41)"]}, {"cell_type": "code", "execution_count": 1, "id": "404fe3ee", "metadata": {}, "outputs": [], "source": ["knn = KNeighborsClassifier(n_neighbors= 5 )\nknn.fit(X_train2, y_train2)\ny_pred2 = knn.predict(X_test2)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "afaa789a", "metadata": {}, "outputs": [], "source": ["print(accuracy_score(y_test2,y_pred2))\n\nprint(classification_report(y_test2, y_pred2))"]}, {"cell_type": "code", "execution_count": 1, "id": "64523a40", "metadata": {}, "outputs": [], "source": ["conf_mat = pd.DataFrame(confusion_matrix(y_test2, y_pred2))\nfig = plt.figure(figsize=(10,7))\nsns.heatmap(conf_mat, annot=True, annot_kws={\"size\": 16}, fmt='g')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()"]}, {"cell_type": "markdown", "id": "2d44e48f", "metadata": {}, "source": ["# CONCLUSION:\n\nTHUS WE CAN SAY THAT RANDOM-FOREST WILL BE THE BEST MODEL COMPARED TO OTHER MODELS FOR THIS DATA-SET WHICH GIVES BETTER SOLUTION"]}, {"cell_type": "markdown", "id": "c709e8a3", "metadata": {}, "source": ["# MULTIPLE LINEAR REGRESSION"]}, {"cell_type": "code", "execution_count": 1, "id": "22cf976c", "metadata": {}, "outputs": [], "source": ["dataset = pd.read_csv(\"../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\ndataset"]}, {"cell_type": "markdown", "id": "ef445696", "metadata": {}, "source": ["# SSC_P and HSC_P vs MBA_P"]}, {"cell_type": "code", "execution_count": 1, "id": "29c46696", "metadata": {}, "outputs": [], "source": ["X=dataset.iloc[:,[2,4]].values # X contain columns hsc_p and ssc_p\nY=dataset.iloc[:,12].values.reshape(-1,1)"]}, {"cell_type": "code", "execution_count": 1, "id": "2720717e", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "5079af70", "metadata": {}, "outputs": [], "source": ["#fitting multiple linear regression to the training set\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X_train,Y_train)\n\n#predicting the test result\ny_pred=regressor.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "6f5a55ed", "metadata": {}, "outputs": [], "source": ["#Let\u2019s check out the coefficients for the predictors:\nregressor.coef_"]}, {"cell_type": "code", "execution_count": 1, "id": "2d7694a5", "metadata": {}, "outputs": [], "source": ["regressor.intercept_"]}, {"cell_type": "code", "execution_count": 1, "id": "c263948e", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import r2_score\nr2_score(Y_test, y_pred)"]}, {"cell_type": "markdown", "id": "ee7dec00", "metadata": {}, "source": ["# The regression equation is \n\nY= 38.56 + 0.13(ssc_p) + 0.225(hsc_p)\n\nRscore is 17%"]}, {"cell_type": "markdown", "id": "f454637d", "metadata": {}, "source": ["# SSC_P, DEGREE_P vs MBA_P"]}, {"cell_type": "code", "execution_count": 1, "id": "7a411626", "metadata": {}, "outputs": [], "source": ["X1=dataset.iloc[:,[2,7]].values\nY1=dataset.iloc[:,12].values.reshape(-1,1)"]}, {"cell_type": "code", "execution_count": 1, "id": "ebf40470", "metadata": {}, "outputs": [], "source": ["# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X1,Y1,test_size=0.2,random_state=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "8e302895", "metadata": {}, "outputs": [], "source": ["#fitting multiple linear regression to the training set\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X_train,Y_train)\n\n#predicting the test result\ny_pred=regressor.predict(X_test)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3ae17a87", "metadata": {}, "outputs": [], "source": ["#Let\u2019s check out the coefficients for the predictors:\nregressor.coef_"]}, {"cell_type": "code", "execution_count": 1, "id": "1a92d8fb", "metadata": {}, "outputs": [], "source": ["regressor.intercept_"]}, {"cell_type": "code", "execution_count": 1, "id": "1c7128eb", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import r2_score\nr2_score(Y_test, y_pred)"]}, {"cell_type": "markdown", "id": "d537b601", "metadata": {}, "source": ["# The regression equation is \n\nY = 39.6580 + 0.123(ssc_p) +0.215(degree_p)"]}, {"cell_type": "markdown", "id": "cb3472f6", "metadata": {}, "source": ["# HSC_P, DEGREE_P VS MBA_P"]}, {"cell_type": "code", "execution_count": 1, "id": "7cdb2713", "metadata": {}, "outputs": [], "source": ["X2=dataset.iloc[:,[4,7]].values\nY2=dataset.iloc[:,12].values.reshape(-1,1)"]}, {"cell_type": "code", "execution_count": 1, "id": "8af69033", "metadata": {}, "outputs": [], "source": ["# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X2,Y2,test_size=0.2,random_state=0)\n\n#fitting multiple linear regression to the training set\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X_train,Y_train)\n\n#predicting the test result\ny_pred=regressor.predict(X_test)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a1e3f260", "metadata": {}, "outputs": [], "source": ["#Let\u2019s check out the coefficients for the predictors:\nregressor.coef_\n"]}, {"cell_type": "code", "execution_count": 1, "id": "76b476c9", "metadata": {}, "outputs": [], "source": ["regressor.intercept_"]}, {"cell_type": "code", "execution_count": 1, "id": "215c55f1", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import r2_score\nr2_score(Y_test, y_pred)"]}, {"cell_type": "markdown", "id": "ad1352d8", "metadata": {}, "source": ["# The regression equation is\nY= 44.04 + 0.138(hsc_p) + 0.225(degree_p)"]}, {"cell_type": "markdown", "id": "6bbd0966", "metadata": {}, "source": ["# HSC_P, SSC_P, DEGREE_P vs MBA_P"]}, {"cell_type": "code", "execution_count": 1, "id": "ae1507a8", "metadata": {}, "outputs": [], "source": ["X3=dataset.iloc[:,[2,4,7]].values # X contain columns hsc_p and ssc_p\nY3=dataset.iloc[:,12].values.reshape(-1,1)"]}, {"cell_type": "code", "execution_count": 1, "id": "f950af07", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X3,Y3,test_size=0.2,random_state=0)\n\n#fitting multiple linear regression to the training set\nfrom sklearn.linear_model import LinearRegression\nregressor=LinearRegression()\nregressor.fit(X_train,Y_train)\n\n#predicting the test result\ny_pred=regressor.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "1691f289", "metadata": {}, "outputs": [], "source": ["regressor.intercept_"]}, {"cell_type": "code", "execution_count": 1, "id": "c7a9fb7c", "metadata": {}, "outputs": [], "source": ["r2_score(Y_test, y_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "0ca2adad", "metadata": {}, "outputs": [], "source": ["regressor.coef_"]}, {"cell_type": "markdown", "id": "eb7320ed", "metadata": {}, "source": ["# The regression equation is \n\nY= 0.0814(ssc_p)+ 0.10799(hsc_p)+ 0.17898(degree_p)"]}, {"cell_type": "markdown", "id": "a5ec28c1", "metadata": {}, "source": ["# CONCLUSION:\n\nThus we can say that the model built with ssc_p and degree_p has good rscore value compared to other models.\n\nFor this data-set,\n\nSo we can say that in order to predict mba percentage, the ssc percentage and degree percentage is enough rather than using\n\nhsc percentage feature"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}