{"cells": [{"cell_type": "code", "execution_count": 1, "id": "6ea4278a", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "a5e947f4", "metadata": {}, "source": ["![](http://worldhappiness.report/assets/images/icons/whr-cover-ico.png)"]}, {"cell_type": "markdown", "id": "c4f7e931", "metadata": {}, "source": ["# Context\n\n\"The World Happiness Report is a landmark survey of the state of global happiness. The first report was published in 2012, the second in 2013, the third in 2015, and the fourth in the 2016 Update. The World Happiness 2017, which ranks 155 countries by their happiness levels, was released at an event celebrating International Day of Happiness on March 20th. The report continues to gain global recognition as governments, organizations and civil society increasingly use happiness indicators to inform their policy-making decisions. Leading experts across fields \u2013 economics, psychology, survey analysis, national statistics, health, public policy and more \u2013 describe how measurements of well-being can be used effectively to assess the progress of nations. The reports review the state of happiness in the world today and show how the new science of happiness explains personal and national variations in happiness.\""]}, {"cell_type": "markdown", "id": "142a5da6", "metadata": {}, "source": ["# Data Content\n\n\"The happiness scores and rankings use data from the Gallup World Poll.\nThe columns following the happiness score estimate the extent to which each of six factors \u2013 economic production, social support, life expectancy, freedom, absence of corruption, and generosity \u2013 contribute to making life evaluations higher in each country than they are in Dystopia, a hypothetical country that has values equal to the world\u2019s lowest national averages for each of the six factors. They have no impact on the total score reported for each country, but they do explain why some countries rank higher than others.\"\n\n* Ladder score: Happiness score or subjective well-being. This is the national average response to the question of life evaluations.\n* Logged GDP per capita: The GDP-per-capita time series from one year to another using countryspecific forecasts of real GDP growth in the following year.\n* Social support: Social support refers to assistance or support provided by members of social networks (like government) to an individual.\n* Healthy life expectancy: Healthy life expectancy is the average life in good health - that is to say without irreversible limitation of activity in daily life or incapacities - of a fictitious generation subject to the conditions of mortality and morbidity prevailing that year.\n* Freedom to make life choices: Freedom to make life choices is the national average of binary responses to the GWP question \u201cAre you satisfied or dissatisfied with your freedom to choose what you do with your life?\u201d ... It is defined as the average of laughter and enjoyment for other waves where the happiness question was not asked\n* Generosity: Generosity is the residual of regressing national average of response to the GWP question \u201cHave you donated money to a charity in the past month?\u201d on GDP per capita.\n* Perceptions of corruption: The measure is the national average of the survey responses to two questions in the GWP: \u201cIs corruption widespread throughout the government or not\u201d and \u201cIs corruption widespread within businesses or not?\u201d\n* Ladder score in Dystopia: It has values equal to the world\u2019s lowest national averages. Dystopia as a benchmark against which to compare contributions from each of the six factors. Dystopia is an imaginary country that has the world's least-happy people. ... Since life would be very unpleasant in a country with the world's lowest incomes, lowest life expectancy, lowest generosity, most corruption, least freedom, and least social support, it is referred to as \u201cDystopia,\u201d in contrast to Utopia.\n\nWorld Happiness Report Official Website: https://worldhappiness.report/"]}, {"cell_type": "markdown", "id": "cc9a7449", "metadata": {}, "source": ["# Does Money Buy Happiness?\n\n\"For many Americans, the pursuit of happiness and the pursuit of money come to much the same thing. More money means more goods (inflation aside) and thus more of the material benefits of life. As it is for the individual, so it is for society as a whole. National economic growth - a steady upward march in average income, year after year, decade after decate - means it is supposed, greater well-being and a happier society.\""]}, {"cell_type": "markdown", "id": "395241ce", "metadata": {}, "source": ["# Hypothesis:\n\n$H_0: \\beta_1 = 0$ vs. $H_a: \\beta_1 \\neq 0$\n\n$H_0$: There is not a significant statistical association between GDP per capita, and happiness score.\n\n$H_a$: There is a significant statistical association between GDP per capita, and happiness score."]}, {"cell_type": "markdown", "id": "bb99c35c", "metadata": {}, "source": ["# Importing Libraries / Reading in the Data"]}, {"cell_type": "code", "execution_count": 1, "id": "d7baa173", "metadata": {}, "outputs": [], "source": ["# Import Libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom statsmodels.formula.api import ols\nimport scipy.stats as st"]}, {"cell_type": "markdown", "id": "f037cafd", "metadata": {}, "source": ["**Reading in data**"]}, {"cell_type": "code", "execution_count": 1, "id": "413ae4d2", "metadata": {}, "outputs": [], "source": ["# Read in the data - \n\n# Import Local CSV files sourced from - \"https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021?select=world-happiness-report.csv\"\n\nworld1 = pd.read_csv(\"../input/world-happiness-report-2021/world-happiness-report.csv\")\nworld2 = pd.read_csv(\"../input/world-happiness-report-2021/world-happiness-report-2021.csv\")"]}, {"cell_type": "markdown", "id": "e3c480c3", "metadata": {}, "source": ["# Preview of Dataset 1 / Cleaning"]}, {"cell_type": "code", "execution_count": 1, "id": "b9b9d7c0", "metadata": {}, "outputs": [], "source": ["# Preview Data World 1 -\n\n# Preview the first dataset\nworld1"]}, {"cell_type": "code", "execution_count": 1, "id": "4be10e36", "metadata": {}, "outputs": [], "source": ["# Preview of info on the dataframe\nprint(world1.info())\nprint('-----------------------------------------------------------------------')\n\n# Check for total count of null vlaues\nprint('Is null count:',world1.isnull().sum().sum())"]}, {"cell_type": "code", "execution_count": 1, "id": "c99920a8", "metadata": {}, "outputs": [], "source": ["# Unique countries used within data set\nprint('Unique countries used:',world1['Country name'].unique())\nprint('-----------------------------------------------------------------------')\n\n# Unique years used within data set\nprint('Unique years used:',world1['year'].unique())"]}, {"cell_type": "code", "execution_count": 1, "id": "7026364f", "metadata": {}, "outputs": [], "source": ["# Clean Data from world1 so there's no NaN values\nworld1_clean_ = world1.dropna(axis=0)\n\n# Clean Data from world1 so column names fit better\nworld1_clean = world1_clean_.rename(columns=\n                                    {\"Country name\": \"Country_name\",\n                                     \"year\": \"Year\",\n                                     \"Life Ladder\": \"Ladder_score\",\n                                     \"Log GDP per capita\": \n                                     \"GDP_per_capita\", \"Social support\":\n                                     \"Social_support\",\n                                     \"Healthy life expectancy at birth\":\n                                     \"Life_expectancy\", \n                                     \"Freedom to make life choices\":\n                                     \"Freedom_of_choice\", \n                                     \"Perceptions of corruption\":\n                                     \"Corruption\",\"Positive affect\":\n                                     \"Positive_affect\", \"Negative affect\": \n                                     \"Negative_affect\"})\n\n# Remove 2005 from dataset since there's limited to no data\n\n# Dropping the row from the set\nworld1_clean_ = world1_clean.drop([0,293])\n\n# Organize set to present columns in a desired fassion\nworld1_final_ = world1_clean_[['Year','Country_name',\n                               'Ladder_score','GDP_per_capita',\n                               'Generosity','Social_support',\n                               'Life_expectancy','Freedom_of_choice',\n                               'Corruption', 'Positive_affect',\n                               'Negative_affect']]\n\n# drop columns to match world2\nworld1_final = world1_final_.drop(['Positive_affect',\n                                   'Negative_affect'],axis=1)"]}, {"cell_type": "markdown", "id": "8c5a7dfe", "metadata": {}, "source": ["**Cleaning Data From Set 1 - Cleaning Columns, NAN values, and Unnecessary Rows**\n\n* First I started by droping all NaN values since there were quite a few.\n* I renamed the columns so they fit better for presentation and they would be easier to type.\n* I wanted to organize the columns in the order that was a bit more structured.\n* I decided to drop the positve and negative affect columns since they weren't included in the second set.\n* I decided to drop the year 2005, since there was only one line item of data. \n  * I didn't want the visualizations to only include one line item when doing multi year timespans."]}, {"cell_type": "markdown", "id": "5ccbcb63", "metadata": {}, "source": ["# Preview of Dataset 2 / Cleaning"]}, {"cell_type": "code", "execution_count": 1, "id": "f690b32a", "metadata": {}, "outputs": [], "source": ["# Preview Data World 2 -\n\n# Preview the second data set\nworld2"]}, {"cell_type": "code", "execution_count": 1, "id": "950408fe", "metadata": {}, "outputs": [], "source": ["# Preview of info on the dataframe\nprint(world2.info())\nprint('-----------------------------------------------------------------------')\n\n# Check for total count of null vlaues\nprint('Null count:',world2.isnull().sum().sum())"]}, {"cell_type": "code", "execution_count": 1, "id": "74b93dd2", "metadata": {}, "outputs": [], "source": ["# Cleaning world 2 Data -\n\n# Drop columns that don't pertain to top dataset\nworld2_clean_ = world2.drop(['Standard error of ladder score',\n                             'upperwhisker','lowerwhisker',\n                             'Ladder score in Dystopia',\n                             'Explained by: Log GDP per capita',\n                             'Explained by: Social support',\n                             'Explained by: Freedom to make life choices', \n                             'Explained by: Generosity', \n                             'Explained by: Perceptions of corruption', \n                             'Dystopia + residual', \n                             'Explained by: Healthy life expectancy'],axis=1)\n\n# Add year column to include the year this data is from is 2021\nworld2_clean_['Year'] = 2021\n\n# Taking previous dataset, including 2021, then orginizing columns\nworld2_final_ = world2_clean_[['Year','Country name',\n                               'Regional indicator',\n                               'Ladder score',\n                               'Logged GDP per capita',\n                               'Generosity',\n                               'Social support',\n                               'Healthy life expectancy',\n                               'Freedom to make life choices',\n                               'Perceptions of corruption']]\n\n# Clean up the names\nworld2_final = world2_final_.rename(columns={\"Country name\": \n                                             \"Country_name\",\n                                             \"Regional indicator\":\n                                             \"Region_indicator\", \n                                             \"Ladder score\": \n                                             \"Ladder_score\", \n                                             \"Logged GDP per capita\":\n                                             \"GDP_per_capita\", \n                                             \"Social support\": \n                                             \"Social_support\", \n                                             \"Healthy life expectancy\": \n                                             \"Life_expectancy\", \n                                             \"Freedom to make life choices\": \n                                            \"Freedom_of_choice\", \n                                             \"Perceptions of corruption\":\n                                             \"Corruption\"})"]}, {"cell_type": "markdown", "id": "1c092861", "metadata": {}, "source": ["**Cleaning Data From Set 2 - Cleaning Columns**\n\n* There were quite a few columns that weren't included in the first set, so I decided to drop them.\n  * I anticipated merging both sets later, so I tried to get the dataframes to match exactly.\n* I noticed that there wasn't a year column for the 2021 dataset, so I decided to create one to match the year column in the first set.\n* I decided to organize the columns to match the first dataset."]}, {"cell_type": "markdown", "id": "39b59366", "metadata": {}, "source": ["# Merging Both Sets Together / Cleaning Final Set"]}, {"cell_type": "code", "execution_count": 1, "id": "d42afef9", "metadata": {}, "outputs": [], "source": ["# Merge World1_final + world 2 Final, try to use country as the identifier so region gets applied to every existing country -\nworld_test = pd.merge(world1_final, world2_final[['Country_name','Region_indicator']], how='left', on = 'Country_name')\n\n# Is null test to see which values are missing, then assign them to a column for revisions.\nworld_test['Missing'] = world_test['Region_indicator'].isnull()\n\n# Assign these missing values to a new dataframe\nworld_missing = pd.DataFrame(world_test.loc[world_test['Missing'] == True])\n\n# calculate the names of the countries missing values\nworld_missing['Country_name'].value_counts(ascending=False)"]}, {"cell_type": "markdown", "id": "d93fee57", "metadata": {}, "source": ["**Creating Final Set - Merge / NaN check**\n\n* After merging both dataframes into one there were a few missing values for the region indicator column.\n* After previewing the data, I noticed there were a few countries missing the region indicator value.\n* I then assigned all the missing values to a temp dataframe where I planned on filling all of the NaN values apposed to dropping them."]}, {"cell_type": "code", "execution_count": 1, "id": "ffaac019", "metadata": {}, "outputs": [], "source": ["# Create values for all nulls using a for loop function, and apply it to the df as a new column\nregion = []\nfor i in range(len(world_test)):\n    if world_test['Country_name'][i] == 'Angola':\n        region.append('Sub-Saharan Africa')\n    elif world_test['Country_name'][i] == 'Belize':\n        region.append('Latin America and Caribbean')\n    elif world_test['Country_name'][i] == 'Congo (Kinshasa)':\n        region.append('Sub-Saharan Africa')\n    elif world_test['Country_name'][i] == 'Syria':\n        region.append('Middle East and North Africa')\n    elif world_test['Country_name'][i] == 'Trinidad and Tobago':\n        region.append('Latin America and Caribbean')\n    elif world_test['Country_name'][i] == 'Qatar':\n        region.append('Middle East and North Africa')\n    elif world_test['Country_name'][i] == 'Sudan':\n        region.append('Middle East and North Africa')\n    elif world_test['Country_name'][i] == 'Central African Republic':\n        region.append('Sub-Saharan Africa')\n    elif world_test['Country_name'][i] == 'Djibouti':\n        region.append('Sub-Saharan Africa')\n    elif world_test['Country_name'][i] == 'Guyana':\n        region.append('Latin America and Caribbean')\n    elif world_test['Country_name'][i] == 'Bhutan':\n        region.append('South Asia')\n    elif world_test['Country_name'][i] == 'Suriname':\n        region.append('Latin America and Caribbea')\n        \nworld_missing['Region'] = region"]}, {"cell_type": "markdown", "id": "5f73b8db", "metadata": {}, "source": ["**Creating Final Set - Filling NaN Values**\n\n* I decided to create a for loop that scanned the missing values by country name, then added the country's region indicator.\n  * I did this so I didn't have to drop a small chunck of values to futher the integrity of my data."]}, {"cell_type": "code", "execution_count": 1, "id": "359818c5", "metadata": {}, "outputs": [], "source": ["# Drop the old Region column, and the missing vlaues column\nworld_missing_cleaner_ = world_missing.drop('Region_indicator',axis=1)\nworld_missing_cleaner = world_missing_cleaner_.drop('Missing',axis=1)\n\n# clean the missing column off, drop the rows from the origional set, and merge this set and the 2021 set.\nworld_missing_final_ = world_missing_cleaner.rename(columns={'Region': 'Region_indicator'})\n\n# Re-order columns to match other dataframes\nworld_missing_final = world_missing_final_[['Year','Country_name',\n                                            'Region_indicator',\n                                            'Ladder_score',\n                                            'GDP_per_capita',\n                                            'Generosity',\n                                            'Social_support',\n                                            'Life_expectancy',\n                                            'Freedom_of_choice',\n                                            'Corruption']]\n\n# Drop the missing column from the previous calculations\nworld_test = world_test.drop(['Missing'],axis=1)\n\n#Organize columns to match other dataframes \nworld_test = world_test[['Year','Country_name',\n                         'Region_indicator',\n                         'Ladder_score',\n                         'GDP_per_capita',\n                         'Generosity',\n                         'Social_support',\n                         'Life_expectancy',\n                         'Freedom_of_choice',\n                         'Corruption']]"]}, {"cell_type": "markdown", "id": "60437d78", "metadata": {}, "source": ["**Creating Final Set - Column / Final Dataframe Cleanup**\n\n* First I dropped all of the old columns that were duplicated, or used in the cleaning process.\n* I then renamed and reordered all columns so all dataframes were consistent."]}, {"cell_type": "code", "execution_count": 1, "id": "4f2bcfba", "metadata": {}, "outputs": [], "source": ["# Concat both dataframes\nworld_final_close = pd.DataFrame(pd.concat([world_test, world_missing_final]))\n\n# Dropping duplicate, na values from the original set, and replacing them with the new values\nworld_final_ = world_final_close.dropna(axis=0)\n\n# Merging the cleaned dataframes to a final dataframe\nworld_final = pd.DataFrame(pd.concat([world_final_, world2_final]))\n\n# Sort year values decending\nworld_final.sort_values(by = 'Year', inplace = True)"]}, {"cell_type": "markdown", "id": "39895760", "metadata": {}, "source": ["**Creating Final Set - Final Merge**\n\n* There were a couple of NA values that were included from the world test in the inital merge, and when I concatinated the cleaned values it created duplicates.\n  * These were removed from the set using the dropna function.\n* I then merged the final two versions of world 1 and world 2 to create one final dataframe.\n* There were a few complications when creating visualizations, so I had to do a sort values in the year column in order to work out the kink."]}, {"cell_type": "markdown", "id": "b9b8f8b6", "metadata": {}, "source": ["# Preview and Analytics of Final Set"]}, {"cell_type": "code", "execution_count": 1, "id": "a3fec51b", "metadata": {}, "outputs": [], "source": ["# Preview of dataframe final\nworld_final"]}, {"cell_type": "code", "execution_count": 1, "id": "34a23002", "metadata": {}, "outputs": [], "source": ["# Final dataframe describe\nround(world_final.describe(),4)"]}, {"cell_type": "markdown", "id": "5ea51922", "metadata": {}, "source": ["**Analytics - Data Describe Visualization**\n\n* The max ladder score appears to be 7.97 and the highest life expectancy age is to 77.1.\n* The lowest score for corruption is .035.\n* The lowest average life expectancy age is 32.3."]}, {"cell_type": "code", "execution_count": 1, "id": "0094106e", "metadata": {}, "outputs": [], "source": ["# Pairplot to show an overview of all of the data, and their distrobutions. \nsns.pairplot(world_final[['Ladder_score', \n                          'GDP_per_capita',\n                          'Generosity',\n                          'Social_support',\n                          'Freedom_of_choice']])\n\n# Show plot\nplt.show();"]}, {"cell_type": "markdown", "id": "cbf9e2bf", "metadata": {}, "source": ["**Analytics - Pairplot Visualization**\n\n* Ladder score appears to have a unimodal distribution.\n* GDP per capita appears to have a non-symetric bimodeal distribution.\n* Generosity appears to have a distribution skewed to the left.\n* Social support appears to have a distribution skewed to the right.\n* Freedom of choice appears to have a distribution skewed to the right."]}, {"cell_type": "code", "execution_count": 1, "id": "db3ddc63", "metadata": {}, "outputs": [], "source": ["# Heat map customization\nplt.figure(figsize = (15,12.5))\nsns.heatmap(world_final[['Country_name',\n                         'Region_indicator',\n                         'Ladder_score',\n                         'GDP_per_capita',\n                         'Generosity',\n                         'Social_support',\n                         'Life_expectancy',\n                         'Freedom_of_choice',\n                         'Corruption']].corr(),\n                         annot=True,\n                         cmap='Blues',\n                         linewidth = .9)\n\n# Axis ticks rotated so full column is displayed\nplt.yticks(rotation=45)\nplt.xticks(rotation=45)\n\n# Create title for plot, and show plot\nplt.title('Relationship Between Columns')\nplt.show();"]}, {"cell_type": "markdown", "id": "008723c1", "metadata": {}, "source": ["**Analytics - Correlation Between Columns, and Visualization**\n\n* GDP per capita, social support, and life expectancy seem to have the highest correlation to ladder score.\n  * After checking the statistical correlation between GDP per capita and happiness, I plan to check the relationship of social support comapared to happiness after accounting for GDP per capita."]}, {"cell_type": "code", "execution_count": 1, "id": "d4921359", "metadata": {}, "outputs": [], "source": ["# Linear regression of GDP per capita vs Happiness, and Social Support vs Happiness\nsns.pairplot(world_final,\n             x_vars=['GDP_per_capita','Social_support'],\n             y_vars=['Ladder_score'],\n             height=9, \n             aspect=.75, \n             kind='reg');\n\n# Create title for plot, and show plot\nplt.title('Linear Regression Models of GDP per Capita, and Social Support Compared to Happiness')\nplt.show();"]}, {"cell_type": "markdown", "id": "513304db", "metadata": {}, "source": ["**Analytics - GDP per Capita, and Social Support Linear Regression Visualization**\n\n* The slope of the linear regression of GDP compared to happiness appears to be > 0. \n* The slope of the linear regression of social support to happiness appears to be > 0. \n* This is a sign of a strong correlation between both variables when compared to happiness."]}, {"cell_type": "code", "execution_count": 1, "id": "39c3a64e", "metadata": {}, "outputs": [], "source": ["# OLS model statistics for GDP compaired to happiness\nmodel = ols('Ladder_score ~ GDP_per_capita',data=world_final).fit()\n\n# Label slope, and intercept\nslope = model.params[1]\nintercept= model.params[0]\n\n# Print Slope / Intercept\nprint('Slope is:',slope)\nprint('------------------------------------------------------------------------------')\nprint('intercept is:',intercept)\nprint('==============================================================================')\n\n# Print the model summary\nprint(model.summary())"]}, {"cell_type": "markdown", "id": "01b0e02f", "metadata": {}, "source": ["**Analytics - GDP per Capita Compared to Happiness**\n\n* We reject our null hypothesis from the .01 significance level and conclude there is a significant statistical correlation between GDP and happiness.\n* Now, let's see if there's a relationship between social support and happiness after accounting for GDP.\n\n\n **$H_0: \\beta_2 = 0$ vs. $H_a: \\beta_2 \\neq 0$**\n\n* $H_0$: There is not a significant statistical association between social support and happiness score after accounting for GDP per capita.\n* $H_a$: There is a significant statistical association between social support and happiness score after accounting for GDP per capita."]}, {"cell_type": "code", "execution_count": 1, "id": "49ae96c2", "metadata": {}, "outputs": [], "source": ["# OLS model statistics for GDP + Social support compaired to happiness\nmodel = ols('Ladder_score ~ GDP_per_capita + Social_support',data=world_final).fit()\n\n# Label slope, and intercept\nslope = model.params[1]\nintercept= model.params[0]\n\n# Print Slope / Intercept\nprint('Slope is:',slope)\nprint('------------------------------------------------------------------------------')\nprint('intercept is:',intercept)\nprint('==============================================================================')\n\n# Print the model summary\nprint(model.summary())"]}, {"cell_type": "markdown", "id": "d5893a7a", "metadata": {}, "source": ["**Analytics - GDP per Capita + Social Support Compared to Happiness**\n\n* We reject our null hypothesis from the .01 significance level and conclude there is a significant statistical association between social support and happiness score after accounting for GDP per capita.\n* There was an increase to the adj. r-squared value of about 5%.\n  * Countries with higher levels of GDP appear to be more social.\n  * This might be because of a lack of work obligations that allows them to focus on their social lives."]}, {"cell_type": "code", "execution_count": 1, "id": "de61500d", "metadata": {}, "outputs": [], "source": ["# Boxplot of GDP per capita per year\nplt.figure(figsize=(15,7))\nsns.boxplot(x='Year',\n            y='GDP_per_capita',\n            data=world_final)\n\n# Create title for plot, and show plot\nplt.title('Box Plot of GDP per Capita by Year')\nplt.show();"]}, {"cell_type": "markdown", "id": "da912b5f", "metadata": {}, "source": ["**Analytics - GDP per Capita Box Plot Visualization**\n\n* It appears the average GDP median across the years is > 9, with 2020 coming in at the highest.\n  * This might be due to the lack of data provided from that year skewing the data.\n* A large majority of the interquartile range of GDP througout the years lies in range of 8 to 10.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b7e94f42", "metadata": {}, "outputs": [], "source": ["# Boxplot of Social Support per year\nplt.figure(figsize=(15,7))\nsns.boxplot(x='Year',\n            y='Social_support',\n            data=world_final)\n\n# Create title for plot, and show plot\nplt.title('Box Plot of Social Support by Year')\nplt.show();"]}, {"cell_type": "markdown", "id": "30cdeffa", "metadata": {}, "source": ["**Analytics - Social Support Box Plot Visualization**\n\n* It appears the average social support median across the years is > .8, with 2006 coming in at the highest.\n* A large majority of the interquartile range of GDP througout the years lies in range of .7 to .9.\n* There appears to be a few outliers across the years, with most outliers in 2010, and 2011."]}, {"cell_type": "code", "execution_count": 1, "id": "7e45a065", "metadata": {}, "outputs": [], "source": ["# Strip plot to show Generosity per regions\nplt.figure(figsize = (15,12.5))\nsns.stripplot(x='Year',\n              y='Generosity',\n              data=world_final,\n              hue='Region_indicator')\n\n# Create title for plot, and show plot\nplt.title('Generosity Per Region by Year')\nplt.show();"]}, {"cell_type": "markdown", "id": "3a22acf6", "metadata": {}, "source": ["**Analytics - Generosity Strip Plot Visualization**\n\n\n* Southeast Asian countries appear to be the most generious countries consistently throughout the years.\n* The Commonwealth of Independent States seemed to be the least generious countries, but slightly improved throughout time."]}, {"cell_type": "code", "execution_count": 1, "id": "d0a628a5", "metadata": {}, "outputs": [], "source": ["# animated scatter plot to present GDP per capita in compairison to happiness rating per year\n# Also plot points based on size of social score\nfig = px.scatter(world_final,\n                x='GDP_per_capita',\n                y='Ladder_score',\n                animation_frame = 'Year',\n                animation_group = 'Country_name',\n                template = 'plotly_white',\n                color='Region_indicator',\n                size='Social_support',\n                size_max= 20,\n                title='GDP per Capita + Social Support per Region Compared to Happiness')\n\n# Show plot\nfig.show();"]}, {"cell_type": "markdown", "id": "00a0d1a2", "metadata": {}, "source": ["# Conclusions:\n\n* We rejected our first null hypothesis and conclude there is a statistically significant relationship between the amount of GDP per capita and happiness score.\n* We rejected our second null hypothesis and conclude there is a significant stitistical association between social score and happiness score after accounting for GDP per capita.\n* After analyzing the data I've come to the conculsion that countries with higher levels of GDP are happier countries. Additionally, I've found that countries with higher GDP have higher social support, leading me to conclude that wealtheir countries have fewer obligations and they can focus on their social lives. This leads to happier well-being as a general population."]}, {"cell_type": "markdown", "id": "72a8ca23", "metadata": {}, "source": ["# Resources / Sources - \n\nhttps://www.proquest.com/openview/6ce2d5a919778d8fada2059d39b7ff89/1?pq-origsite=gscholar&cbl=1817076\n\nhttps://worldhappiness.report/\n\nhttps://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021?select=world-happiness-report.csv\n\nhttps://www.kaggle.com/unsdsn/world-happiness\n\nhttps://colab.research.google.com/github/binnisb/blog/blob/master/_notebooks/2020-04-02-Plotly-in-lab.ipynb#scrollTo=oJ8EFTtlwGBa\n\nhttps://plotly.com/python/\n\nhttps://www.python-graph-gallery.com/\n\nhttps://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide\n\nhttps://seaborn.pydata.org/index.html"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}