{"cells": [{"cell_type": "code", "execution_count": 1, "id": "eca427f5", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import log_loss, mean_squared_error, roc_auc_score\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "a34ebc70", "metadata": {}, "outputs": [], "source": ["df_train = pd.read_csv('../input/titanic/train.csv', index_col=0)\ndf_test = pd.read_csv('../input/titanic/test.csv')\n\ndf_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d3d6fc93", "metadata": {}, "outputs": [], "source": ["df_test.head()"]}, {"cell_type": "markdown", "id": "858d1395", "metadata": {}, "source": ["## Learning More About the data"]}, {"cell_type": "code", "execution_count": 1, "id": "1e7d19b8", "metadata": {}, "outputs": [], "source": ["df_train.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "eefbb1eb", "metadata": {}, "outputs": [], "source": ["df_test.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "56fe7933", "metadata": {}, "outputs": [], "source": ["df_train.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "e87bf429", "metadata": {}, "outputs": [], "source": ["df_train[df_train.duplicated()]"]}, {"cell_type": "code", "execution_count": 1, "id": "c4435eae", "metadata": {}, "outputs": [], "source": ["df_test[df_test.duplicated()]"]}, {"cell_type": "code", "execution_count": 1, "id": "0a61fbe1", "metadata": {}, "outputs": [], "source": ["df_train.groupby(['Survived']).count()"]}, {"cell_type": "code", "execution_count": 1, "id": "646f7f67", "metadata": {}, "outputs": [], "source": ["df_train.nunique()"]}, {"cell_type": "code", "execution_count": 1, "id": "1201520d", "metadata": {}, "outputs": [], "source": ["df_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "55e61bdd", "metadata": {}, "outputs": [], "source": ["df_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "8eff9d89", "metadata": {}, "outputs": [], "source": ["print('Missing values in train dataset:', df_train.isna().sum()) \nprint('-----------------------------------')\nprint('Missing values in test dataset:', df_test.isna().sum())"]}, {"cell_type": "code", "execution_count": 1, "id": "5588c720", "metadata": {}, "outputs": [], "source": ["features= df_train.drop(['Survived', 'Cabin', 'Name'], axis= 1)\ny= df_train['Survived']"]}, {"cell_type": "code", "execution_count": 1, "id": "f08affaa", "metadata": {}, "outputs": [], "source": ["numerical_features = [cname for cname in features.columns if (features[cname].dtype == \"int64\" or features[cname].dtype == \"float64\")]\nprint(\"Numerical Columns =\", numerical_features)"]}, {"cell_type": "code", "execution_count": 1, "id": "cb643cba", "metadata": {}, "outputs": [], "source": ["n_features = [cname for cname in df_train.columns if (df_train[cname].dtype == \"int64\" or df_train[cname].dtype == \"float64\")]\nprint(\"Numerical Columns =\", n_features)"]}, {"cell_type": "code", "execution_count": 1, "id": "ad32a028", "metadata": {}, "outputs": [], "source": ["categorical_features = [cname for cname in features.columns if features[cname].dtype == \"object\"]\nprint(\"Categorical Columns =\", categorical_features)"]}, {"cell_type": "code", "execution_count": 1, "id": "5d87eb42", "metadata": {}, "outputs": [], "source": ["for col in numerical_features:\n    fig = plt.figure(figsize=(9, 4))\n    sns.kdeplot(df_train[col], shade=True, edgecolor='black', linewidth=1.5, alpha=0.9, zorder=3)\n    plt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "c3907318", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(9, 4))\nchart_df = pd.DataFrame(df_train['Survived'].value_counts() / len(df_train) * 100)\nsns.barplot(x=chart_df.index, y=chart_df['Survived'], zorder=3, edgecolor='black', linewidth=1.5)"]}, {"cell_type": "code", "execution_count": 1, "id": "a48b42b7", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(20, 10))\nsns.heatmap(df_train[n_features].corr(), vmin=-1, vmax=1, annot=True, square=True, \n            cbar_kws={\"orientation\": \"horizontal\"}, cbar=False, fmt='.1g')"]}, {"cell_type": "code", "execution_count": 1, "id": "7178f785", "metadata": {}, "outputs": [], "source": ["all_data = pd.concat([df_train, df_test])\n\nfig, ax = plt.subplots(3, 2, figsize=(14, 12))\nfor i, feature in enumerate(n_features):\n    plt.subplot(3, 2, i+1)\n    sns.histplot(all_data[feature], \n                 color=\"blue\", \n                 kde=True, \n                 bins=100)\n    plt.xlabel(feature, fontsize=9)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "b83ef88c", "metadata": {}, "outputs": [], "source": ["numerical_transformer_steps = [\n    ('imputer', SimpleImputer(strategy= 'median')),\n    ('scaler', StandardScaler())]\nnumerical_transformer= Pipeline(steps= numerical_transformer_steps)\n\n\ncategorical_transformer_steps= [\n    ('imputer', SimpleImputer(strategy= 'constant', fill_value= 'missing')),\n    ('onehot', OneHotEncoder(handle_unknown= 'ignore'))\n]\ncategorical_transformer= Pipeline(steps= categorical_transformer_steps)\n\n\ncol_transformers= [\n    ('num', numerical_transformer, numerical_features),\n    ('cat', categorical_transformer, categorical_features)\n]\npreprocessor= ColumnTransformer(transformers= col_transformers)"]}, {"cell_type": "code", "execution_count": 1, "id": "007b0d7f", "metadata": {}, "outputs": [], "source": ["X_train, X_val, y_train, y_val= train_test_split(features, y, test_size= 0.2, random_state= 12)"]}, {"cell_type": "code", "execution_count": 1, "id": "05603718", "metadata": {}, "outputs": [], "source": ["# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n# Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n}\n# XGBOOST parameters\nxgb_params= {\n    #learning_rate = 0.02,\n     'n_estimators': 2000,\n     'max_depth': 4,\n     'min_child_weight': 2,\n     #'gamma': 1,\n     'gamma': 0.9,                        \n     'subsample': 0.8,\n     'colsample_bytree': 0.8,\n     'objective': 'binary:logistic',\n     'nthread': -1,\n     'scale_pos_weight': 1\n}\n"]}, {"cell_type": "code", "execution_count": 1, "id": "613dedfc", "metadata": {}, "outputs": [], "source": ["et = ExtraTreesClassifier(**et_params)\nrf = RandomForestClassifier(**rf_params)\nsvc= SVC(**svc_params)\ngbm= xgb.XGBClassifier(**xgb_params)"]}, {"cell_type": "code", "execution_count": 1, "id": "df624a6e", "metadata": {}, "outputs": [], "source": ["model_et= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', et)\n])\nmodel_et.fit(X_train, y_train)\npreds_et = model_et.predict(X_val)\nmodel_et.score(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "7e7b396b", "metadata": {}, "outputs": [], "source": ["model_rf= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', rf)\n])\nmodel_rf.fit(X_train, y_train)\npreds_rf = model_rf.predict(X_val)\nmodel_rf.score(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "568ba9b4", "metadata": {}, "outputs": [], "source": ["model_svc= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', svc)\n])\nmodel_svc.fit(X_train, y_train)\npreds_svc = model_svc.predict(X_val)\nmodel_svc.score(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "6cef4dc4", "metadata": {}, "outputs": [], "source": ["model_gbm= Pipeline(steps= [\n    ('preprocessor', preprocessor),\n    ('clf', gbm)\n])\nmodel_gbm.fit(X_train, y_train)\npreds_gbm = model_gbm.predict(X_val)\nmodel_gbm.score(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "2d91db9b", "metadata": {}, "outputs": [], "source": ["test_features= df_test.drop(['Cabin', 'Name'], axis= 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "2ed430ba", "metadata": {}, "outputs": [], "source": ["y_pred= model_gbm.predict(test_features)"]}, {"cell_type": "code", "execution_count": 1, "id": "e8c8b15b", "metadata": {}, "outputs": [], "source": ["submission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": y_pred\n    })"]}, {"cell_type": "code", "execution_count": 1, "id": "f1262eec", "metadata": {}, "outputs": [], "source": ["submission.to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}