{"cells": [{"cell_type": "code", "execution_count": 1, "id": "6c99b421", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "f8747beb", "metadata": {}, "outputs": [], "source": ["id_train=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nid_test=pd.read_csv(\"/kaggle/input/titanic/test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4b701aaf", "metadata": {}, "outputs": [], "source": ["id_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "980ca065", "metadata": {}, "outputs": [], "source": ["id_train.drop([\"Name\",\"PassengerId\",'Cabin'],axis=1,inplace=True)\nid_test.drop([\"Name\",'Cabin'],axis=1,inplace=True)\n\nprint(id_train.isnull().sum())\nid_test.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "5c463bb1", "metadata": {}, "outputs": [], "source": ["print(id_train.Sex.value_counts())\nprint(id_test.Sex.value_counts())\n\nid_train['Sex']=id_train['Sex'].replace(['male','female'],[1,0])\nid_test['Sex']=id_test['Sex'].replace(['male','female'],[1,0])"]}, {"cell_type": "code", "execution_count": 1, "id": "59e8656f", "metadata": {}, "outputs": [], "source": ["print(id_train.info())\nprint(id_test.info())"]}, {"cell_type": "code", "execution_count": 1, "id": "0425efa5", "metadata": {}, "outputs": [], "source": ["id_train.describe()\n\n## includez only non object type column"]}, {"cell_type": "code", "execution_count": 1, "id": "69b475ff", "metadata": {}, "outputs": [], "source": ["id_train.describe(include=['O'])"]}, {"cell_type": "code", "execution_count": 1, "id": "ab544efd", "metadata": {}, "outputs": [], "source": ["id_train['Pclass'].value_counts()\n\n## many passengers were in the 3rd class\n## and less in 1st class"]}, {"cell_type": "code", "execution_count": 1, "id": "8533c27b", "metadata": {}, "outputs": [], "source": ["## lets see the survival rate with sex,SidSp, Parch and plcass with survived"]}, {"cell_type": "code", "execution_count": 1, "id": "fa0d1d29", "metadata": {}, "outputs": [], "source": ["id_train[['Sex','Survived']].groupby(['Sex']).mean().sort_values(by='Survived')\n\n## 0 is female\n## 1 is male"]}, {"cell_type": "code", "execution_count": 1, "id": "48350850", "metadata": {}, "outputs": [], "source": ["id_train[['SibSp','Survived']].groupby(['SibSp']).mean().sort_values(by='Survived',ascending=False)\n\n## less the number of siblings onboard, more the probability of survival"]}, {"cell_type": "code", "execution_count": 1, "id": "adb98f5b", "metadata": {}, "outputs": [], "source": ["id_train[['Parch','Survived']].groupby(['Parch']).mean().sort_values(by='Survived',ascending=False)\n\n## more the children : less the survival probability"]}, {"cell_type": "code", "execution_count": 1, "id": "fed98a45", "metadata": {}, "outputs": [], "source": ["id_train[['Pclass','Survived']].groupby(['Pclass']).mean().sort_values(by='Survived',ascending=False)\n\n## better the class : more the survival chances"]}, {"cell_type": "markdown", "id": "5abd24fe", "metadata": {}, "source": ["#  **lets visualize the data**"]}, {"cell_type": "code", "execution_count": 1, "id": "3d3d0d58", "metadata": {}, "outputs": [], "source": ["import seaborn as sns\nimport matplotlib.pyplot as plt\n\nv = sns.FacetGrid(id_train,col='Survived')\nv.map(plt.hist,'Age',bins=15)"]}, {"cell_type": "markdown", "id": "b133af1a", "metadata": {}, "source": ["observation from above :\n1. infants (age<=6) have high survival chances\n2. Oldest passengers (age>75) survived.\n3. age group between (15-30) survived less.\n"]}, {"cell_type": "markdown", "id": "7e1a78d9", "metadata": {}, "source": ["## lets do the survived vs age with respect to pclass"]}, {"cell_type": "code", "execution_count": 1, "id": "20593960", "metadata": {}, "outputs": [], "source": ["v = sns.FacetGrid(id_train,row='Survived',col='Pclass')\nv.map(plt.hist,'Age',bins=15)"]}, {"cell_type": "markdown", "id": "513c0d22", "metadata": {}, "source": ["From above graph :\nPclass==1 : survived the most."]}, {"cell_type": "code", "execution_count": 1, "id": "efb84dda", "metadata": {}, "outputs": [], "source": ["\nv = sns.FacetGrid(id_train,col='Embarked')\nv.map(sns.pointplot,'Pclass','Survived','Sex',palette='deep')\nv.add_legend()\n\n## 0 is female\n## 1 is male"]}, {"cell_type": "markdown", "id": "82874283", "metadata": {}, "source": ["## Observation\n\n1. Overall, Females have high survival chances.\n2. Males of pclass 2 in Embarked==\"C\" have higher survival chances than females in that category."]}, {"cell_type": "code", "execution_count": 1, "id": "1596b2cd", "metadata": {}, "outputs": [], "source": ["v=sns.FacetGrid(id_train,col='Embarked',row='Survived')\nv.map(sns.barplot,'Sex','Fare')"]}, {"cell_type": "markdown", "id": "81bfe333", "metadata": {}, "source": ["## Observation\n1. Higher fare paying people have more chances of survival"]}, {"cell_type": "code", "execution_count": 1, "id": "8784d92a", "metadata": {}, "outputs": [], "source": ["## from above observations, Age and Cabin have null value.\n## lets fill those Na values by mean\n\nid_train['Age'].fillna(id_train['Age'].mean(),inplace=True)\nid_test['Age'].fillna(id_test['Age'].median(),inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "bfefadd3", "metadata": {}, "outputs": [], "source": ["id_train.drop(\"Ticket\",axis=1,inplace=True)\nid_test.drop(\"Ticket\",axis=1,inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "45c644c8", "metadata": {}, "outputs": [], "source": ["id_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "409470b6", "metadata": {}, "outputs": [], "source": ["## lets see the different age bands survival\n\nid_train['ageband'] = pd.cut(id_train['Age'],5)\nid_train[['ageband','Survived']].groupby('ageband').mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "3a1732a6", "metadata": {}, "outputs": [], "source": ["## lets convert the ages into groups for id_train\ndataset=id_train\ndataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\ndataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\ndataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\ndataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\ndataset.loc[ dataset['Age'] > 64, 'Age']\n\nid_train=dataset\nid_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d6c51f8c", "metadata": {}, "outputs": [], "source": ["## lets convert the ages into groups for id_test \ndataset=id_test\ndataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\ndataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\ndataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\ndataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\ndataset.loc[ dataset['Age'] > 64, 'Age']\n\nid_test=dataset\nid_test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "fff1e027", "metadata": {}, "outputs": [], "source": ["id_train.drop('ageband',axis=1,inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "4dabb6e3", "metadata": {}, "outputs": [], "source": ["## lets create a new column of family size\n\nid_train['family'] = id_train['Parch'] + id_train['SibSp'] + 1 \n\n## for idtest\nid_test['family'] = id_test['Parch'] + id_test['SibSp'] + 1 \n\nid_train[['family','Survived']].groupby(\"family\").mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "08926769", "metadata": {}, "outputs": [], "source": ["id_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "bbeb64cb", "metadata": {}, "outputs": [], "source": ["## if family is there : means ge is not alone\n\n\nid_train['alone']=0\n\nid_train.loc[id_train['family']==1,'alone']=1\n\nid_train[['alone','Survived']].groupby(\"alone\").mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "ed823ead", "metadata": {}, "outputs": [], "source": ["## for idtest\n\n## if family is there : means ge is not alone\n\nid_test['alone']=0\n\nid_test.loc[id_test['family']==1,'alone']=1\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ec62af13", "metadata": {}, "outputs": [], "source": ["id_train = id_train.drop(['Parch', 'SibSp', 'family'], axis=1)\nid_test = id_test.drop(['Parch', 'SibSp', 'family'], axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "d16e0d2b", "metadata": {}, "outputs": [], "source": ["## embarked col has null values\n## fill the na values with the most occurening embarking port\n\nprint(id_train['Embarked'].value_counts())\nid_train['Embarked'] = id_train['Embarked'].fillna(('S'))"]}, {"cell_type": "code", "execution_count": 1, "id": "065220ee", "metadata": {}, "outputs": [], "source": ["id_train[['Embarked','Survived']].groupby([\"Embarked\"]).mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "72cd6f76", "metadata": {}, "outputs": [], "source": ["## lets replace S:0; C:1; Q:2 in Embarked ports\n\nid_train['Embarked'] = id_train['Embarked'].replace(['S','C','Q'],[0,1,2])\nid_train['Embarked'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "7d3d0d78", "metadata": {}, "outputs": [], "source": ["## lets replace S:0; C:1; Q:2 in Embarked ports in idtest\n\nid_test['Embarked'] = id_test['Embarked'].replace(['S','C','Q'],[0,1,2])\nid_test['Embarked'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "9a0a6022", "metadata": {}, "outputs": [], "source": ["id_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "85f479f3", "metadata": {}, "outputs": [], "source": ["id_test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "fffe19a6", "metadata": {}, "outputs": [], "source": ["## lets create the band price for fare\n\nid_train['fareband'] = pd.qcut(id_train['Fare'],4)\n\nid_train[['fareband','Survived']].groupby([\"fareband\"]).mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "81903c79", "metadata": {}, "outputs": [], "source": ["dataset=id_train\n\ndataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\ndataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\ndataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\ndataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\ndataset['Fare'] = dataset['Fare'].astype(int)\n\nid_train = dataset\n\nid_train.drop(\"fareband\",axis=1,inplace=True)\n\nid_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "95014441", "metadata": {}, "outputs": [], "source": ["\n## theres null value in idtest['Fare']\nid_test['Fare'].fillna(id_test['Fare'].mean(),inplace=True)\n\n## fareband for idtest\n\ndataset=id_test\n\ndataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\ndataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\ndataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\ndataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\ndataset['Fare'] = dataset['Fare'].astype(int)\n\nid_test = dataset\nid_test.head()"]}, {"cell_type": "markdown", "id": "1eb44c49", "metadata": {}, "source": ["# Model Development"]}, {"cell_type": "code", "execution_count": 1, "id": "59a45944", "metadata": {}, "outputs": [], "source": ["xtrain = id_train.drop('Survived',axis=1)\nytrain = id_train['Survived']\nxtest = id_test.drop(\"PassengerId\",axis=1).copy()\n\nxtrain.shape, ytrain.shape,xtest.shape"]}, {"cell_type": "markdown", "id": "626b9d17", "metadata": {}, "source": ["## Logistic regression"]}, {"cell_type": "code", "execution_count": 1, "id": "5fb7e346", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(xtrain,ytrain)\ny_pred = logreg.predict(xtest)\n\nlog_score=logreg.score(xtrain,ytrain)\nlog_score"]}, {"cell_type": "code", "execution_count": 1, "id": "e52f39a5", "metadata": {}, "outputs": [], "source": ["coeff_df = pd.DataFrame(id_train.columns.delete(0))\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)"]}, {"cell_type": "markdown", "id": "915701f5", "metadata": {}, "source": ["## SVC"]}, {"cell_type": "code", "execution_count": 1, "id": "10739e36", "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC, LinearSVC\n\nsvc=SVC()\nsvc.fit(xtrain,ytrain)\ny_pred = svc.predict(xtest)\n\nsvc_score=svc.score(xtrain,ytrain)\nsvc_score"]}, {"cell_type": "markdown", "id": "d73fad4f", "metadata": {}, "source": ["## KNN"]}, {"cell_type": "code", "execution_count": 1, "id": "7bc9218d", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\n\nknn=KNeighborsClassifier(n_neighbors=3)\nknn.fit(xtrain,ytrain)\ny_pred = knn.predict(xtest)\n\nknn_score=knn.score(xtrain,ytrain)\nknn_score"]}, {"cell_type": "markdown", "id": "e6c1442c", "metadata": {}, "source": ["## Naive Bayes"]}, {"cell_type": "code", "execution_count": 1, "id": "025e495d", "metadata": {}, "outputs": [], "source": ["from sklearn.naive_bayes import GaussianNB\n\ngauss = GaussianNB()\ngauss.fit(xtrain,ytrain)\ny_pred = gauss.predict(xtest)\n\ngauss_score=gauss.score(xtrain,ytrain)\ngauss_score"]}, {"cell_type": "markdown", "id": "9a650a8e", "metadata": {}, "source": ["## Linear SVC"]}, {"cell_type": "code", "execution_count": 1, "id": "d4e8565f", "metadata": {}, "outputs": [], "source": ["\n\nsvc=LinearSVC()\nsvc.fit(xtrain,ytrain)\ny_pred=svc.predict(xtest)\n\nlin_svc_score=svc.score(xtrain,ytrain)\nlin_svc_score"]}, {"cell_type": "markdown", "id": "fcac6e45", "metadata": {}, "source": ["## SGD"]}, {"cell_type": "code", "execution_count": 1, "id": "7b2f4657", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import SGDClassifier\n\nsgd=SGDClassifier()\nsgd.fit(xtrain,ytrain)\ny_pred = sgd.predict(xtest)\n\nsgd_score=sgd.score(xtrain,ytrain)\nsgd_score"]}, {"cell_type": "markdown", "id": "cca45d9d", "metadata": {}, "source": ["## Decision Tree"]}, {"cell_type": "code", "execution_count": 1, "id": "753f8e81", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(xtrain,ytrain)\ny_pred = dt.predict(xtest)\n\ndt_score=dt.score(xtrain,ytrain)\ndt_score"]}, {"cell_type": "markdown", "id": "a6672cb0", "metadata": {}, "source": ["## RandomForest"]}, {"cell_type": "code", "execution_count": 1, "id": "214780be", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(xtrain,ytrain)\ny_pred_rf = rf.predict(xtest)\n\nrf_score=rf.score(xtrain,ytrain)\nrf_score"]}, {"cell_type": "markdown", "id": "1b508ebd", "metadata": {}, "source": ["## CNN Model"]}, {"cell_type": "code", "execution_count": 1, "id": "d3810e65", "metadata": {}, "outputs": [], "source": ["xtrain.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "9a6e28fc", "metadata": {}, "outputs": [], "source": ["from tensorflow import keras\n\nmodel = keras.Sequential([\n    \n    ## reshaping the input entries\n    keras.layers.Dense(50, input_shape=(6,), activation='relu'),  \n    keras.layers.Dropout(0.50),    ## to avoid overfitting and underfiting\n\n    ## creating the hidden layer\n    keras.layers.Dense(100,activation='relu'),\n    keras.layers.Dropout(0.70),    ##  to avoid overfitting and underfiting\n    \n    keras.layers.Dense(150,activation='relu'),\n    keras.layers.Dropout(0.70),     ## to avoid overfitting and underfiting\n \n    \n    ## final neural layer\n    keras.layers.Dense(1,activation='sigmoid')\n    \n])\n\n\nmodel.compile(optimizer='adam',\n             loss='binary_crossentropy',  ## since output in 0 or 1\n             metrics=['accuracy'])"]}, {"cell_type": "code", "execution_count": 1, "id": "4136eeec", "metadata": {}, "outputs": [], "source": ["model.fit(xtrain,ytrain,epochs=100)\n\ny_pred_cnn = model.predict(xtest)\n\ncnn_score = model.evaluate(xtrain,ytrain)[1]\ncnn_score"]}, {"cell_type": "code", "execution_count": 1, "id": "fb7406d5", "metadata": {}, "outputs": [], "source": ["models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree',\"CNN\"],\n    'Score': [svc_score, knn_score, log_score, \n              rf_score, gauss_score, \n              sgd_score, lin_svc_score, dt_score,cnn_score]})\nmodels.sort_values(by='Score', ascending=False)"]}, {"cell_type": "markdown", "id": "573ad85f", "metadata": {}, "source": ["Random Forest has the highest accuracy.\nso we will submit the y_predicted value using random forest model"]}, {"cell_type": "code", "execution_count": 1, "id": "92463789", "metadata": {}, "outputs": [], "source": ["submission = pd.DataFrame({\n        \"PassengerId\": id_test[\"PassengerId\"],\n        \"Survived\": y_pred_rf\n    })\n\nsubmission = submission.to_csv('submission.csv',index=False)\n\n\n\n\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}