{"cells": [{"cell_type": "code", "execution_count": 1, "id": "732c1859", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "ccf7c077", "metadata": {}, "source": ["\u042d\u0442\u043e \u0434\u0435\u043c\u043e\u043d\u0441\u0442\u0440\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u0431\u043b\u043e\u043a\u043d\u043e\u0442 \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0441\u0432\u043e\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 Gensim fasttext \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0440\u0443\u0441\u0441\u043a\u043e\u044f\u0437\u044b\u0447\u043d\u043e\u0433\u043e \u043a\u043e\u0440\u043f\u0443\u0441\u0430. \u0412 \u043a\u043e\u0434\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u044b \u0432\u0441\u0435\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0438\u0437 \u043e\u0442\u043a\u0440\u044b\u0442\u044b\u0445 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u043e\u0432."]}, {"cell_type": "markdown", "id": "e7ad41cb", "metadata": {}, "source": ["\u041d\u0430 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u043c \u0448\u0430\u0433\u0435 \u0431\u044b\u043b\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u044b \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435. \n\n1) \u041d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0444\u0430\u0439\u043b\u043e\u0432 \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 .pdf \u0431\u044b\u043b\u0438 \u0441\u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u044b \u0432 \u0444\u043e\u0440\u043c\u0430\u0442 .txt \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043a\u043e\u043c\u0430\u043d\u0434\u044b \u0432 bash:\n\n> sudo apt-get update && sudo apt-get install -y xpdf\n> for file in *.pdf; do pdftotext \"$file\" \"$file.txt\"; done\n\n2) \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u043e\u0434\u0438\u043d \u0444\u0430\u0439\u043b \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043a\u043e\u043c\u0430\u043d\u0434\u044b \u0432 bash:\n\n> find . -type f -name \"*\" -exec cat >> wrk.txt {} \\;\n"]}, {"cell_type": "markdown", "id": "b74bcaaf", "metadata": {}, "source": ["\u0422\u0435\u043f\u0435\u0440\u044c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0445 \u043f\u0440\u043e\u0446\u0435\u0434\u0443\u0440 \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u043c \u0442\u0435\u043a\u0441\u0442."]}, {"cell_type": "markdown", "id": "5b28bf0e", "metadata": {}, "source": ["\u041f\u043e\u0434\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0431\u0438\u0431\u0438\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0438 \u0434\u0430\u043d\u043d\u044b\u0435:"]}, {"cell_type": "code", "execution_count": 1, "id": "b2ee5446", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": 1, "id": "062af199", "metadata": {}, "outputs": [], "source": ["import nltk.data\nfrom nltk import tokenize"]}, {"cell_type": "code", "execution_count": 1, "id": "d336b804", "metadata": {}, "outputs": [], "source": ["import logging  # Setting up the loggings to monitor gensim\nlogging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"]}, {"cell_type": "code", "execution_count": 1, "id": "b1a0fca9", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "b2ecd31b", "metadata": {}, "outputs": [], "source": ["import nltk"]}, {"cell_type": "code", "execution_count": 1, "id": "37dd55f5", "metadata": {}, "outputs": [], "source": ["import multiprocessing\nfrom gensim.models.fasttext import FastText\nfrom time import time\nimport gensim"]}, {"cell_type": "code", "execution_count": 1, "id": "99c6652e", "metadata": {}, "outputs": [], "source": ["from sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm"]}, {"cell_type": "code", "execution_count": 1, "id": "89b9536f", "metadata": {}, "outputs": [], "source": ["tokenizer = nltk.data.load('tokenizers/punkt/russian.pickle')\n\nfp = open('../input/gensim-fasttext-training-corpus-for-demo-only/wrk.txt', encoding='utf-8-sig', errors='ignore')\n\ndata = fp.read()\n\nx = tokenizer.tokenize(data)\n\ndf = pd.DataFrame(x, columns=['text'])"]}, {"cell_type": "markdown", "id": "02fe3b1a", "metadata": {}, "source": ["\u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043f\u0440\u043e\u0431\u0435\u043b\u044b \u043c\u0435\u0436\u0434\u0443 \u0441\u043b\u043e\u0432\u0430\u043c\u0438 \u0438 \u0437\u043d\u0430\u043a\u0430\u043c\u0438 \u043f\u0440\u0435\u043f\u0438\u043d\u0430\u043d\u0438\u044f:"]}, {"cell_type": "code", "execution_count": 1, "id": "92e2d4b1", "metadata": {}, "outputs": [], "source": ["text = df[\"text\"].str.replace(r'([^\\w\\s]+)', ' \\\\1 ').str.strip()"]}, {"cell_type": "markdown", "id": "c32dbf67", "metadata": {}, "source": ["\u0421\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0438 \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445:"]}, {"cell_type": "code", "execution_count": 1, "id": "629b43eb", "metadata": {}, "outputs": [], "source": ["type(text)"]}, {"cell_type": "code", "execution_count": 1, "id": "f7fe7e96", "metadata": {}, "outputs": [], "source": ["len(text)"]}, {"cell_type": "code", "execution_count": 1, "id": "3292b7f4", "metadata": {}, "outputs": [], "source": ["text[:20]"]}, {"cell_type": "markdown", "id": "9d0c762d", "metadata": {}, "source": ["\u0417\u0430\u043c\u0435\u0442\u043d\u043e, \u0447\u0442\u043e \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0443\u0436\u043d\u043e \u043a\u0430\u043a \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c."]}, {"cell_type": "markdown", "id": "41184bbf", "metadata": {}, "source": ["\u041f\u0440\u0438\u0432\u043e\u0434\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u043d\u0443\u0436\u043d\u044b\u0439 \u043d\u0430\u043c \u0441\u0442\u0440\u043e\u043a\u043e\u0432\u044b\u0439 \u0444\u043e\u0440\u043c\u0430\u0442:"]}, {"cell_type": "code", "execution_count": 1, "id": "1a73037c", "metadata": {}, "outputs": [], "source": ["text = text.astype(str)"]}, {"cell_type": "markdown", "id": "331399a4", "metadata": {}, "source": ["\u041f\u0440\u0438\u0432\u043e\u0434\u0438\u043c \u0441\u043b\u043e\u0432\u0430 \u043a \u043d\u0438\u0436\u043d\u0435\u043c\u0443 \u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0443:"]}, {"cell_type": "code", "execution_count": 1, "id": "73cc226c", "metadata": {}, "outputs": [], "source": ["text = text.str.lower()"]}, {"cell_type": "code", "execution_count": 1, "id": "8fe2b4c0", "metadata": {}, "outputs": [], "source": ["text = \" \".join(map(str, (review for review in text)))\nprint (\"There are {} words in the combination of all review.\".format(len(text)))"]}, {"cell_type": "markdown", "id": "6ec06b6f", "metadata": {}, "source": ["\u0422\u0435\u043f\u0435\u0440\u044c \u0442\u043e\u043a\u0435\u043d\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0442\u0435\u043a\u0441\u0442:"]}, {"cell_type": "code", "execution_count": 1, "id": "f6cf665e", "metadata": {}, "outputs": [], "source": ["WORD = re.compile(r'\\w+')\ndef regTokenize(text):\n    words = WORD.findall(text)\n    return words"]}, {"cell_type": "code", "execution_count": 1, "id": "b31a6d66", "metadata": {}, "outputs": [], "source": ["text_tokens = regTokenize(text)"]}, {"cell_type": "code", "execution_count": 1, "id": "4a6f6dde", "metadata": {}, "outputs": [], "source": ["text = nltk.Text(text_tokens)\nprint(type(text))\ntext[:10]"]}, {"cell_type": "markdown", "id": "49b8cee0", "metadata": {}, "source": ["\u0422\u0435\u043f\u0435\u0440\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0437\u0430\u043c\u0435\u0442\u043d\u043e \u043b\u0443\u0447\u0448\u0435."]}, {"cell_type": "code", "execution_count": 1, "id": "e17b120b", "metadata": {}, "outputs": [], "source": ["text_raw = \" \".join(text)"]}, {"cell_type": "code", "execution_count": 1, "id": "90e43710", "metadata": {}, "outputs": [], "source": ["textfile = open('text.txt', 'w')\ntextfile.write(text_raw)\ntextfile.close()"]}, {"cell_type": "markdown", "id": "10d17135", "metadata": {}, "source": ["\u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438:"]}, {"cell_type": "code", "execution_count": 1, "id": "6675b98e", "metadata": {}, "outputs": [], "source": ["data = gensim.models.word2vec.LineSentence('text.txt')"]}, {"cell_type": "markdown", "id": "9a024922", "metadata": {}, "source": ["\u0418 \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u043d\u0443\u0436\u043d\u044b\u043c\u0438 \u043d\u0430\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 (\u0432 \u043f\u0440\u0438\u043c\u0435\u0440\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442\u0441\u044f \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f)"]}, {"cell_type": "code", "execution_count": 1, "id": "aa9faf91", "metadata": {}, "outputs": [], "source": ["%%time\nft_model = FastText(data, vector_size=100, window=5, min_count=5, workers=4,sg=1)"]}, {"cell_type": "markdown", "id": "2fc6f4ac", "metadata": {}, "source": ["\u0415\u0441\u043b\u0438 \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c, \u0442\u043e \u0432\u043c\u0435\u0441\u0442\u043e \u043a\u043e\u0434\u0430 \u0432 \u044f\u0447\u0435\u0439\u043a\u0435 \u0432\u044b\u0448\u0435 \u043d\u0443\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u044d\u0442\u043e:\n\n> %%time\n\n> ft_model = FastText.load(\"ft_model.model\")\n\n> t = time()\n\n> ft_model.build_vocab(data, progress_per=10000, update=True)\n\n> print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n\n> ft_model.train(data, total_examples=ft_model.corpus_count, epochs=5, report_delay=1)\n\n> print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"]}, {"cell_type": "markdown", "id": "2b4bf454", "metadata": {}, "source": ["\u0421\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c:"]}, {"cell_type": "code", "execution_count": 1, "id": "76926fc6", "metadata": {}, "outputs": [], "source": ["ft_model.save(\"ft_model.model\")"]}, {"cell_type": "markdown", "id": "38f8db79", "metadata": {}, "source": ["\u0422\u0435\u043f\u0435\u0440\u044c \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u043e \u043d\u0430\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044e: \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u0442\u044c \u0441\u043b\u043e\u0432\u0430 \u043d\u0430 \u0441\u0445\u043e\u0434\u0441\u0442\u0432\u043e, \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0433\u0440\u0443\u043f\u043f\u044b \u0441\u043b\u043e\u0432 \u0438 \u0442\u0430\u043a \u0434\u0430\u043b\u0435\u0435:"]}, {"cell_type": "code", "execution_count": 1, "id": "44e57fc2", "metadata": {}, "outputs": [], "source": ["ft_model.wv.most_similar(positive=[\"\u0444\u0430\u043a\u0442\"], topn=20)"]}, {"cell_type": "code", "execution_count": 1, "id": "935f8c6e", "metadata": {}, "outputs": [], "source": ["ft_model.wv.similarity(\"\u0444\u0430\u043a\u0442\", '\u0442\u0435\u043e\u0440\u0438\u044f')"]}, {"cell_type": "code", "execution_count": 1, "id": "61292336", "metadata": {}, "outputs": [], "source": ["ft_model.wv.doesnt_match([\"\u0441\u0443\u0431\u044a\u0435\u043a\u0442\", '\u043e\u0431\u044a\u0435\u043a\u0442', '\u0430\u0440\u0442\u0435\u0444\u0430\u043a\u0442'])"]}, {"cell_type": "code", "execution_count": 1, "id": "504cb8c9", "metadata": {}, "outputs": [], "source": ["ft_model.wv.most_similar(positive=[\"\u0441\u0443\u0431\u044a\u0435\u043a\u0442\", '\u043e\u0431\u044a\u0435\u043a\u0442'], negative=['\u0430\u0440\u0442\u0435\u0444\u0430\u043a\u0442'], topn=20)"]}, {"cell_type": "code", "execution_count": 1, "id": "2065a18b", "metadata": {}, "outputs": [], "source": ["def tsne_plot(labels, tokens, classes, clusters):\n    tsne_model = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=33)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n\n    colors = cm.rainbow(np.linspace(0, 1, clusters))\n    \n    plt.figure(figsize=(16, 9))\n    for i in range(len(x)):\n        plt.scatter(x[i], y[i], c=colors[classes[i]].reshape(1,-1), alpha=0.75)\n        plt.annotate(labels[i], alpha=0.75, xy=(x[i], y[i]), xytext=(5, 2), \n                     textcoords='offset points', ha='right', va='bottom', size=10)\n        \n    plt.grid(True)\n    plt.savefig('embedding.png', dpi=300)\n    plt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "d93a216a", "metadata": {}, "outputs": [], "source": ["labels = []\ntokens = []\nclasses = []\n\nwords = ['\u0442\u0435\u043e\u0440\u0438\u044f',  '\u0444\u0430\u043a\u0442', '\u0441\u0443\u0431\u044a\u0435\u043a\u0442', '\u043e\u0431\u044a\u0435\u043a\u0442', '\u0430\u0440\u0442\u0435\u0444\u0430\u043a\u0442']\n                   \nwords.sort()\n\nsamples = len(words)\nfor i, word in enumerate(words):\n    tokens.append(ft_model.wv[word])\n    labels.append(word.upper())\n    classes.append(i)\n    for similar_word, similarity in ft_model.wv.most_similar(word, topn=10):\n        tokens.append(ft_model.wv[similar_word])\n        labels.append(similar_word)\n        classes.append(i)"]}, {"cell_type": "code", "execution_count": 1, "id": "36ef8c6b", "metadata": {}, "outputs": [], "source": ["tsne_plot(labels, tokens, classes, samples)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}