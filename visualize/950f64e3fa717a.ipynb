{"cells": [{"cell_type": "markdown", "id": "7c293d93", "metadata": {}, "source": ["# Introduction\nHello people, welcome to my kernel. In this kernel I'll examine the dataset and after that, I will train a neural network using the dataset. Before the start, let's take a look at the content\n\n# Content\n1. Importing Libraries and The Data\n1. Data Overview\n1. Simple Data Analyses\n    * Examining Pragnancies Feature\n    * Examining Glucose Feature\n    * Examining Blood Pressure Feature\n    * Examining Skin Thickness Feature\n    * Examining Insulin Feature\n    * Examining BMI Feature\n    * Examining DiabetesPedigreeFunction Feature\n    * Examining Age Feature\n    * Examining Outcome Feature\n1. Outlier Detection\n    * Defining Function\n    * Dropping Outliers\n1. Detailed Data Analyses\n    * Correlation Heatmap\n    * Glucose - Outcome\n    * BMI - Outcome\n    * Age - Outcome\n1. Preprocessing\n    * Preparing Pregnancies Feature\n    * Normalization\n    * Train Test Split\n1. Modeling\n1. Predictinig\n1. Conclusion"]}, {"cell_type": "markdown", "id": "7a431e6c", "metadata": {}, "source": ["# Importing Libraries and The Dataset\n\nIn this section I will import the libraries and the dataset. I am not going to import deep learning libraries, I am going to import them when I will need. "]}, {"cell_type": "code", "execution_count": 1, "id": "627de9a0", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings as wrn\n\nwrn.filterwarnings('ignore')\nsns.set_style(\"whitegrid\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "e2bc64e0", "metadata": {}, "source": ["* And now I'll import the data."]}, {"cell_type": "code", "execution_count": 1, "id": "7147b85d", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\n"]}, {"cell_type": "markdown", "id": "4e9856ff", "metadata": {}, "source": ["# Data Overview\nIn this section I will get a general idea about the dataset."]}, {"cell_type": "code", "execution_count": 1, "id": "7dc74e0f", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "markdown", "id": "9960f7ef", "metadata": {}, "source": ["* There are 9 features in the dataset."]}, {"cell_type": "code", "execution_count": 1, "id": "b519985e", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "markdown", "id": "75f5c2f8", "metadata": {}, "source": ["* All of the features are numerical. 6 of them are int and the rest are float.\n* There is no missing values.\n* There are 768 rows in the dataset."]}, {"cell_type": "markdown", "id": "0d946ee0", "metadata": {}, "source": ["# Simple Data Analyses\n\nIn this section I will examine each feature's value's distribution. In order to do this I am going to use distplots and count plots."]}, {"cell_type": "markdown", "id": "7d4eed46", "metadata": {}, "source": ["## Examining Pregnancies Feature"]}, {"cell_type": "code", "execution_count": 1, "id": "1dc3e37a", "metadata": {}, "outputs": [], "source": ["data[\"Pregnancies\"].value_counts()"]}, {"cell_type": "markdown", "id": "d0597f72", "metadata": {}, "source": ["* Although there are 17 unique values, most of them is 1,0 and 2. \n* We can join 11,12,13,14,15 and 17.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ba9fb176", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()"]}, {"cell_type": "markdown", "id": "20cea5a8", "metadata": {}, "source": ["## Examining Glucose Feature"]}, {"cell_type": "code", "execution_count": 1, "id": "24a1e222", "metadata": {}, "outputs": [], "source": ["data[\"Glucose\"].head()"]}, {"cell_type": "markdown", "id": "877528d5", "metadata": {}, "source": ["* As we can see, glucose data is not categorical, so we should use a distplot for examining it."]}, {"cell_type": "code", "execution_count": 1, "id": "a3ed0947", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize = (10,7))\nsns.distplot(data[\"Glucose\"],color=\"#FE5205\")\nplt.show()"]}, {"cell_type": "markdown", "id": "5a8e4ac2", "metadata": {}, "source": ["* Most of the values are between 70 and 130. "]}, {"cell_type": "markdown", "id": "e6b87f71", "metadata": {}, "source": ["## Examining Blood Pressure Feature"]}, {"cell_type": "markdown", "id": "01ab42c2", "metadata": {}, "source": ["* Let's start with reminding the feature"]}, {"cell_type": "code", "execution_count": 1, "id": "c91b1277", "metadata": {}, "outputs": [], "source": ["data[\"BloodPressure\"].head(10)"]}, {"cell_type": "markdown", "id": "d366ed91", "metadata": {}, "source": ["* This is not a categorical feature as well. \n* So let's use a distplot."]}, {"cell_type": "code", "execution_count": 1, "id": "dc975162", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"BloodPressure\"],color=\"#00B037\")\nplt.show()"]}, {"cell_type": "markdown", "id": "26045147", "metadata": {}, "source": ["* An interesting chart. There are may 0 values in the dataset. However values that between 0 and 40 are very rare.\n* And most of the dataset is between 40 and 100 especially 60 and 80\n"]}, {"cell_type": "markdown", "id": "1efa8986", "metadata": {}, "source": ["## Examining Skin Thickness Feature"]}, {"cell_type": "code", "execution_count": 1, "id": "e6618dfe", "metadata": {}, "outputs": [], "source": ["data[\"SkinThickness\"].head(10)"]}, {"cell_type": "markdown", "id": "d5a02e25", "metadata": {}, "source": ["* This feature is not a categorical like the Blood Pressure and Glucose"]}, {"cell_type": "code", "execution_count": 1, "id": "a6f8a55b", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"SkinThickness\"],color=\"#C0F714\")\nplt.show()"]}, {"cell_type": "markdown", "id": "1ab4859d", "metadata": {}, "source": ["* The values are between 0 and 60. Most of the dataset's value is 0. "]}, {"cell_type": "markdown", "id": "16172480", "metadata": {}, "source": ["## Examining Insulin Feature"]}, {"cell_type": "code", "execution_count": 1, "id": "c1b40605", "metadata": {}, "outputs": [], "source": ["data[\"Insulin\"].head(10)"]}, {"cell_type": "markdown", "id": "754dfe14", "metadata": {}, "source": ["* Most of the dataset's value must be 0."]}, {"cell_type": "code", "execution_count": 1, "id": "32066cfe", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"Insulin\"],color=\"#077F8F\")\nplt.show()"]}, {"cell_type": "markdown", "id": "149045d5", "metadata": {}, "source": ["* Most of the dataset is 0\n* Although they are rare, there are values between 0 and 400.\n"]}, {"cell_type": "markdown", "id": "c987e367", "metadata": {}, "source": ["## Examining BMI Feature\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5cc6d3ae", "metadata": {}, "outputs": [], "source": ["data[\"BMI\"].head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "c18c7922", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(10,7))\nsns.distplot(data[\"BMI\"],color=\"#DB6A14\")\nplt.show()"]}, {"cell_type": "markdown", "id": "8a0be525", "metadata": {}, "source": ["* Not an interesting distplot\n* Most of the values are between 20 and 50."]}, {"cell_type": "markdown", "id": "665bca1d", "metadata": {}, "source": ["## DiabetesPedigreeFunction Feature\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2bbdf039", "metadata": {}, "outputs": [], "source": ["data[\"DiabetesPedigreeFunction\"].head()"]}, {"cell_type": "code", "execution_count": 1, "id": "24ef7828", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"DiabetesPedigreeFunction\"],color=\"#8F105A\")\nplt.show()"]}, {"cell_type": "markdown", "id": "1bfa73f5", "metadata": {}, "source": ["* Although most of the dataset between 0 and 1, there are values between 1 and 2.5"]}, {"cell_type": "markdown", "id": "1e539ec4", "metadata": {}, "source": ["## Examining Age Feature\n"]}, {"cell_type": "code", "execution_count": 1, "id": "910b25f0", "metadata": {}, "outputs": [], "source": ["data[\"Age\"].head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "1967b1c1", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"Age\"],color=\"#DB620D\")\nplt.show()"]}, {"cell_type": "markdown", "id": "38d20c4b", "metadata": {}, "source": ["* Most of the dataset between 20 and 40."]}, {"cell_type": "markdown", "id": "4b36ca50", "metadata": {}, "source": ["## Examining Outcome Feature"]}, {"cell_type": "markdown", "id": "ed242e71", "metadata": {}, "source": ["* Outcome feature is our label.\n* It is a categorical feature, so we can use count plot."]}, {"cell_type": "code", "execution_count": 1, "id": "3b72a2ec", "metadata": {}, "outputs": [], "source": ["data[\"Outcome\"].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "0a66922e", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Outcome\"])\nplt.show()"]}, {"cell_type": "markdown", "id": "a4b79418", "metadata": {}, "source": ["* This is an unbalanced data.\n* Most of the values are 0 \n* They are 500 0 values and 268 1 values."]}, {"cell_type": "markdown", "id": "404d197c", "metadata": {}, "source": ["# Outlier Detection\nIn this section I will drop the outliers, because you know, outliers can cause trouble. I am going to drop outliers using a handwritten function so let's start with defining the function."]}, {"cell_type": "markdown", "id": "f22c70cf", "metadata": {}, "source": ["## Defining Function"]}, {"cell_type": "code", "execution_count": 1, "id": "18c49ca4", "metadata": {}, "outputs": [], "source": ["def outlier_dropper(dataset):\n    check_index = []\n    final_index = []\n    for feature in dataset: # Each iteration is a different feature\n        \n        Q1 = dataset[feature].describe()[\"25%\"] # Lower Quartile\n        Q3 = dataset[feature].describe()[\"75%\"] # Upper Quartile\n        \n        IQR = Q3-Q1\n        STEP = IQR*1.5\n        \n        \n        indexes = data[(data[feature]<Q1-IQR) | (data[feature]>Q3+IQR)].index.values # Taking outlier's indexes.\n        \n        for i in indexes:  \n            check_index.append(i) # Appending each index into the check_index list.\n    \n    for i in check_index:        \n        check_index.remove(i)\n        if i in check_index: # If i still exists (If there is two outliers in the i index)\n            final_index.append(i) # Append it.\n    \n    return np.unique(final_index)"]}, {"cell_type": "markdown", "id": "c60bf274", "metadata": {}, "source": ["* And now let's use our function."]}, {"cell_type": "markdown", "id": "fc9ebe96", "metadata": {}, "source": ["## Dropping Outliers\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ff20e773", "metadata": {}, "outputs": [], "source": ["indexes = outlier_dropper(data)\nprint(indexes)\nprint(\"------------------------------------------------------------------------------\")\nprint(len(indexes))"]}, {"cell_type": "markdown", "id": "08dc0081", "metadata": {}, "source": ["* There are 47 rows in the dataset that have outliers more than one."]}, {"cell_type": "code", "execution_count": 1, "id": "232d5fb1", "metadata": {}, "outputs": [], "source": ["data.drop(indexes,inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "2117f879", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "markdown", "id": "26c18c24", "metadata": {}, "source": ["* Now we have 721 entries."]}, {"cell_type": "markdown", "id": "041df785", "metadata": {}, "source": ["# Detailed Data Analyses\nIn this section I am going to examine the correlations between the features. I am going to start with examining the correlation heatmap."]}, {"cell_type": "code", "execution_count": 1, "id": "e80fd4c9", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(8,8))\nsns.heatmap(data.corr(),annot=True,fmt=\".2f\",linewidths=1.5)\nplt.show()"]}, {"cell_type": "markdown", "id": "0d47cbfc", "metadata": {}, "source": ["* They are three strong correlation between outcome and other features\n\n* Glucose - Outcome (0.46)\n* Age - Outcome (0.24)\n* BMI - Outcome (0.29)\n\nLet's examine them using different plots."]}, {"cell_type": "markdown", "id": "bd250fb5", "metadata": {}, "source": ["## Glucose - Outcome"]}, {"cell_type": "code", "execution_count": 1, "id": "5ba11457", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"Glucose\"],data[\"Outcome\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"Glucose\"],data[\"Outcome\"])\nplt.show()"]}, {"cell_type": "markdown", "id": "87b1d6bd", "metadata": {}, "source": ["* When outcome is 1, glucose is bigger than 100. "]}, {"cell_type": "markdown", "id": "7a2e714c", "metadata": {}, "source": ["## Age - Outcome"]}, {"cell_type": "code", "execution_count": 1, "id": "7ff26425", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"Outcome\"],data[\"Age\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"Outcome\"],data[\"Age\"])\nplt.show()"]}, {"cell_type": "markdown", "id": "e654bec5", "metadata": {}, "source": ["## BMI - Outcome"]}, {"cell_type": "code", "execution_count": 1, "id": "6e123262", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"BMI\"],data[\"Outcome\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"BMI\"],data[\"Outcome\"])\nplt.show()"]}, {"cell_type": "markdown", "id": "0c3d6532", "metadata": {}, "source": ["# Preprocessing\nIn this section I am going to preapre the dataset for modeling. In order to prepare the dataset. I will follow these steps:\n\n* Preparing Pregnancies Feature\n    * Joinining 11,12,13,14,15,17\n    * One Hot Encoding\n* Normalization\n* Train Test Splitting"]}, {"cell_type": "markdown", "id": "3be4f33c", "metadata": {}, "source": ["## Preparing Pregnancies Feature\n\n### Joining 11,12,13,14,15,17 "]}, {"cell_type": "markdown", "id": "b25ac49b", "metadata": {}, "source": ["* Before the joining, let's remind the countplot of pregnancies feature."]}, {"cell_type": "code", "execution_count": 1, "id": "acb51730", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "8e8eefd7", "metadata": {}, "outputs": [], "source": ["pregnancies = []\n\nfor i in data[\"Pregnancies\"]:\n    \n    if i==11 or i==12 or i==13 or i==14 or i==15 or i==17:\n        pregnancies.append(11)\n    \n    else:\n        pregnancies.append(i)\n\ndata.Pregnancies = pregnancies"]}, {"cell_type": "markdown", "id": "2328bca5", "metadata": {}, "source": ["* And now I will check countplot again."]}, {"cell_type": "code", "execution_count": 1, "id": "260652bb", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()"]}, {"cell_type": "markdown", "id": "6b5097c2", "metadata": {}, "source": ["* Okey, we are ready one hot encoding"]}, {"cell_type": "markdown", "id": "2472b57d", "metadata": {}, "source": ["### One Hot Encoding"]}, {"cell_type": "code", "execution_count": 1, "id": "722a167f", "metadata": {}, "outputs": [], "source": ["data = pd.get_dummies(data,columns=[\"Pregnancies\"])\ndata.head()"]}, {"cell_type": "markdown", "id": "ebbc1375", "metadata": {}, "source": ["## Normalization (Scaling)\n\nAnd now I am going to normalize data because if we normalize the data, training time will be better."]}, {"cell_type": "code", "execution_count": 1, "id": "bbd1e6be", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\n\nx = data.drop(\"Outcome\",axis=1)\ny = data.Outcome\n\nx = scaler.fit_transform(x)"]}, {"cell_type": "markdown", "id": "2b373058", "metadata": {}, "source": ["I've created x and y in this section, because I don't want to normalize y axis."]}, {"cell_type": "code", "execution_count": 1, "id": "fbafab5e", "metadata": {}, "outputs": [], "source": ["print(\"Shape of x\",x.shape)\ny = y.values\nprint(\"Shape of y\",y.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "2c784515", "metadata": {}, "outputs": [], "source": ["y = y.reshape(-1,1)"]}, {"cell_type": "markdown", "id": "49a3121f", "metadata": {}, "source": ["## Train Test Splitting\nIn this section I will split the data into train and test. In order to do this I will use SKLearn library's train_test_split"]}, {"cell_type": "code", "execution_count": 1, "id": "298a3077", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=1)"]}, {"cell_type": "markdown", "id": "5be665fc", "metadata": {}, "source": ["* Finally we are ready for modeling!"]}, {"cell_type": "markdown", "id": "76d76cf7", "metadata": {}, "source": ["# Modeling\nIn this section I'll build the model using Keras library and after that I will fit it using our x_train and y_train."]}, {"cell_type": "code", "execution_count": 1, "id": "27373e84", "metadata": {}, "outputs": [], "source": ["from keras.layers import Dropout,Dense\nfrom keras.models import Sequential"]}, {"cell_type": "code", "execution_count": 1, "id": "5944b282", "metadata": {}, "outputs": [], "source": ["model = Sequential()\nmodel.add(Dense(units=16,kernel_initializer=\"uniform\",activation=\"tanh\",input_dim=19)) # Layer 1\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(units=16,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 2\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 3\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 4 \nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 5\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 6\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 7\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=1,kernel_initializer=\"uniform\",activation=\"sigmoid\")) # Output Layer\nmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"]}, {"cell_type": "markdown", "id": "10e631ed", "metadata": {}, "source": ["* Our frame is ready, let's fit it using our train arrays."]}, {"cell_type": "code", "execution_count": 1, "id": "5047f179", "metadata": {}, "outputs": [], "source": ["model.fit(x_train,y_train,epochs=250)"]}, {"cell_type": "markdown", "id": "d09ab605", "metadata": {}, "source": ["# Predicting\nIn this section I will predict the values using our model and after that I will take a look at the confusion matrix and the score."]}, {"cell_type": "code", "execution_count": 1, "id": "9b9662f9", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\ny_head = model.predict_classes(x_test)\n\nprint(\"The score is \",accuracy_score(y_test,y_head))"]}, {"cell_type": "markdown", "id": "c9581812", "metadata": {}, "source": ["* Not bad but not good."]}, {"cell_type": "code", "execution_count": 1, "id": "aa7ff690", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,y_head)\n\nfig,ax = plt.subplots(figsize=(6,6))\nsns.heatmap(confusion_matrix,annot=True,fmt=\"0.1f\",cmap=\"Greens_r\",linewidths=1.5)\nplt.show()"]}, {"cell_type": "markdown", "id": "50978905", "metadata": {}, "source": ["* Model had difficulty when it predict 1 values. \n* It is a predictible result, because you will remember, the number of 1 values in the dataset is lower than 0 values."]}, {"cell_type": "markdown", "id": "779713ca", "metadata": {}, "source": ["# Conclusion\n\nThanks for your attention, if you have any questions in your mind, you can ask me in the comment section. I am waiting for your comments, questions and upvotes. \n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}