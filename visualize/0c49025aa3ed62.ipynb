{"cells": [{"cell_type": "markdown", "id": "20063e1b", "metadata": {}, "source": ["# Simple LightGBM + Optuna integration\n\nOptuna has a LightGBM integration for quick parameter tuning.\n\nThis notebook provides you a good starting point using a simple LGBM module and a baseline workspace around the classifier."]}, {"cell_type": "code", "execution_count": 1, "id": "6085ad85", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "f9ccb81c", "metadata": {}, "source": ["# importing modules"]}, {"cell_type": "code", "execution_count": 1, "id": "8d1cb391", "metadata": {}, "outputs": [], "source": ["# import lightgbm as lgb\nimport optuna.integration.lightgbm as lgb\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nimport optuna"]}, {"cell_type": "markdown", "id": "65c3fee1", "metadata": {}, "source": ["# Reading Data"]}, {"cell_type": "code", "execution_count": 1, "id": "240f78c3", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/test.csv')"]}, {"cell_type": "markdown", "id": "ea31642d", "metadata": {}, "source": ["# Defining model as a function\n\nThis makes much easier to tune hyperparameters or to run a stacking / blending later on"]}, {"cell_type": "code", "execution_count": 1, "id": "8c4e9db4", "metadata": {}, "outputs": [], "source": ["def exec_lgb_model(X_train, X_test, y_train, y_test, params):\n    model = lgb_model(X_train, y_train, params)\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    return log_loss(y_test, y_pred), model, params\ndef lgb_optuna_model(X_train, X_test, y_train, y_test, params):\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n    model = lgb.train(params,\n                      lgb_train,\n                      valid_sets=lgb_eval,\n                      num_boost_round=200,\n                      early_stopping_rounds=20)\n    return model"]}, {"cell_type": "markdown", "id": "6dc9e6a1", "metadata": {}, "source": ["# Defining preprocessing as a funciton"]}, {"cell_type": "code", "execution_count": 1, "id": "4d711647", "metadata": {}, "outputs": [], "source": ["def preprocess_X(df, include_id = False):\n    X = df[['feature_'+str(x) for x in range(1, 75)]]\n    if include_id:\n        X['id'] = df['id']\n    return X\n\ndef preprocess_data(df, drop_tgt = False):\n    df[['_','tgt']] = df['target'].str.split('_', expand=True)\n    if drop_tgt:\n        df=df.drop(['tgt','_'], axis=1)\n    X = preprocess_X(df)\n    y = df['tgt'].astype(int)-1\n    X\n    return X, y"]}, {"cell_type": "code", "execution_count": 1, "id": "5c7b0ccd", "metadata": {}, "outputs": [], "source": ["X, y = preprocess_data(df)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 114514)"]}, {"cell_type": "code", "execution_count": 1, "id": "584386ad", "metadata": {}, "outputs": [], "source": ["lgbm_params = {'objective': 'multiclass',\n 'metric': 'multi_logloss',\n 'num_class': 9,\n 'feature_pre_filter': False,\n 'lambda_l1': 9.970496731080852,\n 'lambda_l2': 0.33605433486440883,\n 'num_leaves': 9,\n 'feature_fraction': 0.4,\n 'bagging_fraction': 0.8180268235748993,\n 'bagging_freq': 5,\n 'min_child_samples': 20,\n 'num_iterations': 100,\n 'early_stopping_round': 10}\nmodel = lgb_optuna_model(X_train, X_test, y_train, y_test, lgbm_params)"]}, {"cell_type": "code", "execution_count": 1, "id": "f10b45f8", "metadata": {}, "outputs": [], "source": ["X_val = preprocess_X(df_test)\ny_pred = model.predict(X_val, num_iteration=model.best_iteration)\nprediction = pd.DataFrame(y_pred, columns=['Class_'+str(x) for x in range(1, 10)])\nprediction['id'] = df_test['id']\nprediction"]}, {"cell_type": "code", "execution_count": 1, "id": "49a06c73", "metadata": {}, "outputs": [], "source": ["prediction.to_csv('/kaggle/working/submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}