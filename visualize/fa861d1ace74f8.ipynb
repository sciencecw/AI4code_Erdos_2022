{"cells": [{"cell_type": "markdown", "id": "91ca9659", "metadata": {}, "source": ["# Import libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "a5b6edd2", "metadata": {}, "outputs": [], "source": ["import re\nimport string\nfrom functools import reduce\n\nimport numpy as np\nimport pandas as pd\nimport transformers\nimport torch\nimport plotly.graph_objects as go\nfrom tqdm.notebook import tqdm\n\n\npd.set_option(\"display.max_colwidth\", 300)"]}, {"cell_type": "markdown", "id": "dc9d5003", "metadata": {}, "source": ["# Load data"]}, {"cell_type": "code", "execution_count": 1, "id": "7e3b8526", "metadata": {}, "outputs": [], "source": ["INPUT_DIR = \"../input/tweet-sentiment-extraction\"\ntrain = pd.read_csv(f\"{INPUT_DIR}/train.csv\")\ntrain.head()"]}, {"cell_type": "markdown", "id": "e8f75da5", "metadata": {}, "source": ["# Drop rows containing NaN"]}, {"cell_type": "code", "execution_count": 1, "id": "e2cc17eb", "metadata": {}, "outputs": [], "source": ["train.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "a9c0a1e1", "metadata": {}, "outputs": [], "source": ["train = train.dropna()\n\nassert train.isnull().sum().eq(0).all()"]}, {"cell_type": "markdown", "id": "66609d7d", "metadata": {}, "source": ["# Clean text"]}, {"cell_type": "code", "execution_count": 1, "id": "417fe30f", "metadata": {}, "outputs": [], "source": ["# Ref: https://www.kaggle.com/parulpandey/basic-preprocessing-and-eda\n\ndef clean_text(text):\n    \"\"\"\n    Does the following:\n    - Make text lowercase\n    - Remove text in square brackets\n    - Remove links\n    - Remove punctuation\n    - Remove words containing numbers\n    \"\"\"\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text"]}, {"cell_type": "code", "execution_count": 1, "id": "7f5bbca2", "metadata": {}, "outputs": [], "source": ["train[\"clean\"] = train[\"text\"].map(clean_text)\ntrain[[\"text\", \"clean\"]].head()"]}, {"cell_type": "markdown", "id": "092635c3", "metadata": {}, "source": ["# Sampling"]}, {"cell_type": "code", "execution_count": 1, "id": "0cdc72b9", "metadata": {}, "outputs": [], "source": ["train[\"num_words\"] = train[\"clean\"].str.split(\" \").map(len)\ntrain[[\"clean\", \"num_words\"]].head()"]}, {"cell_type": "code", "execution_count": 1, "id": "c135417f", "metadata": {}, "outputs": [], "source": ["not_too_short = train[\"num_words\"] >= 10\nnot_too_short.sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "574d2dd0", "metadata": {}, "outputs": [], "source": ["raw_texts = train[not_too_short][\"text\"].sample(n=5000, random_state=42)\nclean_texts = train.loc[raw_texts.index][\"clean\"]\nselected_text = train.loc[raw_texts.index][\"selected_text\"]\nsentiment = train.loc[raw_texts.index][\"sentiment\"]\n\n\ntrain.loc[raw_texts.index][[\"text\", \"clean\", \"sentiment\"]]"]}, {"cell_type": "markdown", "id": "d07957fd", "metadata": {}, "source": ["# Convert text to vectors "]}, {"cell_type": "code", "execution_count": 1, "id": "05995af1", "metadata": {}, "outputs": [], "source": ["# Ref.: https://www.kaggle.com/abhishek/distilbert-use-features-oof/notebook\n\ndef chunks(l, n):\n    \"\"\"\n    Yield successive n-sized chunks from l.\n    \n    Example\n    -------\n    >>> l = list(range(10))\n    >>> for c in chunks(l, 3):\n    ...     print(c)\n    [0, 1, 2]\n    [3, 4, 5]\n    [6, 7, 8]\n    [9]\n\n    \"\"\"\n    for i in range(0, len(l), n):\n        yield l[i:i + n]\n\n\ndef fetch_vectors(string_list, batch_size=64):\n    # inspired by https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    tokenizer = transformers.DistilBertTokenizer.from_pretrained(\"../input/distilbertbaseuncased/\")\n    model = transformers.DistilBertModel.from_pretrained(\"../input/distilbertbaseuncased/\")\n    model.to(DEVICE)\n\n    fin_features = []\n    total = len(string_list) // batch_size + 1\n    for data in tqdm(chunks(string_list, batch_size), total=total):\n        tokenized = []\n        for x in data:\n            x = \" \".join(x.strip().split()[:300])\n            tok = tokenizer.encode(x, add_special_tokens=True)\n            tokenized.append(tok[:512])\n\n        max_len = 512\n        padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized])\n        attention_mask = np.where(padded != 0, 1, 0)\n        input_ids = torch.tensor(padded).to(DEVICE)\n        attention_mask = torch.tensor(attention_mask).to(DEVICE)\n        \n        with torch.no_grad():\n            last_hidden_states = model(input_ids, attention_mask=attention_mask)\n\n        features = last_hidden_states[0][:, 0, :].cpu().numpy()\n        fin_features.append(features)\n\n    fin_features = np.vstack(fin_features)\n    return fin_features"]}, {"cell_type": "code", "execution_count": 1, "id": "c3c14bf8", "metadata": {}, "outputs": [], "source": ["vectors = fetch_vectors(clean_texts)\nvectors.shape"]}, {"cell_type": "markdown", "id": "79f3ce71", "metadata": {}, "source": ["# Dimensionality reduction with t-SNE"]}, {"cell_type": "code", "execution_count": 1, "id": "6179d165", "metadata": {}, "outputs": [], "source": ["from sklearn.manifold import TSNE\n\nreduced = TSNE(n_components=2).fit_transform(vectors)\nreduced.shape"]}, {"cell_type": "markdown", "id": "264a6ba5", "metadata": {}, "source": ["# Visualize vectors "]}, {"cell_type": "code", "execution_count": 1, "id": "1be951ae", "metadata": {}, "outputs": [], "source": ["def wrap_text(text):\n    \"\"\"\n    Insert <br> to wrap long text on a Plotly chart.\n\n    Example\n    -------\n    >>> import string\n    >>> text = \"a b c d e f g h i\"\n    >>> wrap_text(text, 3)\n    \"a b c<br>d e f<br>g h i\"\n\n    \"\"\"\n    rows = [\" \".join(c) for c in chunks(text.split(), 10)]\n    return \"<br>\".join(rows)"]}, {"cell_type": "code", "execution_count": 1, "id": "8760edbc", "metadata": {}, "outputs": [], "source": ["hovertext = reduce(lambda a, b: a + \"<br>\" + b, [\n    \"# Raw text\",\n    raw_texts.map(wrap_text),\n    \"\",\n    \"# Clean text\",\n    clean_texts.map(wrap_text),\n    \"\",\n    \"# Selected text\",\n    selected_text.map(wrap_text),\n    \"\",\n    \"# Sentiment\",\n    sentiment,\n])\n\ncolor = sentiment.map({\n    \"positive\": \"green\",\n    \"neutral\": \"#bbbbbb\",\n    \"negative\": \"red\",\n})\n\ndata = go.Scatter(\n    x=reduced[:, 0],\n    y=reduced[:, 1],\n    mode=\"markers\",\n    hoverinfo=\"text\",\n    hovertext=hovertext,\n    marker=dict(color=color),\n)\n\ngo.Figure(data=data)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}