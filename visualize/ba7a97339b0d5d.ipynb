{"cells": [{"cell_type": "markdown", "id": "2c64b328", "metadata": {}, "source": ["# Macaw \n\nMacaw (Multi-angle c(q)uestion answering) is a ready-to-use model capable of general question answering, showing robustness outside the domains it was trained on. It has been trained in \"multi-angle\" fashion, which means it can handle a flexible set of input and output \"slots\" (like question, answer, explanation) .\n\nSource - https://github.com/allenai/macaw\n\nThis notebook tries to take Macaw for a spin with the help of \ud83e\udd17 `transformers`\n\nModel Hub (with Inference Demo) - https://huggingface.co/allenai/macaw-large?text=%24answer%3D+New+Delhi+is+the+capital+of+India%24%3B+%24question%24"]}, {"cell_type": "markdown", "id": "c3498e1b", "metadata": {}, "source": ["Install `transformers` library (make sure your Internet on Kaggle Notebook settings is on)"]}, {"cell_type": "code", "execution_count": 1, "id": "e2d46d14", "metadata": {}, "outputs": [], "source": ["! pip install transformers"]}, {"cell_type": "markdown", "id": "251d9c2a", "metadata": {}, "source": ["### Load the required Classes"]}, {"cell_type": "code", "execution_count": 1, "id": "1c4ad9cd", "metadata": {}, "outputs": [], "source": ["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"]}, {"cell_type": "markdown", "id": "86e271ac", "metadata": {}, "source": ["### Initialize the Tokenizer and Model (very typical \ud83e\udd17 transformers process)"]}, {"cell_type": "code", "execution_count": 1, "id": "670a9fc9", "metadata": {}, "outputs": [], "source": ["tokenizer = AutoTokenizer.from_pretrained(\"allenai/macaw-large\") #300 million paramaters"]}, {"cell_type": "code", "execution_count": 1, "id": "f9042311", "metadata": {}, "outputs": [], "source": ["model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/macaw-large\") #300 million paramaters\n"]}, {"cell_type": "markdown", "id": "313a4b55", "metadata": {}, "source": ["This is the most important step and the step that requires \"Prompt Engineering\" \ud83d\ude0e\n\nMacaw can take multiple slots like `question`, `answer`, `mcoptions`, `context`, `explanation` and can take Angles like Q -> A and A -> Q\n\nEverything is defined in this `input_string` "]}, {"cell_type": "code", "execution_count": 1, "id": "aba0962d", "metadata": {}, "outputs": [], "source": ["input_string = \"$answer$; $question$ Which one is better? Emacs or Vim \"\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2642933e", "metadata": {}, "outputs": [], "source": ["input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")"]}, {"cell_type": "code", "execution_count": 1, "id": "5137281a", "metadata": {}, "outputs": [], "source": ["output = model.generate(input_ids, max_length=200)"]}, {"cell_type": "markdown", "id": "810be6c1", "metadata": {}, "source": ["Get the Output of **Macaw**"]}, {"cell_type": "code", "execution_count": 1, "id": "2335c50a", "metadata": {}, "outputs": [], "source": ["tokenizer.batch_decode(output, skip_special_tokens=True)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}