{"cells": [{"cell_type": "markdown", "id": "66257f18", "metadata": {}, "source": ["## Import from libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "63f9363d", "metadata": {}, "outputs": [], "source": ["pip install google-colab"]}, {"cell_type": "code", "execution_count": 1, "id": "87a83196", "metadata": {}, "outputs": [], "source": ["import cv2           # extra\u00e7\u00e3o dos pixels;\nimport numpy as np\nimport os\nimport zipfile\nfrom google.colab.patches import cv2_imshow\nimport tensorflow as tf\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "id": "94ff10e9", "metadata": {}, "source": ["## Extraction of pixels from images"]}, {"cell_type": "code", "execution_count": 1, "id": "6dff5267", "metadata": {}, "outputs": [], "source": ["path = '../input/neural-networks-homer-and-bart-classification/homer_bart_1'"]}, {"cell_type": "code", "execution_count": 1, "id": "06951dcb", "metadata": {}, "outputs": [], "source": ["directory = '../input/neural-networks-homer-and-bart-classification/homer_bart_1'\nfiles = [os.path.join(directory, f) for f in sorted(os.listdir(directory))]"]}, {"cell_type": "markdown", "id": "f947619c", "metadata": {}, "source": ["\n\n\n**THIS IS ANOTHER ALGORITHM WE CAN USE TO MAKE RATINGS THROUGH FEATURE EXTRACTION**"]}, {"cell_type": "markdown", "id": "f1b47bdc", "metadata": {}, "source": ["## Feature Extractor"]}, {"cell_type": "code", "execution_count": 1, "id": "9312afb8", "metadata": {}, "outputs": [], "source": ["arquivos = [os.path.join(directory, f) for f in sorted(os.listdir(directory))]  "]}, {"cell_type": "code", "execution_count": 1, "id": "e3c85353", "metadata": {}, "outputs": [], "source": ["export = 'mouth,pants,shoes,shirt,shorts,sneakers,class\\n'  "]}, {"cell_type": "code", "execution_count": 1, "id": "969adafa", "metadata": {}, "outputs": [], "source": ["export"]}, {"cell_type": "code", "execution_count": 1, "id": "579840ad", "metadata": {}, "outputs": [], "source": ["show_images = False\ncharacteristics = []"]}, {"cell_type": "code", "execution_count": 1, "id": "e628e611", "metadata": {}, "outputs": [], "source": ["100 * 200"]}, {"cell_type": "code", "execution_count": 1, "id": "373d0f08", "metadata": {}, "outputs": [], "source": ["(2000 / 20000) * 100"]}, {"cell_type": "code", "execution_count": 1, "id": "6d4a401e", "metadata": {}, "outputs": [], "source": ["for path_image in files:\n  \n  try:\n    original_image = cv2.imread(path_image)\n    (H, W) = original_image.shape[:2]\n  except:\n    continue\n\n  altered_image = original_image.copy()\n  image_features = []\n  image_name = os.path.basename(os.path.normpath(path_image))\n  mouth = pants = shoes = 0\n  shirt = shorts = sneakers = 0\n\n  if image_name.startswith('b'): \n    classe = 0\n  else:\n    classe = 1\n\n  for height in range(0, H):\n    for width in range(0, W):\n      \n      blue = altered_image.item(height, width, 0)\n      green = altered_image.item(height, width, 1)\n      red = altered_image.item(height, width, 2)\n\n      if (blue >= 95 and blue <= 140 and green >= 160 and green <= 185 and red >= 175 and red <= 205):\n        altered_image[height, width] = [0, 255, 255]\n        mouth += 1\n\n\n      if (blue >= 150 and blue <= 180 and green >= 98 and green <= 120 and red >= 0 and red <= 90):\n        altered_image[height, width] = [0, 255, 255]\n        pants += 1\n\n\n      if height > (H / 2):\n        if (blue >= 25 and blue <= 45 and green >= 25 and green <= 45 and red >= 25 and red <= 45):\n          altered_image[height, width] = [0, 255, 255]\n          shoes += 1\n\n\n      if (blue >= 11 and blue <= 50 and green >= 85 and green <= 105 and red >= 240 and red <= 255):\n        altered_image[height, width] = [0, 255, 128]\n        shirt += 1\n\n\n      if (blue >= 125 and blue <= 170 and green >= 0 and green <= 12 and red >= 0 and red <= 20):\n        altered_image[height, width] = [0, 255, 128]\n        shorts += 1\n\n\n      if height > (H / 2):\n        if (blue >= 125 and blue <= 170 and green >= 0 and green <= 12 and red >= 0 and red <= 20):\n          altered_image[height, width] = [0, 255, 128]\n          sneakers += 1\n\n  boca = round((mouth / (H * W)) * 100, 9)\n  calca = round((pants / (H * W)) * 100, 9)\n  sapato = round((shoes / (H * W)) * 100, 9)\n  camisa = round((shirt / (H * W)) * 100, 9)\n  calcao = round((shorts / (H * W)) * 100, 9)\n  tenis = round((sneakers / (H * W)) * 100, 9)\n\n  image_features.append(mouth)\n  image_features.append(pants)\n  image_features.append(shoes)\n  image_features.append(shirt)\n  image_features.append(shorts)\n  image_features.append(sneakers)\n  image_features.append(classe)\n\n  characteristics.append(image_features)\n\n    \n  f = (\",\".join([str(item) for item in image_features]))\n  export += f + '\\n'\n\n  if show_images == True:\n    altered_image = cv2.cvtColor(altered_image, cv2.COLOR_BGR2RGB)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n    figura, im = plt.subplots(1, 2)\n    im[0].imshow(original_image)\n    im[0].axis('off')\n    im[1].imshow(altered_image)\n    im[1].axis('off')\n    plt.show()\n\n\n  #cv2_imshow(original_image)\n  #print(H, W)\n  #print(image_name)"]}, {"cell_type": "code", "execution_count": 1, "id": "4e6921f0", "metadata": {}, "outputs": [], "source": ["export"]}, {"cell_type": "markdown", "id": "2e960d67", "metadata": {}, "source": ["## Training and testing bases"]}, {"cell_type": "code", "execution_count": 1, "id": "e5577152", "metadata": {}, "outputs": [], "source": ["with open('features.csv', 'w') as file:\n  for linha in export:\n    file.write(linha)\nfile.closed"]}, {"cell_type": "code", "execution_count": 1, "id": "446f98f7", "metadata": {}, "outputs": [], "source": ["dataset = pd.read_csv('features.csv', error_bad_lines = False)"]}, {"cell_type": "code", "execution_count": 1, "id": "70c2004c", "metadata": {}, "outputs": [], "source": ["X = dataset.iloc[:, 0:6].values   \nX"]}, {"cell_type": "code", "execution_count": 1, "id": "266e2b2e", "metadata": {}, "outputs": [], "source": ["y = dataset.iloc[:, 6].values  \ny"]}, {"cell_type": "code", "execution_count": 1, "id": "906afb5d", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "af3b2389", "metadata": {}, "outputs": [], "source": ["X_train.shape, y_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "1f8dab60", "metadata": {}, "outputs": [], "source": ["X_test.shape, y_test.shape"]}, {"cell_type": "markdown", "id": "3aee8036", "metadata": {}, "source": ["## Construction and training of the neural network"]}, {"cell_type": "code", "execution_count": 1, "id": "06710f41", "metadata": {}, "outputs": [], "source": ["(6 + 2) / 2"]}, {"cell_type": "code", "execution_count": 1, "id": "f2bfd4b7", "metadata": {}, "outputs": [], "source": ["network = tf.keras.Sequential()\nnetwork.add(tf.keras.layers.Dense(input_shape = (6,), units = 4, activation='relu'))\nnetwork.add(tf.keras.layers.Dense(units=4, activation='relu'))\nnetwork.add(tf.keras.layers.Dense(units=4, activation='relu'))\nnetwork.add(tf.keras.layers.Dense(units = 1, activation='sigmoid'))"]}, {"cell_type": "code", "execution_count": 1, "id": "a59309ff", "metadata": {}, "outputs": [], "source": ["network.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "f673883e", "metadata": {}, "outputs": [], "source": ["network.compile(optimizer='Adam', loss='binary_crossentropy', metrics = ['accuracy'])"]}, {"cell_type": "code", "execution_count": 1, "id": "bcd5eb56", "metadata": {}, "outputs": [], "source": ["historic = network.fit(X_train, y_train, epochs = 80)"]}, {"cell_type": "markdown", "id": "4da1e5b2", "metadata": {}, "source": ["## Neural network evaluation"]}, {"cell_type": "code", "execution_count": 1, "id": "8a766fb6", "metadata": {}, "outputs": [], "source": ["historic.history.keys()"]}, {"cell_type": "code", "execution_count": 1, "id": "971b4653", "metadata": {}, "outputs": [], "source": ["plt.plot(historic.history['loss']);"]}, {"cell_type": "code", "execution_count": 1, "id": "63a42304", "metadata": {}, "outputs": [], "source": ["plt.plot(historic.history['accuracy']);"]}, {"cell_type": "code", "execution_count": 1, "id": "9e971115", "metadata": {}, "outputs": [], "source": ["X_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "c1926c81", "metadata": {}, "outputs": [], "source": ["forecasts = network(X_test)\nforecasts"]}, {"cell_type": "code", "execution_count": 1, "id": "4ef03a9d", "metadata": {}, "outputs": [], "source": ["forecasts = forecasts > 0.5\nforecasts"]}, {"cell_type": "code", "execution_count": 1, "id": "e71d1680", "metadata": {}, "outputs": [], "source": ["y_test"]}, {"cell_type": "code", "execution_count": 1, "id": "2e590ce2", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\naccuracy_score(y_test, forecasts)"]}, {"cell_type": "code", "execution_count": 1, "id": "2bab4279", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, forecasts)\ncm"]}, {"cell_type": "code", "execution_count": 1, "id": "b28b2e32", "metadata": {}, "outputs": [], "source": ["sns.heatmap(cm, annot=True);"]}, {"cell_type": "code", "execution_count": 1, "id": "73fe8b13", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import classification_report\nprint(classification_report(y_test, forecasts))"]}, {"cell_type": "markdown", "id": "2e16f89a", "metadata": {}, "source": ["## Upload and rate a single image"]}, {"cell_type": "code", "execution_count": 1, "id": "0eab23aa", "metadata": {}, "outputs": [], "source": ["network.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "ffa38040", "metadata": {}, "outputs": [], "source": ["image_test = X_test[1]\nimage_test"]}, {"cell_type": "code", "execution_count": 1, "id": "fdc3c564", "metadata": {}, "outputs": [], "source": ["image_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "9cea5365", "metadata": {}, "outputs": [], "source": ["image_test = image_test.reshape(1,-1)\nimage_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "a9f50494", "metadata": {}, "outputs": [], "source": ["network.predict(image_test)[0][0]"]}, {"cell_type": "code", "execution_count": 1, "id": "9f7fa873", "metadata": {}, "outputs": [], "source": ["if network.predict(image_test)[0][0] < 0.5:\n  print('Bart')\nelse:\n  print('Homer')"]}, {"cell_type": "markdown", "id": "176031fa", "metadata": {}, "source": ["**The case study with the extraction of features has a much better result than just with neural networks.**"]}, {"cell_type": "markdown", "id": "6a4cbed8", "metadata": {}, "source": ["https://www.kaggle.com/juniorbueno/neural-networks-simpsons-image-classification"]}, {"cell_type": "markdown", "id": "6c0ffce8", "metadata": {}, "source": ["# **If you find this notebook useful, support with an upvote** \ud83d\udc4d\u00b6"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}