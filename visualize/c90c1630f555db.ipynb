{"cells": [{"cell_type": "code", "execution_count": 1, "id": "5295a041", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "5b3a41cc", "metadata": {}, "source": ["# Import everything needed!"]}, {"cell_type": "code", "execution_count": 1, "id": "ced74dc0", "metadata": {}, "outputs": [], "source": ["import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport collections\nimport math\nimport os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)"]}, {"cell_type": "markdown", "id": "6bdd656b", "metadata": {}, "source": ["# Unzip datasets"]}, {"cell_type": "code", "execution_count": 1, "id": "2c664d94", "metadata": {}, "outputs": [], "source": ["!pip install py7zr"]}, {"cell_type": "markdown", "id": "8a6a0bf1", "metadata": {}, "source": ["## WARNING: It can take a lot of time to uncompress!"]}, {"cell_type": "code", "execution_count": 1, "id": "bc753b64", "metadata": {}, "outputs": [], "source": ["!python -m py7zr x /kaggle/input/cifar-10/train.7z"]}, {"cell_type": "code", "execution_count": 1, "id": "cd19874f", "metadata": {}, "outputs": [], "source": ["!python -m py7zr x /kaggle/input/cifar-10/test.7z # Around 15 minutes to uncompress."]}, {"cell_type": "code", "execution_count": 1, "id": "803e5b0e", "metadata": {}, "outputs": [], "source": ["data_dir = '/kaggle/working/'"]}, {"cell_type": "code", "execution_count": 1, "id": "273c109a", "metadata": {}, "outputs": [], "source": ["def read_csv_labels(fname):\n    \"\"\"Read `fname` to return a filename to label dictionary.\"\"\"\n    with open(fname, 'r') as f:\n        # Skip the file header line (column name)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n\nlabels = read_csv_labels(os.path.join(data_dir, '/kaggle/input/cifar-10/trainLabels.csv'))\nprint(f'Number training examples: {len(labels)}')\nprint(f'Number classes: {len(set(labels.values()))}')"]}, {"cell_type": "code", "execution_count": 1, "id": "29e678e3", "metadata": {}, "outputs": [], "source": ["def copyfile(filename, target_dir):\n    \"\"\"Copy a file into a target directory.\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n\ndef reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"Split the validation set out of the original training set.\"\"\"\n    # The number of examples of the class that has the fewest examples in the\n    # training dataset\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # The number of examples per class for the validation set\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        label = labels[train_file.split('.')[0]]\n        fname = os.path.join(data_dir, 'train', train_file)\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        if label not in label_count or label_count[label] < n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label"]}, {"cell_type": "code", "execution_count": 1, "id": "1716e651", "metadata": {}, "outputs": [], "source": ["def reorg_test(data_dir):\n    \"\"\"Organize the testing set for data loading during prediction.\"\"\"\n    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n        copyfile(os.path.join(data_dir, 'test', test_file),\n                 os.path.join(data_dir, 'train_valid_test', 'test',\n                              'unknown'))"]}, {"cell_type": "code", "execution_count": 1, "id": "994cd918", "metadata": {}, "outputs": [], "source": ["def reorg_cifar10_data(data_dir, valid_ratio):\n    labels = read_csv_labels('/kaggle/input/cifar-10/trainLabels.csv')\n    reorg_train_valid(data_dir, labels, valid_ratio)\n    reorg_test(data_dir)"]}, {"cell_type": "code", "execution_count": 1, "id": "0f2112bb", "metadata": {}, "outputs": [], "source": ["batch_size = 64\nvalid_ratio = 0.1\nreorg_cifar10_data(data_dir, valid_ratio)"]}, {"cell_type": "markdown", "id": "7c49a262", "metadata": {}, "source": ["# Wandb Setup"]}, {"cell_type": "code", "execution_count": 1, "id": "29eb4ffd", "metadata": {}, "outputs": [], "source": ["import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandbkey\") # load wandbkey from Kaggle's secrets\n\nwandb.login(key=secret_value_0)\nwandb.init(project='Cifar 10', save_code=True)"]}, {"cell_type": "markdown", "id": "57ae6345", "metadata": {}, "source": ["# Fine-Tuning"]}, {"cell_type": "code", "execution_count": 1, "id": "afcf762b", "metadata": {}, "outputs": [], "source": ["# Define the data augmentation technique \ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomResizedCrop(32), # RandomSizeCrop, randomly crops and resize to given value\n    torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5,hue=0.5), # Color Jitter\n    torchvision.transforms.RandomHorizontalFlip(), # Horizontal Flip\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n                                     [0.2023, 0.1994, 0.2010])\n])\n\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n                                     [0.2023, 0.1994, 0.2010])])"]}, {"cell_type": "code", "execution_count": 1, "id": "6efd05ef", "metadata": {}, "outputs": [], "source": ["train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_train) for folder in ['train', 'train_valid']]\n\nvalid_ds, test_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_test) for folder in ['valid', 'test']]\n\ntrain_iter, train_valid_iter = [torch.utils.data.DataLoader(\n    dataset, batch_size, shuffle=True, drop_last=True)\n    for dataset in (train_ds, train_valid_ds)]\n\nvalid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n                                         drop_last=True)\n\ntest_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n                                        drop_last=False)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5a489ded", "metadata": {}, "outputs": [], "source": ["# Fine-tune a pre-trained ResNet-18 on CIFAR-10\n# We swap the head with a Linear layer of the correct output shape that we initialize\npretrained_net = torchvision.models.resnet18(pretrained=True)\npretrained_net.fc = nn.Linear(pretrained_net.fc.in_features, 10)\nnn.init.xavier_normal_(pretrained_net.fc.weight)\nnn.init.constant_(pretrained_net.fc.bias, 0)"]}, {"cell_type": "code", "execution_count": 1, "id": "f41ac76a", "metadata": {}, "outputs": [], "source": ["# If we have a GPU, we use it. DataParallel allows to use multiple GPU in parallel if we have them\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\npretrained_net = pretrained_net.to(device)\nif device == 'cuda':\n    pretrained_net = torch.nn.DataParallel(pretrained_net) # if multiple GPUs use them\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(pretrained_net.parameters(), lr=1e-4, weight_decay=0.0001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=1e-5, factor=0.5)"]}, {"cell_type": "code", "execution_count": 1, "id": "8f180815", "metadata": {}, "outputs": [], "source": ["from tqdm.notebook import trange, tqdm\n\nepochs = 10\nfor epoch in trange(epochs):\n    accurate = 0\n    total = 0\n    losses = 0\n    for X, y in tqdm(train_iter): # Training loop\n        # Send to GPU\n        X = X.to(device)\n        y = y.to(device)\n        \n        y_pred = pretrained_net(X)\n        loss = criterion(y_pred, y)\n        score, predicted = torch.max(y_pred, 1)\n        accurate += (y == predicted).sum().float()\n        losses += loss.item()\n        total += len(y)\n\n        # zero the gradients before running\n        # the backward pass.\n        optimizer.zero_grad()\n\n        # Backward pass to compute the gradient\n        # of loss w.r.t our learnable params. \n        loss.backward()\n\n        # Update params\n        optimizer.step()\n    \n    wandb.log({\n            'training-loss': losses / len(train_iter),\n            'training-accuracy': accurate / total\n    })\n    with torch.no_grad(): # Validation loop\n        pretrained_net.eval()\n        accurate = 0\n        total = 0 \n        losses = 0\n        for X, y in tqdm(valid_iter):\n            # Send to GPU\n            X = X.to(device)\n            y = y.to(device)\n                \n            y_pred = pretrained_net(X)\n            loss = criterion(y_pred, y)\n            score, predicted = torch.max(y_pred, 1)\n            accurate += (y == predicted).sum().float()\n            losses += loss.item()\n            total += len(y)\n        wandb.log({\n            'validation-loss': losses / len(valid_iter),\n            'validation-accuracy': accurate / total\n        })"]}, {"cell_type": "code", "execution_count": 1, "id": "897c56e2", "metadata": {}, "outputs": [], "source": ["torch.save(pretrained_net.state_dict(), 'model.pt') # Save de model"]}, {"cell_type": "markdown", "id": "d7375791", "metadata": {}, "source": ["# Prediction Submission"]}, {"cell_type": "code", "execution_count": 1, "id": "c006cd97", "metadata": {}, "outputs": [], "source": ["# Based on \"Generating Predictions\" from \n# https://www.kaggle.com/francescolorenzo/96-fine-tuning-resnet34-with-pytorch submitted 7 months ago.\npreds = []\n\npretrained_net.eval()\nwith torch.no_grad():\n    for X, _ in tqdm(test_iter):\n        X = X.to(device) # Send to GPU\n        preds.extend(pretrained_net(X).argmax(dim=1).type(torch.int32).cpu().numpy()) # Collect predictions\nids = list(range(1, len(test_ds)+1)) # Get IDs from the dataset\nids.sort(key=lambda x: str(x)) # Sort the IDs\ndf = pd.DataFrame({'id': ids, 'label': preds}) # Dataframe creation\ndf['label'] = df['label'].apply(lambda x: train_ds.classes[x]) # Set the class predicted in the prediction column,i.e.cat  \ndf.to_csv('submission.csv', index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "dc224f3f", "metadata": {}, "outputs": [], "source": ["# Load saved model for future stuff\npretrained_net.load_state_dict(torch.load('model.pt'))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}