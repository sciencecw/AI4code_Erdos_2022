{"cells": [{"cell_type": "code", "execution_count": 1, "id": "ffdde8f2", "metadata": {}, "outputs": [], "source": ["# Load Libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport nltk\nimport nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.tokenize import RegexpTokenizer\nimport statsmodels.api as sm\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\nimport re\nfrom nltk.stem.lancaster import LancasterStemmer\nfrom nltk.stem.porter import PorterStemmer\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, SimpleRNN\n\nimport os\nprint(os.listdir(\"../input\"))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "74c41c75", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\", index_col=0)\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "4948aa7a", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "e7fcd658", "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "markdown", "id": "fbf4e0a6", "metadata": {}, "source": ["# EDA - What can you Explore?\n- what age gives what type of rating?\n- What are recommended in each Division, Class, department of Clothes?\n- Which age group gives more comments/ratings on what type of clothes?\n- Rating vs Positive feedback count\n- Lengthy Reviews for what type of cloth?\n- Positive/Negative Reviews for what type of clothes?\n"]}, {"cell_type": "markdown", "id": "b53faf5c", "metadata": {}, "source": ["## What age group has given what types of Ratings?"]}, {"cell_type": "code", "execution_count": 1, "id": "fb962adb", "metadata": {}, "outputs": [], "source": ["# The age distribution in data\nplt.hist(df['Age'], color=\"green\", label = \"Age\")\nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.title(\"Age Distribution in Data\")"]}, {"cell_type": "code", "execution_count": 1, "id": "df272039", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,10))\nsns.boxplot(x = 'Rating', y = 'Age', data = df)"]}, {"cell_type": "markdown", "id": "509eb292", "metadata": {}, "source": ["## What are Recommended Clothes item?"]}, {"cell_type": "code", "execution_count": 1, "id": "14031db0", "metadata": {}, "outputs": [], "source": ["print(df['Division Name'].unique())\nprint(df['Department Name'].unique())\nprint(df['Class Name'].unique())"]}, {"cell_type": "code", "execution_count": 1, "id": "d587879d", "metadata": {}, "outputs": [], "source": ["rd = df[df['Recommended IND'] == 1] # recommended\nnrd = df[df['Recommended IND'] == 0] # not recommended\nrd.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "21465109", "metadata": {}, "outputs": [], "source": ["plt.style.use('ggplot')\n\nfig = plt.figure(figsize=(18, 18))\nax1 = plt.subplot2grid((2, 2), (0, 0))\nax1 = plt.xticks(rotation=45)\nax1 = plt.hist(rd['Division Name'], color = \"red\", alpha = 0.5, label = \"Recommended\")\nax1 = plt.hist(nrd['Division Name'], color = \"blue\", alpha = 0.5, label = \"Not Recommended\")\nax1 = plt.title(\"Recommended Items in each Division\")\nax1 = plt.legend()\n\nax2 = plt.subplot2grid((2, 2), (0, 1))\nax2 = plt.xticks(rotation=45)\nax2 = plt.hist(rd['Department Name'], color=\"green\", alpha = 0.5, label = \"Recommended\")\nax2 = plt.hist(nrd['Department Name'], color=\"yellow\", alpha = 0.5, label = \"Not Recommended\")\nax2 = plt.title(\"Recommended Items in each Department\")\nax2 = plt.legend()\n\nax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\nax3 = plt.xticks(rotation=45)\nax3 = plt.hist(rd['Class Name'], color=\"blue\", alpha = 0.5, label = \"Recommended\")\nax3 = plt.hist(nrd['Class Name'], color=\"cyan\", alpha = 0.5, label = \"Not Recommended\")\nax3 = plt.title(\"Recommended Items in each Class\")\nax3 = plt.legend()"]}, {"cell_type": "markdown", "id": "92a77814", "metadata": {}, "source": ["# Which age group gives what length of comments on what type of clothes?"]}, {"cell_type": "code", "execution_count": 1, "id": "fb22c7fb", "metadata": {}, "outputs": [], "source": ["df['Review Length'] = df['Review Text'].astype(str).apply(len)\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "feb32148", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(10, 5))\n#ax1 = plt.hist(df['Review Length'], color = \"red\", bins = 20)\nax = sns.distplot(df['Review Length'], color=\"blue\")\nax = plt.title(\"Length of Reviews\")"]}, {"cell_type": "code", "execution_count": 1, "id": "b946da38", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20,10))\nsns.boxplot(x = 'Age', y = 'Review Length', data = df)"]}, {"cell_type": "code", "execution_count": 1, "id": "d8a3d1e4", "metadata": {}, "outputs": [], "source": ["plt.style.use('ggplot')\n\nfig = plt.figure(figsize=(18, 18))\nax1 = plt.subplot2grid((2, 2), (0, 0))\nax1 = plt.xticks(rotation=45)\nax1 = sns.boxplot(x = 'Division Name', y = 'Review Length', data = df)\nax1 = plt.title(\"Review Length in each Division\")\n\nax2 = plt.subplot2grid((2, 2), (0, 1))\nax2 = plt.xticks(rotation=45)\nax2 = sns.boxplot(x = 'Department Name', y = 'Review Length', data = df)\nax2 = plt.title(\"Review Length in each Department\")\n\nax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\nax3 = plt.xticks(rotation=45)\nax3 = sns.boxplot(x = 'Class Name', y = 'Review Length', data = df)\nax3 = plt.title(\"Review Length in each Class\")"]}, {"cell_type": "markdown", "id": "73f86c02", "metadata": {}, "source": ["# Ratings vs. Positive Feedback Count"]}, {"cell_type": "code", "execution_count": 1, "id": "9b8cc788", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,10))\nsns.boxplot(x = 'Rating', y = 'Positive Feedback Count', data = df)"]}, {"cell_type": "markdown", "id": "d01a49b8", "metadata": {}, "source": ["# Review Analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "e9fc66ab", "metadata": {}, "outputs": [], "source": ["ps = PorterStemmer()\nReviews = df['Review Text'].astype(str)\nprint(Reviews.shape)\nReviews[Reviews.isnull()] = \"NULL\""]}, {"cell_type": "code", "execution_count": 1, "id": "64342088", "metadata": {}, "outputs": [], "source": ["tokenizer = RegexpTokenizer(r'[a-zA-Z]{3,}')\nstop_words = set(stopwords.words('english'))\ndef preprocessing(data):\n    txt = data.str.lower().str.cat(sep=' ') #1\n    words = tokenizer.tokenize(txt) #2\n    words = [w for w in words if not w in stop_words] #3\n    #words = [ps.stem(w) for w in words] #4\n    return words"]}, {"cell_type": "code", "execution_count": 1, "id": "c50c4642", "metadata": {}, "outputs": [], "source": ["df['tokenized'] = df[\"Review Text\"].astype(str).str.lower() # Turn into lower case text\ndf['tokenized'] = df.apply(lambda row: tokenizer.tokenize(row['tokenized']), axis=1) # Apply tokenize to each row\ndf['tokenized'] = df['tokenized'].apply(lambda x: [w for w in x if not w in stop_words]) # Remove stopwords from each row\n"]}, {"cell_type": "code", "execution_count": 1, "id": "057b2fde", "metadata": {}, "outputs": [], "source": ["def string_unlist(strlist):\n    return \" \".join(strlist)\n\ndf[\"tokenized_unlist\"] = df[\"tokenized\"].apply(string_unlist)\ndf.head()\n"]}, {"cell_type": "markdown", "id": "36060643", "metadata": {}, "source": ["### Sentiment Analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "48dc61ef", "metadata": {}, "outputs": [], "source": ["# Pre-Processing\nSIA = SentimentIntensityAnalyzer()\n\n# Applying Model, Variable Creation\ndf['Polarity Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['compound'])\ndf['Neutral Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['neu'])\ndf['Negative Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['neg'])\ndf['Positive Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['pos'])\n\n# Converting 0 to 1 Decimal Score to a Categorical Variable\ndf['Sentiment']=''\ndf.loc[df['Polarity Score']>0,'Sentiment']='Positive'\ndf.loc[df['Polarity Score']==0,'Sentiment']='Neutral'\ndf.loc[df['Polarity Score']<0,'Sentiment']='Negative'"]}, {"cell_type": "code", "execution_count": 1, "id": "e56eed9f", "metadata": {}, "outputs": [], "source": ["conditions = [\n    df['Sentiment'] == \"Positive\",\n    df['Sentiment'] == \"Negative\",\n    df['Sentiment'] == \"Neutral\"]\nchoices = [1,-1,0]\ndf['label'] = np.select(conditions, choices)\ndf.head()"]}, {"cell_type": "markdown", "id": "599315a0", "metadata": {}, "source": ["### Simple Embedding Deep Neural Network"]}, {"cell_type": "code", "execution_count": 1, "id": "2a236289", "metadata": {}, "outputs": [], "source": ["samples = df[\"tokenized_unlist\"].tolist()\nmaxlen = 100 \nmax_words = 10000\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(samples)\nsequences = tokenizer.texts_to_sequences(samples)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\ndata = pad_sequences(sequences, maxlen=maxlen)"]}, {"cell_type": "code", "execution_count": 1, "id": "29646824", "metadata": {}, "outputs": [], "source": ["labels = np.asarray(df[\"label\"].values)\nprint('Shape of data tensor:', data.shape)\nprint('Shape of label tensor:', labels.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "54e7cf22", "metadata": {}, "outputs": [], "source": ["indices = np.arange(df.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]"]}, {"cell_type": "code", "execution_count": 1, "id": "4bb16b0d", "metadata": {}, "outputs": [], "source": ["training_samples = 11743\nvalidation_samples = 17614\nx_train = data[:training_samples]\ny_train = labels[:training_samples]\nx_val = data[training_samples: validation_samples] \ny_val = labels[training_samples: validation_samples]\nx_test = data[validation_samples:]\ny_test = labels[validation_samples:]\nx_train = pad_sequences(x_train, maxlen=maxlen)\nx_val = pad_sequences(x_val, maxlen=maxlen)"]}, {"cell_type": "markdown", "id": "c087924c", "metadata": {}, "source": ["##### Baseline for Sentiment Analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "0faa156b", "metadata": {}, "outputs": [], "source": ["# BASELINE\n# That is, if all the labels are predicted as 1\n(np.sum(df['label'] == 1)/df.shape[0]) * 100\n\n# we have to make model that performs better than this baseline"]}, {"cell_type": "code", "execution_count": 1, "id": "79045db8", "metadata": {}, "outputs": [], "source": ["def build_model():\n    model = Sequential()\n    model.add(Embedding(max_words, 100, input_length=maxlen))\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['acc'])\n    return model"]}, {"cell_type": "code", "execution_count": 1, "id": "ba76c9b5", "metadata": {}, "outputs": [], "source": ["model = build_model()\nmodel.summary()\nhistory = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model1.h5\")"]}, {"cell_type": "code", "execution_count": 1, "id": "3a85d6ca", "metadata": {}, "outputs": [], "source": ["acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "90dcbdf6", "metadata": {}, "outputs": [], "source": ["model.evaluate(x_test, y_test)"]}, {"cell_type": "markdown", "id": "ec80d08b", "metadata": {}, "source": ["### RNN"]}, {"cell_type": "code", "execution_count": 1, "id": "0643d97c", "metadata": {}, "outputs": [], "source": ["def build_RNN():\n    model = Sequential() \n    model.add(Embedding(max_words, 100, input_length=maxlen)) \n    #model.add(SimpleRNN(32, return_sequences=True))\n    model.add(SimpleRNN(32)) \n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) \n    return model"]}, {"cell_type": "code", "execution_count": 1, "id": "60d38149", "metadata": {}, "outputs": [], "source": ["model = build_RNN()\nmodel.summary()\nhistory_RNN = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model_RNN.h5\")"]}, {"cell_type": "code", "execution_count": 1, "id": "9db4475c", "metadata": {}, "outputs": [], "source": ["acc = history_RNN.history['acc']\nval_acc = history_RNN.history['val_acc']\nloss = history_RNN.history['loss']\nval_loss = history_RNN.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "1dbf2d7a", "metadata": {}, "outputs": [], "source": ["model.evaluate(x_test, y_test)"]}, {"cell_type": "markdown", "id": "f772fa73", "metadata": {}, "source": ["## Prediction of Recommended IND[](http://)"]}, {"cell_type": "code", "execution_count": 1, "id": "85a1584d", "metadata": {}, "outputs": [], "source": ["# BASELINE\n# That is, if all the labels are predicted as 1\n(np.sum(df['Recommended IND'] == 1)/df.shape[0]) * 100\n\n# we have to make model that performs better than this baseline"]}, {"cell_type": "markdown", "id": "b756666b", "metadata": {}, "source": ["### Naive Bayes Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "f55a2e89", "metadata": {}, "outputs": [], "source": ["def create_dict(tokenized_list):\n    my_dict = dict([(word, True) for word in tokenized_list])\n    return my_dict\ndf[\"NBCdata\"] = df[\"tokenized\"].apply(create_dict)\nr_data = df[\"NBCdata\"].values\nreviews_labels = df[\"Recommended IND\"].values\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3e803dd4", "metadata": {}, "outputs": [], "source": ["reviews_data = []\nfor i in range(len(r_data)):\n    reviews_data.append([r_data[i], reviews_labels[i]])"]}, {"cell_type": "code", "execution_count": 1, "id": "bed6a022", "metadata": {}, "outputs": [], "source": ["train_data = reviews_data[:18788]\ntest_data = reviews_data[18788:]"]}, {"cell_type": "code", "execution_count": 1, "id": "944fa1c9", "metadata": {}, "outputs": [], "source": ["classifier = NaiveBayesClassifier.train(train_data)"]}, {"cell_type": "code", "execution_count": 1, "id": "d8779a56", "metadata": {}, "outputs": [], "source": ["classifier.show_most_informative_features()"]}, {"cell_type": "code", "execution_count": 1, "id": "1f11f391", "metadata": {}, "outputs": [], "source": ["accuracy = nltk.classify.util.accuracy(classifier, test_data)\nprint(\"Classification Accuracy for Recommendation is...\")\nprint(accuracy * 100)"]}, {"cell_type": "markdown", "id": "e380ab3c", "metadata": {}, "source": ["### Deep Neural Network Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "f2530257", "metadata": {}, "outputs": [], "source": ["# Deep learning models\nlabels = np.asarray(df[\"Recommended IND\"].values)\nlabels = labels[indices]\nx_train = data[:training_samples]\ny_train = labels[:training_samples]\nx_val = data[training_samples: validation_samples] \ny_val = labels[training_samples: validation_samples]\nx_test = data[validation_samples:]\ny_test = labels[validation_samples:]\nx_train = pad_sequences(x_train, maxlen=maxlen)\nx_val = pad_sequences(x_val, maxlen=maxlen)"]}, {"cell_type": "code", "execution_count": 1, "id": "5352a36e", "metadata": {}, "outputs": [], "source": ["model = build_model()\nmodel.summary()\nhistory = model.fit(x_train, y_train,\n                    epochs=5,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model2.h5\")"]}, {"cell_type": "code", "execution_count": 1, "id": "668e8ab7", "metadata": {}, "outputs": [], "source": ["acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "74eb5b71", "metadata": {}, "outputs": [], "source": ["model.evaluate(x_test, y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "6ff5cda5", "metadata": {}, "outputs": [], "source": ["model = build_RNN()\nmodel.summary()\nhistory_RNN = model.fit(x_train, y_train,\n                    epochs=2,\n                    batch_size=32,\n                    validation_data=(x_val, y_val))\n\nmodel.save(\"model_RNN2.h5\")"]}, {"cell_type": "code", "execution_count": 1, "id": "2e4af21b", "metadata": {}, "outputs": [], "source": ["acc = history_RNN.history['acc']\nval_acc = history_RNN.history['val_acc']\nloss = history_RNN.history['loss']\nval_loss = history_RNN.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "bb8ed45f", "metadata": {}, "outputs": [], "source": ["model.evaluate(x_test, y_test)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}