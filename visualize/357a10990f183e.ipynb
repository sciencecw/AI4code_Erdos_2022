{"cells": [{"cell_type": "code", "execution_count": 1, "id": "92105dcf", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "15ec4bed", "metadata": {}, "source": ["## Loading the Library"]}, {"cell_type": "code", "execution_count": 1, "id": "a23de9a1", "metadata": {}, "outputs": [], "source": ["import os\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns"]}, {"cell_type": "code", "execution_count": 1, "id": "aa352ed5", "metadata": {}, "outputs": [], "source": ["from IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown(string))\n#printmd('**bold**')"]}, {"cell_type": "code", "execution_count": 1, "id": "8f98fb24", "metadata": {}, "outputs": [], "source": ["data_path = \"../input/janatahack-independence-day-2020-ml-hackathon/train.csv\"\ntest_data_path = \"../input/janatahack-independence-day-2020-ml-hackathon/test.csv\""]}, {"cell_type": "code", "execution_count": 1, "id": "7bd6b1cc", "metadata": {}, "outputs": [], "source": ["data_raw = pd.read_csv(data_path)"]}, {"cell_type": "code", "execution_count": 1, "id": "dbc9d94a", "metadata": {}, "outputs": [], "source": ["data_raw.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "182f9f19", "metadata": {}, "outputs": [], "source": ["print(\"Number of rows in data =\",data_raw.shape[0])\nprint(\"Number of columns in data =\",data_raw.shape[1])\nprint(\"\\n\")\nprintmd(\"**Sample data:**\")\ndata_raw.head()"]}, {"cell_type": "markdown", "id": "ab90539f", "metadata": {}, "source": ["## Checking for missing values"]}, {"cell_type": "code", "execution_count": 1, "id": "87b198b9", "metadata": {}, "outputs": [], "source": ["missing_values_check = data_raw.isnull().sum()\nprint(missing_values_check)"]}, {"cell_type": "markdown", "id": "99aed200", "metadata": {}, "source": ["## Calculating number of comments under each label"]}, {"cell_type": "code", "execution_count": 1, "id": "1862a546", "metadata": {}, "outputs": [], "source": ["# Comments with no label are considered to be clean comments.\n# Creating seperate column in dataframe to identify clean comments.\n\n# We use axis=1 to count row-wise and axis=0 to count column wise\n\nrowSums = data_raw.iloc[:,3:].sum(axis=1)\nclean_comments_count = (rowSums==0).sum(axis=0)\n\nprint(\"Total number of comments = \",len(data_raw))\nprint(\"Number of clean comments = \",clean_comments_count)\nprint(\"Number of comments with labels =\",(len(data_raw)-clean_comments_count))"]}, {"cell_type": "code", "execution_count": 1, "id": "5abe4abc", "metadata": {}, "outputs": [], "source": ["categories = list(data_raw.columns.values)\ncategories = categories[3:]\nprint(categories)"]}, {"cell_type": "markdown", "id": "4778f031", "metadata": {}, "source": ["##  Calculating number of comments in each category"]}, {"cell_type": "code", "execution_count": 1, "id": "7acb2a6c", "metadata": {}, "outputs": [], "source": ["counts = []\nfor category in categories:\n    counts.append((category, data_raw[category].sum()))\ndf_stats = pd.DataFrame(counts, columns=['category', 'number of comments'])\ndf_stats"]}, {"cell_type": "code", "execution_count": 1, "id": "cbfd773f", "metadata": {}, "outputs": [], "source": ["df_stats.category.tolist()"]}, {"cell_type": "code", "execution_count": 1, "id": "e06fe758", "metadata": {}, "outputs": [], "source": ["import textwrap\n\nsns.set(font_scale = 2)\nplt.figure(figsize=(15,8))\n\nax= sns.barplot(categories, data_raw.iloc[:,3:].sum().values)\n\nplt.title(\"Comments in each category\", fontsize=24)\nplt.ylabel('Number of comments', fontsize=18)\nplt.xlabel('Comment Type ', fontsize=18)\n\n#adding the text labels\nrects = ax.patches\nlabels = data_raw.iloc[:,3:].sum().values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n\nlabels = df_stats.category.tolist()\n# labels.sort()\nlabels=[textwrap.fill(text,12) for text in labels]\npos = np.arange(len(labels)) \nplt.xticks(pos, labels)\n\nplt.show()"]}, {"cell_type": "markdown", "id": "ba60e343", "metadata": {}, "source": ["## Calculating number of comments having multiple labels"]}, {"cell_type": "code", "execution_count": 1, "id": "6b5c6363", "metadata": {}, "outputs": [], "source": ["data_raw.iloc[:,3:]"]}, {"cell_type": "code", "execution_count": 1, "id": "f14f14f9", "metadata": {}, "outputs": [], "source": ["rowSums = data_raw.iloc[:,3:].sum(axis=1)\nmultiLabel_counts = rowSums.value_counts()\nmultiLabel_counts = multiLabel_counts.iloc[:]\n\nsns.set(font_scale = 2)\nplt.figure(figsize=(15,8))\n\nax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n\nplt.title(\"Comments having multiple labels \")\nplt.ylabel('Number of comments', fontsize=18)\nplt.xlabel('Number of labels', fontsize=18)\n\n#adding the text labels\nrects = ax.patches\nlabels = multiLabel_counts.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n\nplt.show()"]}, {"cell_type": "markdown", "id": "d62e1f81", "metadata": {}, "source": ["## WordCloud representation of most used words in each category of comments"]}, {"cell_type": "code", "execution_count": 1, "id": "a16a69a9", "metadata": {}, "outputs": [], "source": ["data_raw.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "3161476b", "metadata": {}, "outputs": [], "source": ["# Combine the Title and Abstract data\ndata_raw['TEXT'] = data_raw['TITLE'].map(str) + data_raw['ABSTRACT'].map(str)"]}, {"cell_type": "code", "execution_count": 1, "id": "37c7ac09", "metadata": {}, "outputs": [], "source": ["from wordcloud import WordCloud,STOPWORDS\n\nplt.figure(figsize=(40,25))\n\n# Computer Science\nsubset = data_raw[data_raw['Computer Science']==1]\ntext = subset.TEXT.values\ncloud_toxic = WordCloud(\n                          stopwords=STOPWORDS,\n                          background_color='black',\n                          collocations=False,\n                          width=2500,\n                          height=1800\n                         ).generate(\" \".join(text))\n\nplt.subplot(2, 3, 1)\nplt.axis('off')\nplt.title(\"Computer Science\",fontsize=40)\nplt.imshow(cloud_toxic)\n\n\n# Physics\nsubset = data_raw[data_raw.Physics==1]\ntext = subset.TEXT.values\ncloud_severe_toxic = WordCloud(\n                          stopwords=STOPWORDS,\n                          background_color='black',\n                          collocations=False,\n                          width=2500,\n                          height=1800\n                         ).generate(\" \".join(text))\n\nplt.subplot(2, 3, 2)\nplt.axis('off')\nplt.title(\"Physics\",fontsize=40)\nplt.imshow(cloud_severe_toxic)\n\n\n# Mathematics\nsubset = data_raw[data_raw.Mathematics==1]\ntext = subset.TEXT.values\ncloud_obscene = WordCloud(\n                          stopwords=STOPWORDS,\n                          background_color='black',\n                          collocations=False,\n                          width=2500,\n                          height=1800\n                         ).generate(\" \".join(text))\n\nplt.subplot(2, 3, 3)\nplt.axis('off')\nplt.title(\"Mathematics\",fontsize=40)\nplt.imshow(cloud_obscene)\n\n\n# Statistics\t\t\nsubset = data_raw[data_raw.Statistics==1]\ntext = subset.TEXT.values\ncloud_threat = WordCloud(\n                          stopwords=STOPWORDS,\n                          background_color='black',\n                          collocations=False,\n                          width=2500,\n                          height=1800\n                         ).generate(\" \".join(text))\n\nplt.subplot(2, 3, 4)\nplt.axis('off')\nplt.title(\"Statistics\",fontsize=40)\nplt.imshow(cloud_threat)\n\n\n# Quantitative Biology\nsubset = data_raw[data_raw['Quantitative Biology']==1]\ntext = subset.TEXT.values\ncloud_insult = WordCloud(\n                          stopwords=STOPWORDS,\n                          background_color='black',\n                          collocations=False,\n                          width=2500,\n                          height=1800\n                         ).generate(\" \".join(text))\n\nplt.subplot(2, 3, 5)\nplt.axis('off')\nplt.title(\"Quantitative Biology\",fontsize=40)\nplt.imshow(cloud_insult)\n\n\n# Quantitative Finance\nsubset = data_raw[data_raw['Quantitative Finance']==1]\ntext = subset.TEXT.values\ncloud_identity_hate = WordCloud(\n                          stopwords=STOPWORDS,\n                          background_color='black',\n                          collocations=False,\n                          width=2500,\n                          height=1800\n                         ).generate(\" \".join(text))\n\nplt.subplot(2, 3, 6)\nplt.axis('off')\nplt.title(\"Quantitative Finance\",fontsize=40)\nplt.imshow(cloud_identity_hate)\n\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "be7103cd", "metadata": {}, "outputs": [], "source": ["data_raw.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "337d08aa", "metadata": {}, "outputs": [], "source": ["test = pd.read_csv(test_data_path)"]}, {"cell_type": "code", "execution_count": 1, "id": "5744f947", "metadata": {}, "outputs": [], "source": ["# Combine the Title and Abstract data\ntest['TEXT'] = test['TITLE'].map(str) + test['ABSTRACT'].map(str)"]}, {"cell_type": "code", "execution_count": 1, "id": "fb1d0261", "metadata": {}, "outputs": [], "source": ["print(test.shape)\nprint(\"\\n\")\ntest.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "46005132", "metadata": {}, "outputs": [], "source": ["data_raw['split']= 1\ntest['split']=0"]}, {"cell_type": "code", "execution_count": 1, "id": "accb1da2", "metadata": {}, "outputs": [], "source": ["data = pd.concat([data_raw,test])"]}, {"cell_type": "code", "execution_count": 1, "id": "52ed3d53", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "3f16b374", "metadata": {}, "outputs": [], "source": ["# data = data_raw"]}, {"cell_type": "code", "execution_count": 1, "id": "9aca7506", "metadata": {}, "outputs": [], "source": ["import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nimport re\n\nimport sys\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")"]}, {"cell_type": "markdown", "id": "8f2a3809", "metadata": {}, "source": ["## Cleaning the Data"]}, {"cell_type": "code", "execution_count": 1, "id": "82a68dd5", "metadata": {}, "outputs": [], "source": ["def cleanHtml(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', str(sentence))\n    return cleantext\n\n\ndef cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n    cleaned = cleaned.strip()\n    cleaned = cleaned.replace(\"\\n\",\" \")\n    return cleaned\n\n\ndef keepAlpha(sentence):\n    alpha_sent = \"\"\n    for word in sentence.split():\n        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n        alpha_sent += alpha_word\n        alpha_sent += \" \"\n    alpha_sent = alpha_sent.strip()\n    return alpha_sent"]}, {"cell_type": "code", "execution_count": 1, "id": "af498546", "metadata": {}, "outputs": [], "source": ["data['TEXT'] = data['TEXT'].str.lower()\ndata['TEXT'] = data['TEXT'].apply(cleanHtml)\ndata['TEXT'] = data['TEXT'].apply(cleanPunc)\ndata['TEXT'] = data['TEXT'].apply(keepAlpha)\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "326388ef", "metadata": {}, "outputs": [], "source": ["stop_words = set(stopwords.words('english'))\nstop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\nre_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\ndef removeStopWords(sentence):\n    global re_stop_words\n    return re_stop_words.sub(\" \", sentence)\n\ndata['text'] = data['TEXT'].apply(removeStopWords)\ndata.head()"]}, {"cell_type": "markdown", "id": "a7bebc77", "metadata": {}, "source": ["## Stemming"]}, {"cell_type": "code", "execution_count": 1, "id": "001a0411", "metadata": {}, "outputs": [], "source": ["stemmer = SnowballStemmer(\"english\")\ndef stemming(sentence):\n    stemSentence = \"\"\n    for word in sentence.split():\n        stem = stemmer.stem(word)\n        stemSentence += stem\n        stemSentence += \" \"\n    stemSentence = stemSentence.strip()\n    return stemSentence\n\ndata['text'] = data['text'].apply(stemming)\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d4c7a80a", "metadata": {}, "outputs": [], "source": ["test_data = data[data['split']==0]"]}, {"cell_type": "code", "execution_count": 1, "id": "a4fdc5e9", "metadata": {}, "outputs": [], "source": ["test_data.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "091fd402", "metadata": {}, "outputs": [], "source": ["train_df = data[data['split']==1]"]}, {"cell_type": "code", "execution_count": 1, "id": "fd5a3dcb", "metadata": {}, "outputs": [], "source": ["train_df.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "ace598d8", "metadata": {}, "outputs": [], "source": ["train_df['Computer Science']=train_df['Computer Science'].astype(int)\ntrain_df['Physics']=train_df['Physics'].astype(int)\ntrain_df['Mathematics']=train_df['Mathematics'].astype(int)\ntrain_df['Statistics']=train_df['Statistics'].astype(int)\ntrain_df['Quantitative Biology']=train_df['Quantitative Biology'].astype(int)\ntrain_df['Quantitative Finance']=train_df['Quantitative Finance'].astype(int)"]}, {"cell_type": "code", "execution_count": 1, "id": "8952c98f", "metadata": {}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "90858091", "metadata": {}, "outputs": [], "source": ["train_df.shape"]}, {"cell_type": "markdown", "id": "e7a06b56", "metadata": {}, "source": ["# Train Test Split"]}, {"cell_type": "code", "execution_count": 1, "id": "ab09cd6d", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(train_df, random_state=42, test_size=0.30, shuffle=True)\n\nprint(train.shape)\nprint(test.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "7798c9fb", "metadata": {}, "outputs": [], "source": ["train_text = train['text']\ntest_text = test['text']  #test data from the train as validation \ntest_df = test_data['text'] # test data to predict "]}, {"cell_type": "code", "execution_count": 1, "id": "6339d274", "metadata": {}, "outputs": [], "source": ["train_text.head()"]}, {"cell_type": "markdown", "id": "5a4b8025", "metadata": {}, "source": ["## TF- IDF"]}, {"cell_type": "code", "execution_count": 1, "id": "e3face79", "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\nvectorizer.fit(train_text)\nvectorizer.fit(test_text)\nvectorizer.fit(test_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "16bc6d47", "metadata": {}, "outputs": [], "source": ["x_train = vectorizer.transform(train_text)\ny_train = train.drop(labels = ['ID','TITLE','ABSTRACT','TEXT','text'], axis=1)\n\nx_test = vectorizer.transform(test_text)\ny_test = test.drop(labels = ['ID','TITLE','ABSTRACT','TEXT','text'], axis=1)\n\ntest_to_predict  = vectorizer.transform(test_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "ad905d59", "metadata": {}, "outputs": [], "source": ["print(x_train.shape)\nprint(\"=\"*20)\nprint(x_test.shape)\nprint(\"=\"*20)\nprint(test_to_predict.shape)"]}, {"cell_type": "markdown", "id": "d85065a2", "metadata": {}, "source": ["## Multi-Label Classification\n- Multiple Binary Classifications - (One Vs Rest Classifier)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "be66507f", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.multiclass import OneVsRestClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "f1909580", "metadata": {}, "outputs": [], "source": ["%%time\n\n# Using pipeline for applying logistic regression and one vs rest classifier\nLogReg_pipeline = Pipeline([\n                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n            ])\n\n\npredictions = []\naccuracy_list = []\nfor category in categories:\n    printmd('**Processing {} comments...**'.format(category))\n    \n    # Training logistic regression model on train data\n    LogReg_pipeline.fit(x_train, train[category])\n    \n    # calculating test accuracy\n    prediction = LogReg_pipeline.predict(x_test)\n    accuracy = accuracy_score(test[category], prediction)\n    predictions.append(prediction)\n    accuracy_list.append(accuracy)\n    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n    print(\"\\n\")"]}, {"cell_type": "code", "execution_count": 1, "id": "533ce410", "metadata": {}, "outputs": [], "source": ["predictions"]}, {"cell_type": "code", "execution_count": 1, "id": "7fb771f4", "metadata": {}, "outputs": [], "source": ["sample = pd.read_csv('../input/janatahack-independence-day-2020-ml-hackathon/sample_submission_UVKGLZE.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "67ff7eec", "metadata": {}, "outputs": [], "source": ["sample.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "a91ea65b", "metadata": {}, "outputs": [], "source": ["%%time\n\n# Using pipeline for applying logistic regression and one vs rest classifier\nLogReg_pipeline = Pipeline([\n                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n            ])\n\n\npredictions = []\n# accuracy_list = []\nfor category in categories:\n    printmd('**Processing {} comments...**'.format(category))\n    \n    # Training logistic regression model on train data\n    LogReg_pipeline.fit(x_train, train[category])\n    \n    # calculating test accuracy\n    prediction = LogReg_pipeline.predict(test_to_predict)\n#     accuracy = accuracy_score(test[category], prediction)\n    predictions.append(prediction)\n#     accuracy_list.append(accuracy)\n#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n    print(\"Complete....\")\n    print(\"\\n\")"]}, {"cell_type": "code", "execution_count": 1, "id": "6c35d8cd", "metadata": {}, "outputs": [], "source": ["predictions"]}, {"cell_type": "code", "execution_count": 1, "id": "b863360d", "metadata": {}, "outputs": [], "source": ["sample['Computer Science']=predictions[0]\nsample['Physics']=predictions[1]\nsample['Mathematics']=predictions[2]\nsample['Statistics']=predictions[3]\nsample['Quantitative Biology']=predictions[4]\nsample['Quantitative Finance']=predictions[5]"]}, {"cell_type": "code", "execution_count": 1, "id": "a77fc4e6", "metadata": {}, "outputs": [], "source": ["sample.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "a8634683", "metadata": {}, "outputs": [], "source": ["sample.to_csv(\"submission.csv\",index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}