{"cells": [{"cell_type": "code", "execution_count": 1, "id": "53c5cb94", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "01e7e8a8", "metadata": {}, "source": ["# Titanic Survival Analysis and Prediction (Top 10%-Beginner Friendly)"]}, {"cell_type": "markdown", "id": "e7a4dc4b", "metadata": {}, "source": ["This notebook aims to analyze Titanic Disaster and build models to predict survival.  \n* [**Author**](https://www.linkedin.com/in/chi-wang-22a337207/)\n* [**Dataset**](https://www.kaggle.com/c/titanic/data)"]}, {"cell_type": "markdown", "id": "29347a94", "metadata": {}, "source": ["## Key Findings\n* The Label(Survived) is imbalanced. Survived passengers makes up 1/3 of the total number.\n* People who have Carbin information are likely to survive.\n* Female are more likely to survive than male.\n* People with 1(less) sibling seems to have a higer survival rate. The more siblings, the lower survival rate.\n* The higher the class level is, the more possible the passenger can survive.\n* The more expensive the ticket is, the more possible the passenger can survive.(It is coherent with the class level)"]}, {"cell_type": "markdown", "id": "204bbcb2", "metadata": {}, "source": ["## Tips\n* Divide the whole project into several stages, each stage save a middle version of data. It's helpful for later examining.\n* Columns with too much Missing value(>40%) should be useless. However, the \"Missing value information\" could be valuable. Eg. Cabin.\n* Find the high correlation feature as the group key for group imputation.\n* It's better to bin the numerical features in Classification scenario. The strategy of binning(number,range,step) is important. It's better to do it with Visualization.\n* Take the advantage of all the given dataset(train and test). Eg. Imputation, Modelling.\n* Feature Engineering is so important, more than hyper-parameter tuning.\n* Overfitting usually happens especially in the relatively small dataset. Complex models not always outperform than simple model.\n* Do not trust the 100% accuracy performance in the leaderboard. They are cheating.\n* Do not be very struggle with the leaderboard performance. As long as you do everything right, the performance should be acceptable(Top 10%,20%).\n* Don't waste too much time to make small improvement (balance!!!). The important part is the process/method of Analysis and Modelling.\n* Learn from the best. Kernel(Top voted, Top comments) "]}, {"cell_type": "markdown", "id": "d4a1d904", "metadata": {}, "source": ["## Issues\n* Didn't apply feature scaleing for the needed models(Eg. KNN, Logistic regression). Although, Tree-based models don't need this.\n* Didn't apply parameter tuning for modeling.\n* Could enrich the type of the visualization."]}, {"cell_type": "markdown", "id": "056f4417", "metadata": {}, "source": ["## Reference(Thanks for inspiration)\n* https://www.kaggle.com/javiervallejos/titanic-simple-decision-tree-model-score-top-3/notebook\n* https://www.kaggle.com/giorgosfoukarakis/titanic-from-eda-to-the-power-of-ensembles-top4"]}, {"cell_type": "markdown", "id": "9cce3273", "metadata": {}, "source": ["# Table of Content\n1. [Data Overview](#1)\n    * [1. Load Data](#1.1)\n    * [2. Data Type](#1.2)\n    * [3. Statistical View](#1.3)\n2. [Data Preprocessing](#2)\n    * [1. Extract Potential Information](#2.1)\n        * [Title](#2.1.1)\n    * [2. Drop irrelevant columns](#2.2)\n    * [3. Missing Value Detection](#2.3)\n    * [4. Data Imputation](#2.4)\n        * [1.Missing Value Exploratory](#2.4.1)\n            * [Age](#2.4.1.1)\n            * [Fare](#2.4.1.2)\n            * [Embarked](#2.4.1.3)\n            * [Cabin](#2.4.1.4)\n        * [2. Median imputation](#2.4.2)\n        * [3. Majority value imputation](#2.4.3)\n3. [Data Analysis](#3)\n    * [1. What is the distribution of survival? ](#3.1)\n    * [2. What is the distribution of Sex on survival? ](#3.2)\n    * [3. What is the distribution of Pclass on survival? ](#3.3)\n    * [4. What is the distribution of SibSp on survival? ](#3.4)\n    * [5. What is the distribution of Parch on survival? ](#3.5)\n    * [6. What is the distribution of Embarked on survival? ](#3.6)\n    * [7. What is the distribution of Age on survival? ](#3.7)\n    * [8. What is the distribution of Fare on survival? ](#3.8)\n4. [Feature Engineering](#4)\n    * [1. Create new features ](#4.1)\n        * [Family Size](#4.1.1)\n    * [2. One-Hot Encoding ](#4.2)\n    * [3. Label Encoding ](#4.3)\n5. [Modelling](#5)\n    * [1. Train Test Split ](#5.1)\n    * [2. Train Models ](#5.2)\n        * [1. Logistic regression ](#5.2.1)\n        * [2. k-nearest neighbors ](#5.2.2)\n        * [3. Support Vector Machine ](#5.2.3)\n        * [4. Decision Tree ](#5.2.4)\n        * [5. Random Forest ](#5.2.5)\n        * [6. Gradient boosting ](#5.2.6)\n        * [7. XGBoost ](#5.2.7)\n        * [8. CatBoost ](#5.2.8)\n        * [9. LGBoost ](#5.2.9)\n    * [3. Model Comparison ](#5.3)\n6. [Prediction](#6)\n    * [1. Drop irrelevant columns](#6.1)\n    * [2. Feature Engineering](#6.2)\n    * [3. Make Prediction](#6.3)\n    * [4. Save the Prediction to CSV file](#6.4)"]}, {"cell_type": "markdown", "id": "6d1c36cf", "metadata": {}, "source": ["<a id=\"1\"></a>\n# 1. Data Overview"]}, {"cell_type": "code", "execution_count": 1, "id": "78f6c65c", "metadata": {}, "outputs": [], "source": ["# Import packages\n\n## Basic data processing\nimport numpy as np\nimport pandas as pd\n\n## Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\n## Modelling\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, StratifiedShuffleSplit, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\n## Settings\npd.set_option('display.max_columns', 500) # Able to display more columns."]}, {"cell_type": "markdown", "id": "8b7f3acc", "metadata": {}, "source": ["<a id=\"1.1\"></a>\n## 1.1. Load Data"]}, {"cell_type": "code", "execution_count": 1, "id": "34f2b442", "metadata": {}, "outputs": [], "source": ["# Load the dataset\ntrain_df = pd.read_csv(\"../input/titanic/train.csv\")\ntest_df = pd.read_csv(\"../input/titanic/test.csv\")\ndata_df = pd.concat([train_df, test_df])\ndata_df.info() # show entries, dtypes, memory useage."]}, {"cell_type": "code", "execution_count": 1, "id": "1f0c75fa", "metadata": {}, "outputs": [], "source": ["# Have a look\ndata_df.head(5)"]}, {"cell_type": "code", "execution_count": 1, "id": "f557b2d5", "metadata": {}, "outputs": [], "source": ["# Check the shape of train,test and the whole dataset\ntrain_df.shape, test_df.shape, data_df.shape"]}, {"cell_type": "markdown", "id": "02b92b2e", "metadata": {}, "source": ["<a id=\"1.2\"></a>\n## 1.2. Data Type\n\n> [NOIR](https://www.questionpro.com/blog/nominal-ordinal-interval-ratio/): Nominal, Ordinal, Interval, Ratio.   \nSpecify the data type of each variable for the following statistic analysis.  \n\n| Variable              | Type     | Description |\n| :---                  |  :----:  |  :----:     |\n| PassengerID | Nominal | The unique ID of passenger |\n| Name | Nominal | Name\n| Survived | Nominal  | whether the passenger survived; 0 = No, 1 = Yes | \n| Pclass | Ordinal | Ticket class; 1 = 1st, 2 = 2nd, 3 = 3rd |\n| Sex | Nominal | Sex | \n| Age | Ratio | Age in years | \n| Sibsp | Ordinal | Number of siblings / spouses aboard the Titanic;| \n| Parch | Ordinal | Number of parents / children aboard the Titanic;| \n| Ticket | Nominal | Ticket number |\n| Fare | Ratio | Passenger fare |\n| Cabin | Nominal | Cabin number | \n| Embarked | Nominal | Port of Embarkation |\n"]}, {"cell_type": "markdown", "id": "6ca6adc3", "metadata": {}, "source": ["<a id=\"1.3\"></a>\n## 1.3. Statistical View "]}, {"cell_type": "code", "execution_count": 1, "id": "a29e124e", "metadata": {}, "outputs": [], "source": ["# Basic statistic on Ordinal, Interval and Ratio data.\nOIR_columns =  ['Pclass','Age', 'Fare', 'SibSp', 'Parch']\ndata_df[OIR_columns].describe()"]}, {"cell_type": "markdown", "id": "4a23d5da", "metadata": {}, "source": ["1. Most passengers are young(75%)\n2. There are some expensive tickets(> 500), some weird price(min=0)\n3. It seems most of the passengers have fewer relatives(SibSp/Parch)---75%"]}, {"cell_type": "code", "execution_count": 1, "id": "525d824b", "metadata": {}, "outputs": [], "source": ["# Basic statistic on Nominal data\ndata_df.loc[:, ~data_df.columns.isin(OIR_columns)].astype(\"object\").describe() # All the Nominal data can be treated as \"object\" type for simplicity."]}, {"cell_type": "markdown", "id": "b1052391", "metadata": {}, "source": ["1. There are 3 Ports of Embarkation\n2. It seems that there are less Cabin information. There are some people share the same cabin\n3. There are some people have the same ticket(1309-929=380)"]}, {"cell_type": "markdown", "id": "7c161926", "metadata": {}, "source": ["<a id=\"2\"></a>\n# 2. Data Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "3ccd458e", "metadata": {}, "outputs": [], "source": ["'''\nDescription: Calculate and Visualize survival rate for chosen feature.\nArgs:\n    data: The dataset\n    feature: The chosen feature\n    graph_type: The graph type. Eg. \"bar\", \"point\"\nReturn: None\n'''\ndef survival_rate(data, feature, graph_type):\n    # Calculate survival rate\n    print(data[[feature, 'Survived']].groupby([feature], as_index=False).mean().sort_values(by='Survived'))\n    # Visualization\n    sns.catplot(x=feature, y=\"Survived\", data=data, kind=graph_type, height=6, aspect=1)\\\n       .set_ylabels(\"Survival Rate\")\\\n       .ax.set_title(f\"Survival Rate on {feature}\", fontsize = 20)"]}, {"cell_type": "markdown", "id": "05611474", "metadata": {}, "source": ["<a id=\"2.1\"></a>\n## 2.1. Extract Potential Information"]}, {"cell_type": "markdown", "id": "1e96778f", "metadata": {}, "source": ["<a id=\"2.1.1\"></a>\n### Title"]}, {"cell_type": "code", "execution_count": 1, "id": "069c1a20", "metadata": {}, "outputs": [], "source": ["# Extract title from Name\ndata_df['title'] = data_df['Name'].map(lambda x:x.split(',')[1].split('.')[0].strip())\ndata_df['title'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "0baf00a1", "metadata": {}, "outputs": [], "source": ["# Aggregate rare titles\ntitle_dic={\n    'Mr':'Mr',\n    'Miss':'Miss',\n    'Mrs':'Mrs',\n    'Master':'Master',\n    'Dr':'Other',\n    'Rev':'Other',\n    'Mlle':'Miss',\n    'Col': 'Other',\n    'Major':'Other',\n    'Sir':'Mr',\n    'Mme':'Miss',\n    'Jonkheer':'Other',\n    'Lady':'Miss',\n    'Capt':'Other',\n    'Don':'Mr',\n    'Dona':'Mrs',\n    'Ms':'Miss',\n    'the Countess':'Other'\n}"]}, {"cell_type": "code", "execution_count": 1, "id": "c94eab3d", "metadata": {}, "outputs": [], "source": ["# Use the defined rules to set categories for title\ndata_df['title'] = data_df['title'].map(title_dic)\nsurvival_rate(data_df, 'title', 'bar')"]}, {"cell_type": "markdown", "id": "63bbddb3", "metadata": {}, "source": ["<a id=\"2.2\"></a>\n## 2.2. Drop irrelevant columns"]}, {"cell_type": "code", "execution_count": 1, "id": "b48118e8", "metadata": {}, "outputs": [], "source": ["# Irrelevant columns\n'''\nPassengerId: Passenger Id is useless for analysis and modeling.\nName: Title has already been extracted.\nTicket: Ticket seems useless here.\n'''\nirrelevant_columns = ['PassengerId', 'Name', 'Ticket']\ndata_preprocessed_df = data_df.drop(irrelevant_columns, axis=1)"]}, {"cell_type": "markdown", "id": "328f0294", "metadata": {}, "source": ["<a id=\"2.3\"></a>\n## 2.3. Missing Value Detection"]}, {"cell_type": "code", "execution_count": 1, "id": "3248cda0", "metadata": {}, "outputs": [], "source": ["# Replace the empty data with NaN\ndata_preprocessed_df.replace(\"\", float(\"NaN\"), inplace=True)\ndata_preprocessed_df.replace(\" \", float(\"NaN\"), inplace=True)\n\n# Count missing value(NaN, na, null, None) of each columns, Then transform the result to a pandas dataframe. \ncount_missing_value = data_preprocessed_df.isna().sum() / data_preprocessed_df.shape[0] * 100\ncount_missing_value_df = pd.DataFrame(count_missing_value.sort_values(ascending=False), columns=['Missing%'])"]}, {"cell_type": "code", "execution_count": 1, "id": "519b9c48", "metadata": {}, "outputs": [], "source": ["# Visualize the percentage(>0) of Missing value in each column.\nmissing_value_df = count_missing_value_df[count_missing_value_df['Missing%'] > 0]\n\nplt.figure(figsize=(5, 8)) # Set the figure size\nmissing_value_graph = sns.barplot(x = missing_value_df.index, y = \"Missing%\", data=missing_value_df, orient=\"v\")\nmissing_value_graph.set_title(\"Percentage Missing Value\", fontsize = 20)\nmissing_value_graph.set_xlabel(\"Features\")\nfor p in missing_value_graph.patches:\n        missing_value_graph.annotate(round(p.get_height(), 2), (p.get_x()+0.25, p.get_height())) #show value on each bar"]}, {"cell_type": "markdown", "id": "a374de2c", "metadata": {}, "source": ["This is the overall missing value of the whole dataset(train + test)."]}, {"cell_type": "markdown", "id": "e3d3f437", "metadata": {}, "source": ["<a id=\"2.4\"></a>\n## 2.4. Data Imputation\n> Choose the suitable imputation tech which can highly represent the central tendency of the data."]}, {"cell_type": "markdown", "id": "ec69fb4c", "metadata": {}, "source": ["<a id=\"2.4.1\"></a>\n### 2.4.1. Missing Value Exploratory"]}, {"cell_type": "markdown", "id": "81deacea", "metadata": {}, "source": ["<a id=\"2.4.1.1\"></a>\n### Age"]}, {"cell_type": "code", "execution_count": 1, "id": "e6c10bfb", "metadata": {}, "outputs": [], "source": ["# Visualize the distribution of Age\nage_fig = go.Figure()\nage_fig.add_trace(go.Box(\n                        y=data_preprocessed_df[\"Age\"],\n                        name='Age',\n                        boxmean=True))\n\nage_fig.update_layout(\n                height=600, \n                width=800,\n                title={\n                'text': \"The Distribution of Age\",\n                'font': {'size': 24},\n                'y':0.95,\n                'x':0.5,\n                'xanchor': 'center',\n                'yanchor': 'top'},\n                yaxis_title='Age',\n                )\n\nage_fig.show()"]}, {"cell_type": "markdown", "id": "e0bdecb5", "metadata": {}, "source": ["It seems overall mean and median of age doesn't differ so much."]}, {"cell_type": "markdown", "id": "98c9ee88", "metadata": {}, "source": ["<a id=\"2.4.1.2\"></a>\n### Fare"]}, {"cell_type": "code", "execution_count": 1, "id": "e3dd648a", "metadata": {}, "outputs": [], "source": ["# Visualize the distribution of Fare\nfare_fig = go.Figure()\nfare_fig.add_trace(go.Box(\n                        y=data_preprocessed_df[\"Fare\"],\n                        name='Fare',\n                        boxmean=True))\n\nfare_fig.update_layout(\n                height=600, \n                width=800,\n                title={\n                'text': \"The Distribution of Fare\",\n                'font': {'size': 24},\n                'y':0.95,\n                'x':0.5,\n                'xanchor': 'center',\n                'yanchor': 'top'},\n                yaxis_title='Fare',\n                )\n\nfare_fig.show()"]}, {"cell_type": "markdown", "id": "2db01171", "metadata": {}, "source": ["It seems mean and median of age does differ so much. However, it is only 1 Missing value, it should not affect the modelling process so much."]}, {"cell_type": "markdown", "id": "d32bbb2a", "metadata": {}, "source": ["<a id=\"2.4.1.3\"></a>\n### Embarked"]}, {"cell_type": "code", "execution_count": 1, "id": "7c737f2e", "metadata": {}, "outputs": [], "source": ["# Visualize the distribution of Embarked\nembarked_fig = px.histogram(data_preprocessed_df, x=\"Embarked\")\nembarked_fig.update_layout(\n                height=600, \n                width=800,\n                title={\n                'text': \"The count of Embarked\",\n                'font': {'size': 24},\n                'y':0.95,\n                'x':0.5,\n                'xanchor': 'center',\n                'yanchor': 'top'},\n                )\n\nembarked_fig.show()"]}, {"cell_type": "markdown", "id": "7cf40919", "metadata": {}, "source": ["It seems S is the most frequent value of Embarked.  \n**It seems that we can try simplely use Median imputation on *Age* and *Fare* and Majority value imputation on *Embarked*.**"]}, {"cell_type": "markdown", "id": "551b2d13", "metadata": {}, "source": ["<a id=\"2.4.1.4\"></a>\n### Cabin"]}, {"cell_type": "code", "execution_count": 1, "id": "895e38fd", "metadata": {}, "outputs": [], "source": ["# Calculate the relationship between Cabin and Survived Rate\ndata_preprocessed_df.groupby(data_preprocessed_df['Cabin'].isnull())['Survived'].mean()"]}, {"cell_type": "markdown", "id": "b9d5c613", "metadata": {}, "source": ["It seems people who have Carbin information are likely to survive."]}, {"cell_type": "code", "execution_count": 1, "id": "0e3db115", "metadata": {}, "outputs": [], "source": ["# Transform Carbin information to an indicator representing whether passenger have Carbin information.\ndata_preprocessed_df['Cabin_indicator'] = np.where(data_preprocessed_df['Cabin'].isnull(), 0, 1)\ndata_preprocessed_df.drop('Cabin', axis=1, inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "b8df8da3", "metadata": {}, "outputs": [], "source": ["data_preprocessed_df"]}, {"cell_type": "markdown", "id": "e72a5e89", "metadata": {}, "source": ["<a id=\"2.4.2\"></a>\n### 2.4.2. Median imputation "]}, {"cell_type": "code", "execution_count": 1, "id": "a8963611", "metadata": {}, "outputs": [], "source": ["# Find correlated column with Age\nplt.figure(figsize=(12,9))\nsns.heatmap(data_preprocessed_df.corr(), cmap=\"coolwarm\", annot = True, fmt='.3f').set_title('Pearson Correlation', fontsize=22)"]}, {"cell_type": "code", "execution_count": 1, "id": "9ec89a28", "metadata": {}, "outputs": [], "source": ["data_preprocessed_median_df = data_preprocessed_df.copy()\n#data_preprocessed_median_df['Age'] = data_preprocessed_df['Age'].fillna(data_preprocessed_df['Age'].median())\n# Group imputation for Age by 'Pclass' and 'Sex'\ndata_preprocessed_median_df[\"Age\"].fillna(data_preprocessed_median_df.groupby(['Pclass','Sex'])['Age'].transform(\"median\"), inplace=True)\ndata_preprocessed_median_df['Fare'] = data_preprocessed_df['Fare'].fillna(data_preprocessed_df['Fare'].median())"]}, {"cell_type": "markdown", "id": "653eaa77", "metadata": {}, "source": ["<a id=\"2.4.3\"></a>\n### 2.4.3. Majority value imputation "]}, {"cell_type": "code", "execution_count": 1, "id": "49ffae8c", "metadata": {}, "outputs": [], "source": ["data_preprocessed_median_df['Embarked'].fillna(data_preprocessed_median_df['Embarked'].mode()[0], inplace=True)\n# Check Missing value for\nprint(f'Missing value:\\n Median imputation: {sum(data_preprocessed_median_df.isna().sum())}')"]}, {"cell_type": "markdown", "id": "1ca48432", "metadata": {}, "source": ["418 is the number of survived passenger in test data. Therefore, it means no Missing value in the dataset."]}, {"cell_type": "code", "execution_count": 1, "id": "84d79079", "metadata": {}, "outputs": [], "source": ["# Cut the Age and Fare into bins. Set labels by alphabetically for later encoding.\ndata_preprocessed_median_df['AgeBin'] = pd.cut(data_preprocessed_median_df['Age'].astype(int), 5, labels=['a', 'b', 'c', 'd','e'])\ndata_preprocessed_median_df['FareBin'] = pd.cut(data_preprocessed_median_df['Fare'].astype(int), 4, labels=['a', 'b', 'c', 'd'])\n\n# Women and Children indicator\n#data_preprocessed_median_df['WomChi'] = ((data_preprocessed_median_df.AgeBin == 'a') | (data_preprocessed_median_df.Sex == 'female'))"]}, {"cell_type": "code", "execution_count": 1, "id": "11a7b509", "metadata": {}, "outputs": [], "source": ["# Create a new dataset only include training data.\ndata_best_df = data_preprocessed_median_df.iloc[:891].copy()"]}, {"cell_type": "markdown", "id": "b8dcea64", "metadata": {}, "source": ["<a id=\"3\"></a>\n# 3. Data Analysis\n* Sex, Pclass, SibSp, Parch, Embarked - Pie\n* Age, Fare - Boxplot\n* Survival Rate - Barplot/Lineplot"]}, {"cell_type": "markdown", "id": "0e94aa8c", "metadata": {}, "source": ["<a id=\"3.1\"></a>\n## 3.1. What is the distribution of survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "8dbdf50c", "metadata": {}, "outputs": [], "source": ["# Count the number of survived(0/1), transform the result to pandas dataframe\nsurvival_counts = data_best_df[\"Survived\"].value_counts()\nsurvival_counts_df = pd.DataFrame(survival_counts)"]}, {"cell_type": "code", "execution_count": 1, "id": "7d77968d", "metadata": {}, "outputs": [], "source": ["# Visualize the distribution of the survival\nsurvival_fig = make_subplots(\n    rows=1, cols=2, \n    specs=[[{\"type\": \"xy\"}, {\"type\": \"domain\"}]])\n\nsurvival_fig.add_trace(go.Bar(x=survival_counts_df.index, \n                              y=survival_counts_df[\"Survived\"],\n                              text=survival_counts_df[\"Survived\"],\n                              textposition='outside',\n                              showlegend=False),\n                              1, 1)\n\nsurvival_fig.add_trace(go.Pie(labels=survival_counts_df.index, \n                     values=survival_counts_df[\"Survived\"],\n                     showlegend=True),\n                     1, 2)\n\nsurvival_fig.update_layout(\n                  height=600, \n                  width=1000,\n                  title={\n                  'text': \"The distribution of Survival\",\n                  'font': {'size': 24},\n                  'y':0.95,\n                  'x':0.5,\n                  'xanchor': 'center',\n                  'yanchor': 'top'},\n                  xaxis1_title = 'Survived', \n                  yaxis1_title = 'Counts',\n                  legend_title_text=\"Survived\"\n                 )\nsurvival_fig.update_xaxes(type='category')\nsurvival_fig.show()"]}, {"cell_type": "markdown", "id": "f001eaef", "metadata": {}, "source": ["* The Label(Survived) is imbalanced. The survived passenger makes up 1/3 of the total number."]}, {"cell_type": "markdown", "id": "b4f25b96", "metadata": {}, "source": ["<a id=\"3.2\"></a>\n## 3.2. What is the distribution of Sex on survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "c018d623", "metadata": {}, "outputs": [], "source": ["# Visualize the categorical data by Pie chart\n'''\nDescription:\nArgs:\n    data: The dataset is going to be visualized\n    feature: The chosen feature\nReturn: None\n'''\ndef categorical_VIS(data, feature):\n    \n    # Calculate the distribution of the chosen feature\n    survived = data[data[\"Survived\"] == 1][feature]\n    survived_df = pd.DataFrame(survived.value_counts())\n    not_survived = data[data[\"Survived\"] == 0][feature]\n    not_survived_df = pd.DataFrame(not_survived.value_counts())\n    \n    # Visualization\n    survival_fig = make_subplots(\n    rows=1, cols=2, \n    subplot_titles=(\"Survived\", \"Non-Survived\"),\n    specs=[[{\"type\": \"domain\"}, {\"type\": \"domain\"}]])\n    survival_fig.add_trace(go.Pie(labels=survived_df.index, \n                     values=survived_df[feature],\n                     showlegend=True),\n                     1, 1)\n    survival_fig.add_trace(go.Pie(labels=not_survived_df.index, \n                     values=not_survived_df[feature],\n                     showlegend=True),\n                     1, 2)\n    survival_fig.update_layout(\n                  height=600, \n                  width=1000,\n                  title={\n                  'text': \"The Distribution of \"+ feature + \" on Survival\",\n                  'font': {'size': 24},\n                  'y':0.95,\n                  'x':0.5,\n                  'xanchor': 'center',\n                  'yanchor': 'top'},\n                  legend_title_text=feature\n                 )\n    survival_fig.update_xaxes(type='category')\n    survival_fig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "091dc69e", "metadata": {}, "outputs": [], "source": ["categorical_VIS(data_best_df, \"Sex\")"]}, {"cell_type": "code", "execution_count": 1, "id": "40e41ff1", "metadata": {}, "outputs": [], "source": ["# Calcute the survival Rate\nsurvival_rate(data_best_df, 'Sex', 'bar')"]}, {"cell_type": "markdown", "id": "2ab82a3d", "metadata": {}, "source": ["* Female are more likely to survive than male."]}, {"cell_type": "markdown", "id": "f6faf230", "metadata": {}, "source": ["<a id=\"3.3\"></a>\n## 3.3. What is the distribution of Pclass on survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "f7b82cea", "metadata": {}, "outputs": [], "source": ["categorical_VIS(data_best_df, \"Pclass\")"]}, {"cell_type": "code", "execution_count": 1, "id": "103a080e", "metadata": {}, "outputs": [], "source": ["# Calcute the survival Rate\nsurvival_rate(data_best_df, 'Pclass', 'bar')"]}, {"cell_type": "markdown", "id": "174438df", "metadata": {}, "source": ["* The higher the class level is, the more possible the passenger can survive."]}, {"cell_type": "markdown", "id": "866a4df5", "metadata": {}, "source": ["<a id=\"3.4\"></a>\n## 3.4. What is the distribution of SibSp on survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "fafb7165", "metadata": {}, "outputs": [], "source": ["categorical_VIS(data_best_df, \"SibSp\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4939e8f9", "metadata": {}, "outputs": [], "source": ["# Calcute the survival Rate\nsurvival_rate(data_best_df, 'SibSp', 'point')"]}, {"cell_type": "markdown", "id": "c5747634", "metadata": {}, "source": ["People with 1(fewer) sibling seems to have a higer survival rate."]}, {"cell_type": "markdown", "id": "c4ac3ad0", "metadata": {}, "source": ["<a id=\"3.5\"></a>\n## 3.5. What is the distribution of Parch on survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "06d19cbe", "metadata": {}, "outputs": [], "source": ["categorical_VIS(data_best_df, \"Parch\")"]}, {"cell_type": "code", "execution_count": 1, "id": "cc227210", "metadata": {}, "outputs": [], "source": ["# Calcute the survival Rate\nsurvival_rate(data_best_df, 'Parch', 'point')"]}, {"cell_type": "markdown", "id": "bc0e9643", "metadata": {}, "source": ["It seems people who have fewer parents or children are likely to survive."]}, {"cell_type": "markdown", "id": "c167c877", "metadata": {}, "source": ["<a id=\"3.6\"></a>\n## 3.6. What is the distribution of Embarked on survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "1986565e", "metadata": {}, "outputs": [], "source": ["categorical_VIS(data_best_df, \"Embarked\")"]}, {"cell_type": "code", "execution_count": 1, "id": "ba2b0e28", "metadata": {}, "outputs": [], "source": ["# Calcute the survival Rate\nsurvival_rate(data_best_df, 'Embarked', 'bar')"]}, {"cell_type": "markdown", "id": "f8d81e9f", "metadata": {}, "source": ["It seems people who from C(Cherbourg) have a relatively high survival rate."]}, {"cell_type": "markdown", "id": "a8a32e81", "metadata": {}, "source": ["<a id=\"3.7\"></a>\n## 3.7. What is the distribution of Age on survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "5ca46b16", "metadata": {}, "outputs": [], "source": ["age_fig = px.box(data_best_df, x=\"Survived\", y=\"Age\")\nage_fig.update_layout(\n                  height=600, \n                  width=1000,\n                  title={\n                  'text': \"The Distribution of Age on Survival\",\n                  'font': {'size': 24},\n                  'y':0.95,\n                  'x':0.5,\n                  'xanchor': 'center',\n                  'yanchor': 'top'},\n                  legend_title_text=\"Survived\"\n                 )"]}, {"cell_type": "code", "execution_count": 1, "id": "4e196835", "metadata": {}, "outputs": [], "source": ["# Calcute the survival Rate\nsurvival_rate(data_best_df, 'AgeBin', 'point')"]}, {"cell_type": "markdown", "id": "4da86e9d", "metadata": {}, "source": ["<a id=\"3.8\"></a>\n## 3.8. What is the distribution of Fare on survival?"]}, {"cell_type": "code", "execution_count": 1, "id": "d3ea9f69", "metadata": {}, "outputs": [], "source": ["fare_fig = px.box(data_best_df, x=\"Survived\", y=\"Fare\")\nfare_fig.update_layout(\n                  height=600, \n                  width=1000,\n                  title={\n                  'text': \"The Distribution of Fare on Survival\",\n                  'font': {'size': 24},\n                  'y':0.95,\n                  'x':0.5,\n                  'xanchor': 'center',\n                  'yanchor': 'top'},\n                  legend_title_text=\"Survived\"\n                 )"]}, {"cell_type": "code", "execution_count": 1, "id": "0a671fff", "metadata": {}, "outputs": [], "source": ["# Calcute the survival Rate\nsurvival_rate(data_best_df, 'FareBin', 'point')"]}, {"cell_type": "markdown", "id": "7abb816c", "metadata": {}, "source": ["* The more expensive the ticket is, the more possible the passenger can survive."]}, {"cell_type": "markdown", "id": "f36b0241", "metadata": {}, "source": ["<a id=\"4\"></a>\n# 4. Feature Engineering"]}, {"cell_type": "markdown", "id": "057ba2c4", "metadata": {}, "source": ["<a id=\"4.1\"></a>\n## 4.1. Create new features"]}, {"cell_type": "markdown", "id": "d74781da", "metadata": {}, "source": ["<a id=\"4.1.1\"></a>\n### Family Size"]}, {"cell_type": "code", "execution_count": 1, "id": "8abfaec3", "metadata": {}, "outputs": [], "source": ["# Combine the SibSp and Parch to Family Size\ndata_best_df['Family_size'] = data_best_df['SibSp'] + data_best_df['Parch'] + 1\nsurvival_rate(data_best_df, 'Family_size', 'point')"]}, {"cell_type": "code", "execution_count": 1, "id": "9fce0aea", "metadata": {}, "outputs": [], "source": ["# Binning the family_size\ndata_best_df.loc[data_best_df['Family_size'] == 1, 'Family_size'] = 0 # Alone\ndata_best_df.loc[(data_best_df['Family_size'] > 1) & (data_best_df['Family_size'] <= 4), 'Family_size'] = 1  # Small Family \ndata_best_df.loc[(data_best_df['Family_size'] > 4) & (data_best_df['Family_size'] <= 6), 'Family_size'] = 2  # Medium Family\ndata_best_df.loc[data_best_df['Family_size']  > 6, 'Family_size'] = 3 # Large Family"]}, {"cell_type": "code", "execution_count": 1, "id": "a7145971", "metadata": {}, "outputs": [], "source": ["# Feature SibSp and Parch are replaced by Family_size\ndata_best_df.drop(['SibSp', 'Parch'], axis=1, inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "6e916213", "metadata": {}, "outputs": [], "source": ["# Feature Age and Fare are replaced by AgeBin and FareBin\ndata_best_df.drop(['Age', 'Fare'], axis=1, inplace=True)"]}, {"cell_type": "markdown", "id": "a536776e", "metadata": {}, "source": ["<a id=\"4.2\"></a>\n## 4.2. One-Hot Encoding"]}, {"cell_type": "code", "execution_count": 1, "id": "e616cf61", "metadata": {}, "outputs": [], "source": ["# Select features that are suitable for One Hot Encoding\nonehot_features = [\"Embarked\",\"title\"]\nonehot_df = pd.get_dummies(data_best_df[onehot_features])\ndata_best_df.drop(onehot_features, axis=1, inplace=True)\ndata_best_df = pd.concat([data_best_df, onehot_df], axis=1)"]}, {"cell_type": "markdown", "id": "0c9438be", "metadata": {}, "source": ["<a id=\"4.3\"></a>\n## 4.3. Label Encoding"]}, {"cell_type": "code", "execution_count": 1, "id": "e14b6344", "metadata": {}, "outputs": [], "source": ["# Select features that are suitable for Label Encoding\ndata_best_df[\"Sex\"]  = LabelEncoder().fit_transform(data_best_df[\"Sex\"])\ndata_best_df[\"AgeBin\"]  = LabelEncoder().fit_transform(data_best_df[\"AgeBin\"])\ndata_best_df[\"FareBin\"]  = LabelEncoder().fit_transform(data_best_df[\"FareBin\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "c9ffb85d", "metadata": {}, "outputs": [], "source": ["data_best_df"]}, {"cell_type": "markdown", "id": "514d26bc", "metadata": {}, "source": ["<a id=\"5\"></a>\n# 5. Modelling"]}, {"cell_type": "markdown", "id": "c5f15d70", "metadata": {}, "source": ["<a id=\"5.1\"></a>\n## 5.1. Train Test Split"]}, {"cell_type": "code", "execution_count": 1, "id": "b4593894", "metadata": {}, "outputs": [], "source": ["# Train/Test Split\nX = data_best_df.drop([\"Survived\"], axis=1)\nY = data_best_df.Survived.astype('int8')\nx_train, x_test, y_train, y_test = train_test_split(X, Y,test_size = 0.25, random_state=0, stratify=Y)"]}, {"cell_type": "markdown", "id": "52a7db10", "metadata": {}, "source": ["<a id=\"5.2\"></a>\n## 5.2. Train and Validation"]}, {"cell_type": "markdown", "id": "d5b6111d", "metadata": {}, "source": ["<a id=\"5.2.1\"></a>\n### 5.2.1 Logistic regression"]}, {"cell_type": "code", "execution_count": 1, "id": "df7ac6c0", "metadata": {}, "outputs": [], "source": ["# Logistic regression\n# https://stackoverflow.com/questions/65682019/attributeerror-str-object-has-no-attribute-decode-in-fitting-logistic-regre\nlr = LogisticRegression(penalty = 'l2',solver = 'liblinear')\nlr.fit(x_train, y_train)\npredictions = lr.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "a121ebba", "metadata": {}, "outputs": [], "source": ["# Cross Validation\nlr_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\nlr_cv_avg = cross_val_score(lr, X, Y, cv=lr_cv, scoring=\"accuracy\").mean()\nlr_cv_avg"]}, {"cell_type": "markdown", "id": "504c1e30", "metadata": {}, "source": ["<a id=\"5.2.2\"></a>\n### 5.2.2 k-nearest neighbors"]}, {"cell_type": "code", "execution_count": 1, "id": "daad1740", "metadata": {}, "outputs": [], "source": ["# KNN\nkNN = KNeighborsClassifier()\nkNN.fit(x_train, y_train)\npredictions = kNN.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "df37dfc1", "metadata": {}, "outputs": [], "source": ["# Cross Validation\nkNN_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\nkNN_cv_avg = cross_val_score(kNN, X, Y, cv=kNN_cv, scoring=\"accuracy\").mean()\nkNN_cv_avg"]}, {"cell_type": "markdown", "id": "ffa5bdc5", "metadata": {}, "source": ["<a id=\"5.2.3\"></a>\n### 5.2.3 Support Vector Machine"]}, {"cell_type": "code", "execution_count": 1, "id": "48d38c99", "metadata": {}, "outputs": [], "source": ["# SVM\nsvm = SVC(probability=True)\nsvm.fit(x_train, y_train)\npredictions = svm.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "0ae39322", "metadata": {}, "outputs": [], "source": ["# Cross Validation\nsvm_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\nsvm_cv_avg = cross_val_score(svm, X, Y, cv=svm_cv, scoring=\"accuracy\").mean()\nsvm_cv_avg"]}, {"cell_type": "markdown", "id": "a487c485", "metadata": {}, "source": ["<a id=\"5.2.4\"></a>\n### 5.2.4 Decision Tree"]}, {"cell_type": "code", "execution_count": 1, "id": "42a97b85", "metadata": {}, "outputs": [], "source": ["# Decision tree\ndt = DecisionTreeClassifier(random_state=0)\ndt.fit(x_train, y_train)\npredictions = dt.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "93c24bf3", "metadata": {}, "outputs": [], "source": ["# Cross Validation\ndt_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\ndt_cv_avg = cross_val_score(dt, X, Y, cv=dt_cv, scoring=\"accuracy\").mean()\ndt_cv_avg"]}, {"cell_type": "markdown", "id": "db38e594", "metadata": {}, "source": ["<a id=\"5.2.5\"></a>\n### 5.2.5 Random Forest"]}, {"cell_type": "code", "execution_count": 1, "id": "76cd6282", "metadata": {}, "outputs": [], "source": ["# Random Forest\nrf = RandomForestClassifier(random_state=0)\nrf.fit(x_train, y_train)\npredictions = rf.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "aa157b2e", "metadata": {}, "outputs": [], "source": ["# Cross Validation\nrf_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\nrf_cv_avg = cross_val_score(rf, X, Y, cv=rf_cv, scoring=\"accuracy\").mean()\nrf_cv_avg"]}, {"cell_type": "markdown", "id": "b2b6d996", "metadata": {}, "source": ["<a id=\"5.2.6\"></a>\n### 5.2.6 Gradient boosting"]}, {"cell_type": "code", "execution_count": 1, "id": "5fbf1ace", "metadata": {}, "outputs": [], "source": ["# Gradient boosting\ngbt = GradientBoostingClassifier(random_state=0)\ngbt.fit(x_train, y_train)\npredictions = gbt.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "803ff53a", "metadata": {}, "outputs": [], "source": ["# Cross Validation\ngbt_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\ngbt_cv_avg = cross_val_score(gbt, X, Y, cv=gbt_cv, scoring=\"accuracy\").mean()\ngbt_cv_avg"]}, {"cell_type": "markdown", "id": "d0e5ced3", "metadata": {}, "source": ["<a id=\"5.2.7\"></a>\n### 5.2.7 XGBoost"]}, {"cell_type": "code", "execution_count": 1, "id": "408db02d", "metadata": {}, "outputs": [], "source": ["xgbc = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='error')\nxgbc.fit(x_train, y_train)\npredictions = xgbc.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "33d2b15c", "metadata": {}, "outputs": [], "source": ["# Cross Validation\nxgbc_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\nxgbc_cv_avg = cross_val_score(xgbc, X, Y, cv=xgbc_cv, scoring=\"accuracy\").mean()\nxgbc_cv_avg"]}, {"cell_type": "markdown", "id": "e68d3b02", "metadata": {}, "source": ["<a id=\"5.2.8\"></a>\n### 5.2.8 CatBoost"]}, {"cell_type": "code", "execution_count": 1, "id": "12477bb6", "metadata": {}, "outputs": [], "source": ["catbc = CatBoostClassifier(random_state=0, eval_metric='Accuracy', verbose=False)\ncatbc.fit(x_train, y_train)\npredictions = catbc.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "a456c5d4", "metadata": {}, "outputs": [], "source": ["# Cross Validation\ncatbc_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\ncatbc_cv_avg = cross_val_score(catbc, X, Y, cv=catbc_cv, scoring=\"accuracy\").mean()\ncatbc_cv_avg"]}, {"cell_type": "markdown", "id": "833fdf8f", "metadata": {}, "source": ["<a id=\"5.2.9\"></a>\n### 5.2.9 LGBoost"]}, {"cell_type": "code", "execution_count": 1, "id": "9d24fef9", "metadata": {}, "outputs": [], "source": ["lgbc = LGBMClassifier(random_state=0)\nlgbc.fit(x_train, y_train, eval_metric='Accuracy', verbose=-1)\npredictions = lgbc.predict(x_test)\nprint(classification_report(y_test, predictions))"]}, {"cell_type": "code", "execution_count": 1, "id": "32c5b38b", "metadata": {}, "outputs": [], "source": ["# Cross Validation\nlgbc_cv = StratifiedShuffleSplit(n_splits=5, test_size=.25, random_state=0)\nlgbc_cv_avg = cross_val_score(lgbc, X, Y, cv=lgbc_cv, scoring=\"accuracy\", verbose=False).mean()\nlgbc_cv_avg"]}, {"cell_type": "markdown", "id": "ba5d2ef4", "metadata": {}, "source": ["<a id=\"5.3\"></a>\n## 5.3. Model Comparison"]}, {"cell_type": "code", "execution_count": 1, "id": "e45e312a", "metadata": {}, "outputs": [], "source": ["# Collect all the model performance\nmodel_comparison = pd.DataFrame(data = [lr_cv_avg, kNN_cv_avg, svm_cv_avg, dt_cv_avg, rf_cv_avg, gbt_cv_avg, xgbc_cv_avg, catbc_cv_avg, lgbc_cv_avg], \n                                index = [\"lr\", \"kNN\", \"SVM\", \"DT\", \"RF\", \"GBT\", \"XGBoost\", \"CatBoost\", \"LGBoost\"],\n                                columns=['Accuracy'])\\\n                      .sort_values(by = \"Accuracy\", ascending=False)\n\nmodel_comparison"]}, {"cell_type": "markdown", "id": "a2815948", "metadata": {}, "source": ["It seems that the top 5 models are: lr, SVM, GBT, CatBoost, XGBoost"]}, {"cell_type": "markdown", "id": "7777bed4", "metadata": {}, "source": ["<a id=\"6\"></a>\n# 6. Prediction"]}, {"cell_type": "code", "execution_count": 1, "id": "b143ec90", "metadata": {}, "outputs": [], "source": ["# Get the test dataset\ntesting_df = data_preprocessed_median_df.iloc[891:].copy()\ntesting_df.info() # show entries, dtypes, memory useage."]}, {"cell_type": "code", "execution_count": 1, "id": "9d4867f5", "metadata": {}, "outputs": [], "source": ["# Have a look\ntesting_df.head()"]}, {"cell_type": "markdown", "id": "6478a9a6", "metadata": {}, "source": ["<a id=\"6.1\"></a>\n## 6.1. Drop irrelevant columns"]}, {"cell_type": "code", "execution_count": 1, "id": "ad431b25", "metadata": {}, "outputs": [], "source": ["# Drop Irrelevant columns\ntest_preprocessed_df = testing_df.drop('Survived', axis=1)\n\n# Feature Age and Fare are replaced by AgeBin and FareBin\ntest_preprocessed_df.drop([\"Age\", \"Fare\"],axis=1, inplace=True)\n\n# Check Missing value\ntest_preprocessed_df.isna().sum()"]}, {"cell_type": "markdown", "id": "76b4f634", "metadata": {}, "source": ["<a id=\"6.2\"></a>\n## 6.2. Feature Engineering"]}, {"cell_type": "code", "execution_count": 1, "id": "570db183", "metadata": {}, "outputs": [], "source": ["# Combine the SibSp and Parch to Family Size\ntest_preprocessed_df['Family_size'] = test_preprocessed_df['SibSp'] + test_preprocessed_df['Parch'] + 1\ntest_preprocessed_df.drop(['SibSp', 'Parch'], axis=1, inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "45e5741c", "metadata": {}, "outputs": [], "source": ["# Binning the family_size\ntest_preprocessed_df.loc[test_preprocessed_df['Family_size'] == 1, 'Family_size'] = 0 # Alone\ntest_preprocessed_df.loc[(test_preprocessed_df['Family_size'] > 1) & (test_preprocessed_df['Family_size'] <= 4), 'Family_size'] = 1  # Small Family \ntest_preprocessed_df.loc[(test_preprocessed_df['Family_size'] > 4) & (test_preprocessed_df['Family_size'] <= 6), 'Family_size'] = 2  # Medium Family\ntest_preprocessed_df.loc[test_preprocessed_df['Family_size']  > 6, 'Family_size'] = 3 # Large Family"]}, {"cell_type": "code", "execution_count": 1, "id": "9664535a", "metadata": {}, "outputs": [], "source": ["# One-Hot Encoding\nonehot_df = pd.get_dummies(test_preprocessed_df[onehot_features])\ntest_preprocessed_df.drop(onehot_features, axis=1, inplace=True)\ntest_preprocessed_df = pd.concat([test_preprocessed_df, onehot_df], axis=1)\n\n# Label Encoding\ntest_preprocessed_df[\"Sex\"]  = LabelEncoder().fit_transform(test_preprocessed_df[\"Sex\"])\ntest_preprocessed_df[\"AgeBin\"]  = LabelEncoder().fit_transform(test_preprocessed_df[\"AgeBin\"])\ntest_preprocessed_df[\"FareBin\"]  = LabelEncoder().fit_transform(test_preprocessed_df[\"FareBin\"])\n\n# Check the data after Feature Engineering\ntest_preprocessed_df.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "b687f391", "metadata": {}, "outputs": [], "source": ["test_preprocessed_df"]}, {"cell_type": "markdown", "id": "8103fa14", "metadata": {}, "source": ["<a id=\"6.3\"></a>\n## 6.3. Make Prediction"]}, {"cell_type": "code", "execution_count": 1, "id": "61d14d0c", "metadata": {}, "outputs": [], "source": ["# Make Prediction by the top 5 classifiers\nvoting_clas = VotingClassifier(estimators=[('SVM', svm), ('Logistic_Reg', lr), ('CatBoost', catbc), ('GBt',gbt), ('XGBoost',xgbc)], voting='soft', n_jobs=-1)\nvotingC = voting_clas.fit(X, Y)\n\nresults = votingC.predict(test_preprocessed_df)\nresults_df = pd.DataFrame(results, columns=['Survived'])\npredictions_df = pd.concat([test_df['PassengerId'], results_df], axis=1)"]}, {"cell_type": "markdown", "id": "f5e0b360", "metadata": {}, "source": ["<a id=\"6.4\"></a>\n## 6.4. Save the Prediction to CSV file"]}, {"cell_type": "code", "execution_count": 1, "id": "5427aea3", "metadata": {}, "outputs": [], "source": ["# Save predictions to .csv for project submission\npredictions_df.to_csv('submission.csv', index=False)"]}, {"cell_type": "markdown", "id": "b094e094", "metadata": {}, "source": ["# Thanks for reading, have a good day ~"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}