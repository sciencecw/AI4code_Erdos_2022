{"cells": [{"cell_type": "markdown", "id": "da5bddd0", "metadata": {}, "source": ["# Pfizer Vaccine Tweets Analysis\n\n<center>\n    <img src=\"https://i.guim.co.uk/img/media/f9cb10ec580aab5cdb195116cf9e8496472cdd2d/0_227_5625_3375/master/5625.jpg?width=300&quality=85&auto=format&fit=max&s=590c232179cd32826ca9734144336a52\">\n</center>\n<center> Pfizer's vaccine from The Guardian </center> \n\n[The Guardian](https://www.theguardian.com/world/2020/nov/27/hospitals-england-told-prepare-early-december-covid-vaccine-rollout-nhs)\n\nIn this notebook, we are going to analyze pfizer vaccine tweets. To do so, we will talk\n\n1. [Exploratory data analysis](#eda)\n2. [Text mining ](#tm)\n3. [Sentiment analysis](#sa)\n4. [conclusion](#conc)\n\nLet's start"]}, {"cell_type": "markdown", "id": "3da34e8e", "metadata": {}, "source": ["# Load library, data and prepare data"]}, {"cell_type": "code", "execution_count": 1, "id": "0791f3f7", "metadata": {}, "outputs": [], "source": ["import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom scipy.stats import normaltest\nfrom warnings import filterwarnings"]}, {"cell_type": "code", "execution_count": 1, "id": "82810c5e", "metadata": {}, "outputs": [], "source": ["import string\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport spacy\nfrom spacy import displacy\nfrom pprint import pprint \nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.base import TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom spacy.lang.en import English"]}, {"cell_type": "code", "execution_count": 1, "id": "b6fd5147", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder \nfrom xgboost import XGBRFClassifier\nfrom sklearn.naive_bayes import MultinomialNB \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, RocCurveDisplay,confusion_matrix,r2_score\nfrom sklearn.metrics import plot_roc_curve, roc_auc_score, classification_report, accuracy_score, f1_score\nfrom sklearn.metrics import recall_score, plot_confusion_matrix, precision_score, plot_precision_recall_curve, classification_report\n    \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers"]}, {"cell_type": "code", "execution_count": 1, "id": "7d06f170", "metadata": {}, "outputs": [], "source": ["sns.set(style='whitegrid')\npd.set_option('display.max_colwidth', 300)\npd.set_option('display.max_rows', 10000)\nfilterwarnings('ignore')\npd.plotting.register_matplotlib_converters()\n%matplotlib inline\nprint(\"Setup Complete\")"]}, {"cell_type": "code", "execution_count": 1, "id": "a09f00f3", "metadata": {}, "outputs": [], "source": ["# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "68c38c87", "metadata": {}, "outputs": [], "source": ["!pip install tweet-preprocessor"]}, {"cell_type": "code", "execution_count": 1, "id": "4fb29373", "metadata": {}, "outputs": [], "source": ["tweets = pd.read_csv('/kaggle/input/pfizer-vaccine-tweets/vaccination_tweets.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "ad00c316", "metadata": {}, "outputs": [], "source": ["tweets.tail()"]}, {"cell_type": "code", "execution_count": 1, "id": "d93d75da", "metadata": {}, "outputs": [], "source": ["tweets.info()"]}, {"cell_type": "markdown", "id": "9102dc91", "metadata": {}, "source": ["## Some feature explained\n1. **user_name**: the name of the user, as they have defined it.\n2. **user_location**: the user-defined location for this account's profile.\n3. **user_description**: the user-defined UTF-8 string describing their account\n4. **user_verified**: when true, indicates that the user has a verified account.\n5. **user_followers**: the number of followers this account currently has. \n6. **user_friends**: the number of user this account is following\n7. **user_favorites**: the number of tweets this user has liked in the account's lifetime. \n8. **user_created**: the UTC datetime that the user account was created on twitter.\n9. **hashtag**: is any word or phrase immediately preceded by the # symbol. When you click or tap on a hashtag, you will see other tweets containing the same keyword or topic.\n10. **retweet**: a tweet that you forward to your followers is known as a retweet.\n11. **favorite** refers to topics or subjects that users are most interested in."]}, {"cell_type": "markdown", "id": "51e8ca95", "metadata": {}, "source": ["**Checking missing values**"]}, {"cell_type": "code", "execution_count": 1, "id": "184fdac8", "metadata": {}, "outputs": [], "source": ["tweets.isnull().sum()[tweets.isnull().sum()>0]"]}, {"cell_type": "markdown", "id": "bdc387a7", "metadata": {}, "source": ["As user_location, user_description, hashtags and source are object type, we are going to use \n.fillna."]}, {"cell_type": "code", "execution_count": 1, "id": "a773dd5c", "metadata": {}, "outputs": [], "source": ["tweets.fillna(' ', inplace=True) #imputation"]}, {"cell_type": "code", "execution_count": 1, "id": "90fddcfd", "metadata": {}, "outputs": [], "source": ["tweets.isnull().sum()[tweets.isnull().sum()>0]"]}, {"cell_type": "markdown", "id": "a41fcd14", "metadata": {}, "source": ["**convert object date to datetime format**"]}, {"cell_type": "code", "execution_count": 1, "id": "038f3521", "metadata": {}, "outputs": [], "source": ["tweets['user_created'] = pd.to_datetime(tweets['user_created'])\ntweets['date'] = pd.to_datetime(tweets['date'])"]}, {"cell_type": "markdown", "id": "a53fc1fc", "metadata": {}, "source": ["**check**"]}, {"cell_type": "code", "execution_count": 1, "id": "7a6a097a", "metadata": {}, "outputs": [], "source": ["tweets.info()"]}, {"cell_type": "markdown", "id": "01bce1b3", "metadata": {}, "source": ["# Feature engineering\n\nWe will create new feature:\n\n1. **user_account_lifetime**: the number of years an user is on twitter.\n2. **user_year_created**: the year of creation of the twitter account.\n3. **user_month_created**: the month of creation of the twitter account.\n4. **user_time_created**: the time of creation of the twitter account.\n5. **user_day_created**: the day of creation of the twitter account.\n6. **user_date_created**: the date of creation of the twitter account.\n\n7. **user_year_write**: the year that an user writes about the pfizer vaccine.\n8. **user_month_write**: the month that an user writes about the pfizer vaccine.\n9. **user_day_write**: the day that an user writes about pfizer vaccine.\n10. **user_time_write**: the hour that an user writes about pfizer vaccine.\n11. **user_date_write**: the date that an user writes about pfizer vaccine."]}, {"cell_type": "code", "execution_count": 1, "id": "dcee1b77", "metadata": {}, "outputs": [], "source": ["tweets['user_account_lifetime'] = tweets.date.dt.year - tweets.user_created.dt.year\ntweets['user_year_created'] = tweets.user_created.dt.year\ntweets['user_month_created'] = tweets.user_created.dt.month\ntweets['user_time_created'] = tweets.user_created.dt.time\ntweets['user_day_created'] = tweets.user_created.dt.dayofweek\ntweets['user_date_created'] = tweets.user_created.dt.date"]}, {"cell_type": "code", "execution_count": 1, "id": "7f39de29", "metadata": {}, "outputs": [], "source": ["tweets['user_year_write'] = tweets.date.dt.year\ntweets['user_month_write'] = tweets.date.dt.month\ntweets['user_day_write'] = tweets.date.dt.dayofweek\ntweets['user_time_write'] = tweets.date.dt.time\ntweets['user_date_write'] = tweets.date.dt.date"]}, {"cell_type": "markdown", "id": "927fa4cf", "metadata": {}, "source": ["**rename**"]}, {"cell_type": "code", "execution_count": 1, "id": "2f9daf9a", "metadata": {}, "outputs": [], "source": ["#rename \ntweets.user_month_created.replace(to_replace=sorted(tweets.user_month_created.unique()),\n                                 value=['january', 'february','march', 'april','may','june','july','august',\n                                       'september','october','november','december'], inplace=True)\n\ntweets.user_month_write.replace(to_replace=sorted(tweets.user_month_write.unique()),\n                                value=['january', 'december'], inplace=True)\n\ntweets.user_day_write.replace(to_replace=sorted(tweets.user_day_write.unique()),\n                              value=['monday','tuesday','wednesday','thursday','friday','saturday','sunday'],\n                             inplace=True)\n\ntweets.user_day_created.replace(to_replace=sorted(tweets.user_day_created.unique()),\n                              value=['monday','tuesday','wednesday','thursday','friday','saturday','sunday'],\n                               inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "52eef173", "metadata": {}, "outputs": [], "source": ["tweets.tail(2)"]}, {"cell_type": "code", "execution_count": 1, "id": "4c79dd8e", "metadata": {}, "outputs": [], "source": ["tweets.drop(columns=['id'], inplace=True)"]}, {"cell_type": "markdown", "id": "1953793d", "metadata": {}, "source": ["<a id = 'eda'></a>"]}, {"cell_type": "markdown", "id": "6cffbe88", "metadata": {}, "source": ["# Exploratory data analysis"]}, {"cell_type": "markdown", "id": "8372798d", "metadata": {}, "source": ["## Descriptive analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "0195bfd4", "metadata": {}, "outputs": [], "source": ["tweets.describe()"]}, {"cell_type": "markdown", "id": "791a6323", "metadata": {}, "source": ["**We explain**\n\nwe have, \n1. $user followers = 63430\\pm 476213$ with 50% of accounts have user_followers less than 606 where one account reach 13714930 user followers.\n2. $user friend = 1171\\pm2469$ with 50% of accounts have user_friend less than 441 where one account reach 64441.\nand so on..."]}, {"cell_type": "code", "execution_count": 1, "id": "f857c3a5", "metadata": {}, "outputs": [], "source": ["#month when there is more creation of twitter account \ntweets.user_month_created.mode()"]}, {"cell_type": "code", "execution_count": 1, "id": "d7595288", "metadata": {}, "outputs": [], "source": ["#day when there is more creation of twitter account \ntweets.user_day_created.mode()"]}, {"cell_type": "code", "execution_count": 1, "id": "6db0a550", "metadata": {}, "outputs": [], "source": ["#year when there is more creation of twitter account \ntweets.user_year_created.mode()"]}, {"cell_type": "code", "execution_count": 1, "id": "75bbfd82", "metadata": {}, "outputs": [], "source": ["#month when user write more about pfizer vaccine\ntweets.user_month_write.mode()"]}, {"cell_type": "code", "execution_count": 1, "id": "b06a6a7c", "metadata": {}, "outputs": [], "source": ["#day when user write more about pfizer vaccine\ntweets.user_day_write.mode()"]}, {"cell_type": "code", "execution_count": 1, "id": "7b28f6e5", "metadata": {}, "outputs": [], "source": ["#source must using by user\ntweets.source.mode()"]}, {"cell_type": "code", "execution_count": 1, "id": "10c0530a", "metadata": {}, "outputs": [], "source": ["tweets.corr()"]}, {"cell_type": "markdown", "id": "e6cfce4c", "metadata": {}, "source": ["1. $corr(retweets, favorite) = 0.837641$ **means that users who favor a tweet tend to retweet this tweet.**\n2. $corr(user year created, user account lifetime) = -0.9951$ **means that most people who create twitter account each year does not see theirs accounts take more lifetime.**\n\nThe other features are purely independent."]}, {"cell_type": "markdown", "id": "2521ad37", "metadata": {}, "source": ["## Visualization: Distribution"]}, {"cell_type": "markdown", "id": "933002fa", "metadata": {}, "source": ["### Twitter Accounts creation\n\nWe visualize feature"]}, {"cell_type": "code", "execution_count": 1, "id": "f82850b9", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.countplot(x='user_month_created', data=tweets, hue='user_verified')\nplt.title('Monthly Twitter accounts creation')\nplt.show()"]}, {"cell_type": "markdown", "id": "26bca729", "metadata": {}, "source": ["Most users likes create twitter account but does not like to make account verification. "]}, {"cell_type": "code", "execution_count": 1, "id": "6081c98d", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.countplot(x='user_day_created', data=tweets, hue='user_verified')\nplt.title('Daily Twitter accounts creation')\nplt.show()"]}, {"cell_type": "markdown", "id": "2e4d5f08", "metadata": {}, "source": ["Daily, most people does not like to make account verification."]}, {"cell_type": "code", "execution_count": 1, "id": "4a317f15", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.countplot(x='user_year_created', data=tweets, hue='user_verified')\nplt.title('Yearly Twitter accounts creation')\nplt.show()"]}, {"cell_type": "markdown", "id": "f3c7ad49", "metadata": {}, "source": ["only half of the twitter users are making account verification in year 2009.  "]}, {"cell_type": "code", "execution_count": 1, "id": "1d23434a", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.countplot(x='user_account_lifetime', data=tweets, hue='user_verified')\nplt.title('Twitter accounts lifetime')\nplt.show()"]}, {"cell_type": "markdown", "id": "980cb86a", "metadata": {}, "source": ["Only twitter users  who have 11 years lifetime are making account verification."]}, {"cell_type": "markdown", "id": "92718475", "metadata": {}, "source": ["**We learn**\n1. most twitter users does not like to make account verification."]}, {"cell_type": "markdown", "id": "028213a6", "metadata": {}, "source": ["### Twitter users write about pfizers vaccine"]}, {"cell_type": "code", "execution_count": 1, "id": "8948df02", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.countplot(x='user_month_write', data=tweets, hue='user_verified')\nplt.title('Monthly Twitter user write about Pfizer vaccine')\nplt.show()"]}, {"cell_type": "markdown", "id": "5c9ac683", "metadata": {}, "source": ["In december, people discover and write  a pfizer vaccine deployment"]}, {"cell_type": "code", "execution_count": 1, "id": "89937c41", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.countplot(x='user_day_write', data=tweets, hue='is_retweet')\nplt.title('Daily Twitter user write about Pfizer vaccine')\nplt.show()"]}, {"cell_type": "markdown", "id": "12d45bfa", "metadata": {}, "source": ["tuesday and wednesday are the two days who users write most about pfizer vaccine."]}, {"cell_type": "code", "execution_count": 1, "id": "0b85fd22", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.countplot(x='user_year_write', data=tweets, hue='is_retweet')\nplt.title('Yearly Twitter user write about Pfizer vaccine')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "64fc5b69", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(5,10))\nsns.countplot(y='source', data=tweets)\nplt.title('Source')\nplt.show()"]}, {"cell_type": "markdown", "id": "b7c89ed3", "metadata": {}, "source": ["most people like to use twitter on android, iphone and web app."]}, {"cell_type": "markdown", "id": "dfc2e202", "metadata": {}, "source": ["## correlation plot"]}, {"cell_type": "code", "execution_count": 1, "id": "2ef0736e", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.regplot('favorites','retweets', data=tweets)\nplt.title('correlation feature plot')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "eeff097d", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.regplot('user_account_lifetime','user_year_created', data=tweets)\nplt.title('correlation feature plot')\nplt.show()"]}, {"cell_type": "markdown", "id": "2dad45f8", "metadata": {}, "source": ["user_year_created and user_account_lifetime are strong opposite."]}, {"cell_type": "markdown", "id": "1f3634a6", "metadata": {}, "source": ["## Time series"]}, {"cell_type": "code", "execution_count": 1, "id": "40625f9c", "metadata": {}, "outputs": [], "source": ["sns.catplot(x='user_account_lifetime', y='user_followers', hue='user_verified', data=tweets,kind=\"swarm\")\nplt.show()"]}, {"cell_type": "markdown", "id": "bc3d9a50", "metadata": {}, "source": ["Only account having an account verification have huge user followers."]}, {"cell_type": "code", "execution_count": 1, "id": "2b778e96", "metadata": {}, "outputs": [], "source": ["tweets.plot(x='user_time_write', y='favorites', figsize=(15,5), title='favorites time series')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "01dd9cb5", "metadata": {}, "outputs": [], "source": ["tweets.plot(x='user_date_write', y='favorites', figsize=(15,5), title='favorites time series')\nplt.show()"]}, {"cell_type": "markdown", "id": "87c49458", "metadata": {}, "source": ["**summary**\n1. users who favor a tweet tend to retweet this tweet.\n2. most people who create twitter account each year does not see theirs accounts take more lifetime.\n3. Most users likes create twitter account but does not like to make account verification.\n4. In december, people discover and write a pfizer vaccine deployment\n5. most people like to use twitter on android, iphone and web app.\n6. Only account having an account verification have huge user followers"]}, {"cell_type": "markdown", "id": "17f25133", "metadata": {}, "source": ["<a id = 'tm'></a>"]}, {"cell_type": "markdown", "id": "c8bc75b0", "metadata": {}, "source": ["# Text mining"]}, {"cell_type": "code", "execution_count": 1, "id": "fa503bf2", "metadata": {}, "outputs": [], "source": ["import preprocessor as p"]}, {"cell_type": "code", "execution_count": 1, "id": "64dbdd2a", "metadata": {}, "outputs": [], "source": ["def tokenizer(sentence):\n    import string\n    from spacy.lang.en import English\n    import spacy\n    # Create our list of punctuation marks\n    punctuations = string.punctuation\n\n    # Create our list of stopwords\n    nlp = spacy.load('en')\n    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n\n    # Load English tokenizer, tagger, parser, NER and word vectors\n    parser = English()\n    \n    #clean tweet text\n    sentence = p.clean(sentence)\n\n    # Creating our token object, which is used to create documents with linguistic annotations.\n    mytokens = parser(sentence)\n\n    # Lemmatizing each token and converting each token into lowercase\n    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n\n    # Removing stop words\n    mytokens = [word for word in mytokens if word not in stop_words and word not in punctuations]\n\n    # return preprocessed list of tokens\n    return mytokens"]}, {"cell_type": "code", "execution_count": 1, "id": "c83a6069", "metadata": {}, "outputs": [], "source": ["def get_bigrams(corpus, n=None):\n    vec = CountVectorizer(tokenizer=tokenizer, ngram_range=(3, 3), ).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    \n    x,y =map(list,zip(*words_freq[:n]))\n    \n    return x, y"]}, {"cell_type": "code", "execution_count": 1, "id": "8a457721", "metadata": {}, "outputs": [], "source": ["text = tweets.loc[:, ['user_location','user_description','text','hashtags']]"]}, {"cell_type": "code", "execution_count": 1, "id": "f98fee1d", "metadata": {}, "outputs": [], "source": ["text.tail()"]}, {"cell_type": "markdown", "id": "979d41ae", "metadata": {}, "source": ["## Where users are local?"]}, {"cell_type": "code", "execution_count": 1, "id": "59a95bd6", "metadata": {}, "outputs": [], "source": ["local = ' '.join(u for u in list(text.user_location))"]}, {"cell_type": "code", "execution_count": 1, "id": "18992a01", "metadata": {}, "outputs": [], "source": ["token_local = tokenizer(local)"]}, {"cell_type": "code", "execution_count": 1, "id": "9d38567a", "metadata": {}, "outputs": [], "source": ["from collections import Counter"]}, {"cell_type": "code", "execution_count": 1, "id": "47085ceb", "metadata": {}, "outputs": [], "source": ["count_token = Counter(token_local)"]}, {"cell_type": "code", "execution_count": 1, "id": "8bed679a", "metadata": {}, "outputs": [], "source": ["#show 30 most common\npprint(count_token.most_common(30))"]}, {"cell_type": "markdown", "id": "db80c963", "metadata": {}, "source": ["## Word cloud: user description"]}, {"cell_type": "code", "execution_count": 1, "id": "6b2c8dd6", "metadata": {}, "outputs": [], "source": ["from wordcloud import WordCloud"]}, {"cell_type": "code", "execution_count": 1, "id": "ed96e2ec", "metadata": {}, "outputs": [], "source": ["#clean tweet\ndesc = p.clean(' '.join([u for u in text.user_description]))"]}, {"cell_type": "code", "execution_count": 1, "id": "1bc4c7d8", "metadata": {}, "outputs": [], "source": ["wordcloud = WordCloud().generate(' '.join(u for u in tokenizer(desc)))"]}, {"cell_type": "code", "execution_count": 1, "id": "b9b6e637", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(14,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title('User description word cloud')\nplt.axis('off')\nplt.show()"]}, {"cell_type": "markdown", "id": "c03daeed", "metadata": {}, "source": ["Some users are interested by:\n1. Opinion\n2. nurse\n3. love\n4. life\n5. clinical\n6. science\n7. and so on ..."]}, {"cell_type": "markdown", "id": "b7f6f56f", "metadata": {}, "source": ["### 3-gram user description"]}, {"cell_type": "code", "execution_count": 1, "id": "75666ce4", "metadata": {}, "outputs": [], "source": ["desc_x, desc_y = get_bigrams(np.array([desc]), 30)"]}, {"cell_type": "code", "execution_count": 1, "id": "887d5296", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,20))\nplt.barh(sorted(desc_x), sorted(desc_y))\nplt.title('3 grams user description')\nplt.show()"]}, {"cell_type": "markdown", "id": "3b6ee5e2", "metadata": {}, "source": ["## Wordcloud: hashtags"]}, {"cell_type": "code", "execution_count": 1, "id": "c13b95b6", "metadata": {}, "outputs": [], "source": ["hashtag = p.clean(' '.join(u for u in text.hashtags))\nw_hash = WordCloud().generate(' '.join(u for u in tokenizer(hashtag)))"]}, {"cell_type": "code", "execution_count": 1, "id": "0073327c", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(14,10))\nplt.imshow(w_hash, interpolation='bilinear')\nplt.title('User hashtags word cloud')\nplt.axis('off')\nplt.show()"]}, {"cell_type": "markdown", "id": "7a39253c", "metadata": {}, "source": ["Vaccine, covid19, pfizer, biontech hashtags"]}, {"cell_type": "markdown", "id": "9500cd6e", "metadata": {}, "source": ["## Text analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "e2ab443c", "metadata": {}, "outputs": [], "source": ["# we clean tweet text by usisng tweet-preprocessor\ndef preprocess_tweet(sent):\n    return p.clean(sent['text'])"]}, {"cell_type": "code", "execution_count": 1, "id": "e00f6601", "metadata": {}, "outputs": [], "source": ["def word_frequence(dtext, n=1):\n\n    tfvector = TfidfVectorizer(tokenizer=tokenizer, ngram_range=(n, n))\n    transformed_text = tfvector.fit_transform(dtext)\n    transformed_text_as_array = transformed_text.toarray()\n\n    for counter, doc in enumerate(transformed_text_as_array):\n        #construct a dataframe\n        tf_idf_tuples = list(zip(tfvector.get_feature_names(), doc))\n        one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, \n        columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n\n    return one_doc_as_df"]}, {"cell_type": "code", "execution_count": 1, "id": "2e6b842f", "metadata": {}, "outputs": [], "source": ["text['text'] = text.apply(preprocess_tweet, axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "02333571", "metadata": {}, "outputs": [], "source": ["dtext = text.text"]}, {"cell_type": "markdown", "id": "78ee27d0", "metadata": {}, "source": ["### Word frequency\n\nWe compute word frequency to see which word users write most in the tweet. "]}, {"cell_type": "markdown", "id": "b33af986", "metadata": {}, "source": ["**1-gram**"]}, {"cell_type": "code", "execution_count": 1, "id": "ca8b60ee", "metadata": {}, "outputs": [], "source": ["#we transform our n-dim text to 1-dim text\ntw_text = np.array([\" \".join([u for u in dtext])])"]}, {"cell_type": "code", "execution_count": 1, "id": "491ec235", "metadata": {}, "outputs": [], "source": ["word_freq = word_frequence(tw_text)"]}, {"cell_type": "code", "execution_count": 1, "id": "bb5341c6", "metadata": {}, "outputs": [], "source": ["word_freq.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "db8cf32d", "metadata": {}, "outputs": [], "source": ["word_freq[:10].plot(kind=\"bar\", x='term',y='score', figsize=(15,5))\nplt.ylabel('frequence')\nplt.title('word frequency')\nplt.show()"]}, {"cell_type": "markdown", "id": "a9aad515", "metadata": {}, "source": ["Vaccine is word more used by users after coming the others."]}, {"cell_type": "markdown", "id": "1854bb9d", "metadata": {}, "source": ["### collocation\n\nHere, we identified words that commonly co-occur in the tweet text."]}, {"cell_type": "markdown", "id": "938569e9", "metadata": {}, "source": ["**2-grams**"]}, {"cell_type": "code", "execution_count": 1, "id": "6e2e58f2", "metadata": {}, "outputs": [], "source": ["two_grams = word_frequence(tw_text, n=2)"]}, {"cell_type": "code", "execution_count": 1, "id": "6bb7a8a4", "metadata": {}, "outputs": [], "source": ["two_grams.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d69e2008", "metadata": {}, "outputs": [], "source": ["two_grams[:30].plot(kind=\"bar\", x='term', y='score', figsize=(15,5))\nplt.ylabel('frequence')\nplt.title('30 most common 2-grams ')\nplt.show()"]}, {"cell_type": "markdown", "id": "c751d07a", "metadata": {}, "source": ["This graph two very well that users are most write **covid-19 vaccine, pfizer biontech, 1 dose, ...** and also word vaccine are cooccured with more word in the text."]}, {"cell_type": "markdown", "id": "a99a595f", "metadata": {}, "source": ["**3-grams**\n\nLet's see trigram."]}, {"cell_type": "code", "execution_count": 1, "id": "801745b3", "metadata": {}, "outputs": [], "source": ["tri_grams = word_frequence(tw_text, n=3)"]}, {"cell_type": "code", "execution_count": 1, "id": "f14a51c7", "metadata": {}, "outputs": [], "source": ["tri_grams.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "aa3164c8", "metadata": {}, "outputs": [], "source": ["tri_grams[:30].plot(kind=\"bar\", x='term', y='score', figsize=(15,5))\nplt.ylabel('frequence')\nplt.title('30 most commons 3-grams ')\nplt.show()"]}, {"cell_type": "markdown", "id": "333b3e26", "metadata": {}, "source": ["we can identify four important words   **Pfizer, Biontech, Coronavirus, Vaccine, Covid19**"]}, {"cell_type": "markdown", "id": "ab0a564b", "metadata": {}, "source": ["## Word cloud"]}, {"cell_type": "code", "execution_count": 1, "id": "af4406bf", "metadata": {}, "outputs": [], "source": ["cloud = WordCloud().generate(\" \".join([u for u in dtext]))"]}, {"cell_type": "code", "execution_count": 1, "id": "13a1dfc3", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,10))\nplt.imshow(cloud, interpolation='bilinear')\nplt.title('Tweet text word cloud')\nplt.axis('off')\nplt.show()"]}, {"cell_type": "markdown", "id": "fe947dd0", "metadata": {}, "source": ["keyword: **covid, vaccine, dose, pfizer , biontech,**"]}, {"cell_type": "markdown", "id": "12d7aa8c", "metadata": {}, "source": ["<a id='sm'></a>"]}, {"cell_type": "markdown", "id": "8bafa39c", "metadata": {}, "source": ["# Sentiment Analysis\n\nIn this section, we are using textblob model."]}, {"cell_type": "markdown", "id": "816efd67", "metadata": {}, "source": ["## TextBlob"]}, {"cell_type": "code", "execution_count": 1, "id": "02bc1de5", "metadata": {}, "outputs": [], "source": ["from textblob import TextBlob"]}, {"cell_type": "code", "execution_count": 1, "id": "abcf6b14", "metadata": {}, "outputs": [], "source": ["docs = [TextBlob(u) for u in dtext]"]}, {"cell_type": "code", "execution_count": 1, "id": "a1734f94", "metadata": {}, "outputs": [], "source": ["len(docs)"]}, {"cell_type": "code", "execution_count": 1, "id": "8a347bf9", "metadata": {}, "outputs": [], "source": ["docs[1].tags"]}, {"cell_type": "code", "execution_count": 1, "id": "662bea6b", "metadata": {}, "outputs": [], "source": ["docs[0].noun_phrases"]}, {"cell_type": "code", "execution_count": 1, "id": "ff04f25a", "metadata": {}, "outputs": [], "source": ["sentiment_polarity = [u.sentiment.polarity for u in docs]"]}, {"cell_type": "code", "execution_count": 1, "id": "1abd7cbd", "metadata": {}, "outputs": [], "source": ["sentiment_subjectivity = [u.sentiment.subjectivity for u in docs]"]}, {"cell_type": "code", "execution_count": 1, "id": "4e33f98f", "metadata": {}, "outputs": [], "source": ["text['polarity'] = ['positive' if score >= 0.1 else 'negative' for score in sentiment_polarity]\ntext['subjective'] = sentiment_subjectivity"]}, {"cell_type": "code", "execution_count": 1, "id": "71332f50", "metadata": {}, "outputs": [], "source": ["text.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "92620b47", "metadata": {}, "outputs": [], "source": ["text.tail()"]}, {"cell_type": "markdown", "id": "fba29d8d", "metadata": {}, "source": ["We are going to analyse our result below."]}, {"cell_type": "code", "execution_count": 1, "id": "d763dffb", "metadata": {}, "outputs": [], "source": ["text.polarity.value_counts().plot(kind='pie', figsize=(15,5))\nplt.title('Sentiment opinion about Pfizer-Biontech vaccine')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "a709b221", "metadata": {}, "outputs": [], "source": ["val_count = text.polarity.value_counts()\np1 = 100*(val_count[0]/sum(val_count))\np2 = 100*(val_count[1]/sum(val_count))"]}, {"cell_type": "code", "execution_count": 1, "id": "d75e4e89", "metadata": {}, "outputs": [], "source": ["print(f'The percentage of users who have negative opinion about Pfizer-Biontech vaccine is: {p1}.')\nprint(f'The percentage of users who have positive opinion about Pfizer-Biontech vaccine is: {p2}.')"]}, {"cell_type": "code", "execution_count": 1, "id": "52952d19", "metadata": {}, "outputs": [], "source": ["text.polarity.value_counts().plot(kind='bar', figsize=(15,5))\nplt.title('Sentiment opinion about Pfizer-Biontech vaccine')\nplt.show()"]}, {"cell_type": "markdown", "id": "63f0aee6", "metadata": {}, "source": ["Okay, we can now see the subjectivity of all users."]}, {"cell_type": "code", "execution_count": 1, "id": "b3df2973", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nsns.violinplot(y='polarity', x='subjective', data=text, hue='polarity')\nplt.title('Objective and subjective opinion')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "a06849af", "metadata": {}, "outputs": [], "source": ["opinion = pd.pivot_table(text, values='subjective', index='text',columns='polarity')"]}, {"cell_type": "code", "execution_count": 1, "id": "50068b46", "metadata": {}, "outputs": [], "source": ["opinion.describe()"]}, {"cell_type": "markdown", "id": "8465e4c9", "metadata": {}, "source": ["1. The median of negative opinion is equal to zero, this means that half of the users have an objective opinion. many users are not convenient with Pfizer-Biontech vaccine.\n2. The median of positive opinion is equal to 0.5, this means that half of the users have a subjective and non-objective opinion. Which may show that these users remain in doubt about the Pfizers vaccine"]}, {"cell_type": "markdown", "id": "7ec7098d", "metadata": {}, "source": ["<a id='conc'></a>"]}, {"cell_type": "markdown", "id": "c4885139", "metadata": {}, "source": ["# Conclusion \n\nwhat we can say about Pfizers' vaccine is:\n\n1. **60%** of users do not trust Pfizers' vaccine and over **50%** of users with **negative opinions** are **objective** about what they say. while those who have a **positive opinion (40%)** are **subjective** about what they write.\n2. Therefore the Pfizers-Biontech vaccine is not welcome"]}, {"cell_type": "markdown", "id": "79fbf27e", "metadata": {}, "source": ["# Sentiment classsification\n\nAfter that we know the percentage of negative and positive opinion about Pfizer-Biontech vaccine, we can now automatically identified what user are positive or negative. Let's create a classification model using Textblob. "]}, {"cell_type": "code", "execution_count": 1, "id": "e46f373e", "metadata": {}, "outputs": [], "source": ["#divide our text to trains and test\nptext = text[['text','polarity']]\nxtrain, xtest, ytrain, ytest = train_test_split(ptext.text, ptext.polarity, stratify=ptext.polarity,\n                                                random_state=0, test_size=0.2)"]}, {"cell_type": "code", "execution_count": 1, "id": "b3d80ea2", "metadata": {}, "outputs": [], "source": ["#let's create a function which return train and test data\ndef create_train_test(x,y):\n    df = pd.DataFrame()\n    df['x'] = list(x)\n    df['y'] = list(y)\n    \n    return  [tuple(df.iloc[i, [0,1]].values) for i in range(df.shape[0])]"]}, {"cell_type": "code", "execution_count": 1, "id": "ec21d6a2", "metadata": {}, "outputs": [], "source": ["train = create_train_test(xtrain, ytrain)\ntest = create_train_test(xtest, ytest)"]}, {"cell_type": "code", "execution_count": 1, "id": "94ead9ce", "metadata": {}, "outputs": [], "source": ["train[:3]"]}, {"cell_type": "code", "execution_count": 1, "id": "ec8caa6c", "metadata": {}, "outputs": [], "source": ["test[:3]"]}, {"cell_type": "code", "execution_count": 1, "id": "16a4f2f9", "metadata": {}, "outputs": [], "source": ["from textblob.classifiers import NaiveBayesClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "da35c9d8", "metadata": {}, "outputs": [], "source": ["cl = NaiveBayesClassifier(train)"]}, {"cell_type": "code", "execution_count": 1, "id": "91887a50", "metadata": {}, "outputs": [], "source": ["# evaluation\ncl.accuracy(test)"]}, {"cell_type": "code", "execution_count": 1, "id": "d74a2002", "metadata": {}, "outputs": [], "source": ["cl.show_informative_features(10)"]}, {"cell_type": "markdown", "id": "4b525be6", "metadata": {}, "source": ["### Conclusion\n\nOur model is not bad then we can make sentiment classification. From the Informative feature we can know the sentiment of an user if we locate thess word in his tweets."]}, {"cell_type": "markdown", "id": "cf5957c1", "metadata": {}, "source": ["**Bee free to share and download this notebook. I Hope that this notebook help everyone to understand the opinion about Pfizers-Biontech vaccine**"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}