{"cells": [{"cell_type": "code", "execution_count": 1, "id": "b4e028fc", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "422ef872", "metadata": {}, "source": ["### Load Basic Libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "554ed31c", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "8b4a2e28", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('/kaggle/input/amazon-fine-food-reviews/Reviews.csv')"]}, {"cell_type": "markdown", "id": "3440474d", "metadata": {}, "source": ["### Explore the Data"]}, {"cell_type": "code", "execution_count": 1, "id": "02782234", "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "8fe88db9", "metadata": {}, "outputs": [], "source": ["df.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "23142724", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "markdown", "id": "3b53bcaf", "metadata": {}, "source": ["##### Let us check the summary and Text column"]}, {"cell_type": "code", "execution_count": 1, "id": "7d97c63d", "metadata": {}, "outputs": [], "source": ["df.Summary.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "cb2cf091", "metadata": {}, "outputs": [], "source": ["df.Text.head()"]}, {"cell_type": "markdown", "id": "9c5ec2eb", "metadata": {}, "source": ["#  Text Preprocessing"]}, {"cell_type": "markdown", "id": "f845a82f", "metadata": {}, "source": ["For Text Preprocessing we will use TextBlob Library. \nIn Text Preprocessing we remove stop words, punctuations, convert into lower cases, lemmatize,spell check \n\nTextBlob is built upon NLTK and provides an easy to use interface to the NLTK library.\nvarious tasks can be performed like part-of-speech tagging, noun phrase extraction, sentiment analysis, \nclassification, translation, and more."]}, {"cell_type": "code", "execution_count": 1, "id": "9f6bb527", "metadata": {}, "outputs": [], "source": ["! pip install textblob"]}, {"cell_type": "code", "execution_count": 1, "id": "122b328b", "metadata": {}, "outputs": [], "source": ["from nltk.corpus import stopwords \nfrom textblob import TextBlob\nfrom textblob import Word\n# Lower casing and removing punctuations\n\ndf['Text'] = df['Text'].apply(lambda x: \" \".join(x.lower() for\nx in x.split()))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3dfdcfe1", "metadata": {}, "outputs": [], "source": ["df['Text'] = df['Text'].str.replace('[^\\w\\s]', \"\")\ndf.Text.head(5)"]}, {"cell_type": "code", "execution_count": 1, "id": "24e6ce2c", "metadata": {}, "outputs": [], "source": ["#remove the stopwords\nstop = stopwords.words('english')\ndf['Text'] = df['Text'].apply(lambda x: \" \".join(x for x in\nx.split() if x not in stop))\ndf.Text.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "66a0d0bc", "metadata": {}, "outputs": [], "source": ["#Lemmatization\ndf['Text'] = df['Text'].apply(lambda x: \" \".join([Word(word).\nlemmatize() for word in x.split()]))\ndf.Text.head()"]}, {"cell_type": "markdown", "id": "ded78400", "metadata": {}, "source": ["# WORDCLOUD"]}, {"cell_type": "markdown", "id": "36c3372a", "metadata": {}, "source": ["A Wordcloud (or Tag cloud) is a visual representation of text data.\nIt displays a list of words, the importance of each being shown with font size or colorm. \nThis format is useful for quickly perceiving the most prominent term"]}, {"cell_type": "code", "execution_count": 1, "id": "b1dafa6e", "metadata": {}, "outputs": [], "source": ["! pip install wordcloud"]}, {"cell_type": "code", "execution_count": 1, "id": "6ca18572", "metadata": {}, "outputs": [], "source": ["from wordcloud import WordCloud\nfrom wordcloud import STOPWORDS"]}, {"cell_type": "markdown", "id": "f34cc04c", "metadata": {}, "source": ["Make the Wordcloud for Summary and for that a little more analysis and exploration is \nrequired."]}, {"cell_type": "code", "execution_count": 1, "id": "22447340", "metadata": {}, "outputs": [], "source": ["# Create a new data frame \"reviews\" to perform exploratory data analysis upon that\nreviews = df\n# Dropping null values\nreviews.dropna(inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "03d056bf", "metadata": {}, "outputs": [], "source": ["score_1 = reviews[reviews['Score'] == 1]\nscore_2 = reviews[reviews['Score'] == 2]\nscore_3 = reviews[reviews['Score'] == 3]\nscore_4 = reviews[reviews['Score'] == 4]\nscore_5 = reviews[reviews['Score'] == 5]"]}, {"cell_type": "code", "execution_count": 1, "id": "a3f36c8b", "metadata": {}, "outputs": [], "source": ["reviews_sample = pd.concat([score_1,score_2,score_3,score_4,score_5],axis=0)\nreviews_sample.reset_index(drop=True,inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "0dac2198", "metadata": {}, "outputs": [], "source": ["#Wordcloud function's input needs to be a single string of text.\n# concatenating all Summaries into a single string.\n# similarly you can build for Text column\nreviews_str = reviews_sample.Summary.str.cat()\nwordcloud = WordCloud(background_color='white').generate(reviews_str)\nplt.figure(figsize=(10,10))\nplt.imshow(wordcloud,interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "5750dd24", "metadata": {}, "outputs": [], "source": ["# Now let's split the data into Negative (Score is 1 or 2) and Positive (4 or #5) Reviews.\nnegative_reviews = reviews_sample[reviews_sample['Score'].isin([1,2]) ]\npositive_reviews = reviews_sample[reviews_sample['Score'].isin([4,5]) ]\n# Transform to single string\nnegative_reviews_str = negative_reviews.Summary.str.cat()\npositive_reviews_str = positive_reviews.Summary.str.cat()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "667ef590", "metadata": {}, "outputs": [], "source": ["wordcloud_negative = WordCloud(background_color='white').generate(negative_reviews_str)\nwordcloud_positive = WordCloud(background_color='black').generate(positive_reviews_str)\n# Plot\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(211)\nax1.imshow(wordcloud_negative,interpolation='bilinear')\nax1.axis(\"off\")\nax1.set_title('Reviews with Negative Scores',fontsize=20)"]}, {"cell_type": "code", "execution_count": 1, "id": "864298ba", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(10,10))\nax2 = fig.add_subplot(212)\nax2.imshow(wordcloud_positive,interpolation='bilinear')\nax2.axis(\"off\")\nax2.set_title('Reviews with Positive Scores',fontsize=20)\nplt.show()"]}, {"cell_type": "markdown", "id": "244d8934", "metadata": {}, "source": ["Sentiment Analysis: Pretrained model takes the input from the text\ndescription and outputs the sentiment score ranging from -1 to +1 for each\nsentence\n\nVADER (Valence Aware Dictionary and sEntiment Reasoner) is\na lexicon and rule-based sentiment analysis tool that is specifically \nattuned to sentiments expressed in social media. VADER uses a combination of \nA sentiment lexicon is a list of lexical features (e.g., words) which are generally\nlabeled according to their semantic orientation as either positive or negative. \nVADER not only tells about the Positive and Negative score\nbut also tells us about how positive or negative a sentiment is."]}, {"cell_type": "code", "execution_count": 1, "id": "3c48a949", "metadata": {}, "outputs": [], "source": ["!pip install vaderSentiment"]}, {"cell_type": "code", "execution_count": 1, "id": "5fe095e1", "metadata": {}, "outputs": [], "source": ["import re\nimport os\nimport sys\nimport ast\nplt.style.use('fivethirtyeight')\n# Function for getting the sentiment\ncp = sns.color_palette()\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyzer = SentimentIntensityAnalyzer()"]}, {"cell_type": "code", "execution_count": 1, "id": "5903bb07", "metadata": {}, "outputs": [], "source": ["# Generating sentiment for all the sentence present in the dataset\nemptyline=[]\nfor row in df['Text']:\n    \n    vs=analyzer.polarity_scores(row)\n    emptyline.append(vs)\n# Creating new dataframe with sentiments\ndf_sentiments=pd.DataFrame(emptyline)\ndf_sentiments.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "fb7a18cf", "metadata": {}, "outputs": [], "source": ["# Merging the sentiments back to reviews dataframe\ndf_c = pd.concat([df.reset_index(drop=True), df_sentiments], axis=1)\ndf_c.head(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "a399538c", "metadata": {}, "outputs": [], "source": ["# Convert scores into positive and negetive sentiments using some threshold\ndf_c['Sentiment'] = np.where(df_c['compound'] >= 0 , 'Positive','Negative')\ndf_c.head(5)"]}, {"cell_type": "markdown", "id": "a178ab7e", "metadata": {}, "source": ["# Results"]}, {"cell_type": "code", "execution_count": 1, "id": "e0a2fb94", "metadata": {}, "outputs": [], "source": ["result=df_c['Sentiment'].value_counts()\nresult.plot(kind='bar', rot=0, color=['plum','cyan']);"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}