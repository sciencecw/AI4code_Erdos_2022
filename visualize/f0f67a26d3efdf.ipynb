{"cells": [{"cell_type": "markdown", "id": "83407116", "metadata": {}, "source": ["# Introduction\n\nWe show in this Kernel how we can process the data to prepare it for easier processing. Let's check the data files."]}, {"cell_type": "code", "execution_count": 1, "id": "6525d607", "metadata": {}, "outputs": [], "source": ["import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"]}, {"cell_type": "markdown", "id": "92981be0", "metadata": {}, "source": ["# Analysis preparation\n\n## Load packages"]}, {"cell_type": "code", "execution_count": 1, "id": "0d66c4fc", "metadata": {}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "markdown", "id": "fae73212", "metadata": {}, "source": ["## Load the data\n\nThe datafiles are in TSV format. We will read the files using pandas, just include in the function call the `sep` (tab separator data).\nWe demonstrate first how to read and process the Annual data."]}, {"cell_type": "code", "execution_count": 1, "id": "aa155ef1", "metadata": {}, "outputs": [], "source": ["data_df = pd.read_csv(\"/kaggle/input/production-in-industry-annual-data/sts_inpr_a.tsv\", sep='\\t')"]}, {"cell_type": "markdown", "id": "f1f5f650", "metadata": {}, "source": ["Let's glimpse the data columns."]}, {"cell_type": "code", "execution_count": 1, "id": "574f313b", "metadata": {}, "outputs": [], "source": ["print(list(data_df.columns))"]}, {"cell_type": "markdown", "id": "72e6c32c", "metadata": {}, "source": ["Let's also take a look to few of the rows."]}, {"cell_type": "code", "execution_count": 1, "id": "0df7fa3a", "metadata": {}, "outputs": [], "source": ["data_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "aca3c12e", "metadata": {}, "outputs": [], "source": ["data_df.tail()"]}, {"cell_type": "markdown", "id": "f1f8e488", "metadata": {}, "source": ["The first column is a composed one, containing 5 different information (indic_bt, nace_r2, s_adj, unit,geo \\ time). The next columns are temporal values, the years value."]}, {"cell_type": "markdown", "id": "54e3044e", "metadata": {}, "source": ["# Data pre-processing\n\nWe start by defining two working lists."]}, {"cell_type": "code", "execution_count": 1, "id": "9a068eae", "metadata": {}, "outputs": [], "source": ["pivot_data_col = data_df.columns[0]\nyear_columns = data_df.columns[1:]"]}, {"cell_type": "markdown", "id": "2d0fe9ef", "metadata": {}, "source": ["Then, we split from `pivot_data_col` the 5 separate fields:\n* indic_bt;\n* nace_r2;   \n* s_adj;\n* unit;\n* geo;"]}, {"cell_type": "code", "execution_count": 1, "id": "4ece71ba", "metadata": {}, "outputs": [], "source": ["data_df['indic_bt'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[0])\ndata_df['nace_r2'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[1])\ndata_df['s_adj'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[2])\ndata_df['unit'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[3])\ndata_df['geo']     = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[4])"]}, {"cell_type": "markdown", "id": "75cbe6bc", "metadata": {}, "source": ["We select now only the new columns resulted from splitting the `pivot_data_col` and the time columns."]}, {"cell_type": "code", "execution_count": 1, "id": "588357c5", "metadata": {}, "outputs": [], "source": ["selected_columns = list(['indic_bt', 'nace_r2', 's_adj', 'unit', 'geo']) +  list(year_columns)\ndata_df = data_df[selected_columns]"]}, {"cell_type": "markdown", "id": "ce3f790f", "metadata": {}, "source": ["Next, we pivot the time columns using `melt` operation in pandas.  \nWe also make sure we transform `date` to be an integer (here is a year data).  \nWe set `value` to be a float, after we replace \": \" (for N/A) with `NAN`."]}, {"cell_type": "code", "execution_count": 1, "id": "94be65ef", "metadata": {}, "outputs": [], "source": ["data_tr_df = data_df.melt(id_vars=['indic_bt', 'nace_r2', 's_adj', 'unit', 'geo'], \n        var_name=\"year\", \n        value_name=\"value\")\ndata_tr_df['geo'] = data_tr_df['geo'].apply(lambda x: str(x))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"e\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"b\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"u\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"c\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"d\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"z\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"p\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"s\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\": \", \"NAN\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: float(x))"]}, {"cell_type": "markdown", "id": "d5faeb83", "metadata": {}, "source": ["Let's inspect the result."]}, {"cell_type": "code", "execution_count": 1, "id": "730f76fa", "metadata": {}, "outputs": [], "source": ["print(f\"Transformed data shape: {data_tr_df.shape} (rows/columns)\")\ndata_tr_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "42b3cd7e", "metadata": {}, "outputs": [], "source": ["data_tr_df.tail()"]}, {"cell_type": "markdown", "id": "ed40d1d7", "metadata": {}, "source": ["# A very preliminary exploratory data analysis\n\nThis would be a very short exploratory data analysis. The role of this Kernel is just to show how we can prepare the annual data for analysis and we already did this."]}, {"cell_type": "code", "execution_count": 1, "id": "498ce2e9", "metadata": {}, "outputs": [], "source": ["import pandas_profiling\npandas_profiling.ProfileReport(data_tr_df)"]}, {"cell_type": "markdown", "id": "6ec41929", "metadata": {}, "source": ["# Export data in csv format"]}, {"cell_type": "code", "execution_count": 1, "id": "818917ba", "metadata": {}, "outputs": [], "source": ["data_tr_df.to_csv(\"eu_production_in_industry_annual_data.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}