{"cells": [{"cell_type": "markdown", "id": "7890ddb4", "metadata": {}, "source": ["# Data Analytics and Classification Model for Failure Detection of Wind Turbine from IIoT Data"]}, {"cell_type": "markdown", "id": "015474f3", "metadata": {}, "source": ["<div>\n<img src=\"https://user-images.githubusercontent.com/51282928/143174095-7908d4f9-08d6-4c9a-9446-a26f60e80953.png\" width=\"800\"/>\n</div>\n\n[Image Source](https://www.windpowermonthly.com/article/1594597/windtech-new-hybrid-gearbox-splits-loads-scalability)"]}, {"cell_type": "code", "execution_count": 1, "id": "31770975", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "098414b7", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport missingno as msno\nimport seaborn as sns\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import plot_confusion_matrix, classification_report\nfrom lightgbm import LGBMClassifier\n\n%config InlineBackend.figure_format = 'retina'"]}, {"cell_type": "markdown", "id": "bcf03d33", "metadata": {}, "source": ["# 1. Read data"]}, {"cell_type": "markdown", "id": "c41ed3e4", "metadata": {}, "source": ["We have 3 data:\n\n* `scada_data.csv`: Contains >60 information (or status) of wind turbine components recorded by SCADA system\n* `fault_data.csv`: Contains wind turbine fault types (or modes)\n* `status_data.csv`: Contains description of status of wind turbine operational"]}, {"cell_type": "code", "execution_count": 1, "id": "31d57a27", "metadata": {}, "outputs": [], "source": ["scada_df = pd.read_csv('../input/iiot-data-of-wind-turbine/scada_data.csv')\nscada_df['DateTime'] = pd.to_datetime(scada_df['DateTime'])\n# scada_df.set_index('DateTime', inplace=True)\n\nscada_df"]}, {"cell_type": "code", "execution_count": 1, "id": "af0e619b", "metadata": {}, "outputs": [], "source": ["status_df = pd.read_csv('../input/iiot-data-of-wind-turbine/status_data.csv')\nstatus_df['Time'] = pd.to_datetime(status_df['Time'])\nstatus_df.rename(columns={'Time': 'DateTime'}, inplace=True)\n# status_df.set_index('DateTime', inplace=True)\n\nstatus_df"]}, {"cell_type": "code", "execution_count": 1, "id": "754dcfce", "metadata": {}, "outputs": [], "source": ["fault_df = pd.read_csv('../input/iiot-data-of-wind-turbine/fault_data.csv')\nfault_df['DateTime'] = pd.to_datetime(fault_df['DateTime'])\n# fault_df.set_index('DateTime', inplace=True)\n\nfault_df"]}, {"cell_type": "markdown", "id": "36611f5e", "metadata": {}, "source": ["In the fault data, there are 5 types of faults, or fault modes:\n\n* gf: generator heating fault\n* mf: mains failure fault\n* ff: feeding fault\n* af: air cooling fault\n* ef: excitation fault\n\nI don't know exactly what these are. The source of these fault modes in this [GitHub](https://github.com/lkev/wt-fdd)."]}, {"cell_type": "code", "execution_count": 1, "id": "e7d77e7b", "metadata": {}, "outputs": [], "source": ["fault_df.Fault.unique()"]}, {"cell_type": "markdown", "id": "cccc084e", "metadata": {}, "source": ["# 2. Time series analysis"]}, {"cell_type": "markdown", "id": "45336e9a", "metadata": {}, "source": ["The 3 data have different time spans. The status data has the longest record timespan from January 2014 to December 2015. The shortest is SCADA data from April 2014 to April 2015. Therefore, when seeing the SCADA records, we can refer to status and fault data to see what happens on the turbine at certain timestamps."]}, {"cell_type": "code", "execution_count": 1, "id": "bb231354", "metadata": {}, "outputs": [], "source": ["# Plot time span of all data\nt_scada = scada_df.DateTime\nt_fault = fault_df.DateTime\nt_status = status_df.DateTime\n\nplt.figure(figsize=(10,4))\nplt.plot(t_scada, np.full(len(scada_df), 1), label='scada data')\nplt.plot(t_fault, np.full(len(fault_df), 2), label='fault data')\nplt.plot(t_status, np.full(len(status_df), 3), label='status data')\nplt.legend(loc='lower right')\nplt.ylim(0,4)"]}, {"cell_type": "code", "execution_count": 1, "id": "f74619a7", "metadata": {}, "outputs": [], "source": ["# Plot of max power from SCADA data\nscada_df.plot(x='DateTime', y='WEC: max. Power', figsize=(15,4))"]}, {"cell_type": "code", "execution_count": 1, "id": "ae336944", "metadata": {}, "outputs": [], "source": ["# Plot of max power on weekly resampled data\ny = 'WEC: max. Power'\nscada_df.resample('W', on='DateTime').mean().plot(y=y, figsize=(15,4))"]}, {"cell_type": "markdown", "id": "3dd84548", "metadata": {}, "source": ["There were times when power dropped, for example in October 2014, December 2014, and the most significant in January 2015."]}, {"cell_type": "code", "execution_count": 1, "id": "55b2ae27", "metadata": {}, "outputs": [], "source": ["# Plot of power production on monthly resampled data\ny = 'WEC: Production kWh'\nscada_df.resample('D', on='DateTime').mean().plot(y=y, figsize=(15,4))"]}, {"cell_type": "markdown", "id": "dfaf5a0a", "metadata": {}, "source": ["The number of wind turbine faults significantly increases on October 2014."]}, {"cell_type": "code", "execution_count": 1, "id": "a576d7dd", "metadata": {}, "outputs": [], "source": ["# Plot of number of faults on monthly resampled data\nfault_df.resample('M', on='DateTime').Fault.count().plot.bar()"]}, {"cell_type": "code", "execution_count": 1, "id": "ac8f36a5", "metadata": {}, "outputs": [], "source": ["fault_df.resample('M', on='DateTime').Fault.value_counts()"]}, {"cell_type": "markdown", "id": "3b13fb9f", "metadata": {}, "source": ["Let's plot the faults grouped by its fault modes. There are lots of EF events in October and November 2014, and lots of FF events from October 2014 - January 2015."]}, {"cell_type": "code", "execution_count": 1, "id": "1e24c47d", "metadata": {}, "outputs": [], "source": ["def line_format(label):\n    \"\"\"\n    Convert time label to the format of pandas line plot\n    \"\"\"\n    month = label.month_name()[:3]\n    if month == 'Jan':\n        month += f'\\n{label.year}'\n    return month"]}, {"cell_type": "code", "execution_count": 1, "id": "89e56e18", "metadata": {}, "outputs": [], "source": ["c = ['red', 'orange', 'green', 'blue', 'violet']\nfault_df.resample('M', on='DateTime').Fault.value_counts().unstack().plot.bar(stacked=True, width=0.8, figsize=(10,5), color=c, rot=45,\n                                                                              title='Wind Turbine Faults', ylabel='Fault Counts')"]}, {"cell_type": "markdown", "id": "3b45e8a6", "metadata": {}, "source": ["# 3. Combine SCADA and faults data"]}, {"cell_type": "markdown", "id": "987151fe", "metadata": {}, "source": ["We combine SCADA and fault data to pair each measurements with associated faults."]}, {"cell_type": "code", "execution_count": 1, "id": "273276ff", "metadata": {}, "outputs": [], "source": ["# Combine scada and fault data\ndf_combine = scada_df.merge(fault_df, on='Time', how='outer')\nmsno.matrix(df_combine)"]}, {"cell_type": "markdown", "id": "68bc054f", "metadata": {}, "source": ["There are lots of NaNs, or unmatched SCADA timestamps with fault timestamps, simply because there are no faults happen at certain time. For these NaNs, we will replace with \"NF\".\n\n**NF is No Fault (normal condition)**"]}, {"cell_type": "code", "execution_count": 1, "id": "b6b7aa2a", "metadata": {}, "outputs": [], "source": ["# Replace records that has no fault label (NaN) as 'NF' (no fault)\ndf_combine['Fault'] = df_combine['Fault'].replace(np.nan, 'NF')\n\ndf_combine"]}, {"cell_type": "markdown", "id": "db8cbc11", "metadata": {}, "source": ["# 4. Exploratory Data Analysis"]}, {"cell_type": "markdown", "id": "4cedc71d", "metadata": {}, "source": ["Print the averages of SCADA values grouped by fault modes."]}, {"cell_type": "code", "execution_count": 1, "id": "0ed9fa98", "metadata": {}, "outputs": [], "source": ["# Suppress scientific notations\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\n# Groupby fault and take average\ndf_summary = df_combine.groupby('Fault').mean().T\ndf_summary.tail(20)"]}, {"cell_type": "markdown", "id": "ed74ac7a", "metadata": {}, "source": ["Seeing the averages above, we could identify the anomalous behavior of Fault Modes:\n\n* WF has lower ava, min, max active reactive power than No Fault (NF)\n* EF has higher ava, min, max active reactive power than No Fault (NF)\n* GF has ZERO ava, min, max active reactive power\n* FF and MF have higher nacelle cable twisting than NF\n* AF and GF have negative nacelle cable twisting\n* AF and MF have lower production\n* All faults have higher blade angle, the highest is FF\n* GF in general has the lowest temperature in ALL components (cabinet temp, T spinner, T front bearing, ..., T transformer)\n* While other faults (FF, AF, MF, EF) have higher temperature\n* EF temperature is highest in cabinet, pitch, rotor, stator, ambient, control, tower, and transformer\n* AF temperature is highest in spinner, front bearing, rare bearing, nacelle, main carrier, rectifier, yaw, and fan inverter"]}, {"cell_type": "markdown", "id": "c9d63e39", "metadata": {}, "source": ["The boxplots of temperatures (at spinner, bearing, nacelle, and fan inverter) shows that during GF, the temperatures are anomalously lower than normal condition. However, temperatures are higher than normal during AF and EF."]}, {"cell_type": "code", "execution_count": 1, "id": "1e90de90", "metadata": {}, "outputs": [], "source": ["# Boxplots of temperature\nf, axes = plt.subplots(nrows=2, ncols=2,figsize=(10,8))\n\nsns.boxplot(x='Fault', y='Spinner temp.', data=df_combine, ax=axes[0][0])\naxes[0][0].set_title('Spinner Temperature')\nsns.boxplot(x='Fault', y='Rear bearing temp.', data=df_combine, ax=axes[0][1])\naxes[0][1].set_title('Rear Bearing Temperature')\nsns.boxplot(x='Fault', y='Nacelle temp.', data=df_combine, ax=axes[1][0])\naxes[1][0].set_title('Nacelle Temperature')\nsns.boxplot(x='Fault', y='Fan inverter cabinet temp.', data=df_combine, ax=axes[1][1])\naxes[1][1].set_title('Fan Inverter Temperature')\n\nplt.tight_layout()"]}, {"cell_type": "markdown", "id": "d1be9c3c", "metadata": {}, "source": ["Boxplot of reactive power (power from the generator?) shows the power during EF is anomalously high, while the power during MF is lower than normal condition. "]}, {"cell_type": "code", "execution_count": 1, "id": "73571de4", "metadata": {}, "outputs": [], "source": ["sns.catplot(data=df_combine, x='Fault', y='WEC: ava. reactive Power', kind='box')"]}, {"cell_type": "markdown", "id": "c44da121", "metadata": {}, "source": ["The boxplot of nacelle position and cable twisting shows that during AF, nacelle position is negative (up to -500) while during MF, FF, and EF, nacelle position is positive (up to +500)."]}, {"cell_type": "code", "execution_count": 1, "id": "85f441b0", "metadata": {}, "outputs": [], "source": ["sns.catplot(data=df_combine, x='Fault', y='WEC: ava. Nacel position including cable twisting', kind='box')"]}, {"cell_type": "markdown", "id": "8af4d009", "metadata": {}, "source": ["The boxplot of operating hours shows that during MF and AF, the operating hours are shorter than normal condition. However, during FF, the operating hours are longer than normally are."]}, {"cell_type": "code", "execution_count": 1, "id": "a53af746", "metadata": {}, "outputs": [], "source": ["sns.catplot(data=df_combine, x='Fault', y='WEC: Operating Hours', kind='box')"]}, {"cell_type": "markdown", "id": "f8b54810", "metadata": {}, "source": ["# 5. Data preparation for ML"]}, {"cell_type": "markdown", "id": "ba20f3d2", "metadata": {}, "source": ["There are far more records of NF (normal condition) than faulty records - imbalanced dataset. We will sample the No Fault dataframe and pick only 300 records. "]}, {"cell_type": "code", "execution_count": 1, "id": "c7bae69f", "metadata": {}, "outputs": [], "source": ["df_combine.Fault.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "f499c9f0", "metadata": {}, "outputs": [], "source": ["# Pick 300 samples of NF (No Fault) mode data\ndf_nf = df_combine[df_combine.Fault=='NF'].sample(300, random_state=42)\n\ndf_nf"]}, {"cell_type": "code", "execution_count": 1, "id": "3911cff1", "metadata": {}, "outputs": [], "source": ["# With fault mode data\ndf_f = df_combine[df_combine.Fault!='NF']\n\ndf_f"]}, {"cell_type": "code", "execution_count": 1, "id": "3b6e3c91", "metadata": {}, "outputs": [], "source": ["# Combine no fault and faulty dataframes\ndf_combine = pd.concat((df_nf, df_f), axis=0).reset_index(drop=True)\n\ndf_combine"]}, {"cell_type": "markdown", "id": "5688abbb", "metadata": {}, "source": ["Preparing for the training dataset, we **drop irrelevant features**. First we drop datetime, time, and error columns. Next, features that \"de facto\" are output of wind turbine, such as power from wind, operating hours, and kWh production, are dropped. Also, climatic variable such as wind speed are not useful."]}, {"cell_type": "code", "execution_count": 1, "id": "5701e071", "metadata": {}, "outputs": [], "source": ["# Drop irrelevant features\ntrain_df = df_combine.drop(columns=['DateTime_x', 'Time', 'Error', 'WEC: ava. windspeed', \n                                    'WEC: ava. available P from wind',\n                                    'WEC: ava. available P technical reasons',\n                                    'WEC: ava. Available P force majeure reasons',\n                                    'WEC: ava. Available P force external reasons',\n                                    'WEC: max. windspeed', 'WEC: min. windspeed', \n                                    'WEC: Operating Hours', 'WEC: Production kWh',\n                                    'WEC: Production minutes', 'DateTime_y'])\n\ntrain_df"]}, {"cell_type": "code", "execution_count": 1, "id": "aecb8fac", "metadata": {}, "outputs": [], "source": ["# Imbalanced fault modes\ntrain_df.Fault.value_counts().plot.pie(title='Fault Modes')"]}, {"cell_type": "markdown", "id": "237e6ac2", "metadata": {}, "source": ["# 6. Machine learning - fault modes classification"]}, {"cell_type": "markdown", "id": "5e6756ce", "metadata": {}, "source": ["We are going to build a predictive model to classify fault modes of wind turbine based on the information or status of wind turbine components (gear box, tower, nacelle, bearing, etc.) from SCADA system. This is a multiclass classification task.\n\nBecause our training data is largely imbalanced for each fault modes, we use **SMOTE** (Synthetic Minority Oversampling Technique) to oversample the minority classes. The classifier that we use is **LightGBM** (Gradient Boosting Machine). To avoid overfitting, we did **Stratified K-Fold** cross-validation with 5-folds. **Multiple scoring metrics** are used: accuracy, macro-averaged precision, macro recall, and macro F1 score.  \n\n**NOTE.** During cross-validation, the train set will be divided into train set and validation set. Therefore, to ensure that the train set is balanced, the SMOTE should be put inside via **pipeline**. If outside, the score result will be unfair (see this [article](https://towardsdatascience.com/the-right-way-of-using-smote-with-cross-validation-92a8d09d00c7))."]}, {"cell_type": "code", "execution_count": 1, "id": "48eaa0e3", "metadata": {}, "outputs": [], "source": ["# Feature and target\n# X = df_combine.iloc[:,3:-2]\n# y = df_combine.iloc[:,-1]\nX = train_df.iloc[:,:-1]\ny = train_df.iloc[:,-1]\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Make pipeline of SMOTE, scaling, and classifier\npipe = make_pipeline(SMOTE(), StandardScaler(), LGBMClassifier(random_state=42))\n\n# Define multiple scoring metrics\nscoring = {\n    'acc': 'accuracy',\n    'prec_macro': 'precision_macro',\n    'rec_macro': 'recall_macro',\n    'f1_macro': 'f1_macro'\n}\n\n# Stratified K-Fold \nstratkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Return a dictionary of all scorings\ncv_scores = cross_validate(pipe, X_train, y_train, cv=stratkfold, scoring=scoring)"]}, {"cell_type": "code", "execution_count": 1, "id": "5f0f3e7d", "metadata": {}, "outputs": [], "source": ["# Print scoring results from dictionary\nfor metric_name, metric_value in cv_scores.items():\n    mean = np.mean(metric_value)\n    print(f'{metric_name}: {np.round(metric_value, 4)}, Mean: {np.round(mean, 4)}')"]}, {"cell_type": "markdown", "id": "40f2c252", "metadata": {}, "source": ["**The precision, recall, and F1 score are 65%.**"]}, {"cell_type": "code", "execution_count": 1, "id": "d0986288", "metadata": {}, "outputs": [], "source": ["# Fit pipeline to train set\npipe.fit(X_train, y_train)\n\n# Predict on test set\ny_pred = pipe.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "4e105920", "metadata": {}, "outputs": [], "source": ["# Confusion matrix of test set\nplot_confusion_matrix(pipe, X_test, y_test, values_format='.5g') \nplt.show()"]}, {"cell_type": "markdown", "id": "36f815cf", "metadata": {}, "source": ["We can see 2 problematic (false predicted) classes here are FF and EF. There are 30 EF predicted as FF, and 26 FF predicted as EF."]}, {"cell_type": "code", "execution_count": 1, "id": "5533fbdd", "metadata": {}, "outputs": [], "source": ["# Classification report\nprint(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "id": "61deb904", "metadata": {}, "source": ["# 7. Hyperparameter tuning"]}, {"cell_type": "markdown", "id": "f5d10592", "metadata": {}, "source": ["From our previous LightGBM model, we achieved 65% precision, recall, and F1, however we find 2 problematic classes being falsely predicted. We will improve our model with hyperparameter tuning. We will do grid search over **4 hyperparameters** and optimize the **F1 score** as our metric."]}, {"cell_type": "code", "execution_count": 1, "id": "a9a90947", "metadata": {}, "outputs": [], "source": ["# Define parameter search grid\nparam_grid = {'lgbmclassifier__n_estimators': [6, 8, 16, 24], \n              'lgbmclassifier__num_leaves': [4, 6, 8],\n              'lgbmclassifier__reg_alpha' : [1, 1.5],\n              'lgbmclassifier__reg_lambda': [1, 1.5],\n              'lgbmclassifier__boosting_type': ['gbdt'] # Gradient Boosting Decision Tree\n             }\n\n# Grid search CV\ngrid = GridSearchCV(pipe, param_grid, verbose=1, cv=stratkfold, n_jobs=-1, scoring='f1_macro')\n\n# Fit grid on train set\ngrid.fit(X_train, y_train)"]}, {"cell_type": "markdown", "id": "d12ec821", "metadata": {}, "source": ["We got **improvement to 70% F1-score** with the following tuned hyperparameters."]}, {"cell_type": "code", "execution_count": 1, "id": "ea9a1cc0", "metadata": {}, "outputs": [], "source": ["# Best model from tuning\nprint(grid.best_params_)\nprint(f'Average of Macro F1: {grid.best_score_}')"]}, {"cell_type": "markdown", "id": "264fc0b6", "metadata": {}, "source": ["Using the tuned LightGBM model, we had successfully reduced the false classes i.e. from 30 to only 8 EF classes falsely predicted as FF. "]}, {"cell_type": "code", "execution_count": 1, "id": "aca232fa", "metadata": {}, "outputs": [], "source": ["# Confusion matrix of test set\nplot_confusion_matrix(grid, X_test, y_test, values_format='.5g') \nplt.show()"]}, {"cell_type": "markdown", "id": "8688fb8f", "metadata": {}, "source": ["Comparing the present classification report to the previous report, we improved the F1-score of EF class from 46% to 69%, and small improvement of FF class from 62% to 68%.  "]}, {"cell_type": "code", "execution_count": 1, "id": "e10d9bea", "metadata": {}, "outputs": [], "source": ["# Classification report\ny_pred = grid.predict(X_test)\n\nprint(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "id": "d642f433", "metadata": {}, "source": ["With this improvement, however, there remains some issues recommended for **future improvements of this work**:\n* Eventhough there is improvement, 26 FF class still falsely predicted as EF\n* Score of MF and AF are very low: 13% and 41%"]}, {"cell_type": "markdown", "id": "0e99a417", "metadata": {}, "source": ["# 8. Conclusion"]}, {"cell_type": "markdown", "id": "49d084b8", "metadata": {}, "source": ["We analyzed data that comes from the Supervisory Control and Data Acquisition (SCADA) system of a wind turbine from April 2014 until April 2015, with the associated faults that occured during the operating times. The SCADA system gives more than 60 records of all components of the wind turbine such as nacelle, inverter, bearing, and so on. There were 5 fault modes that developed, labeled as FF, AF, EF, MF, and GF. We found out that the number of faults significantly increases in October 2014. \n\nDuring faulty times, there are anomalous behaviors of the wind turbine components. For example, during GF, the temperatures of all wind turbine components are lower than during normal conditions. However, temperatures during AF and EF are higher than normal. And then, the reactive power is anomalously high during EF, while power is lower during MF. Therefore, we could classify fault modes based on various SCADA measured components. \n\nWe made an Adaptive Boosting (AdaBoost) based predictive model to classify fault modes. The data is largely imbalanced among fault modes, therefore SMOTE was implemented within a 5-fold CV pipeline. From that attempt, we achieved a macro F1 score of 64-65%. Two problematic classes, EF and FF, were falsely predicted. To correct this and improve the model performance, we performed hyperparameter tuning to tune 4 AdaBoost hyperparameters. After tuning, the macro F1 score improved to 69-70%. The number of false prediction of EF classes successfully reduces. \n\nThe individual F1 scores of AF and MF were still low. Therefore, an improvement of this work is recommended and will be appreciated.\n\n**Thank you!**"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}