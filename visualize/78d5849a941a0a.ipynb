{"cells": [{"cell_type": "markdown", "id": "7a539c98", "metadata": {}, "source": ["# Titanic Prediction/Classification"]}, {"cell_type": "code", "execution_count": 1, "id": "fe0256c7", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import shapiro\nfrom scipy.stats import randint\nfrom imblearn.over_sampling import SMOTE"]}, {"cell_type": "code", "execution_count": 1, "id": "4f31b50f", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv(\"../input/titanic/train.csv\")\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d26a54c0", "metadata": {}, "outputs": [], "source": ["data.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "796f12f5", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "8016435b", "metadata": {}, "outputs": [], "source": ["data.isnull().sum()"]}, {"cell_type": "markdown", "id": "bb1d864a", "metadata": {}, "source": ["# Data Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "6c5f5f13", "metadata": {}, "outputs": [], "source": ["def data_pipeline(data):\n    data[\"Age\"].fillna((data[\"Age\"].mean()), inplace=True)\n    data = data.drop([\"Name\", \"Ticket\"], axis=1)\n    data.Sex.replace(to_replace=dict(female=1, male=0), inplace=True)\n    data.Embarked.replace(to_replace=dict(Q=1, C=2, S=3), inplace=True)\n    data[\"Embarked\"].fillna((data[\"Embarked\"].mean()), inplace=True)\n    data['Deck'] = data['Cabin'].str.extract('([A-Za-z])', expand=False)\n    data.Deck.replace(to_replace=dict(A=1, B=2, C=3, D=4, E=5, F=6, G=7, T=8), inplace=True)\n    data[\"Deck\"].fillna((data[\"Deck\"].median()), inplace=True)\n    data = data.drop([\"Cabin\"], axis=1)\n    data[\"Fare\"].fillna((data[\"Fare\"].mean()), inplace=True)\n    \n    return data"]}, {"cell_type": "code", "execution_count": 1, "id": "0dd7e0df", "metadata": {}, "outputs": [], "source": ["data = data_pipeline(data)"]}, {"cell_type": "code", "execution_count": 1, "id": "4316b722", "metadata": {}, "outputs": [], "source": ["data"]}, {"cell_type": "markdown", "id": "8280c554", "metadata": {}, "source": ["# Data Interpretation and Visualization"]}, {"cell_type": "markdown", "id": "efecb383", "metadata": {}, "source": ["### Outlier Visualization, Interpretation and Handling"]}, {"cell_type": "code", "execution_count": 1, "id": "03936c7b", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 10))\nsns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(data))\nsns.stripplot(x=\"variable\", y=\"value\", data=pd.melt(data), color=\"orange\", jitter=0.2, size=2.5)\nplt.grid()"]}, {"cell_type": "code", "execution_count": 1, "id": "afbb9e0b", "metadata": {}, "outputs": [], "source": ["import warnings\nwarnings.filterwarnings(\"ignore\")\n\na=1\nplt.figure(figsize=(20, 10))\nfor i in data.columns:\n    plt.subplot(4, 3, a)\n    sns.distplot(data[i])\n    a += 1\nplt.show()"]}, {"cell_type": "markdown", "id": "a1daffe4", "metadata": {}, "source": ["#### Hypothesis 1: Not one of the columns are normal distriuted\n\nThis will be evaluated by using the p-value measurement:\n\n${\\displaystyle p=2\\min\\{\\Pr(T\\geq t\\mid H_{0}),\\Pr(T\\leq t\\mid H_{0})\\}}$ for a two-sided test. If distribution ${\\displaystyle T}$ is symmetric about zero, then ${\\displaystyle p=\\Pr(|T|\\geq |t|\\mid H_{0})}{\\displaystyle p=\\Pr(|T|\\geq |t|\\mid H_{0})}$"]}, {"cell_type": "code", "execution_count": 1, "id": "5fb5d1e7", "metadata": {}, "outputs": [], "source": ["# Shapiro-Wilk Test\nfor col in data:\n    stat, p = shapiro(data[col])\n    print(\"----------------------------------------------\")\n    print(col)\n    print('Statistics=%.3f, p=%.3f' % (stat, p))\n    # interpret\n    alpha = 0.05\n    if p > alpha:\n        print('Sample looks Gaussian (fail to reject H0)')\n    else:\n        print('Sample does not look Gaussian (reject H0)')"]}, {"cell_type": "markdown", "id": "3a757268", "metadata": {}, "source": ["#### On the basis of the knowledge gained from above the data in columns are not normal distributed."]}, {"cell_type": "markdown", "id": "6ddad5a8", "metadata": {}, "source": ["### Outlier handling\nWe do not handle any outliers for the following reason:\n- a woman, with age 70 in the 3rd class has it a lot harder than a man, with 30 ages and in the 1st class\n\nThis statement will be proven in the section visualizations..."]}, {"cell_type": "code", "execution_count": 1, "id": "8472699e", "metadata": {}, "outputs": [], "source": ["# Visualize correlations of each column (not necessary but for interest)\ncorrelations = data.corr(method=\"pearson\")\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlations, vmin= -1, cmap=\"coolwarm\", annot=True)"]}, {"cell_type": "markdown", "id": "1008275e", "metadata": {}, "source": ["### Visualization"]}, {"cell_type": "markdown", "id": "0e38cd21", "metadata": {}, "source": ["#### More Men than Women died:"]}, {"cell_type": "code", "execution_count": 1, "id": "18e7413f", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 8))\n\nplt.subplot(1, 2, 1)\nplt.ylim(0, 600)\nsns.countplot(data=data, x=\"Survived\")\n\n\nplt.subplot(1, 2, 2)\nfig_2 = sns.countplot(data=data, x=\"Sex\", hue=\"Survived\")\nfig_2.set_xticklabels([\"male\", \"female\"])\nplt.ylim(0, 600)\nplt.show(fig_2.containers[0])\nplt.show(fig_2.containers[1])\n\nplt.show()\n"]}, {"cell_type": "markdown", "id": "b127d3c5", "metadata": {}, "source": ["#### Persons which are in the Age Group 30 are died the most but not in percentage:"]}, {"cell_type": "code", "execution_count": 1, "id": "8a4b9862", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 8))\nsns.histplot(data=data, x=\"Age\", hue=\"Survived\", element=\"step\", kde=True)"]}, {"cell_type": "markdown", "id": "f697b6fb", "metadata": {}, "source": ["#### According to the Classes 1-3 (1 = 1st class (best class) -> upper levels of the ship, 2 = 2nd class -> middle level of the ship, 3 = 3rd class -> lower levels of the ship) this means that passengers in the 3rd class had it harder to get on top than 1st class passengers:"]}, {"cell_type": "code", "execution_count": 1, "id": "ef40401c", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 8))\nplt.subplot(1, 2, 1)\nplt.ylim(0, 550)\nfig_2 = sns.countplot(data=data, x=\"Pclass\")\nplt.bar_label(fig_2.containers[0])\n\n\nplt.subplot(1, 2, 2)\nfig_2 = sns.countplot(data=data, x=\"Pclass\", hue=\"Survived\")\nfig_2.set_xticklabels([\"1\", \"2\", \"3\"])\nplt.ylim(0, 550)\nplt.show(fig_2.containers[0])\nplt.show(fig_2.containers[1])"]}, {"cell_type": "code", "execution_count": 1, "id": "6dd1f3be", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 8))\nplt.subplot(1, 2, 1)\nplt.ylim(0, 650)\nsns.countplot(data=data, x=\"SibSp\")\n\n\nplt.subplot(1, 2, 2)\nfig_4 = sns.countplot(data=data, x=\"SibSp\", hue=\"Survived\")\nplt.ylim(0, 650)\nplt.show(fig_4.containers[0])\nplt.show(fig_4.containers[1])\n"]}, {"cell_type": "code", "execution_count": 1, "id": "60fe10e3", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 8))\nplt.subplot(1, 2, 1)\nplt.ylim(0, 700)\nsns.countplot(data=data, x=\"Parch\")\n\n\nplt.subplot(1, 2, 2)\nfig_4 = sns.countplot(data=data, x=\"Parch\", hue=\"Survived\")\nplt.ylim(0, 700)\nplt.show(fig_4.containers[0])\nplt.show(fig_4.containers[1])\n"]}, {"cell_type": "markdown", "id": "454ab654", "metadata": {}, "source": ["# Preprocessing and Classification"]}, {"cell_type": "markdown", "id": "ece11c11", "metadata": {}, "source": ["#### First of all we split the Survived column from the other columns and use SMOTE to make the \"Survived\" column distribution equal"]}, {"cell_type": "code", "execution_count": 1, "id": "b3f9e455", "metadata": {}, "outputs": [], "source": ["x = data.drop(columns=[\"Survived\"])\ny = data[\"Survived\"]\n\n# Show distribution of 0 and 1\ny.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "78f9a7a8", "metadata": {}, "outputs": [], "source": ["sm = SMOTE(random_state=42)\nx, y = sm.fit_resample(x, y)\ny.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "7c16a678", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=14)"]}, {"cell_type": "markdown", "id": "4a5b9bd4", "metadata": {}, "source": ["### Prepare the models for testing"]}, {"cell_type": "code", "execution_count": 1, "id": "dc624f5a", "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC, LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier , ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV\n%matplotlib inline\n\n# Create empty list and append each model to list\nmodels = []\nmodels.append((\"SVC\", SVC(random_state=14)))\nmodels.append((\"SVM\", LinearSVC(random_state=14)))\nmodels.append((\"LOGR\", LogisticRegression(solver=\"liblinear\", random_state=14)))\nmodels.append((\"LDA\", LinearDiscriminantAnalysis()))\nmodels.append((\"KNN\", KNeighborsClassifier()))\nmodels.append((\"CART\", DecisionTreeClassifier(random_state=14)))\nmodels.append((\"NB\", GaussianNB()))\nmodels.append((\"DT\", DecisionTreeClassifier(random_state=14)))\nmodels.append((\"RF\", RandomForestClassifier(random_state=14)))\nmodels.append((\"ET\", ExtraTreesClassifier(random_state=14)))\nmodels.append((\"GB\", GradientBoostingClassifier(random_state=14)))\nmodels.append((\"BC\", BaggingClassifier(random_state=14)))\n\n# Empty list for results of the evaluation\nmodel_results = []"]}, {"cell_type": "code", "execution_count": 1, "id": "649b848d", "metadata": {}, "outputs": [], "source": ["# Function: for each element in model list there will be an evaluation -> Results will be added to results df\ndef train_all_models(models):\n    i = 1\n    plt.figure(figsize=(25, 15))\n    for method, model in models:\n        model.fit(x_train, y_train)\n        test_pred = model.predict(x_test)\n\n        f_score = model.score(x_test, y_test)\n        model_results.append((method, f_score))\n\n        plt.subplot(3, 4, i)\n        plt.subplots_adjust(hspace=0.3, wspace=0.3)\n        sns.heatmap(confusion_matrix(y_test, test_pred), annot=True, cmap=\"Greens\")\n        plt.title(model, fontsize=14)\n        plt.xlabel('Test', fontsize=12)\n        plt.ylabel('Predict', fontsize=12)\n        df = pd.DataFrame(model_results).transpose()\n        i+=1\n\n# Show confusion matrix for each trained model \n    plt.show()\n    df = pd.DataFrame(model_results)\n    return df"]}, {"cell_type": "code", "execution_count": 1, "id": "72144703", "metadata": {}, "outputs": [], "source": ["# Sort results df for later visualizations    \nbest_models = train_all_models(models)\nbest_models = best_models.sort_values([1], ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "03827d02", "metadata": {}, "outputs": [], "source": ["best_models"]}, {"cell_type": "code", "execution_count": 1, "id": "d08c2a4e", "metadata": {}, "outputs": [], "source": ["y_pos = np.arange(len(best_models[0]))\nplt.figure(figsize=(10, 6))\nplt.bar(y_pos, best_models[1], color=(0.2, 0.4, 0.6, 0.6))\nplt.xticks(y_pos, best_models[0])\nplt.title('F-Score of all trained models')\nplt.xlabel('Model Type')\nplt.ylabel('F-Score')\nplt.show()"]}, {"cell_type": "markdown", "id": "69bb6247", "metadata": {}, "source": ["### Hyperparameter Tuning of best 3 models"]}, {"cell_type": "code", "execution_count": 1, "id": "8d0f9055", "metadata": {}, "outputs": [], "source": ["# Take top 3 models and define new -> for randomized search cv\ntop3_RF = RandomForestClassifier()\ntop3_ET = ExtraTreesClassifier()\ntop3_GB = GradientBoostingClassifier()\n\ntop3_RF.fit(x_train, y_train)\ntop3_ET.fit(x_train, y_train)\ntop3_GB.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "f1930004", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import RandomizedSearchCV\n\n# Grid Search for RandomForesClassifier\ngrid_param_RF = {\n    \"n_estimators\": randint(low=1, high=100),\n    \"max_depth\": randint(low=10, high=100),\n    \"max_features\": randint(low=1, high=4)\n}\n\nRF_grid_search = RandomizedSearchCV(estimator=top3_RF, param_distributions=grid_param_RF, cv= 10, verbose=1, random_state=14)\nRF_grid_search.fit(x_train, y_train)\n\nRF_best_grid = RF_grid_search.best_estimator_\nprint(RF_best_grid)\nprint(RF_grid_search.best_score_)"]}, {"cell_type": "code", "execution_count": 1, "id": "3ec166c1", "metadata": {}, "outputs": [], "source": ["# Grid Search for ExtraTreesClassifier\ngrid_param_ET = {\n    \"n_estimators\": randint(low=1, high=100),\n    \"max_depth\": randint(low=10, high=100),\n    \"max_features\": randint(low=1, high=4)\n}\n\nET_grid_search = RandomizedSearchCV(estimator=top3_ET, param_distributions=grid_param_ET, cv= 10, verbose=1, random_state=14)\nET_grid_search.fit(x_train, y_train)\n\nET_best_grid = ET_grid_search.best_estimator_\n\nprint(ET_best_grid)\nprint(ET_grid_search.best_score_)"]}, {"cell_type": "code", "execution_count": 1, "id": "07a5e9ba", "metadata": {}, "outputs": [], "source": ["# Grid Search for GradientBoostingClassifier\ngrid_param_GB = {\n    \"n_estimators\": randint(low=1, high=100),\n    \"max_depth\": randint(low=10, high=100),\n    \"max_features\": randint(low=1, high=4)\n}\n\nGB_grid_search = RandomizedSearchCV(estimator=top3_GB, param_distributions=grid_param_GB, cv= 10, verbose=1, random_state=14)\nGB_grid_search.fit(x_train, y_train)\n\nGB_best_grid = GB_grid_search.best_estimator_\n\nprint(GB_best_grid)\nprint(GB_grid_search.best_score_)"]}, {"cell_type": "code", "execution_count": 1, "id": "745f26c0", "metadata": {}, "outputs": [], "source": ["# Show results of grid search\nprint(RF_best_grid, \"\\n Score: \", RF_grid_search.best_score_, \"\\n ------------------------------------\")\nprint(ET_best_grid, \"\\n Score: \", ET_grid_search.best_score_, \"\\n ------------------------------------\")\nprint(GB_best_grid, \"\\n Score: \", GB_grid_search.best_score_, \"\\n ------------------------------------\")"]}, {"cell_type": "markdown", "id": "6078de6d", "metadata": {}, "source": ["# Taking best Model and train it again with best Hyperparameters"]}, {"cell_type": "code", "execution_count": 1, "id": "50e7c4ff", "metadata": {}, "outputs": [], "source": ["# ExtraTreesClassifier is best one, create model and learn again with defined parameters of grid search\nbest_model = RandomForestClassifier(max_depth=20, max_features=1, n_estimators=62)\nbest_model.fit(x, y)"]}, {"cell_type": "markdown", "id": "223001fd", "metadata": {}, "source": ["# Using the best_model for test.csv"]}, {"cell_type": "code", "execution_count": 1, "id": "73aaccff", "metadata": {}, "outputs": [], "source": ["test_data = pd.read_csv(\"../input/titanic/test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "336d9310", "metadata": {}, "outputs": [], "source": ["test_data = data_pipeline(test_data)\n\ntest_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "7211182e", "metadata": {}, "outputs": [], "source": ["test_data.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "dde88a0a", "metadata": {}, "outputs": [], "source": ["test_data[\"Survived\"] = best_model.predict(test_data)"]}, {"cell_type": "code", "execution_count": 1, "id": "609070c4", "metadata": {}, "outputs": [], "source": ["test_data[['PassengerId', 'Survived']].to_csv('submission.csv', index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "fb2bc52a", "metadata": {}, "outputs": [], "source": ["submission = pd.read_csv(\"./submission.csv\")\nsubmission.shape"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}