{"cells": [{"cell_type": "code", "execution_count": 1, "id": "6164c0fc", "metadata": {}, "outputs": [], "source": ["!pip install -q segmentation-models-pytorch\n\nfrom glob import glob\nimport os\nimport time\n\nimport albumentations as A\nimport cv2\nimport numpy as np\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy.ndimage.morphology import binary_dilation\nimport segmentation_models_pytorch as smp\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nfrom tqdm import tqdm"]}, {"cell_type": "code", "execution_count": 1, "id": "bf05899e", "metadata": {}, "outputs": [], "source": ["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]}, {"cell_type": "markdown", "id": "ff6e298a", "metadata": {}, "source": ["# 1. Loading data"]}, {"cell_type": "code", "execution_count": 1, "id": "23c718a2", "metadata": {}, "outputs": [], "source": ["def get_file_row(path):\n    \"\"\"Produces ID of a patient, image and mask filenames from a particular path\"\"\"\n    path_no_ext, ext = os.path.splitext(path)\n    filename = os.path.basename(path)\n    \n    patient_id = '_'.join(filename.split('_')[:3]) # Patient ID in the csv file consists of 3 first filename segments\n    \n    return [patient_id, path, f'{path_no_ext}_mask{ext}']"]}, {"cell_type": "code", "execution_count": 1, "id": "82936509", "metadata": {}, "outputs": [], "source": ["get_file_row('/kaggle/input/lgg-mri-segmentation/lgg-mri-segmentation/kaggle_3m/TCGA_DU_7010_19860307/TCGA_DU_7010_19860307_45.tif')"]}, {"cell_type": "code", "execution_count": 1, "id": "a717fb5c", "metadata": {}, "outputs": [], "source": ["files_dir = '/kaggle/input/lgg-mri-segmentation/lgg-mri-segmentation/kaggle_3m/'\nfile_paths = glob(f'{files_dir}/*/*[0-9].tif')"]}, {"cell_type": "markdown", "id": "b14d7af5", "metadata": {}, "source": ["I am not sure if the csv data would be useful, but I'll put it together with the images anyway."]}, {"cell_type": "code", "execution_count": 1, "id": "61a47545", "metadata": {}, "outputs": [], "source": ["csv_path = '/kaggle/input/lgg-mri-segmentation/lgg-mri-segmentation/kaggle_3m/data.csv'\ndf = pd.read_csv(csv_path)\n\ndf.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "e1a1aeb1", "metadata": {}, "outputs": [], "source": ["imputer = SimpleImputer(strategy=\"most_frequent\")\nprint(list(df.columns))\ndf = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\ndf"]}, {"cell_type": "code", "execution_count": 1, "id": "07f69196", "metadata": {}, "outputs": [], "source": ["filenames_df = pd.DataFrame((get_file_row(filename) for filename in file_paths), columns=['Patient', 'image_filename', 'mask_filename'])\nfilenames_df"]}, {"cell_type": "code", "execution_count": 1, "id": "50d031c2", "metadata": {}, "outputs": [], "source": ["class MriDataset(Dataset):\n    def __init__(self, df, transform=None, mean=0.5, std=0.25):\n        super(MriDataset, self).__init__()\n        self.df = df\n        self.transform = transform\n        self.mean = mean\n        self.std = std\n        \n        \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx, raw=False):\n        row = self.df.iloc[idx]\n        img = cv2.imread(row['image_filename'], cv2.IMREAD_UNCHANGED)\n        mask = cv2.imread(row['mask_filename'], cv2.IMREAD_GRAYSCALE)\n        if raw:\n            return img, mask\n        \n        if self.transform:\n            augmented = self.transform(image=img, mask=mask)\n            image, mask = augmented['image'], augmented['mask']\n        \n        img = T.functional.to_tensor(img)\n        mask = mask // 255\n        mask = torch.Tensor(mask)\n        return img, mask"]}, {"cell_type": "code", "execution_count": 1, "id": "f9d87daf", "metadata": {}, "outputs": [], "source": ["df = pd.merge(df, filenames_df, on=\"Patient\")"]}, {"cell_type": "markdown", "id": "375ebef1", "metadata": {}, "source": ["# 2. Preparing the datasets"]}, {"cell_type": "code", "execution_count": 1, "id": "cce99901", "metadata": {}, "outputs": [], "source": ["train_df, test_df = train_test_split(df, test_size=0.3)\ntest_df, valid_df = train_test_split(test_df, test_size=0.5)"]}, {"cell_type": "markdown", "id": "7040367e", "metadata": {}, "source": ["Only applied channel dropout and random color changes, the model gave subpar results when confronted with rotations and flips."]}, {"cell_type": "code", "execution_count": 1, "id": "e07dd6ce", "metadata": {}, "outputs": [], "source": ["transform = A.Compose([\n    A.ChannelDropout(p=0.3),\n    A.RandomBrightnessContrast(p=0.3),\n    A.ColorJitter(p=0.3),\n])\n\ntrain_dataset = MriDataset(train_df, transform)\nvalid_dataset = MriDataset(valid_df)\ntest_dataset = MriDataset(test_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "15255d75", "metadata": {}, "outputs": [], "source": ["batch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1)"]}, {"cell_type": "markdown", "id": "a4375533", "metadata": {}, "source": ["# 3. Visualization and analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "2aa76710", "metadata": {}, "outputs": [], "source": ["%matplotlib inline\nn_examples = 4\n\nfig, axs = plt.subplots(n_examples, 3, figsize=(20, n_examples*7), constrained_layout=True)\ni = 0\nfor ax in axs:\n    while True:\n        image, mask = train_dataset.__getitem__(i, raw=True)\n        i += 1\n        if np.any(mask): \n            ax[0].set_title(\"MRI images\")\n            ax[0].imshow(image)\n            ax[1].set_title(\"Highlited abnormality\")\n            ax[1].imshow(image)\n            ax[1].imshow(mask, alpha=0.2)\n            ax[2].imshow(mask)\n            ax[2].set_title(\"Abnormality mask\")\n            break\n        \n    \n    "]}, {"cell_type": "markdown", "id": "d1648baf", "metadata": {}, "source": ["# 4. Preparing model and training"]}, {"cell_type": "code", "execution_count": 1, "id": "6907d9ef", "metadata": {}, "outputs": [], "source": ["class EarlyStopping():\n    \"\"\"\n    Stops training when loss stops decreasing in a PyTorch module.\n    \"\"\"\n    def __init__(self, patience:int = 6, min_delta: float = 0, weights_path: str = 'weights.pt'):\n        \"\"\"\n        :param patience: number of epochs of non-decreasing loss before stopping\n        :param min_delta: minimum difference between best and new loss that is considered\n            an improvement\n        :paran weights_path: Path to the file that should store the model's weights\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.weights_path = weights_path\n\n    def __call__(self, val_loss: float, model: torch.nn.Module):\n        if self.best_loss - val_loss > self.min_delta:\n            self.best_loss = val_loss\n            torch.save(model.state_dict(), self.weights_path)\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n    def load_weights(self, model: torch.nn.Module):\n        \"\"\"\n        Loads weights of the best model.\n        :param model: model to which the weigths should be loaded\n        \"\"\"\n        return model.load_state_dict(torch.load(self.weights_path))\n            "]}, {"cell_type": "code", "execution_count": 1, "id": "bae4eebd", "metadata": {}, "outputs": [], "source": ["def iou_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n    \"\"\"Calculates Intersection over Union for a tensor of predictions\"\"\"\n    predictions = torch.where(predictions > 0.5, 1, 0)\n    labels = labels.byte()\n    \n    intersection = (predictions & labels).float().sum((1, 2))\n    union = (predictions | labels).float().sum((1, 2))\n    \n    iou = (intersection + e) / (union + e)\n    return iou\n\ndef dice_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n    \"\"\"Calculates Dice coefficient for a tensor of predictions\"\"\"\n    predictions = torch.where(predictions > 0.5, 1, 0)\n    labels = labels.byte()\n    \n    intersection = (predictions & labels).float().sum((1, 2))\n    return ((2 * intersection) + e) / (predictions.float().sum((1, 2)) + labels.float().sum((1, 2)) + e)"]}, {"cell_type": "markdown", "id": "5b9e873e", "metadata": {}, "source": ["Adding custom lose consisting of binary crossentropy and soft dice coefficient gives slightly better results."]}, {"cell_type": "code", "execution_count": 1, "id": "81db94fc", "metadata": {}, "outputs": [], "source": ["def BCE_dice(output, target, alpha=0.01):\n    bce = torch.nn.functional.binary_cross_entropy(output, target)\n    soft_dice = 1 - dice_pytorch(output, target).mean()\n    return bce + alpha * soft_dice"]}, {"cell_type": "code", "execution_count": 1, "id": "8022202e", "metadata": {}, "outputs": [], "source": ["model = smp.FPN(\n    encoder_name=\"efficientnet-b7\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation='sigmoid',\n)\nmodel.to(device);"]}, {"cell_type": "code", "execution_count": 1, "id": "81d91f16", "metadata": {}, "outputs": [], "source": ["def training_loop(epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler):\n    history = {'train_loss': [], 'val_loss': [], 'val_IoU': [], 'val_dice': []}\n    early_stopping = EarlyStopping(patience=7)\n    \n    for epoch in range(1, epochs + 1):\n        start_time = time.time()\n        \n        running_loss = 0\n        model.train()\n        for i, data in enumerate(tqdm(train_loader)):\n            img, mask = data\n            img, mask = img.to(device), mask.to(device)\n            predictions = model(img)\n            predictions = predictions.squeeze(1)\n            loss = loss_fn(predictions, mask)\n            running_loss += loss.item() * img.size(0)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        model.eval()\n        with torch.no_grad():\n            running_IoU = 0\n            running_dice = 0\n            running_valid_loss = 0\n            for i, data in enumerate(valid_loader):\n                img, mask = data\n                img, mask = img.to(device), mask.to(device)\n                predictions = model(img)\n                predictions = predictions.squeeze(1)\n                running_dice += dice_pytorch(predictions, mask).sum().item()\n                running_IoU += iou_pytorch(predictions, mask).sum().item()\n                loss = loss_fn(predictions, mask)\n                running_valid_loss += loss.item() * img.size(0)\n        train_loss = running_loss / len(train_loader.dataset)\n        val_loss = running_valid_loss / len(valid_loader.dataset)\n        val_dice = running_dice / len(valid_loader.dataset)\n        val_IoU = running_IoU / len(valid_loader.dataset)\n        \n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_IoU'].append(val_IoU)\n        history['val_dice'].append(val_dice)\n        print(f'Epoch: {epoch}/{epochs} | Training loss: {train_loss} | Validation loss: {val_loss} | Validation Mean IoU: {val_IoU} '\n         f'| Validation Dice coefficient: {val_dice}')\n        \n        lr_scheduler.step(val_loss)\n        if early_stopping(val_loss, model):\n            early_stopping.load_weights(model)\n            break\n    model.eval()\n    return history"]}, {"cell_type": "code", "execution_count": 1, "id": "825dcd76", "metadata": {}, "outputs": [], "source": ["loss_fn = BCE_dice\noptimizer = Adam(model.parameters(), lr=0.001)\nepochs = 60\nlr_scheduler = ReduceLROnPlateau(optimizer=optimizer, patience=2,factor=0.2)\n\nhistory = training_loop(epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler)"]}, {"cell_type": "markdown", "id": "aaed2d73", "metadata": {}, "source": ["# 5. Testing"]}, {"cell_type": "code", "execution_count": 1, "id": "710166b3", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(7, 7))\nplt.plot(history['train_loss'], label='Training loss')\nplt.plot(history['val_loss'], label='Validation loss')\nplt.ylim(0, 0.01)\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "7164b96d", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(7, 7))\nplt.plot(history['val_IoU'], label='Validation mean Jaccard index')\nplt.plot(history['val_dice'], label='Validation Dice coefficient')\nplt.legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "f16d7e26", "metadata": {}, "outputs": [], "source": ["with torch.no_grad():\n    running_IoU = 0\n    running_dice = 0\n    running_loss = 0\n    for i, data in enumerate(test_loader):\n        img, mask = data\n        img, mask = img.to(device), mask.to(device)\n        predictions = model(img)\n        predictions = predictions.squeeze(1)\n        running_dice += dice_pytorch(predictions, mask).sum().item()\n        running_IoU += iou_pytorch(predictions, mask).sum().item()\n        loss = loss_fn(predictions, mask)\n        running_loss += loss.item() * img.size(0)\n    loss = running_loss / len(test_dataset)\n    dice = running_dice / len(test_dataset)\n    IoU = running_IoU / len(test_dataset)\n    \n    print(f'Tests: loss: {loss} | Mean IoU: {IoU} | Dice coefficient: {dice}')"]}, {"cell_type": "code", "execution_count": 1, "id": "79faee37", "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n\nwidth = 3\ncolumns = 10\nn_examples = columns * width\n\nfig, axs = plt.subplots(columns, width, figsize=(7*width , 7*columns), constrained_layout=True)\nred_patch = mpatches.Patch(color='red', label='The red data')\nfig.legend(loc='upper right',handles=[\n    mpatches.Patch(color='red', label='Ground truth'),\n    mpatches.Patch(color='green', label='Predicted abnormality')])\ni = 0\nwith torch.no_grad():\n    for data in test_loader:\n        image, mask = data\n        mask = mask[0]\n        if not mask.byte().any():\n            continue\n        image = image.to(device)\n        prediction = model(image).to('cpu')[0][0]\n        prediction = torch.where(prediction > 0.5, 1, 0)\n        prediction_edges = prediction - binary_dilation(prediction)\n        ground_truth = mask - binary_dilation(mask)\n        image[0, 0, ground_truth.bool()] = 1\n        image[0, 1, prediction_edges.bool()] = 1\n        \n        axs[i//width][i%width].imshow(image[0].to('cpu').permute(1, 2, 0))\n        if n_examples == i + 1:\n            break\n        i += 1\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}