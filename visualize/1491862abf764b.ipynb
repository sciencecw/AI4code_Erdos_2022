{"cells": [{"cell_type": "markdown", "id": "00fe5a49", "metadata": {}, "source": ["# Load Prediction based on Customer Behavious"]}, {"cell_type": "code", "execution_count": 1, "id": "2d3abbc7", "metadata": {}, "outputs": [], "source": ["import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pickle"]}, {"cell_type": "markdown", "id": "ca14733c", "metadata": {}, "source": ["## 1. Problem defination\n\n* Classify the Potential Bank Loan Defaulters"]}, {"cell_type": "markdown", "id": "5e9f7473", "metadata": {}, "source": ["## 2. Data\nThere are 2 main datasets:\n\n* Training Data.csv is the training set, which contains data of previous bank customers and defaulters.*\n* Test Data.csv is the test set, which is going to used for testing our model prediction accuracy*\n"]}, {"cell_type": "code", "execution_count": 1, "id": "f4ca3235", "metadata": {}, "outputs": [], "source": ["train_df = pd.read_csv('../input/loan-prediction-based-on-customer-behavior/Training Data.csv')\ntrain_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "c23d750b", "metadata": {}, "outputs": [], "source": ["train_df.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "81338568", "metadata": {}, "outputs": [], "source": ["## How Likely Married or single people are loan defaulters\nsns.countplot(x = train_df['Married/Single'] , hue = train_df['Risk_Flag']);"]}, {"cell_type": "code", "execution_count": 1, "id": "ec12f6ce", "metadata": {}, "outputs": [], "source": ["# Checking the people distribution with their working experience\nsns.histplot(train_df['Experience'])"]}, {"cell_type": "code", "execution_count": 1, "id": "207e19aa", "metadata": {}, "outputs": [], "source": ["# Checking, people with how much expreince are usually loan defaulters\nsns.countplot(train_df['Experience'] , hue = train_df['Risk_Flag']);"]}, {"cell_type": "code", "execution_count": 1, "id": "01e1efc4", "metadata": {}, "outputs": [], "source": ["# How Likely house owners, house renters and withour house people does not pay loan\nsns.countplot(train_df['House_Ownership'] , hue = train_df['Risk_Flag']);"]}, {"cell_type": "code", "execution_count": 1, "id": "47a42abf", "metadata": {}, "outputs": [], "source": ["##How many Loan Defaulters are their in the dataset\ntrain_df[\"Risk_Flag\"].value_counts().plot.bar(figsize=(6,6))"]}, {"cell_type": "code", "execution_count": 1, "id": "6fd5b2d3", "metadata": {}, "outputs": [], "source": ["train_df.Profession.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "80292c4b", "metadata": {}, "outputs": [], "source": ["# Droping the Id, CITY, STATE and Profession columns from the dataset and copying the new dataset\ndf_copy = train_df.drop(['Id', 'CITY', 'STATE', 'Profession'], axis=1).copy()\ndf_copy.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "5c5e5de9", "metadata": {}, "outputs": [], "source": ["df_copy.corr()"]}, {"cell_type": "code", "execution_count": 1, "id": "d8fa1cc3", "metadata": {}, "outputs": [], "source": ["df_copy.describe()"]}, {"cell_type": "markdown", "id": "d3199576", "metadata": {}, "source": ["# Data Processing"]}, {"cell_type": "code", "execution_count": 1, "id": "3c046837", "metadata": {}, "outputs": [], "source": ["## This will convert all the string values into category value\n# def convert_string_to_category():\nfor label,content in df_copy.items():\n    if pd.api.types.is_string_dtype(content):\n        df_copy[label] = content.astype(\"category\").cat.as_ordered()"]}, {"cell_type": "code", "execution_count": 1, "id": "b5f97977", "metadata": {}, "outputs": [], "source": ["df_copy.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "e9443e29", "metadata": {}, "outputs": [], "source": ["# Turn Categorical variables into numbers\nfor labels, content in df_copy.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        df_copy[labels] = pd.Categorical(content).codes + 1"]}, {"cell_type": "code", "execution_count": 1, "id": "3a091d1e", "metadata": {}, "outputs": [], "source": ["df_copy['Married/Single'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "988ab74d", "metadata": {}, "outputs": [], "source": ["df_copy.House_Ownership.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "03604583", "metadata": {}, "outputs": [], "source": ["df_copy.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "b884fd5d", "metadata": {}, "outputs": [], "source": ["# Increase the size of the heatmap.\nplt.figure(figsize=(16, 6))\n# Store heatmap object in a variable to easily access it when you want to include more features (such as title).\n# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\nheatmap = sns.heatmap(df_copy.corr(), vmin=-1, vmax=1, annot=True)\n# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"]}, {"cell_type": "markdown", "id": "9aa087eb", "metadata": {}, "source": ["From the correlation matrix, we can see that there is not much effect of the features on the risk_flag"]}, {"cell_type": "markdown", "id": "c16d4276", "metadata": {}, "source": ["## Splitting the dataset into train and test set"]}, {"cell_type": "code", "execution_count": 1, "id": "850a4559", "metadata": {}, "outputs": [], "source": ["X_train , X_test , y_train , y_test = train_test_split(df_copy.drop(\"Risk_Flag\", axis=1) , df_copy[\"Risk_Flag\"] , train_size = 0.8, random_state=42)"]}, {"cell_type": "code", "execution_count": 1, "id": "da59ff80", "metadata": {}, "outputs": [], "source": ["X_train.shape, y_train.shape"]}, {"cell_type": "markdown", "id": "7233d5c5", "metadata": {}, "source": ["# Fitting the Classification models on the train dataset "]}, {"cell_type": "markdown", "id": "ee1e1459", "metadata": {}, "source": ["### Using Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "54533136", "metadata": {}, "outputs": [], "source": ["%%time\nlogistic_model = LogisticRegression()\nlogistic_model.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "8fc469aa", "metadata": {}, "outputs": [], "source": ["def evaluation_metrics(y_test,X_test, model):\n    pred = model.predict(X_test)\n    acc_score = accuracy_score(y_test, pred)\n    roc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n    score = f1_score(y_test,pred)\n    cm = confusion_matrix(y_test, pred)\n    \n    \n    print(\"Accuracy Score of the classification model is:\", acc_score)\n    print(\"ROC_AUC Score of the classification model is:\", roc_score)\n    print(\"F1 Score of the classification model is:\", score)\n    plt.figure(figsize=(9,9))\n    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n    plt.ylabel('Actual label');\n    plt.xlabel('Predicted label');\n    all_sample_title = 'Accuracy Score: {0}'.format(acc_score)\n    plt.title(all_sample_title, size = 15);\n    "]}, {"cell_type": "code", "execution_count": 1, "id": "3bebbf83", "metadata": {}, "outputs": [], "source": ["evaluation_metrics(y_test, X_test, logistic_model)"]}, {"cell_type": "markdown", "id": "c11e4280", "metadata": {}, "source": ["### Using Random Forest Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "3c4c226d", "metadata": {}, "outputs": [], "source": ["%%time\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "4424f562", "metadata": {}, "outputs": [], "source": ["evaluation_metrics(y_test, X_test, rfc)"]}, {"cell_type": "markdown", "id": "9f09bbab", "metadata": {}, "source": ["### Using Decision Tree Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "df2b6115", "metadata": {}, "outputs": [], "source": ["%%time\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "93323792", "metadata": {}, "outputs": [], "source": ["evaluation_metrics(y_test, X_test, dtc)"]}, {"cell_type": "markdown", "id": "b8066857", "metadata": {}, "source": ["### Using Bagging Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "589f3bfa", "metadata": {}, "outputs": [], "source": ["%%time\nbgc = BaggingClassifier()\nbgc.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "1b1dc4e3", "metadata": {}, "outputs": [], "source": ["evaluation_metrics(y_test, X_test, bgc)"]}, {"cell_type": "markdown", "id": "262c5583", "metadata": {}, "source": ["### Using Voting Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "1c6cd17e", "metadata": {}, "outputs": [], "source": ["vc = VotingClassifier(estimators=[('bagging classifier', bgc), ('random forest', rfc), ('decision tree classifier', dtc)],voting='soft')\nvc.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "76773024", "metadata": {}, "outputs": [], "source": ["evaluation_metrics(y_test, X_test, vc)"]}, {"cell_type": "markdown", "id": "4fae88eb", "metadata": {}, "source": ["## Checking Features Importance for this task"]}, {"cell_type": "code", "execution_count": 1, "id": "ff4fa59e", "metadata": {}, "outputs": [], "source": ["rfc.feature_importances_"]}, {"cell_type": "code", "execution_count": 1, "id": "9d5da072", "metadata": {}, "outputs": [], "source": ["def plot_features(columns, importances, n=8):\n    df = pd.DataFrame({\"features\": columns,\n                          \"features_importances\": importances}).sort_values(\"features_importances\", ascending=False).reset_index(drop=True)\n\n    #Plot the DataFRame\\n\",\n    fig, ax = plt.subplots()\n    ax.barh(df[\"features\"][:n], df[\"features_importances\"][:n])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature Importance\")\n    ax.invert_yaxis()"]}, {"cell_type": "code", "execution_count": 1, "id": "c1899699", "metadata": {}, "outputs": [], "source": ["plot_features(X_train.columns,rfc.feature_importances_)"]}, {"cell_type": "markdown", "id": "fe9c800e", "metadata": {}, "source": ["## Saving Machine Learning Model"]}, {"cell_type": "code", "execution_count": 1, "id": "2c7754fa", "metadata": {}, "outputs": [], "source": ["filename = 'Random_Forest_Classifier.sav'\npickle.dump(rfc, open(filename, 'wb'))"]}, {"cell_type": "code", "execution_count": 1, "id": "72fc5808", "metadata": {}, "outputs": [], "source": ["# load the model from disk\nloaded_model = pickle.load(open(filename, 'rb'))\nresult = loaded_model.score(X_test, y_test)\nprint(result)"]}, {"cell_type": "markdown", "id": "8ea3d6fd", "metadata": {}, "source": ["# Make Predictions on Test Dataset\nI am going to use Random Forest Classifier as it gives the best f1 and accuracy score"]}, {"cell_type": "code", "execution_count": 1, "id": "c8abe37f", "metadata": {}, "outputs": [], "source": ["# Import the test data\ntest_df = pd.read_csv(\"../input/loan-prediction-based-on-customer-behavior/Test Data.csv\")\n\ntest_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "36137833", "metadata": {}, "outputs": [], "source": ["def preprocess_data(df):\n    \"\"\"\n    Perform data preprocessing for model prediction\n    \"\"\"\n    \n    df = df.drop([\"ID\",\"Profession\", \"CITY\", \"STATE\"], axis=1)\n    \n    ##Fill the categorical datab missing data and turned categories into numbers\n    for labels, content in df.items():\n        if not pd.api.types.is_numeric_dtype(content):\n            df[labels] = pd.Categorical(content).codes + 1\n            \n        \n    return df"]}, {"cell_type": "code", "execution_count": 1, "id": "4724e73c", "metadata": {}, "outputs": [], "source": ["processed_test_df = preprocess_data(test_df)\nprocessed_test_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "a3ffc209", "metadata": {}, "outputs": [], "source": ["test_preds = rfc.predict(processed_test_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "6e93bc2f", "metadata": {}, "outputs": [], "source": ["df_preds = pd.DataFrame()\ndf_preds[\"id\"] = test_df[\"ID\"]\ndf_preds[\"risk_flag\"] = test_preds\n\ndf_preds"]}, {"cell_type": "code", "execution_count": 1, "id": "f047b869", "metadata": {}, "outputs": [], "source": ["df_preds.risk_flag.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "c9c549f1", "metadata": {}, "outputs": [], "source": ["#Export predictions data\ndf_preds.to_csv(\"Submission.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}