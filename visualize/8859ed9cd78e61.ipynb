{"cells": [{"cell_type": "code", "execution_count": 1, "id": "5bb96824", "metadata": {}, "outputs": [], "source": ["from tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n%matplotlib inline"]}, {"cell_type": "markdown", "id": "8378d095", "metadata": {}, "source": ["## Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "94d85bae", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('../input/beijing-pm25-data-data-set/PRSA_data_2010.1.1-2014.12.31.csv')\ndf"]}, {"cell_type": "code", "execution_count": 1, "id": "4cbc51a2", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "96dca315", "metadata": {}, "outputs": [], "source": ["df['pm2.5'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "c008aafc", "metadata": {}, "outputs": [], "source": ["# drop the rows directly -> mess up the order\n# first 24 rows have pm2.5 value that is NaN -> discard\n# else: forward filling\ndf = df[24:].fillna(method='ffill')\ndf['pm2.5'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "c87fb5af", "metadata": {}, "outputs": [], "source": ["import datetime\n\ndf['time'] = df.apply(lambda x : datetime.datetime(year=x['year'], month=x['month'], day=x['day'], hour=x['hour']), axis=1)\ndf.drop(columns=['year', 'month', 'day', 'hour', 'No'], inplace=True)\ndf = df.set_index('time')\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "af842f43", "metadata": {}, "outputs": [], "source": ["df['cbwd'].unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "1b545418", "metadata": {}, "outputs": [], "source": ["df = df.join(pd.get_dummies(df['cbwd'])) # one-hot encoding\ndel df['cbwd']\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "6bde08f4", "metadata": {}, "outputs": [], "source": ["df['pm2.5'][-1000:].plot()"]}, {"cell_type": "code", "execution_count": 1, "id": "81d8f48e", "metadata": {}, "outputs": [], "source": ["df['TEMP'][-1000:].plot()"]}, {"cell_type": "markdown", "id": "17ff57bb", "metadata": {}, "source": ["## Determine Parameters"]}, {"cell_type": "code", "execution_count": 1, "id": "a40cbd61", "metadata": {}, "outputs": [], "source": ["seq_len = 5*24 # observe the data for the past 5 days\ndelay = 1*24 # predict the PM2.5 value one day after\n\ndf_ = np.array([df.iloc[i : i + seq_len + delay].values for i in range(len(df) - seq_len - delay)])\ndf_.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "da0a00d9", "metadata": {}, "outputs": [], "source": ["np.random.shuffle(df_)\nx = df_[:, :5*24, :]\ny = df_[:, -1, 0]\nx.shape, y.shape"]}, {"cell_type": "markdown", "id": "4f56e7ac", "metadata": {}, "source": ["## Split & Normalize the Data"]}, {"cell_type": "code", "execution_count": 1, "id": "9c4b954b", "metadata": {}, "outputs": [], "source": ["split = int(y.shape[0]*0.8)\ntrain_x = x[:split]\ntrain_y = y[:split]\ntest_x = x[split:]\ntest_y = y[split:]\n\nmean = train_x.mean(axis=0)\nstd = train_x.std(axis=0)\ntrain_x = (train_x - mean) / std\ntest_x = (test_x - mean) / std # Use the mean & std of train. Since there's no way for us to know the future."]}, {"cell_type": "code", "execution_count": 1, "id": "0d2c2d5a", "metadata": {}, "outputs": [], "source": ["train_x.shape, test_x.shape"]}, {"cell_type": "markdown", "id": "2640a2ed", "metadata": {}, "source": ["## Start by Trying a Simple Model"]}, {"cell_type": "code", "execution_count": 1, "id": "85fd91f9", "metadata": {}, "outputs": [], "source": ["model = keras.Sequential()\nmodel.add(layers.Flatten(input_shape=(120, 11)))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(1)) # Regression -> No Need for Activation\n\nmodel.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "5f6bc167", "metadata": {}, "outputs": [], "source": ["model.compile(optimizer='adam', loss='mse', metrics=['mae'])\nhistory = model.fit(train_x, train_y, batch_size=128, epochs=50, validation_data=(test_x, test_y))"]}, {"cell_type": "code", "execution_count": 1, "id": "81e380ac", "metadata": {}, "outputs": [], "source": ["plt.plot(history.epoch, history.history['mae'], c='m')\nplt.plot(history.epoch, history.history['val_mae'], c='c')"]}, {"cell_type": "markdown", "id": "ea8ed315", "metadata": {}, "source": ["## Build LSTM Model (Single-Layer)\n\n(34924, 120, 11) -> (batch, time for observation, features per observation)"]}, {"cell_type": "code", "execution_count": 1, "id": "4b102efb", "metadata": {}, "outputs": [], "source": ["model = keras.Sequential()\nmodel.add(layers.LSTM(32, input_shape=(120, 11)))\nmodel.add(layers.Dense(1))\nmodel.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "84ff22ea", "metadata": {}, "outputs": [], "source": ["model.compile(optimizer='adam', loss='mae')\nhistory = model.fit(train_x, train_y, batch_size=128, epochs=150, validation_data=(test_x, test_y))"]}, {"cell_type": "code", "execution_count": 1, "id": "54550791", "metadata": {}, "outputs": [], "source": ["plt.plot(history.epoch, history.history['loss'], c='m')\nplt.plot(history.epoch, history.history['val_loss'], c='c')"]}, {"cell_type": "markdown", "id": "3a4e9249", "metadata": {}, "source": ["## Build LSTM Model (Multi-Layer)\nReturn the state info to feed back to the second LSTM layer\n\nUse callbacks to decrease learning rate"]}, {"cell_type": "code", "execution_count": 1, "id": "b1226d8f", "metadata": {}, "outputs": [], "source": ["model = keras.Sequential()\nmodel.add(layers.LSTM(32, input_shape=(120, 11), return_sequences=True)) \nmodel.add(layers.LSTM(32, return_sequences=True)) \nmodel.add(layers.LSTM(32)) \nmodel.add(layers.Dense(1))\nmodel.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "d96320bf", "metadata": {}, "outputs": [], "source": ["lr_reduced = keras.callbacks.ReduceLROnPlateau('val_loss', patience=3, factor=0.5, min_lr=0.00001)"]}, {"cell_type": "code", "execution_count": 1, "id": "0cff9285", "metadata": {}, "outputs": [], "source": ["model.compile(optimizer='adam', loss='mae')\nhistory = model.fit(train_x, train_y, batch_size=128, epochs=150, validation_data=(test_x, test_y), callbacks=[lr_reduced])"]}, {"cell_type": "code", "execution_count": 1, "id": "5da46773", "metadata": {}, "outputs": [], "source": ["plt.plot(history.epoch, history.history['loss'], c='m')\nplt.plot(history.epoch, history.history['val_loss'], c='c')"]}, {"cell_type": "markdown", "id": "d6f448a1", "metadata": {}, "source": ["## Evaluation & Prediction"]}, {"cell_type": "code", "execution_count": 1, "id": "980c7833", "metadata": {}, "outputs": [], "source": ["model.evaluate(test_x, test_y, verbose=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "412e5c9c", "metadata": {}, "outputs": [], "source": ["test_predict = model.predict(test_x)\ntest_x.shape, test_predict.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "b83e1152", "metadata": {}, "outputs": [], "source": ["test_predict[:5]"]}, {"cell_type": "code", "execution_count": 1, "id": "c6f39f24", "metadata": {}, "outputs": [], "source": ["test_data = df[-120:]\ntest_data = (test_data - mean)/std\ntest_data"]}, {"cell_type": "code", "execution_count": 1, "id": "4e1a5fe6", "metadata": {}, "outputs": [], "source": ["test_data = np.expand_dims(test_data, axis=0)\ntest_data.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "218ce690", "metadata": {}, "outputs": [], "source": ["model.predict(test_data) # 2015.1.1 11pm pM2.5"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}