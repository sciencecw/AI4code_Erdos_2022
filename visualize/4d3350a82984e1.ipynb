{"cells": [{"cell_type": "markdown", "id": "8428964a", "metadata": {}, "source": ["## House sales predict"]}, {"cell_type": "markdown", "id": "44a40b04", "metadata": {}, "source": ["Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home."]}, {"cell_type": "markdown", "id": "fb44cb2f", "metadata": {}, "source": ["### We will make a work plan"]}, {"cell_type": "markdown", "id": "b3d9e895", "metadata": {}, "source": ["* #### Analysis the target\n* #### Filling missing values \n* #### Feature Engineering\n* #### Converting categorical to numerical\n* #### Modeling and predicting\n\n"]}, {"cell_type": "markdown", "id": "63fcb924", "metadata": {}, "source": ["#### Import required libraries "]}, {"cell_type": "code", "execution_count": 1, "id": "cddb5e8b", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\n\n%matplotlib inline\nplt.style.use('seaborn-darkgrid')\npalette = plt.get_cmap('Set2')"]}, {"cell_type": "markdown", "id": "ae47c651", "metadata": {}, "source": ["#### Read train and test datasets"]}, {"cell_type": "code", "execution_count": 1, "id": "8c4ea09a", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')"]}, {"cell_type": "markdown", "id": "1015501a", "metadata": {}, "source": ["#### Display first 10 rows from train and test datasets"]}, {"cell_type": "code", "execution_count": 1, "id": "1f2976a9", "metadata": {}, "outputs": [], "source": ["train.head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "97cc3ac5", "metadata": {}, "outputs": [], "source": ["test.head(10)"]}, {"cell_type": "markdown", "id": "b14d964d", "metadata": {}, "source": ["#### Display information on values in columns"]}, {"cell_type": "code", "execution_count": 1, "id": "01ff1e1c", "metadata": {}, "outputs": [], "source": ["train.info()"]}, {"cell_type": "markdown", "id": "64d4bf41", "metadata": {}, "source": ["#### display a graph of missing values"]}, {"cell_type": "markdown", "id": "08e1ca93", "metadata": {}, "source": ["##### first group"]}, {"cell_type": "code", "execution_count": 1, "id": "47bae41a", "metadata": {}, "outputs": [], "source": ["msno.bar(train.iloc[:, :40])"]}, {"cell_type": "code", "execution_count": 1, "id": "b434cf67", "metadata": {}, "outputs": [], "source": ["msno.bar(train.iloc[:, 40:])"]}, {"cell_type": "markdown", "id": "c3a86668", "metadata": {}, "source": ["#### As we can see there are a lot of missing values in some columns, not missing values do not exceed the mark of 30. We'll fix it after a while!"]}, {"cell_type": "markdown", "id": "3927bbb2", "metadata": {}, "source": ["#### Display the description of the values in the columns"]}, {"cell_type": "code", "execution_count": 1, "id": "40062a42", "metadata": {}, "outputs": [], "source": ["train.iloc[:, :40].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "79a82cf7", "metadata": {}, "outputs": [], "source": ["train.iloc[:, 40:-1].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "02fe343b", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(train['SalePrice'].describe())"]}, {"cell_type": "code", "execution_count": 1, "id": "e9d0e4dc", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 7))\n\nsns.distplot(train['SalePrice']).set(ylabel=None, xlabel=None)\nplt.title('House price distribution histogram', fontsize=18)\nplt.show()"]}, {"cell_type": "markdown", "id": "858a759d", "metadata": {}, "source": ["#### As we can see, we have a positive skew, we must fix it."]}, {"cell_type": "code", "execution_count": 1, "id": "51e2d0a8", "metadata": {}, "outputs": [], "source": ["train['SalePrice'] = np.log1p(train['SalePrice'])"]}, {"cell_type": "code", "execution_count": 1, "id": "188e3fe0", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 7))\n\nsns.distplot(train['SalePrice'])\nplt.title('House price distribution histogram after fix', fontsize=18)\nplt.show()"]}, {"cell_type": "markdown", "id": "4e548009", "metadata": {}, "source": ["#### its ok now"]}, {"cell_type": "markdown", "id": "bc65dcd8", "metadata": {}, "source": ["#### Let's build a Pearson correlation matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "523d7967", "metadata": {}, "outputs": [], "source": ["corr_train = train.corr()\n\ncolormap = plt.cm.RdBu\n\nplt.figure(figsize=(14,12))\nplt.title('Pearson correlation matrix between features', y=1, size=15)\nsns.heatmap(corr_train, vmax=.8, square=True, cmap=colormap)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "87e11159", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "id": "00bcfe01", "metadata": {}, "source": ["#### We see the relationship (correlation) between the features, but let's see the correlation between the \"Price of houses\" and features"]}, {"cell_type": "code", "execution_count": 1, "id": "ea353f44", "metadata": {}, "outputs": [], "source": ["highest_corr_features = corr_train.index[\n    abs(corr_train['SalePrice']) > 0.5\n    ]\n\nplt.figure(figsize=(14,12))\nplt.title('Pearson correlation matrix between features and \"SalePrice\"', y=1, size=15)\nsns.heatmap(train[highest_corr_features].corr(), linewidths=0.1, vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()"]}, {"cell_type": "markdown", "id": "545a9dd5", "metadata": {}, "source": ["### Let's celebrate"]}, {"cell_type": "markdown", "id": "f8cc93e7", "metadata": {}, "source": ["* #### Saleprice is highly correlated with OverallQual\n* #### GarageArea logically has a great relationship with GarageCars\n* #### Have the smallest connection YearBuilt and TotRmsAbvGrd\n* #### Also highly correlated 1stFirSF and TotalBsmtSF\n* #### TotRmsAbvGrd is highly correlated with GrLivArea"]}, {"cell_type": "code", "execution_count": 1, "id": "d4090dcf", "metadata": {}, "outputs": [], "source": ["SalePrice = pd.DataFrame(corr_train['SalePrice'].sort_values(ascending=False))\nSalePrice"]}, {"cell_type": "markdown", "id": "66dfc0c3", "metadata": {}, "source": ["#### Let's take only strongly related features"]}, {"cell_type": "code", "execution_count": 1, "id": "9b62975d", "metadata": {}, "outputs": [], "source": ["features = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n\nsns.pairplot(train[features])\nplt.show()"]}, {"cell_type": "markdown", "id": "236e16a1", "metadata": {}, "source": ["### Good job! Now we know important features"]}, {"cell_type": "markdown", "id": "9526ae14", "metadata": {}, "source": ["### Let's find and fill in the missing data"]}, {"cell_type": "markdown", "id": "8b08f2b3", "metadata": {}, "source": ["#### Let's combine training and test datasets for convenience"]}, {"cell_type": "code", "execution_count": 1, "id": "72c2ee15", "metadata": {}, "outputs": [], "source": ["y_train = train['SalePrice']\ntest_id = test['Id']\ndata = pd.concat([train, test], axis=0, sort=False)\ndata = data.drop(['Id', 'SalePrice'], axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "f916d2c9", "metadata": {}, "outputs": [], "source": ["Total = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum() / data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([Total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)"]}, {"cell_type": "markdown", "id": "570e3904", "metadata": {}, "source": ["#### We can safely remove these features as they are not important and do not have a high correlation."]}, {"cell_type": "code", "execution_count": 1, "id": "f45ff584", "metadata": {}, "outputs": [], "source": ["data.drop((missing_data[missing_data['Total'] > 5]).index, axis=1, inplace=True)\nprint(data.isnull().sum().max())"]}, {"cell_type": "code", "execution_count": 1, "id": "750f9510", "metadata": {}, "outputs": [], "source": ["# numeric data\nnumeric_missed = ['BsmtFinSF1',\n                  'BsmtFinSF2',\n                  'BsmtUnfSF',\n                  'TotalBsmtSF',\n                  'BsmtFullBath',\n                  'BsmtHalfBath',\n                  'GarageArea',\n                  'GarageCars']\n\nfor feature in numeric_missed:\n    data[feature].fillna(0, inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "cb1c7c56", "metadata": {}, "outputs": [], "source": ["# categorical data\ncategorical_missed = ['Exterior1st',\n                  'Exterior2nd',\n                  'SaleType',\n                  'MSZoning',\n                   'Electrical',\n                     'KitchenQual']\n\nfor feature in categorical_missed:\n    data[feature].fillna(data[feature].mode()[0], inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "0a80956d", "metadata": {}, "outputs": [], "source": ["data['Functional'].fillna('Typ', inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "31b9158d", "metadata": {}, "outputs": [], "source": ["data.isnull().sum().max() "]}, {"cell_type": "markdown", "id": "e7417729", "metadata": {}, "source": ["#### Almost done! That is enough"]}, {"cell_type": "markdown", "id": "f90910e9", "metadata": {}, "source": ["### Feature Engineering"]}, {"cell_type": "markdown", "id": "c5bf6ef6", "metadata": {}, "source": ["#### Fix The Skewness in the other features"]}, {"cell_type": "code", "execution_count": 1, "id": "0d71798f", "metadata": {}, "outputs": [], "source": ["from scipy.stats import skew\nfrom sklearn.decomposition import PCA"]}, {"cell_type": "code", "execution_count": 1, "id": "2a16a69d", "metadata": {}, "outputs": [], "source": ["numeric = data.dtypes[data.dtypes != 'object'].index\nskewed = data[numeric].apply(lambda col: skew(col)).sort_values(ascending=False)\nskewed = skewed[abs(skewed) > 0.5]\n\nfor feature in skewed.index:\n    data[feature] = np.log1p(data[feature])"]}, {"cell_type": "code", "execution_count": 1, "id": "75a4c7d5", "metadata": {}, "outputs": [], "source": ["data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']"]}, {"cell_type": "markdown", "id": "76cb132f", "metadata": {}, "source": ["### Converting the categorical to numerical."]}, {"cell_type": "markdown", "id": "67af043c", "metadata": {}, "source": ["#### The simplest is to use the function pd.get_dummies()"]}, {"cell_type": "code", "execution_count": 1, "id": "de7d0c4e", "metadata": {}, "outputs": [], "source": ["data = pd.get_dummies(data)\ndata"]}, {"cell_type": "code", "execution_count": 1, "id": "6f5bbc00", "metadata": {}, "outputs": [], "source": ["x_train = data[:len(y_train)]\nx_test = data[len(y_train):]"]}, {"cell_type": "code", "execution_count": 1, "id": "6a202f29", "metadata": {}, "outputs": [], "source": ["x_valid = x_train[:1168]\ny_valid = y_train[:1168]"]}, {"cell_type": "markdown", "id": "52e1426b", "metadata": {}, "source": ["### We cleaned the data very well, good job!"]}, {"cell_type": "markdown", "id": "acfad56d", "metadata": {}, "source": ["### Modeling and predicting"]}, {"cell_type": "code", "execution_count": 1, "id": "4c531da7", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import make_scorer\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf"]}, {"cell_type": "code", "execution_count": 1, "id": "5650e167", "metadata": {}, "outputs": [], "source": ["!pip install xgboost"]}, {"cell_type": "code", "execution_count": 1, "id": "dd3fbd52", "metadata": {}, "outputs": [], "source": ["x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "241e6d58", "metadata": {}, "outputs": [], "source": ["model = tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Flatten(input_shape=(221,)))\nmodel.add(tf.keras.layers.Dense(512, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\nloss = tf.keras.losses.BinaryCrossentropy()\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\nmodel.compile(optimizer=optimizer,\n              loss=loss,\n              metrics=['mse'])\n\nhistory = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=150, batch_size=128)"]}, {"cell_type": "code", "execution_count": 1, "id": "4e68f6ca", "metadata": {}, "outputs": [], "source": ["y_predict = np.floor(np.expm1(model.predict(x_test)))\n\nsub = pd.DataFrame()\nsub['Id'] = test_id\nsub['SalePrice'] = y_predict\nsub.to_csv('submission.csv',index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}