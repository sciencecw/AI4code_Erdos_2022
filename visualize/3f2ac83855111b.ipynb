{"cells": [{"cell_type": "markdown", "id": "341c83b5", "metadata": {}, "source": ["<img src=\"https://images.livemint.com/img/2019/09/10/600x338/BSE_1568133535025.jpg\">\n<h1><center>Bombay Stock Exchange </center></h1>\n<h2><center>EDA and Preprocessing</center></h2>\n\n\n# Introduction\n\n\nThe Bombay Stock Exchange (BSE) is the first and largest securities market in India and was established in 1875 as the Native Share and Stock Brokers' Association. Based in Mumbai, India, the BSE lists close to 6,000 companies and is one of the largest exchanges in the world, along with the New York Stock Exchange (NYSE), Nasdaq, London Stock Exchange Group, Japan Exchange Group, and Shanghai Stock Exchange.\n\n### Dataset \nThis dataset contains historical prices of various stocks from Bombay Stock Exchange with 15 minute interval.\n\n\n#### For this notebook only SIEMENS's stock data is used."]}, {"cell_type": "markdown", "id": "4288b692", "metadata": {}, "source": ["#### Libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "02178405", "metadata": {}, "outputs": [], "source": ["import plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport seaborn as sns\nimport plotly.figure_factory as ff\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dropout,Dense\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "4f9bd9f7", "metadata": {}, "outputs": [], "source": ["df = pd.read_pickle('/kaggle/input/bse-stocks-data-15-minute-interval-historical/SIEMENS-15minute-Hist')\ndf = pd.DataFrame(df)\ndf['date'] = df['date'].apply(pd.to_datetime)\ndf.set_index('date',inplace=True)\n"]}, {"cell_type": "markdown", "id": "9dbfbe4a", "metadata": {}, "source": ["## Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "10f7598b", "metadata": {}, "outputs": [], "source": ["fig = go.Figure(data=[go.Table(\n    header=dict(values=list(['date','open','high','low','close','volume']),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[df.index,df.open, df.high, df.low, df.close,df.volume],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()"]}, {"cell_type": "markdown", "id": "19337016", "metadata": {}, "source": ["### So basically this dataset contains 6 different features i.e. date, open, high, low, close, volume\n\n### Date - This contains date + time at the instant of trade\n \n### Open - Open is the price when the stock began\n \n### High - Maximum price at the given time period\n \n### Low - Minimum price at the given time period\n \n### Close - Price at which stock ended\n \n### Volume - It is the total amount of trading activity\n\n### Incase of our data the time period is 15 minutes"]}, {"cell_type": "code", "execution_count": 1, "id": "6ef86d70", "metadata": {}, "outputs": [], "source": ["from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom plotly.graph_objs import Line\n\nfig = make_subplots(rows=4, cols=1,subplot_titles=('Open','High','Low','Close'))\n\nfig.add_trace(\n    Line(x=df.index, y=df.open),\n    row=1, col=1\n)\n\nfig.add_trace(\n    Line(x=df.index, y=df.high),\n    row=2, col=1\n)\n\nfig.add_trace(\n    Line(x=df.index, y=df.low),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Line(x=df.index, y=df.close),\n    row=4, col=1\n)\n\nfig.update_layout(height=1400, width=1000, title_text=\"OHLC Line Plots\")\n\nfig.show()\n"]}, {"cell_type": "markdown", "id": "1e966b68", "metadata": {}, "source": ["## Visualizing Patterns in the Data"]}, {"cell_type": "code", "execution_count": 1, "id": "03456633", "metadata": {}, "outputs": [], "source": ["#only first 5000 values are taken because it was looking very crowded\nresult = seasonal_decompose(df.close.head(5000), model='additive', period = 30)\nfig = go.Figure()  \nfig = result.plot()  \nfig.set_size_inches(20, 19)"]}, {"cell_type": "markdown", "id": "bbd6f513", "metadata": {}, "source": ["## Candlestick\n\n* Candlestick charts are used by traders to determine possible price movement based on past patterns.\n\n* Candlesticks are useful when trading as they show four price points (open, close, high, and low) throughout the period of time the trader specifies.\n\n* Many algorithms are based on the same price information shown in candlestick charts.\n\n* Trading is often dictated by emotion, which can be read in candlestick charts.\n\n<img src=\"https://alpari.com/storage/inline-images/Forex%20candlestick%20patterns%20and%20how%20to%20use%20them%20-%201_0.png\">\n"]}, {"cell_type": "markdown", "id": "ffe19f12", "metadata": {}, "source": ["## Sample Candlesticks\n\n#### We can see 5 different types of candlesticks below."]}, {"cell_type": "code", "execution_count": 1, "id": "716edd8a", "metadata": {}, "outputs": [], "source": ["open_data = [33.0, 33.3, 33.5, 33.0, 34.1]\nhigh_data = [33.1, 33.3, 33.6, 33.2, 34.8]\nlow_data = [32.7, 32.7, 32.8, 32.6, 32.8]\nclose_data = [33.0, 32.9, 33.3, 33.1, 33.1]\ndates = [datetime(year=2013, month=10, day=10),\n         datetime(year=2013, month=11, day=10),\n         datetime(year=2013, month=12, day=10),\n         datetime(year=2014, month=1, day=10),\n         datetime(year=2014, month=2, day=10)]\n\nfig = go.Figure(data=[go.Candlestick(x=dates,\n                       open=open_data, high=high_data,\n                       low=low_data, close=close_data,\n               increasing_line_color= 'green', decreasing_line_color= 'red')])\n\nfig.show()"]}, {"cell_type": "markdown", "id": "b96eb9ad", "metadata": {}, "source": ["# Candlestick chart for Siemens"]}, {"cell_type": "code", "execution_count": 1, "id": "83bd53ff", "metadata": {}, "outputs": [], "source": ["import plotly.graph_objects as go\n\nimport pandas as pd\nfrom datetime import datetime\n\n\nfig = go.Figure(data=[go.Candlestick(x=df.index,\n                open=df['open'],\n                high=df['high'],\n                low=df['low'],\n                close=df['close'])])\n\nfig.show()"]}, {"cell_type": "markdown", "id": "803da152", "metadata": {}, "source": ["# Creating Train Test Data"]}, {"cell_type": "code", "execution_count": 1, "id": "2a8c8c66", "metadata": {}, "outputs": [], "source": ["new_df = pd.DataFrame()\nnew_df = df['close']\nnew_df.index = df.index"]}, {"cell_type": "code", "execution_count": 1, "id": "31b81cbb", "metadata": {}, "outputs": [], "source": ["scaler=MinMaxScaler(feature_range=(0,1))\nfinal_dataset=new_df.values\n\ntrain_data=final_dataset[0:20000,]\nvalid_data=final_dataset[20000:,]\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "cfe64a17", "metadata": {}, "outputs": [], "source": ["train_df = pd.DataFrame()\nvalid_df = pd.DataFrame()\ntrain_df['Close'] = train_data\ntrain_df.index = new_df[0:20000].index\nvalid_df['Close'] = valid_data\nvalid_df.index = new_df[20000:].index\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e7f789b0", "metadata": {}, "outputs": [], "source": ["scaler=MinMaxScaler(feature_range=(0,1))\nscaled_data=scaler.fit_transform(final_dataset.reshape(-1,1))\n\nx_train_data,y_train_data=[],[]\n\nfor i in range(60,len(train_data)):\n    x_train_data.append(scaled_data[i-60:i,0])\n    y_train_data.append(scaled_data[i,0])\n    \nx_train_data,y_train_data=np.array(x_train_data),np.array(y_train_data)\n\nx_train_data=np.reshape(x_train_data,(x_train_data.shape[0],x_train_data.shape[1],1))"]}, {"cell_type": "markdown", "id": "e7ffc874", "metadata": {}, "source": ["# Long Short Term Memory Networks(LSTM)\n\nDo you think about everything from scratch. No. You perform the actions based on your past memory. For example if you are reading a newspaper, you understand words because in your past you have read them and they are stored in your memory. If you encounter a new word then it gets stored in your memory newly. So the question is Do you want your model to process everything from scratch? Or you want to make it more intelligent by creating a memory space. Thats when LSTM comes into the game. LSTM which is long short term memory is the type of RNN which can hold memory for longer period of time. They are a good fit for time series preditiction, or forecasting problems.\n\n<img src=\"https://miro.medium.com/max/3000/1*laH0_xXEkFE0lKJu54gkFQ.png\">\n\nImage Taken From [Here](https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714)"]}, {"cell_type": "code", "execution_count": 1, "id": "ab0e7a56", "metadata": {}, "outputs": [], "source": ["lstm_model=Sequential()\nlstm_model.add(LSTM(units=50,return_sequences=True,input_shape=(x_train_data.shape[1],1)))\nlstm_model.add(LSTM(units=50))\nlstm_model.add(Dense(1))\n\ninputs_data=new_df[len(new_df)-len(valid_data)-60:].values\ninputs_data=inputs_data.reshape(-1,1)\ninputs_data=scaler.transform(inputs_data)\n\nlstm_model.compile(loss='mean_squared_error',optimizer='adam')\nlstm_model.fit(x_train_data,y_train_data,epochs=1,batch_size=1,verbose=2)\n\nlstm_model.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "917166bc", "metadata": {}, "outputs": [], "source": ["X_test=[]\nfor i in range(60,inputs_data.shape[0]):\n    X_test.append(inputs_data[i-60:i,0])\nX_test=np.array(X_test)\n\nX_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\npredicted_closing_price=lstm_model.predict(X_test)\npredicted_closing_price=scaler.inverse_transform(predicted_closing_price)"]}, {"cell_type": "code", "execution_count": 1, "id": "ddfbbda9", "metadata": {}, "outputs": [], "source": ["valid_df['Predictions']=predicted_closing_price"]}, {"cell_type": "markdown", "id": "afe03da4", "metadata": {}, "source": ["# Predictions"]}, {"cell_type": "code", "execution_count": 1, "id": "e56d3bfa", "metadata": {}, "outputs": [], "source": ["fig = go.Figure()\nfig.add_trace(go.Scatter(x=train_df.index,y=train_df['Close'],\n                    mode='lines',\n                    name='Siemens Train Data'))\nfig.add_trace(go.Scatter(x=valid_df.index,y=valid_df['Close'],\n                    mode='lines',\n                    name='Siemens Valid Data'))\nfig.add_trace(go.Scatter(x=valid_df.index,y=valid_df['Predictions'],\n                    mode='lines',\n                    name='Prediction'))"]}, {"cell_type": "code", "execution_count": 1, "id": "d2e9007e", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import mean_squared_error\nprint('The Mean Squared Error is',mean_squared_error(valid_df['Close'].values,valid_df['Predictions'].values))"]}, {"cell_type": "markdown", "id": "dce894fc", "metadata": {}, "source": ["# Let's have a closer look"]}, {"cell_type": "code", "execution_count": 1, "id": "e2135ca3", "metadata": {}, "outputs": [], "source": ["fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=valid_df.index,y=valid_df['Close'],\n                    mode='lines',\n                    name='Test'))\nfig.add_trace(go.Scatter(x=valid_df.index,y=valid_df['Predictions'],\n                    mode='lines',\n                    name='Predicted'))"]}, {"cell_type": "markdown", "id": "83e6d6b5", "metadata": {}, "source": ["### From this visualization we can conclude that LSTM worked well. It can be improved though!"]}, {"cell_type": "code", "execution_count": 1, "id": "a871fd7e", "metadata": {}, "outputs": [], "source": ["!pip install see_rnn\n"]}, {"cell_type": "code", "execution_count": 1, "id": "750c3e74", "metadata": {}, "outputs": [], "source": ["from see_rnn import *"]}, {"cell_type": "code", "execution_count": 1, "id": "315c35ed", "metadata": {}, "outputs": [], "source": ["grads1 = get_gradients(lstm_model, 1, x_train_data, y_train_data)\ngrads2 = get_gradients(lstm_model,2,x_train_data,y_train_data)\noutput = get_outputs(lstm_model, 1, x_train_data)"]}, {"cell_type": "markdown", "id": "77fc2f58", "metadata": {}, "source": ["# A Visual Exploration of LSTM's\n\n\n## Layer 1 Visualization\nLayer1 plots are as follows\n1. 1D with 10 gradients\n2. 1D with 500 gradients\n3. 2D with 500 gradients\n3. 1D with all gradients"]}, {"cell_type": "code", "execution_count": 1, "id": "2414add6", "metadata": {}, "outputs": [], "source": ["features_1D(grads1[:10] ,n_rows=2)\nfeatures_1D(grads1[:500] ,n_rows=2)\nfeatures_2D(grads1[:500])\nfeatures_1D(grads1 ,n_rows=2)\n"]}, {"cell_type": "markdown", "id": "438bb328", "metadata": {}, "source": ["## Layer2 Visualization\nLayer2 plots are as follows\n1. 1D with 500 gradients\n2. 2D with 500 gradients\n3. 1D with all gradients\n4. 2D with all gradients"]}, {"cell_type": "code", "execution_count": 1, "id": "ae70d01e", "metadata": {}, "outputs": [], "source": ["features_1D(grads2[:500], n_rows=2)\nfeatures_2D(grads2[:500], n_rows=2)\nfeatures_1D(grads2, n_rows=2)"]}, {"cell_type": "markdown", "id": "6580440d", "metadata": {}, "source": ["## Output Layer Visualization"]}, {"cell_type": "code", "execution_count": 1, "id": "b8d0c05f", "metadata": {}, "outputs": [], "source": ["features_1D(output, n_rows=2)\nfeatures_2D(output, n_rows=2)\n"]}, {"cell_type": "markdown", "id": "af7e9ac8", "metadata": {}, "source": ["## LSTM Histograms"]}, {"cell_type": "code", "execution_count": 1, "id": "dc220d63", "metadata": {}, "outputs": [], "source": ["rnn_histogram(lstm_model, 'lstm', equate_axes=False)"]}, {"cell_type": "markdown", "id": "03ac6681", "metadata": {}, "source": ["## HEATMAP"]}, {"cell_type": "code", "execution_count": 1, "id": "47556a12", "metadata": {}, "outputs": [], "source": ["rnn_heatmap(lstm_model, 'lstm')"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}