{"cells": [{"cell_type": "code", "execution_count": 1, "id": "cb00e55c", "metadata": {}, "outputs": [], "source": ["!pip install pretrainedmodels"]}, {"cell_type": "code", "execution_count": 1, "id": "39b52791", "metadata": {}, "outputs": [], "source": ["from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport fastai\nfrom fastai import vision\n\nimport pretrainedmodels as pm"]}, {"cell_type": "code", "execution_count": 1, "id": "f475ad6f", "metadata": {}, "outputs": [], "source": ["%matplotlib inline"]}, {"cell_type": "markdown", "id": "c9fa32f4", "metadata": {}, "source": ["## Create training and validation data\n\nCode in the cell below is used to split the raw training data set in `../input/train/train` into interim training and \nvalidation data sets. The interim training and validation data sets are stored in `./data/interim/train` and \n`./data/interim/valid`, respectively.\n\nThe raw training data set is divided into 80% interim training data and 20% interim validation data using startified \nsampling on the image labels so that the distribution of labels in to raw training data is preserved in the interim \ntraining and validation data sets."]}, {"cell_type": "code", "execution_count": 1, "id": "7ab45a14", "metadata": {}, "outputs": [], "source": ["import glob\nimport os\nimport shutil\nfrom typing import List\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\n\nPREFIX = \"./data\"\nSEED = 42\nTEST_SIZE = 0.2\n\ndef _filepaths_to_dataframe(paths: List[str]) -> pd.DataFrame:\n    \"\"\"Converts filepaths to a Pandas DataFrame.\"\"\"\n    results = {\"label\": [], \"filename\": []}\n    for path in paths:\n        _, _, _, _, _label, _ = path.split('/')\n        results[\"label\"].append(_label)\n        results[\"filename\"].append(path)\n    df = (pd.DataFrame\n            .from_dict(results))\n    return df\n\n\ndef _make_interim_training_data(prefix: str, df: pd.DataFrame) -> None:\n    if not os.path.isdir(f\"{prefix}/interim/train\"):\n        os.makedirs(f\"{prefix}/interim/train\")\n\n    for _, row in df.iterrows():\n        label, path = row\n        filename = (os.path\n                      .basename(path))\n        if not os.path.isdir(f\"{prefix}/interim/train/{label}\"):\n            os.mkdir(f\"{prefix}/interim/train/{label}\")\n        shutil.copy(path, f\"{prefix}/interim/train/{label}/{filename}\")\n\n        \ndef _make_interim_validation_data(prefix: str, df: pd.DataFrame) -> None:\n    if not os.path.isdir(f\"{prefix}/interim/valid\"):\n        os.makedirs(f\"{prefix}/interim/valid\")\n\n    for _, row in df.iterrows():\n        label, path = row\n        filename = (os.path\n                      .basename(path))\n        if not os.path.isdir(f\"{prefix}/interim/valid/{label}\"):\n            os.mkdir(f\"{prefix}/interim/valid/{label}\")\n        shutil.copy(path, f\"{prefix}/interim/valid/{label}/{filename}\")\n\n        \nfilepaths = glob.glob(f\"../input/train/train/*/*.jpg\", recursive=True)\ndf = _filepaths_to_dataframe(filepaths)\nprng = np.random.RandomState(SEED)\n\ntraining_df, validation_df = model_selection.train_test_split(df,\n                                                              test_size=TEST_SIZE,\n                                                              random_state=prng,\n                                                              stratify=df[\"label\"])\n    \nif not os.path.isdir(PREFIX):\n    os.mkdir(PREFIX)\n_make_interim_training_data(PREFIX, training_df)\n_make_interim_validation_data(PREFIX, validation_df)\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "745945b1", "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(15, 8))\n\n_ = (df.loc[:, \"label\"]\n       .value_counts()\n       .plot\n       .bar(ax=axes[0], title=\"Raw\"))\n\n_ = (training_df.loc[:, \"label\"]\n                .value_counts()\n                .plot\n                .bar(ax=axes[1], title=\"Training\"))\n\n_ = (validation_df.loc[:, \"label\"]\n                  .value_counts()\n                  .plot\n                  .bar(ax=axes[2], title=\"Validation\"))"]}, {"cell_type": "code", "execution_count": 1, "id": "a35af084", "metadata": {}, "outputs": [], "source": ["def set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(42)"]}, {"cell_type": "markdown", "id": "b69d978f", "metadata": {}, "source": ["# Creating a `ImageDataBunch`\n\nTo create the training data set we use standard data augmentation techniques. All parameters defining the transformations used for data augmentation are left at their default values (unless otherwise specified)."]}, {"cell_type": "code", "execution_count": 1, "id": "9ad239ad", "metadata": {}, "outputs": [], "source": ["_transform_kwargs = {\"do_flip\": True,\n                     \"flip_vert\": True,  # default is False\n                     \"max_rotate\": 180,  # default is 10\n                     \"max_zoom\": 1.2,    # default is 1.1\n                     \"max_lighting\": 0.2,\n                     \"max_warp\": 0.2,\n                     \"p_affine\": 0.75,\n                     \"p_lighting\": 0.7,\n                    }\n        \n_transforms = vision.get_transforms(**_transform_kwargs)\n\n_data_bunch_kwargs = {\"path\": \"./data/interim\",\n                      \"train\": \"train\",\n                      \"valid\": \"valid\",\n                      \"bs\": 16,\n                      \"size\": 448,\n                      \"ds_tfms\": _transforms,\n                      \"test\": \"../../../input/test/test\",  ## hack to access the test data without copying to ./data\n                     }\n\nimage_data_bunch = (vision.ImageDataBunch\n                          .from_folder(**_data_bunch_kwargs)\n                          .normalize())"]}, {"cell_type": "code", "execution_count": 1, "id": "716ae65e", "metadata": {}, "outputs": [], "source": ["image_data_bunch.train_ds"]}, {"cell_type": "code", "execution_count": 1, "id": "d0719ff2", "metadata": {}, "outputs": [], "source": ["image_data_bunch.valid_ds"]}, {"cell_type": "code", "execution_count": 1, "id": "7a4e144a", "metadata": {}, "outputs": [], "source": ["image_data_bunch.test_ds"]}, {"cell_type": "markdown", "id": "599cf996", "metadata": {}, "source": ["# Exploring the data\n\nAlways important to understand what the images that are being fed into your model actually look like.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b365dcdf", "metadata": {}, "outputs": [], "source": ["image_data_bunch.show_batch(figsize=(20,20))"]}, {"cell_type": "markdown", "id": "4802d031", "metadata": {}, "source": ["# Fitting the model"]}, {"cell_type": "markdown", "id": "541a0ab1", "metadata": {}, "source": ["## Transfer Learning\n\nFor computer vision applications always start by trying transfer learning with a standard architecture: [SE-ResNeXt-101](https://arxiv.org/pdf/1803.09820.pdf)."]}, {"cell_type": "code", "execution_count": 1, "id": "9ffbe6dd", "metadata": {}, "outputs": [], "source": ["_base_arch = lambda arg: pm.se_resnext101_32x4d(num_classes=1000, pretrained=\"imagenet\")\nlearner = vision.cnn_learner(image_data_bunch,\n                             base_arch=_base_arch,\n                             pretrained=True,\n                             metrics=vision.error_rate,\n                             model_dir=\"/kaggle/working/models/se-resnext101-32x4d\")"]}, {"cell_type": "code", "execution_count": 1, "id": "cff6b32d", "metadata": {}, "outputs": [], "source": ["learner.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "43ca1cc7", "metadata": {}, "outputs": [], "source": ["learner.lr_find()"]}, {"cell_type": "code", "execution_count": 1, "id": "9bb900e4", "metadata": {}, "outputs": [], "source": ["(learner.recorder\n        .plot())"]}, {"cell_type": "code", "execution_count": 1, "id": "729e8a1e", "metadata": {}, "outputs": [], "source": ["def find_optimal_lr(recorder):\n    \"\"\"Extract the optimal learning rate from recorder data.\"\"\"\n    optimal_lr = 0\n    minimum_loss = float(\"inf\")\n    for loss, lr in zip(recorder.losses, recorder.lrs):\n        if loss < minimum_loss:\n            optimal_lr = lr\n            minimum_loss = loss\n    return optimal_lr, minimum_loss\n"]}, {"cell_type": "code", "execution_count": 1, "id": "6257a5f0", "metadata": {}, "outputs": [], "source": ["# define a callback that stores state of \"best\" model.\n# N.B. best model is re-loaded when training completes\n_save_model_kwargs = {\"every\": \"improvement\",\n                      \"monitor\": \"valid_loss\",\n                      \"name\": \"best-model-stage-1\"}\n_save_model = (fastai.callbacks\n                     .SaveModelCallback(learner, **_save_model_kwargs))\n\n# if validation loss < training loss either learning rate too low or not enough training epoch\nlearner.fit_one_cycle(15, callbacks=[_save_model])"]}, {"cell_type": "markdown", "id": "95a6b964", "metadata": {}, "source": ["# Exploring the model's predictions"]}, {"cell_type": "code", "execution_count": 1, "id": "366013e2", "metadata": {}, "outputs": [], "source": ["clf_interp = (vision.ClassificationInterpretation\n                    .from_learner(learner))"]}, {"cell_type": "code", "execution_count": 1, "id": "cf3098f3", "metadata": {}, "outputs": [], "source": ["clf_interp.plot_top_losses(16, figsize=(20,20))"]}, {"cell_type": "code", "execution_count": 1, "id": "d2fe2a1b", "metadata": {}, "outputs": [], "source": ["clf_interp.plot_confusion_matrix()"]}, {"cell_type": "code", "execution_count": 1, "id": "446eda36", "metadata": {}, "outputs": [], "source": ["clf_interp.most_confused()"]}, {"cell_type": "markdown", "id": "d62f2d04", "metadata": {}, "source": ["## Unfreezing, fine-tuning, and learning rates"]}, {"cell_type": "code", "execution_count": 1, "id": "e1184496", "metadata": {}, "outputs": [], "source": ["learner.unfreeze()"]}, {"cell_type": "code", "execution_count": 1, "id": "8a988bec", "metadata": {}, "outputs": [], "source": ["learner.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "154ca0b2", "metadata": {}, "outputs": [], "source": ["learner.lr_find()"]}, {"cell_type": "code", "execution_count": 1, "id": "a2824923", "metadata": {}, "outputs": [], "source": ["(learner.recorder\n        .plot())"]}, {"cell_type": "code", "execution_count": 1, "id": "4a6f5a5e", "metadata": {}, "outputs": [], "source": ["_save_model_kwargs = {\"every\": \"improvement\",\n                      \"monitor\": \"valid_loss\",\n                      \"name\": \"best-model-stage-2\"}\n_save_model = (fastai.callbacks\n                     .SaveModelCallback(learner, **_save_model_kwargs))\nlearner.fit_one_cycle(15, max_lr=slice(1e-6, 1e-4), callbacks=[_save_model])"]}, {"cell_type": "markdown", "id": "4f6bb043", "metadata": {}, "source": ["## Exploring results of the fine-tuned model"]}, {"cell_type": "code", "execution_count": 1, "id": "c6eb6157", "metadata": {}, "outputs": [], "source": ["clf_interp = (vision.ClassificationInterpretation\n                    .from_learner(learner))"]}, {"cell_type": "code", "execution_count": 1, "id": "c081da4b", "metadata": {}, "outputs": [], "source": ["clf_interp.plot_confusion_matrix()"]}, {"cell_type": "markdown", "id": "f9bc4396", "metadata": {}, "source": ["## Test-Time Augmentation (TTA)"]}, {"cell_type": "code", "execution_count": 1, "id": "c5cfdbea", "metadata": {}, "outputs": [], "source": ["predicted_class_probabilities, _ = learner.TTA(ds_type=fastai.basic_data.DatasetType.Test)"]}, {"cell_type": "markdown", "id": "713ae911", "metadata": {}, "source": ["## Creating a submission"]}, {"cell_type": "code", "execution_count": 1, "id": "ad60b58b", "metadata": {}, "outputs": [], "source": ["_predicted_classes = (predicted_class_probabilities.argmax(dim=1)\n                                                   .numpy())\n_class_labels = np.array(['cbb','cbsd','cgm','cmd','healthy'])\n_predicted_class_labels = _class_labels[_predicted_classes]\n\n_filenames = np.array([item.name for item in image_data_bunch.test_ds.items])\n\nsubmission = (pd.DataFrame\n                .from_dict({'Category': _predicted_class_labels,'Id': _filenames}))"]}, {"cell_type": "code", "execution_count": 1, "id": "198ca68c", "metadata": {}, "outputs": [], "source": ["submission.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "ef264e11", "metadata": {}, "outputs": [], "source": ["submission.to_csv('submission.csv', header=True, index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "17ca9ded", "metadata": {}, "outputs": [], "source": ["shutil.rmtree(PREFIX)  # necessary not to overwhlem Kaggle with unused output files"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}