{"cells": [{"cell_type": "markdown", "id": "6e29b7ab", "metadata": {}, "source": ["# Accelerating XGboost with GPU\n\nThis kernel uses the Xgboost models, running on CPU and GPU. With the GPU acceleration, we gain a ~8.5x performance improvement on an NVIDIA K80 card compared to the 2-core virtual CPU available in the Kaggle VM (1h 8min 46s vs. 8min 20s).\n\nThe gain on a NVIDIA 1080ti card compared to an Intel i7 6900K 16-core CPU is ~6.6x.\n\nTo turn GPU support on in Kaggle, in notebook settings, set the **GPU beta** option to \"GPU on\".\n\n## Notebook  Content\n1. [Loading the data](#0) <br>    \n1. [Training the model on CPU](#1)\n1. [Training the model on GPU](#2)\n1. [Submission](#3)\n"]}, {"cell_type": "markdown", "id": "ab22aee4", "metadata": {}, "source": ["<a id=\"0\"></a>\n## 1. Loading the data"]}, {"cell_type": "code", "execution_count": 1, "id": "1751cfc9", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport gc\nimport xgboost as xgb\n\npd.set_option('display.max_columns', 200)"]}, {"cell_type": "code", "execution_count": 1, "id": "e511d05f", "metadata": {}, "outputs": [], "source": ["train_df = pd.read_csv('../input/train.csv', engine='python')\ntest_df = pd.read_csv('../input/test.csv', engine='python')"]}, {"cell_type": "markdown", "id": "2374a45e", "metadata": {}, "source": ["<a id=\"1\"></a> \n## 2. Training the model on CPU"]}, {"cell_type": "code", "execution_count": 1, "id": "a50d2715", "metadata": {}, "outputs": [], "source": ["import subprocess\nprint((subprocess.check_output(\"lscpu\", shell=True).strip()).decode())"]}, {"cell_type": "code", "execution_count": 1, "id": "cfff892b", "metadata": {}, "outputs": [], "source": ["MAX_TREE_DEPTH = 8\nTREE_METHOD = 'hist'\nITERATIONS = 1000\nSUBSAMPLE = 0.6\nREGULARIZATION = 0.1\nGAMMA = 0.3\nPOS_WEIGHT = 1\nEARLY_STOP = 10\n\nparams = {'tree_method': TREE_METHOD, 'max_depth': MAX_TREE_DEPTH, 'alpha': REGULARIZATION,\n          'gamma': GAMMA, 'subsample': SUBSAMPLE, 'scale_pos_weight': POS_WEIGHT, 'learning_rate': 0.05, \n          'silent': 1, 'objective':'binary:logistic', 'eval_metric': 'auc', 'silent':True, \n          'verbose_eval': False}"]}, {"cell_type": "code", "execution_count": 1, "id": "545571dd", "metadata": {}, "outputs": [], "source": ["%%time\nnfold = 5\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\n\ntarget = 'target'\npredictors = train_df.columns.values.tolist()[2:]\n\ni = 1\nfor train_index, valid_index in skf.split(train_df, train_df.target.values):\n    print(\"\\nFold {}\".format(i))\n    xg_train = xgb.DMatrix(train_df.iloc[train_index][predictors].values,\n                           train_df.iloc[train_index][target].values,                           \n                           )\n    xg_valid = xgb.DMatrix(train_df.iloc[valid_index][predictors].values,\n                           train_df.iloc[valid_index][target].values,                           \n                           )   \n\n    \n    clf = xgb.train(params, xg_train, ITERATIONS, evals=[(xg_train, \"train\"), (xg_valid, \"eval\")],\n                early_stopping_rounds=EARLY_STOP, verbose_eval=False)\n    oof[valid_index] = clf.predict(xgb.DMatrix(train_df.iloc[valid_index][predictors].values)) \n    \n    predictions += clf.predict(xgb.DMatrix(test_df[predictors].values)) / nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.2f}\".format(metrics.roc_auc_score(train_df.target.values, oof)))"]}, {"cell_type": "markdown", "id": "a4a32c2b", "metadata": {}, "source": ["<a id=\"2\"></a>\n## 3. Training the model on GPU"]}, {"cell_type": "code", "execution_count": 1, "id": "410426e9", "metadata": {}, "outputs": [], "source": ["!nvidia-smi"]}, {"cell_type": "markdown", "id": "48a064e3", "metadata": {}, "source": ["We now train the model with a K80 GPU available in Kaggle. Xgboost provides out of the box support for single GPU training. On a local workstation, a GPU-ready xgboost docker image can be obtained from https://hub.docker.com/r/rapidsai/rapidsai/.\n\nAll we need to change is to set: `TREE_METHOD = 'gpu_hist'`"]}, {"cell_type": "code", "execution_count": 1, "id": "5ba692e7", "metadata": {}, "outputs": [], "source": ["MAX_TREE_DEPTH = 8\nTREE_METHOD = 'gpu_hist'\nITERATIONS = 1000\nSUBSAMPLE = 0.6\nREGULARIZATION = 0.1\nGAMMA = 0.3\nPOS_WEIGHT = 1\nEARLY_STOP = 10\n\nparams = {'tree_method': TREE_METHOD, 'max_depth': MAX_TREE_DEPTH, 'alpha': REGULARIZATION,\n          'gamma': GAMMA, 'subsample': SUBSAMPLE, 'scale_pos_weight': POS_WEIGHT, 'learning_rate': 0.05, \n          'silent': 1, 'objective':'binary:logistic', 'eval_metric': 'auc',\n          'n_gpus': 1}"]}, {"cell_type": "code", "execution_count": 1, "id": "11d1caa4", "metadata": {}, "outputs": [], "source": ["%%time\nnfold = 5\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\n\ntarget = 'target'\npredictors = train_df.columns.values.tolist()[2:]\n\ni = 1\nfor train_index, valid_index in skf.split(train_df, train_df.target.values):\n    print(\"\\nFold {}\".format(i))\n    xg_train = xgb.DMatrix(train_df.iloc[train_index][predictors].values,\n                           train_df.iloc[train_index][target].values,                           \n                           )\n    xg_valid = xgb.DMatrix(train_df.iloc[valid_index][predictors].values,\n                           train_df.iloc[valid_index][target].values,                           \n                           )   \n\n    \n    clf = xgb.train(params, xg_train, ITERATIONS, evals=[(xg_train, \"train\"), (xg_valid, \"eval\")],\n                early_stopping_rounds=EARLY_STOP, verbose_eval=False)\n    oof[valid_index] = clf.predict(xgb.DMatrix(train_df.iloc[valid_index][predictors].values)) \n    \n    predictions += clf.predict(xgb.DMatrix(test_df[predictors].values)) / nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.2f}\".format(metrics.roc_auc_score(train_df.target.values, oof)))"]}, {"cell_type": "markdown", "id": "0a4a2129", "metadata": {}, "source": ["<a id=\"3\"></a>\n## 4. Submission"]}, {"cell_type": "code", "execution_count": 1, "id": "b8510b52", "metadata": {}, "outputs": [], "source": ["sub_df = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\nsub_df[\"target\"] = predictions\nsub_df[:10]"]}, {"cell_type": "code", "execution_count": 1, "id": "6824d335", "metadata": {}, "outputs": [], "source": ["sub_df.to_csv(\"xgboost_gpu.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}