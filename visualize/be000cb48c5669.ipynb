{"cells": [{"cell_type": "markdown", "id": "dd483ac4", "metadata": {}, "source": ["In this notebook I'll try a simple EDA to understand the composition of our data. I already did a first EDA in my previous notebook [here](https://www.kaggle.com/amelnozieres/eda-sweetviz-profiling)"]}, {"cell_type": "code", "execution_count": 1, "id": "d88e36c3", "metadata": {}, "outputs": [], "source": ["import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport json\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline"]}, {"cell_type": "markdown", "id": "7ce9f71e", "metadata": {}, "source": ["# Explore the JSON files"]}, {"cell_type": "code", "execution_count": 1, "id": "a9c7f49c", "metadata": {}, "outputs": [], "source": ["def read_json(json_path):\n    \"\"\" args = takes the Json files \n        returns = create the five dataframes for the five tables in the annotations json file\n    \"\"\"\n    # # Opening JSON file\n    f = open(json_path, )\n\n    # returns JSON object as\n    # a dictionary\n    \n    data = json.load(f)\n\n    # Create different lists from the data dictionary\n\n    annotations = pd.DataFrame(data[\"annotations\"])\n    category = pd.DataFrame(data[\"categories\"])\n    info = pd.DataFrame.from_dict(data[\"info\"], orient='index')\n    images = pd.DataFrame(data['images'])\n    licenses = pd.DataFrame(data['licenses'])\n    # Closing file\n    f.close()\n    return annotations, category, info, images, licenses"]}, {"cell_type": "code", "execution_count": 1, "id": "6b8706a3", "metadata": {}, "outputs": [], "source": ["json_train_path = '/kaggle/input/fungi-annotations/train.json'\njson_val_path = '/kaggle/input/fungi-annotations/val.json'\ntr_annotation, tr_category, tr_info, tr_images, tr_licenses = read_json(json_train_path)\nval_annotation, val_category, val_info, val_images, val_licenses = read_json(json_val_path)"]}, {"cell_type": "code", "execution_count": 1, "id": "c6fa88a8", "metadata": {}, "outputs": [], "source": ["def create_merged_json_df(images, annotations, category):\n    \"\"\" args = takes the three important dataframes\n    returns = create a merged dataframe with all the important data\n    \"\"\"\n    data_df = images.copy()\n\n    ## to the images dataframe, we add the category_id column - our target\n    data_df['category_id'] = annotations[annotations['image_id'] == data_df['id']]['category_id']\n    category.set_index('id')\n    data_df = pd.merge(left=data_df, right=category, how='left', left_on='category_id', right_on='id')\n    data_df.drop(columns = ['id_y'], inplace=True)\n    #change the column to a string?\n    data_df['category_id'] = data_df['category_id'].astype(str) \n    # Add the columns of image name and its subdirectory/catefory\n    data_df['image_name'] = data_df['file_name'].str.split('/').str[2]\n    data_df['subdir'] = data_df['file_name'].str.split('/',1).str[1]\n    return data_df"]}, {"cell_type": "code", "execution_count": 1, "id": "b069367a", "metadata": {}, "outputs": [], "source": ["tr_data = create_merged_json_df(tr_images, tr_annotation, tr_category)\nval_data = create_merged_json_df(val_images, val_annotation, val_category)"]}, {"cell_type": "code", "execution_count": 1, "id": "6be7c83b", "metadata": {}, "outputs": [], "source": ["tr_data"]}, {"cell_type": "code", "execution_count": 1, "id": "f7a77b05", "metadata": {}, "outputs": [], "source": ["tr_data.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "6a600a19", "metadata": {}, "outputs": [], "source": ["len(tr_data['category_id'].unique())"]}, {"cell_type": "code", "execution_count": 1, "id": "233967e3", "metadata": {}, "outputs": [], "source": ["len(val_data['category_id'].unique())"]}, {"cell_type": "markdown", "id": "3189db09", "metadata": {}, "source": ["ok so there is the same number of categories between the train and the validation data: 1394 classes"]}, {"cell_type": "code", "execution_count": 1, "id": "3d9541af", "metadata": {}, "outputs": [], "source": ["tr_data['category_id'].value_counts()"]}, {"cell_type": "markdown", "id": "61ddeab5", "metadata": {}, "source": ["This is a bad distribution so far!"]}, {"cell_type": "code", "execution_count": 1, "id": "7ca78b79", "metadata": {}, "outputs": [], "source": ["tr_data['name'].describe()"]}, {"cell_type": "markdown", "id": "2e94a1fd", "metadata": {}, "source": ["So here we can see that there isn't the same number of images for each class in the training data. But it is balanced in the validation data."]}, {"cell_type": "markdown", "id": "89ae1a45", "metadata": {}, "source": ["Let's check the distribution of our data by the target column"]}, {"cell_type": "code", "execution_count": 1, "id": "47278f37", "metadata": {}, "outputs": [], "source": ["tr_data['freq'] = tr_data.groupby('category_id')['category_id'].transform('count')"]}, {"cell_type": "code", "execution_count": 1, "id": "ee116bcf", "metadata": {}, "outputs": [], "source": ["tr_data"]}, {"cell_type": "code", "execution_count": 1, "id": "f79dc2e1", "metadata": {}, "outputs": [], "source": ["fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nax = sns.barplot(x = 'category_id', y = 'freq',data = tr_data)\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "70f8b0f8", "metadata": {}, "outputs": [], "source": ["fig_dims = (15,15)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.boxplot(x=tr_data['freq'])\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "8a0798d2", "metadata": {}, "outputs": [], "source": ["fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nax = sns.countplot(x = 'category_id', data = tr_data)\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "f5da8952", "metadata": {}, "outputs": [], "source": ["fig_dims = (15,15)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.boxplot(x=tr_data['category_id'].value_counts())\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()"]}, {"cell_type": "markdown", "id": "af08d970", "metadata": {}, "source": ["So the distribution is not equivalent between categories so it will skwed our predictions. Let's check it is the same for the validation data"]}, {"cell_type": "code", "execution_count": 1, "id": "621f9f26", "metadata": {}, "outputs": [], "source": ["fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nsns.distplot(val_data['category_id'])\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "4a3b9d2a", "metadata": {}, "outputs": [], "source": ["fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nax = sns.countplot(x = 'category_id', data = val_data)\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()"]}, {"cell_type": "markdown", "id": "40beb52d", "metadata": {}, "source": ["So we have an imbalanced training dataset. yay! "]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}