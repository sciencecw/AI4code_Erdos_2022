{"cells": [{"cell_type": "code", "execution_count": 1, "id": "c7c6cd5f", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "c6b94093", "metadata": {}, "source": ["<font size=\"6\"> (BikeShare_Toronto_Ridership_Data_2017-2020.)</font>\n\n [BikeShare Toronto Ridership Data 2017-2020](https://www.kaggle.com/jasonzxho/bikeshare-toronto-ridership-data-20172020)\n \n<font size=\"6\"> by (Peter Gamal Girgis)</font>\n\n<span style=\"color:orange\"><font size=\"4\"> **Task Details:** </font></span>\n\n><font size=\"5\"> About the Dataset</font>\n>\n>The following dataset contain bike trips taken during the year 2017-2020 across more than 600 stations across the City of Toronto. The CSVs for 2017 and 2018 contains 9 features. The description of each feature is listed below:\n>\n>>    `trip_id`: Unique ID code for individual trip taken.\n>>\n>>    `trip_start_time`: Trip start time.\n>>\n>>    `trip_end_time`: Trip end time.\n>>\n>>    `trip_duration_seconds`: Duration of the trip in seconds.\n>>\n>>    `from_station_id`: Unique ID code for the start station.\n>>\n>>    `from_station_name`: Name of start station.\n>>\n>>    `to_station_id`: Unique ID code for the end station.\n>>\n>>    `to_station_name`: Name of end station.\n>>\n>>    `user_type`: Type of user, either Member or Casual.\n>>\n>\n> The CSVs for 2019 and 2020 contains 11 features. The description of each feature is listed below:\n>\n>>    `Trip Id`: Unique ID code for individual trip taken.\n>>    Subscription Id: Unique ID code for the individual member, this can be used to track Annual Member usage.\n>>\n>>    `Trip Duration`: Duration of the trip in seconds.\n>>\n>>    `Start Station Id`: Unique ID code for the start station.\n>>\n>>    `Start Time`: Trip start time.\n>>\n>>    `Start Station Name`: Name of start station.\n>>\n>>    `End Station Id`: Unique ID code for the end station.\n>>\n>>    `End Time`: Trip end time.\n>>\n>>    `End Station Name`: Name of end station.\n>>\n>>   `Bike Id`: Unique ID for the individual bike used.\n>> \n>>   `User Type`: Type of user, either Annual or Casual.\n "]}, {"cell_type": "code", "execution_count": 1, "id": "ab611872", "metadata": {}, "outputs": [], "source": ["# Import all Requiring Libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport requests\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nfrom datetime import timedelta\n\n# Combining several CSV files\nfrom glob import glob \n\n# to get web contents\nimport json\nfrom urllib.request import urlopen\n\nimport holidays\n\nimport pycountry\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom collections import namedtuple\n\n# for offline ploting\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# hide warnings\nimport warnings\nwarnings.simplefilter('ignore')"]}, {"cell_type": "markdown", "id": "75d92ec4", "metadata": {}, "source": ["<span style=\"color:orange\"><font size=\"4\"> **1. Year_2017** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "293f4bb8", "metadata": {}, "outputs": [], "source": ["# Using glob function to combine several CSV files with same strucure at 2017 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2017/2017-Q*.csv'))\nfiles"]}, {"cell_type": "code", "execution_count": 1, "id": "4b3dbc2f", "metadata": {}, "outputs": [], "source": ["# Using concat to combined all files and assign() methods\nY_2017 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2017"]}, {"cell_type": "code", "execution_count": 1, "id": "cd9c0846", "metadata": {}, "outputs": [], "source": ["# check unique file's names\nY_2017.filename.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "99c3a397", "metadata": {}, "outputs": [], "source": ["# Modify file path to Y_2017 number.\nY_2017.filename = Y_2017.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2017/', '')\nY_2017.filename = Y_2017.filename.str.replace('.csv', '')\n\nY_2017.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "92c0b881", "metadata": {}, "outputs": [], "source": ["# Change column \"filename to \"Quarter\"\nY_2017 = Y_2017.rename(columns = {'filename' :'Quarter'})\nY_2017.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "4107ba20", "metadata": {}, "outputs": [], "source": ["# Check Dataframe shape\nY_2017.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "9e3de5dd", "metadata": {}, "outputs": [], "source": ["# Check Dataframe info()\nY_2017.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "1e690e5a", "metadata": {}, "outputs": [], "source": ["# check Dataframe NULL values\nY_2017.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "f1e8b181", "metadata": {}, "outputs": [], "source": ["# Found \"NULLNULL\" values\nY_2017.query('trip_stop_time == \"NULLNULL\"')"]}, {"cell_type": "markdown", "id": "1d377259", "metadata": {}, "source": ["> Cancel trip while `trip_duration_seconds` & `trip_stop_time` equal Zero and no distination at `to_station_name` or `to_station_id`"]}, {"cell_type": "code", "execution_count": 1, "id": "75719313", "metadata": {}, "outputs": [], "source": ["# Drop Row's have NULLNULL Values\nY_2017 = Y_2017[Y_2017['trip_stop_time'] != 'NULLNULL']\nY_2017"]}, {"cell_type": "code", "execution_count": 1, "id": "42679669", "metadata": {}, "outputs": [], "source": ["# Check \"NULLNULL\" values are droped\nY_2017.query('trip_stop_time == \"NULLNULL\"')"]}, {"cell_type": "code", "execution_count": 1, "id": "04a18b85", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_2017.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "291e22e3", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Y_17\"\nY_17 = Y_2017[['from_station_id','from_station_name']]\nY_17 = Y_17.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_17"]}, {"cell_type": "code", "execution_count": 1, "id": "268cc5f8", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Z_17\"\nZ_17 = Y_2017[['to_station_id','to_station_name']]\nZ_17 = Z_17.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_17"]}, {"cell_type": "code", "execution_count": 1, "id": "7bedf48f", "metadata": {}, "outputs": [], "source": ["# Concatenate new Dtaframes \"Y_17 & Z_17\" at new Dtaframe \"X_17\"\nX_17 = pd.concat([Y_17,Z_17])\nX_17"]}, {"cell_type": "code", "execution_count": 1, "id": "474312b6", "metadata": {}, "outputs": [], "source": ["# Check number of Unique values\nX_17.station_id.nunique()"]}, {"cell_type": "code", "execution_count": 1, "id": "40552804", "metadata": {}, "outputs": [], "source": ["# Check Dataframe duplication\nX_17.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "40e07a71", "metadata": {}, "outputs": [], "source": ["# Drop douplication at X_17\nX_17 = X_17.drop_duplicates()\nX_17"]}, {"cell_type": "code", "execution_count": 1, "id": "aedc513e", "metadata": {}, "outputs": [], "source": ["# Drop Row's have NULL Values in column \"station_id\"\nX_17 = X_17[pd.notnull(X_17['station_id'])]\nX_17"]}, {"cell_type": "code", "execution_count": 1, "id": "7adbc988", "metadata": {}, "outputs": [], "source": ["# Merge 2 Dataframe \"X_17\" and \"Y_2017\"\nY_2017 = Y_2017.merge(X_17, left_on = 'from_station_name', right_on = 'station_name', how = 'left')\nY_2017"]}, {"cell_type": "code", "execution_count": 1, "id": "55ea45dc", "metadata": {}, "outputs": [], "source": ["# Replace NUll Value in column \"from_station_id\" with data at column \"station_id\"\nY_2017['from_station_id'] = Y_2017.from_station_id.fillna(Y_2017.station_id)\n\n# Drop un-necessary columns\nY_2017 = Y_2017.drop(['station_id','station_name'], axis = 1)\n\n# check Dataframe NULL values\nY_2017.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "af0758eb", "metadata": {}, "outputs": [], "source": ["# merge 2 Dataframe \"X_17\" and \"Y_2017\"\nY_2017 = Y_2017.merge(X_17, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_2017"]}, {"cell_type": "code", "execution_count": 1, "id": "2375fbdb", "metadata": {}, "outputs": [], "source": ["# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\nY_2017['to_station_id'] = Y_2017.to_station_id.fillna(Y_2017.station_id)\n\n# Drop un-necessary columns\nY_2017 = Y_2017.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2017.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "b89b63cd", "metadata": {}, "outputs": [], "source": ["# save \"Y_2017\" dataframe in CSV format at new created folder(gathering_data)\nY_2017.to_csv('/kaggle/working/Y_2017.csv', index=False)"]}, {"cell_type": "markdown", "id": "db7696a1", "metadata": {}, "source": ["<span style=\"color:orange\"><font size=\"4\"> **2. Year_2018** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "568fb900", "metadata": {}, "outputs": [], "source": ["## Using glob function to combine several CSV files with same strucure at 2018 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2018/2018-Q*.csv'))\nfiles"]}, {"cell_type": "code", "execution_count": 1, "id": "461916b8", "metadata": {}, "outputs": [], "source": ["# Using concat to combined all files and assign() methods\nY_2018 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2018"]}, {"cell_type": "code", "execution_count": 1, "id": "a6b21028", "metadata": {}, "outputs": [], "source": ["# Check unique file's names\nY_2018.filename.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "29f0e2ce", "metadata": {}, "outputs": [], "source": ["# Modify file path to Y_2018 number.\nY_2018.filename = Y_2018.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2018/', '')\nY_2018.filename = Y_2018.filename.str.replace('.csv', '')\n\nY_2018.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "e41b1f01", "metadata": {}, "outputs": [], "source": ["# Change column \"filename to \"Quarter\"\nY_2018 = Y_2018.rename(columns = {'filename' :'Quarter'})\nY_2018.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "9888a1df", "metadata": {}, "outputs": [], "source": ["# Check Dataframe shape\nY_2018.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "cfb9c450", "metadata": {}, "outputs": [], "source": ["# Check Dataframe info()\nY_2018.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "a7f2641c", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Y_18\"\nY_18 = Y_2018[['from_station_id','from_station_name']]\nY_18 = Y_18.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_18"]}, {"cell_type": "code", "execution_count": 1, "id": "d9ddb5d3", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Z_18\"\nZ_18 = Y_2018[['to_station_id','to_station_name']]\nZ_18 = Z_18.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_18"]}, {"cell_type": "code", "execution_count": 1, "id": "665f0d31", "metadata": {}, "outputs": [], "source": ["# Concatenate new Dtaframes \"Y_18 & Z_18\" at new Dtaframe \"X_18\"\nX_18 = pd.concat([Y_18,Z_18])\nX_18"]}, {"cell_type": "code", "execution_count": 1, "id": "1d5e2dda", "metadata": {}, "outputs": [], "source": ["# Check number of Unique values\nX_18.station_id.nunique()"]}, {"cell_type": "code", "execution_count": 1, "id": "73c6de7b", "metadata": {}, "outputs": [], "source": ["# check Dataframe duplication\nX_18.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "f21582f2", "metadata": {}, "outputs": [], "source": ["# Drop douplication at X_18\nX_18 = X_18.drop_duplicates()\nX_18"]}, {"cell_type": "code", "execution_count": 1, "id": "6bde7b42", "metadata": {}, "outputs": [], "source": ["# Drop Row's have NULL Values\nX_18 = X_18.dropna(axis = 0)\nX_18"]}, {"cell_type": "code", "execution_count": 1, "id": "1a727de6", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_2018.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "161a4e51", "metadata": {}, "outputs": [], "source": ["# Check Dataframe duplication\nY_2018.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "7ac5a164", "metadata": {}, "outputs": [], "source": ["# save \"Y_2018\" dataframe in CSV format at new created folder(gathering_data)\nY_2018.to_csv('/kaggle/working/Y_2018.csv', index=False)"]}, {"cell_type": "markdown", "id": "97a0f373", "metadata": {}, "source": ["<span style=\"color:orange\"><font size=\"4\"> **3. Year_2019** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "8fa43518", "metadata": {}, "outputs": [], "source": ["## Using glob function to combine several CSV files with same strucure at 2019 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2019/2019-Q*.csv'))\nfiles"]}, {"cell_type": "code", "execution_count": 1, "id": "c06ac855", "metadata": {}, "outputs": [], "source": ["# Using concat to combined all files and assign() methods\nY_2019 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2019"]}, {"cell_type": "code", "execution_count": 1, "id": "64d83850", "metadata": {}, "outputs": [], "source": ["# Check unique file's names\nY_2019.filename.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "d2531fd2", "metadata": {}, "outputs": [], "source": ["# Modify file path to Y_2019 number.\nY_2019.filename = Y_2019.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2019/', '')\nY_2019.filename = Y_2019.filename.str.replace('.csv', '')\n\nY_2019.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "8f792377", "metadata": {}, "outputs": [], "source": ["# Change column \"filename to \"Quarter\"\nY_2019 = Y_2019.rename(columns = {'filename' :'Quarter'})\nY_2019.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "5607a431", "metadata": {}, "outputs": [], "source": ["# Check Dataframe shape\nY_2019.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "1c963b58", "metadata": {}, "outputs": [], "source": ["# Check Dataframe info()\nY_2019.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "39a33baf", "metadata": {}, "outputs": [], "source": ["# Rename columns to matching with columns at other years.\nY_2019 = Y_2019.rename(columns = {'Trip Id':'trip_id', 'Trip  Duration':'trip_duration_seconds', 'Start Station Id':'from_station_id',\n                                  'Start Time':'trip_start_time', 'Start Station Name':'from_station_name', 'End Station Id':'to_station_id',\n                                 'End Time':'trip_stop_time', 'End Station Name':'to_station_name', 'User Type': 'user_type'})"]}, {"cell_type": "code", "execution_count": 1, "id": "50a7edd5", "metadata": {}, "outputs": [], "source": ["# Drop un-necessary column\nY_2019 = Y_2019.drop(['Subscription Id','Bike Id'], axis = 1)\nY_2019.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "be840eb2", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_2019.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "dfa60d0f", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Y_19\"\nY_19 = Y_2019[['from_station_id','from_station_name']]\nY_19 = Y_19.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_19"]}, {"cell_type": "code", "execution_count": 1, "id": "f7257556", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Z_19\"\nZ_19 = Y_2019[['to_station_id','to_station_name']]\nZ_19 = Z_19.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_19"]}, {"cell_type": "code", "execution_count": 1, "id": "198814ba", "metadata": {}, "outputs": [], "source": ["# Concatenate new Dtaframes \"Y_19 & Z_19\" at new Dtaframe \"X_19\"\nX_19 = pd.concat([Y_19,Z_19])\nX_19"]}, {"cell_type": "code", "execution_count": 1, "id": "58642f8f", "metadata": {}, "outputs": [], "source": ["# Check number of Unique values\nX_19.station_id.nunique()"]}, {"cell_type": "code", "execution_count": 1, "id": "b83d35fa", "metadata": {}, "outputs": [], "source": ["# Check Dataframe duplication\nX_19.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "bf5a97de", "metadata": {}, "outputs": [], "source": ["# Drop douplication at X_19\nX_19 = X_19.drop_duplicates()\nX_19"]}, {"cell_type": "code", "execution_count": 1, "id": "d1a2ad43", "metadata": {}, "outputs": [], "source": ["# Drop Row's have NULL Values related column \"station_name\"\nX_19 = X_19[pd.notnull(X_19['station_name'])]\nX_19"]}, {"cell_type": "code", "execution_count": 1, "id": "0df67422", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_2019.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "6310636e", "metadata": {}, "outputs": [], "source": ["# Merge 2 Dataframe \"X_19\" and \"Y_2019\"\nY_2019 = Y_2019.merge(X_19, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_2019"]}, {"cell_type": "code", "execution_count": 1, "id": "cb212ad2", "metadata": {}, "outputs": [], "source": ["# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\n# Replace NUll Value in column \"to_station_name\" with data at column \"station_name\"\nY_2019['to_station_id'] = Y_2019.to_station_id.fillna(Y_2019.station_id)\nY_2019['to_station_name'] = Y_2019.to_station_name.fillna(Y_2019.station_name)\n\n# Drop un-necessary column\nY_2019 = Y_2019.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2019.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "8dcb5dcd", "metadata": {}, "outputs": [], "source": ["# Check Dataframe duplication\nY_2019.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "55e32a19", "metadata": {}, "outputs": [], "source": ["# Save \"Y_2019\" dataframe in CSV format at new created folder(gathering_data)\nY_2019.to_csv('/kaggle/working/Y_2019.csv', index=False)"]}, {"cell_type": "markdown", "id": "72d89630", "metadata": {}, "source": ["<span style=\"color:orange\"><font size=\"4\"> **4. Year_2020** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "063fe44a", "metadata": {}, "outputs": [], "source": ["## Using glob function to combine several CSV files with same strucure at 2020 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-*.csv'))\nfiles"]}, {"cell_type": "code", "execution_count": 1, "id": "30340a9c", "metadata": {}, "outputs": [], "source": ["# Using concat to combined all files and assign() methods\nY_2020 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2020.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "fdc02c78", "metadata": {}, "outputs": [], "source": ["# Check unique file's names\nY_2020.filename.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "f8ac9876", "metadata": {}, "outputs": [], "source": ["# Modify file path to Y_2020 number.\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-01','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-02','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-03','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-04','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-05','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-06','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-07','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-08','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-09','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-10','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-11','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-12','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('.csv', '')\n\nY_2020.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "3fb04679", "metadata": {}, "outputs": [], "source": ["# Change column \"filename to \"Quarter\"\nY_2020 = Y_2020.rename(columns = {'filename' :'Quarter'})\nY_2020.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "4aac85b9", "metadata": {}, "outputs": [], "source": ["# Check Columns names at DataFrame \"Y_2020\"\nY_2020.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "b5855762", "metadata": {}, "outputs": [], "source": ["# Check Dataframe shape\nY_2020.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "ac837540", "metadata": {}, "outputs": [], "source": ["# Check Dataframe info()\nY_2020.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "e9d715c0", "metadata": {}, "outputs": [], "source": ["# Rename columns to matching with columns at other years.\nY_2020 = Y_2020.rename(columns = {'Trip Id':'trip_id', 'Trip  Duration':'trip_duration_seconds', 'Start Station Id':'from_station_id',\n                                  'Start Time':'trip_start_time', 'Start Station Name':'from_station_name', 'End Station Id':'to_station_id',\n                                 'End Time':'trip_stop_time', 'End Station Name':'to_station_name', 'User Type': 'user_type'})"]}, {"cell_type": "code", "execution_count": 1, "id": "48b06eff", "metadata": {}, "outputs": [], "source": ["# Check Dataframe info()\nY_2020.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "cb61b4a8", "metadata": {}, "outputs": [], "source": ["# Drop un-necessary column\nY_2020 = Y_2020.drop(['Subscription Id','Bike Id', '10293877', '863410', '905', '7038', '11/01/2020 00:00', 'Dundas St W / Yonge St',\n                     '7253', '11/01/2020 00:15', 'John St  / Mercer St - SMART', '2260', 'Casual Member', '10529965', '832983', '304', '7542',\n                     '12/01/2020 00:02', 'Queen St W / John St', '7544', '12/01/2020 00:07', 'Foster Pl / Elizabeth St - SMART', '1182',\n                     'Annual Member'], axis = 1)\nY_2020.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "a0e37137", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_2020.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "cb7a8c4d", "metadata": {}, "outputs": [], "source": ["# Drop Row's have NULL Values related column \"trip_id\"\nY_2020 = Y_2020[pd.notnull(Y_2020['trip_id'])]\nY_2020"]}, {"cell_type": "code", "execution_count": 1, "id": "df55fd45", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_2020.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "dd36e07b", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Y_20\"\nY_20 = Y_2020[['from_station_id','from_station_name']]\nY_20 = Y_20.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_20"]}, {"cell_type": "code", "execution_count": 1, "id": "a580f1d1", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Z_20\"\nZ_20 = Y_2020[['to_station_id','to_station_name']]\nZ_20 = Z_20.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_20"]}, {"cell_type": "code", "execution_count": 1, "id": "80322a40", "metadata": {}, "outputs": [], "source": ["# Concatenate new Dtaframes \"Y_20 & Z_20\" at new Dtaframe \"X_20\"\nX_20 = pd.concat([Y_20,Z_20])\nX_20"]}, {"cell_type": "code", "execution_count": 1, "id": "0447c14b", "metadata": {}, "outputs": [], "source": ["# Check Dataframe duplication\nX_20.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "006aff31", "metadata": {}, "outputs": [], "source": ["# Drop douplication at X_20\nX_20 = X_20.drop_duplicates()\nX_20"]}, {"cell_type": "code", "execution_count": 1, "id": "fcc332c9", "metadata": {}, "outputs": [], "source": ["# Drop Row's have NULL Values related column \"station_name\"\nX_20 = X_20[pd.notnull(X_20['station_name'])]\nX_20"]}, {"cell_type": "code", "execution_count": 1, "id": "318b6371", "metadata": {}, "outputs": [], "source": ["# Merge 2 Dataframe \"X_20\" and \"Y_2020\"\nY_2020 = Y_2020.merge(X_20, left_on = 'from_station_id', right_on = 'station_id', how = 'left')\nY_2020"]}, {"cell_type": "code", "execution_count": 1, "id": "48ed8236", "metadata": {}, "outputs": [], "source": ["# Replace NUll Value in column \"from_station_name\" with data at column \"station_name\"\nY_2020['from_station_name'] = Y_2020.from_station_name.fillna(Y_2020.station_name)\n\n# Drop un-necessary column\nY_2020 = Y_2020.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2020.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "5579289d", "metadata": {}, "outputs": [], "source": ["# Merge 2 Dataframe \"X_20\" and \"Y_2020\"\nY_2020 = Y_2020.merge(X_20, left_on = 'to_station_id', right_on = 'station_id', how = 'left')\nY_2020"]}, {"cell_type": "code", "execution_count": 1, "id": "2e138a20", "metadata": {}, "outputs": [], "source": ["# Replace NUll Value in column \"to_station_name\" with data at column \"station_name\"\nY_2020['to_station_name'] = Y_2020.to_station_name.fillna(Y_2020.station_name)\n\n# Drop un-necessary column\nY_2020 = Y_2020.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2020.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "6d9f7ef3", "metadata": {}, "outputs": [], "source": ["# check Dataframe duplication\nY_2020.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "2467f7da", "metadata": {}, "outputs": [], "source": ["# Save \"Y_2020\" dataframe in CSV format at new created folder(gathering_data)\nY_2020.to_csv('/kaggle/working/Y_2020.csv', index=False)"]}, {"cell_type": "markdown", "id": "93db8c55", "metadata": {}, "source": ["<span style=\"color:orange\"><font size=\"4\"> **5. Combine All DF's** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "328396c9", "metadata": {}, "outputs": [], "source": ["## Using glob function to combine several CSV files with same strucure at gathering_data\nfiles = sorted (glob('/kaggle/working/Y_20*.csv'))\nfiles"]}, {"cell_type": "code", "execution_count": 1, "id": "79031d3c", "metadata": {}, "outputs": [], "source": ["# using concat to combined all files\nY_All = pd.concat((pd.read_csv(file) for file in files), ignore_index = True)\nY_All"]}, {"cell_type": "code", "execution_count": 1, "id": "369cfd5f", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Y\"\nY = Y_All[['from_station_id','from_station_name']]\nY = Y.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY"]}, {"cell_type": "code", "execution_count": 1, "id": "43169460", "metadata": {}, "outputs": [], "source": ["# Select certian columns and add it at new DataFrame \"Z\"\nZ = Y_All[['to_station_id','to_station_name']]\nZ = Z.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ"]}, {"cell_type": "code", "execution_count": 1, "id": "cbfebd04", "metadata": {}, "outputs": [], "source": ["# Concatenate new Dtaframes \"Y & Z\" at new Dtaframe \"X\"\nX = pd.concat([Y,Z])\nX"]}, {"cell_type": "code", "execution_count": 1, "id": "bf3cb80b", "metadata": {}, "outputs": [], "source": ["# Check Dataframe duplication\nX.duplicated().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "0f70e2a7", "metadata": {}, "outputs": [], "source": ["# Drop douplication at X\nX = X.drop_duplicates()\nX"]}, {"cell_type": "code", "execution_count": 1, "id": "e149f24b", "metadata": {}, "outputs": [], "source": ["# Check NULL values at Column \"station_id\"\nX.query('station_id.isnull()', engine='python')"]}, {"cell_type": "code", "execution_count": 1, "id": "8aa26c3f", "metadata": {}, "outputs": [], "source": ["# Update the repeated stations with same ID number\n# Update station_id = 7183 for station \"Margueretta St / College St\"\nX['station_id'][465831] = 7183.0\n\n# Update station_id = 7180 for station \"Lansdowne Subway Green P\"\nX['station_id'][465850] = 7180.0\n\n# Update station_id = 7161 for station \"Beverly St / College St\"\nX['station_id'][465532] = 7161.0"]}, {"cell_type": "code", "execution_count": 1, "id": "cbc1b441", "metadata": {}, "outputs": [], "source": ["# Update station without ID by adding ID for them\n# Station \"Michael Sweet Ave / St. Patrick St\" using station_id = 7080.0\nX['station_id'][465490] = 7080.0\n\n# Station \"Roxton Rd / College St\" using station_id = 7081.0\nX['station_id'][728511] = 7081.0\n\n# Station \"Base Station\" using station_id = 7082.0\nX['station_id'][731204] = 7082.0\n\n# Station \"Lake Shore Blvd W / Ontario Dr(Ontario Place)\" using station_id = 7212.0\nX['station_id'][734637] = 7212.0\n\n# Station \"Dovercourt Rd / Harrison St - SMART\" using station_id = 7213.0\nX['station_id'][797267] = 7213.0\n\n# Station \"Summerhill Ave / MacLennan Ave - SMART\" using station_id = 7214.0\nX['station_id'][800483] = 7214.0\n\n# Station \"Fringe Next Stage - 7219\" using station_id = 7215.0\nX['station_id'][1038094] = 7215.0"]}, {"cell_type": "code", "execution_count": 1, "id": "7ce5a9a3", "metadata": {}, "outputs": [], "source": ["# Check above stations name related column\"station_name\"\nX.query('station_name == \"Fringe Next Stage - 7219\" ')"]}, {"cell_type": "code", "execution_count": 1, "id": "18fb9937", "metadata": {}, "outputs": [], "source": ["# Check NULL values at Column \"station_id\"\nX.query('station_id.isnull()', engine='python')"]}, {"cell_type": "code", "execution_count": 1, "id": "06fed7e0", "metadata": {}, "outputs": [], "source": ["# Drop Row's have NULL Values at X\nX = X.dropna(axis = 0)\nX"]}, {"cell_type": "code", "execution_count": 1, "id": "6e4f5787", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_All.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "694d6e46", "metadata": {}, "outputs": [], "source": ["# Merge 2 Dataframe \"X\" and \"Y_All\"\nY_All = Y_All.merge(X, left_on = 'from_station_name', right_on = 'station_name', how = 'left')\nY_All"]}, {"cell_type": "code", "execution_count": 1, "id": "7184a0db", "metadata": {}, "outputs": [], "source": ["# Replace NUll Value in column \"from_station_id\" with data at column \"station_id\"\nY_All['from_station_id'] = Y_All.from_station_id.fillna(Y_All.station_id)\n\n# Drop un-necessary column\nY_All = Y_All.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_All.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "2f91c724", "metadata": {}, "outputs": [], "source": ["# Merge 2 Dataframe \"X\" and \"Y_All\"\nY_All = Y_All.merge(X, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_All"]}, {"cell_type": "code", "execution_count": 1, "id": "539d1874", "metadata": {}, "outputs": [], "source": ["# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\nY_All['to_station_id'] = Y_All.to_station_id.fillna(Y_All.station_id)\n\n# Drop un-necessary column\nY_All = Y_All.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_All.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "35331a1a", "metadata": {}, "outputs": [], "source": ["# Correct data type for \"trip_start_time , trip_stop_time\" to be time stamp\nY_All['trip_start_time']= pd.to_datetime(Y_All.trip_start_time)\nY_All['trip_stop_time'] = pd.to_datetime(Y_All.trip_stop_time)\nY_All.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "de8daaed", "metadata": {}, "outputs": [], "source": ["# check total trip time in seconds for all trips and convert it to integer \nY_All['trip_duration_seconds'] = (Y_All.trip_stop_time - Y_All.trip_start_time).dt.total_seconds().astype('int64')\n\n# Check Dataframe info()\nY_All.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "e14250af", "metadata": {}, "outputs": [], "source": ["# check trip_duration_seconds = zero values ( that mean trips are cancelled)\nY_All.query('trip_duration_seconds == 0')"]}, {"cell_type": "code", "execution_count": 1, "id": "5daedfac", "metadata": {}, "outputs": [], "source": ["# Drop Row's have trip_duration_seconds = zero values \nY_All = Y_All[(Y_All['trip_duration_seconds'] > 0)]\nY_All"]}, {"cell_type": "code", "execution_count": 1, "id": "e1866f7d", "metadata": {}, "outputs": [], "source": ["# Check trip_duration_seconds = zero values are all removed\nY_All.query('trip_duration_seconds == 0')"]}, {"cell_type": "code", "execution_count": 1, "id": "6e384dd9", "metadata": {}, "outputs": [], "source": ["# Check Dataframe NULL values\nY_All.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "3f0a9c77", "metadata": {}, "outputs": [], "source": ["# Modify \"Casual\" to \"Casual Member\" at \"user_type\" column\nY_All.user_type = Y_All.user_type.replace('Casual', 'Casual Member')\n\n# Modify \"Member\" to \"Annual Member\" at \"user_type\" column\nY_All.user_type = Y_All.user_type.replace('Member', 'Annual Member')\n\n# Check changes applied\nY_All.user_type.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "97812d22", "metadata": {}, "outputs": [], "source": ["# Save \"Y_All\" dataframe in CSV format at new created folder(gathering_data)\nY_All.to_csv('/kaggle/working/Y_All.csv', index=False)"]}, {"cell_type": "markdown", "id": "579fcc29", "metadata": {}, "source": ["<span style=\"color:orange\"><font size=\"4\"> **6. Copying DataFrame** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "c0379bc3", "metadata": {}, "outputs": [], "source": ["# Copying the merged DataFrame\ndf_All = Y_All.copy()\ndf_All"]}, {"cell_type": "markdown", "id": "ba96b890", "metadata": {}, "source": ["<span style=\"color:orange\"><font size=\"4\"> **7. Exploratory Data Analysis ( Analyzing and Visualization)** </font></span>\n><span style=\"color:orange\"><font size=\"3\"> **Q1:How Many user type at All Period?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "7d2f7997", "metadata": {}, "outputs": [], "source": ["# Plot \"user_type\" Analysis\nplt.figure(figsize=[6, 6])\ncolor_base = sns.color_palette()[0]\n\nax = sns.countplot(data = df_All, x = 'user_type', color = color_base, order = df_All.user_type.value_counts().index)\n\nfor i,j in enumerate (df_All.user_type.value_counts()):\n    ax.text(i,100 + df_All.user_type.value_counts()[i], j, weight = \"bold\", size = 13,va='baseline', ha='center')\n    \nplt.yticks([0, 1e6, 2e6, 3e6, 4e6, 5e6, 6e6],['0','1M','2M','3M','4M','5M','6M'])\nplt.xlabel(\"User's Type\", size = 15)\nplt.ylabel(\"Total User's Count\", size = 15)\nplt.title(\"User's Type Distribution\", size = 15, weight = 'bold')\nplt.show();"]}, {"cell_type": "markdown", "id": "59cc79e0", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q2:How Many User Type / Quarter in each Year ?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "0ea8ea33", "metadata": {}, "outputs": [], "source": ["# Plot \"user_type\" Analysis\ndate_quarter = df_All.groupby(df_All.Quarter)['user_type'].count()\n\nax = date_quarter.plot(kind ='line',figsize = (20,10), marker = 'o')       \nplt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], ['2017-Q1', '2017-Q2', '2017-Q3', '2017-Q4','2018-Q1', '2018-Q2', '2018-Q3', '2018-Q4',\n                                                                    '2019-Q1', '2019-Q2', '2019-Q3', '2019-Q4','2020-Q1', '2020-Q2', '2020-Q3', '2020-Q4'])\nplt.yticks([0, 0.2e6, 0.4e6, 0.6e6, 0.8e6, 1.0e6, 1.2e6, 1.4e6, 1.6e6],['0', '200K', '400K', '600K','800K', '1M', '1.2M', '1.4M', '1.6M'])\nplt.xlabel(\"Date(Year-Quarter)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.title(\"User's Type Distribution / Quarter\", weight = 'bold', size = 15)\n\nplt.grid(True)\nplt.show();"]}, {"cell_type": "markdown", "id": "13ff69dc", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q3:What's Total Trips per year?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "f10af347", "metadata": {}, "outputs": [], "source": ["date_year = df_All.trip_start_time.groupby(df_All.trip_start_time.dt.year).count()\n\nax = date_year.plot(kind ='line',figsize = (6,6), marker = 'o')       \nplt.title('Trips per Years', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Year's)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.xticks([2017.0,2018.0, 2019.0, 2020.0], ['2017', '2018', '2019','2020'])\nplt.yticks([1.6e6, 1.8e6, 2.0e6, 2.2e6, 2.4e6, 2.6e6], ['1.6M', '1.8M', '2M','2.2M', '2.4M', '2.6M'])\nplt.grid(True)\nplt.show();"]}, {"cell_type": "markdown", "id": "dca49b5c", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q4:What's the Total Count Trips per Month?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "649d2a0a", "metadata": {}, "outputs": [], "source": ["trips_month = df_All.trip_start_time.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month]).count()\n\nax = trips_month.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Total Count Trips per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([100000, 200000, 300000, 400000, 500000], ['100K', '200K', '300K','400K', '500K'])\nplt.grid(True)\nplt.show();"]}, {"cell_type": "markdown", "id": "fdb84d0f", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q5: What's the Total Count Trips per Quarter as (Annual / Casual) Member?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "6b412c83", "metadata": {}, "outputs": [], "source": ["# Plot \"user_type\" Analysis\ntrips_quarter = df_All.groupby(['Quarter','user_type'])['trip_id'].count().reset_index()\ntrips_quarter.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "e539d328", "metadata": {}, "outputs": [], "source": ["# combine 2 colums \"user_type\" & \"trip_start_time\" \nAnnual = pd.DataFrame(trips_quarter.query('user_type == \"Annual Member\"').value_counts()).reset_index()\n# combine 2 colums \"user_type\" & \"trip_start_time\" \nCasual = pd.DataFrame(trips_quarter.query('user_type == \"Casual Member\"').value_counts()).reset_index()\nAnnual"]}, {"cell_type": "code", "execution_count": 1, "id": "9ba4629e", "metadata": {}, "outputs": [], "source": ["fig,(ax1,ax2) = plt.subplots (1,2,figsize = (20,20))\n\n# figure \"a\" represent number of Annual Member in user type \na = sns.barplot (x = Annual.trip_id, y = Annual.Quarter, ax = ax1 , \n                 linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# figure \"a\" represent number of  Casual Member in user type\nb = sns.barplot (x = Casual.trip_id, y = Casual.Quarter, ax = ax2 , \n                 linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count number of Trips in each Annual Member\nfor i,j in enumerate(Annual.trip_id):\n        ax1.text(.07,i+0.15,j,weight = \"bold\", size = 15)\n\n# create loop to count number of Trips in each Casual Member\nfor k,l in enumerate(Casual.trip_id):\n        ax2.text(.07,k+0.15,l,weight = \"bold\", size = 15)     \n        \na.set_title(\"Total Count Trips / Quarter as Annual Member\" , weight = 'bold', size = 15)\na.set_xlabel('Total Annual Member Count / Quarter', size = 15)\na.set_ylabel(\"Date(Year-Quarter)\", size = 15)\n\n\nb.set_title(\"Total Count Trips / Quarter as Casual Member\" , weight = 'bold', size = 15)\nb.set_xlabel('Total Casual Member Count / Quarter', size = 15)\nb.set_ylabel(\"Date(Year-Quarter)\", size = 15)\n\nplt.show();"]}, {"cell_type": "markdown", "id": "b84dd625", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q6: What's the Total Period Trip / Month?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "1bcf79c3", "metadata": {}, "outputs": [], "source": ["total_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].sum())\n\nax = total_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([1e8, 2e8, 3e8, 4e8, 5e8, 6e8, 7e8, 8e8, 9e8], ['100M', '200M', '300M','400M', '500M', '600M', '700M', '800M', '900M'])\nplt.grid(True)\nplt.legend('')\nplt.show();"]}, {"cell_type": "markdown", "id": "3841f377", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q7: What's the Min. Period Trip / Month?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "ff65cecb", "metadata": {}, "outputs": [], "source": ["min_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].idxmin())\n\nax = min_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([0, 1e6, 2e6, 3e6, 4e6, 5e6, 6e6, 7e6, 8e6, 9e6], ['0', '1M', '2M', '3M','4M', '5M', '6M', '7M', '8M', '9M'])\nplt.grid(True)\nplt.legend('')\nplt.show();"]}, {"cell_type": "markdown", "id": "0501afad", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q8: What's the Max. Period Trip / Month?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "a355a80c", "metadata": {}, "outputs": [], "source": ["max_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].idxmax())\n\nax = max_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([1e6, 2e6, 3e6, 4e6, 5e6, 6e6, 7e6, 8e6, 9e6], ['1M', '2M', '3M','4M', '5M', '6M', '7M', '8M', '9M'])\nplt.grid(True)\nplt.legend('')\nplt.show();"]}, {"cell_type": "markdown", "id": "feb618f7", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q9: What's the Average Period Trip / Month?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "652d3e97", "metadata": {}, "outputs": [], "source": ["average_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].mean())\n\nax = average_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([2e3, 4e3, 6e3, 8e3, 10e3, 12e3, 14e3], ['2K', '4K', '6K','8K', '10K', '12K', '14K'])\nplt.grid(True)\nplt.legend('')\nplt.show();"]}, {"cell_type": "markdown", "id": "eff951e4", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q10: What's the Top 20 Stations at Start Point?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "5761fc23", "metadata": {}, "outputs": [], "source": ["# combine 2 colums \"from_station_id\" & \"trip_id\" then sort stations desending regarding number of trips results\nmost_Start_id = df_All.groupby('from_station_name')['trip_id'].count().reset_index().sort_values( by = 'trip_id', ascending = False )"]}, {"cell_type": "code", "execution_count": 1, "id": "e0099a37", "metadata": {}, "outputs": [], "source": ["fig, ax1 = plt.subplots (1,figsize = (10,12))\n\n# figure \"a\" represent number of player heighest\na = sns.barplot (x = most_Start_id.trip_id, y = most_Start_id.from_station_name[:20], ax = ax1 , linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count players depend on height player.\nfor i,j in enumerate(most_Start_id.trip_id[:20]):\n        ax1.text(.7,i+0.08,j,weight = \"bold\", size = 15)\n\na.set_title(\"Top 20 Stations at start Point Distribution\" , weight = 'bold', size = 15)\na.set_xlabel('Total Count', size = 15)\na.set_ylabel(\"Top Station's Distribution\", size = 15)\nplt.xticks([0, 2e4, 4e4, 6e4, 8e4, 1e5], ['0', '20K', '40K','60K', '80K', '100K'])\nplt.show();"]}, {"cell_type": "markdown", "id": "37407dd5", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q11: What's the Top 20 Stations at End Point?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "ee47ad38", "metadata": {}, "outputs": [], "source": ["# combine 2 colums \"to_station_name\" & \"trip_id\" then sort stations desending regarding number of trips results\nmost_End_id = df_All.groupby('to_station_name')['trip_id'].count().reset_index().sort_values( by = 'trip_id', ascending = False )"]}, {"cell_type": "code", "execution_count": 1, "id": "6a50f000", "metadata": {}, "outputs": [], "source": ["fig, ax1 = plt.subplots (1,figsize = (10,12))\n\n# figure \"a\" represent number of player heighest\na = sns.barplot (x = most_End_id.trip_id, y = most_End_id.to_station_name[:20], ax = ax1 , linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count players depend on height player.\nfor i,j in enumerate(most_End_id.trip_id[:20]):\n        ax1.text(.7,i+0.08,j,weight = \"bold\", size = 15)\n\na.set_title(\"Top 20 Stations at End Point Distribution\" , weight = 'bold', size = 15)\na.set_xlabel('Total Count', size = 15)\na.set_ylabel(\"Top Station's Distribution\", size = 15)\nplt.xticks([0, 2e4, 4e4, 6e4, 8e4, 1e5], ['0', '20K', '40K','60K', '80K', '100K'])\nplt.show();"]}, {"cell_type": "markdown", "id": "c5c0d776", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q12: What's the Q10: What's Correlation Between Variables?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "7d7a5eee", "metadata": {}, "outputs": [], "source": ["# get correlation in specific columns\ncorrelation = df_All.corr()\nplt.figure(figsize=(8,8))\n\n# create heatmap plot\nsns.heatmap(correlation,annot=True ,cmap = plt.cm.plasma, linecolor='white', linewidths=2)\nplt.title('Correlation Between Variables')\nplt.show();"]}, {"cell_type": "markdown", "id": "f7e70faf", "metadata": {}, "source": ["><span style=\"color:orange\"><font size=\"3\"> **Q13: Using \"worldcloud\" to print Top stations at Start Point?** </font></span>"]}, {"cell_type": "code", "execution_count": 1, "id": "2fd677ca", "metadata": {}, "outputs": [], "source": ["from wordcloud import WordCloud\n# get player counts value acheived gameId > 32000 \ntop_rate = most_Start_id[most_Start_id.trip_id  > 30000 ]['from_station_name'].value_counts().index\n\n# using bckground\" WorldCloud\nw_c = WordCloud(background_color=\"white\",scale=2).generate(\" \".join(top_rate))\nfig = plt.figure(figsize=(15,8))\n\n# plot show in \"bilionear style\"\nplt.imshow(w_c,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Top stations at Start Point\")\nplt.show();"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}