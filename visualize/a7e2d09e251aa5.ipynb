{"cells": [{"cell_type": "code", "execution_count": 1, "id": "09680c85", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "8cdba10a", "metadata": {}, "outputs": [], "source": ["#Import Libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\n\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\nnp.random.seed(10)\n\n%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "15937c2f", "metadata": {}, "outputs": [], "source": ["#Import Dataset\ntrain_df = pd.read_csv('../input/atm-data/ATM_training.csv')\ntest_df = pd.read_csv('../input/atm-data/ATM_test.csv')"]}, {"cell_type": "markdown", "id": "d432fa30", "metadata": {}, "source": ["# Exploratory Data Analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "36a18355", "metadata": {}, "outputs": [], "source": ["# Histogram of the Dependent Variable\nsns.distplot(train_df['Withdraw']);"]}, {"cell_type": "code", "execution_count": 1, "id": "336ff79e", "metadata": {}, "outputs": [], "source": ["#scatter plot of Shops and Withdraw\nvar = 'Shops'\ndata = pd.concat([train_df['Withdraw'], train_df[var]], axis=1)\ndata.plot.scatter(x=var, y='Withdraw', ylim=(0,150));"]}, {"cell_type": "code", "execution_count": 1, "id": "2c3c4cfe", "metadata": {}, "outputs": [], "source": ["# Box plot of ATMs and Withdraw\nvar = 'ATMs'\ndata = pd.concat([train_df['Withdraw'], train_df[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"Withdraw\", data=data)\nfig.axis(ymin=0, ymax=150);"]}, {"cell_type": "code", "execution_count": 1, "id": "4ddc402e", "metadata": {}, "outputs": [], "source": ["# Boxplot of Weekday and Withdraw\nvar = 'Weekday'\ndata = pd.concat([train_df['Withdraw'], train_df[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"Withdraw\", data=data)\nfig.axis(ymin=0, ymax=150);"]}, {"cell_type": "code", "execution_count": 1, "id": "a6c33f70", "metadata": {}, "outputs": [], "source": ["#skewness and kurtosis\nprint(\"Skewness: %f\" % train_df['Withdraw'].skew())\nprint(\"Kurtosis: %f\" % train_df['Withdraw'].kurt())"]}, {"cell_type": "code", "execution_count": 1, "id": "6c310a0a", "metadata": {}, "outputs": [], "source": ["#correlation matrix\ncorrmat = train_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);"]}, {"cell_type": "code", "execution_count": 1, "id": "64f3e8f5", "metadata": {}, "outputs": [], "source": ["#Withdraw correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'Withdraw')['Withdraw'].index\ncm = np.corrcoef(train_df[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "d8145bb6", "metadata": {}, "outputs": [], "source": ["# Scatter plot\nsns.set()\ncols = ['Shops', 'ATMs', 'Downtown', 'Weekday', 'Center', 'High', 'Withdraw']\nsns.pairplot(train_df[cols], size = 2.5)\nplt.show();"]}, {"cell_type": "code", "execution_count": 1, "id": "8aabddcc", "metadata": {}, "outputs": [], "source": ["# Checking missing data\ntotal = train_df.isnull().sum().sort_values(ascending=False)\npercent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)"]}, {"cell_type": "code", "execution_count": 1, "id": "3dbb5acd", "metadata": {}, "outputs": [], "source": ["#standardizing data\nfrom sklearn.preprocessing import StandardScaler\n\nsaleprice_scaled = StandardScaler().fit_transform(train_df['Withdraw'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)"]}, {"cell_type": "code", "execution_count": 1, "id": "4dcc951e", "metadata": {}, "outputs": [], "source": ["#histogram and normal probability plot\nfrom scipy.stats import norm, stats\nfrom scipy import stats\n\nsns.distplot(train_df['Withdraw'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train_df['Withdraw'], plot=plt)"]}, {"cell_type": "code", "execution_count": 1, "id": "32c6f1b2", "metadata": {}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "97eb3773", "metadata": {}, "outputs": [], "source": ["matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\nprices = pd.DataFrame({\"Withdraw\":train_df[\"Withdraw\"], \"log(Withdraw + 1)\":np.log1p(train_df[\"Withdraw\"])})\nprices.hist()"]}, {"cell_type": "code", "execution_count": 1, "id": "fa724029", "metadata": {}, "outputs": [], "source": ["all_data = pd.concat((train_df.loc[:,'Shops':'High'],\n                      test_df.loc[:,'Shops':'High']))"]}, {"cell_type": "code", "execution_count": 1, "id": "b5c35dc8", "metadata": {}, "outputs": [], "source": ["#log transform the target:\ntrain_df[\"Withdraw\"] = np.log1p(train_df[\"Withdraw\"])\n\n#log transform skewed numeric features:\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\nskewed_feats = train_df[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])"]}, {"cell_type": "code", "execution_count": 1, "id": "0d2fd937", "metadata": {}, "outputs": [], "source": ["all_data = pd.get_dummies(all_data)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "971e256b", "metadata": {}, "outputs": [], "source": ["all_data.head()"]}, {"cell_type": "markdown", "id": "7e56e3e4", "metadata": {}, "source": ["# Ridge Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "6366e724", "metadata": {}, "outputs": [], "source": ["#creating matrices for sklearn:\nX_train = all_data[:train_df.shape[0]]\nX_test = all_data[train_df.shape[0]:]\ny = train_df.Withdraw\ny_test = test_df.iloc[:,-1]"]}, {"cell_type": "code", "execution_count": 1, "id": "d88af45b", "metadata": {}, "outputs": [], "source": ["# Import libraries for Logic-based algorithms\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import mean_absolute_error, explained_variance_score\nfrom sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV, Lasso\nfrom sklearn.model_selection import cross_val_score\nimport lightgbm as lgb\nfrom sklearn.kernel_ridge import KernelRidge\n\ndef mse_cv(model):\n    mse= -cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5)\n    return(mse)"]}, {"cell_type": "code", "execution_count": 1, "id": "c92b724f", "metadata": {}, "outputs": [], "source": ["# Cross validation and hyperparmater tuning for ridge regression so we can visualize\n# MSE in a plot\nalphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [mse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]"]}, {"cell_type": "code", "execution_count": 1, "id": "b8fb327e", "metadata": {}, "outputs": [], "source": ["# Plot MSE mean for each cross validation and hyperparameter\ncv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Hypertuning-Ridge Regression\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"MSE\")"]}, {"cell_type": "code", "execution_count": 1, "id": "e150a7ce", "metadata": {}, "outputs": [], "source": ["cv_ridge.min()"]}, {"cell_type": "code", "execution_count": 1, "id": "69c93092", "metadata": {}, "outputs": [], "source": ["# Fit ridge regression cross validation\nmodel_ridge = RidgeCV(alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]).fit(X_train, y)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0e27e1b2", "metadata": {}, "outputs": [], "source": ["# predict on test set\npred_ridge_all =  np.expm1(model_ridge.predict(X_test))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "11939c9c", "metadata": {}, "outputs": [], "source": ["# compare to true results\nmse = MSE(y_test, pred_ridge_all)\nprint(\"MSE : % f\" %(mse))"]}, {"cell_type": "code", "execution_count": 1, "id": "a9c3d0eb", "metadata": {}, "outputs": [], "source": ["# Check differences between true value and predicted value\ndifference = y_test - pred_ridge_all"]}, {"cell_type": "code", "execution_count": 1, "id": "a350105a", "metadata": {}, "outputs": [], "source": ["data = {'y_test': y_test, 'values': pred_ridge_all, 'Error': difference}\ndf = pd.DataFrame(data=data)\ndf"]}, {"cell_type": "code", "execution_count": 1, "id": "39427738", "metadata": {}, "outputs": [], "source": ["abs(df['Error']).min(), abs(df['Error']).max()"]}, {"cell_type": "code", "execution_count": 1, "id": "d7be83af", "metadata": {}, "outputs": [], "source": ["# plot coefficients\ncoef = pd.Series(model_ridge.coef_, index = X_train.columns)\nprint(\"Ridge picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\nimp_coef = pd.concat([coef.sort_values().head(10)])\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Ridge Model\")"]}, {"cell_type": "markdown", "id": "9f97179b", "metadata": {}, "source": ["# LASSO"]}, {"cell_type": "code", "execution_count": 1, "id": "4af97711", "metadata": {}, "outputs": [], "source": ["# Cross validation and hyperparmater tuning for LASSO regression so we can visualize\n# MSE in a plot\nalphas = [1, 0.1, 0.001, 0.0005]\ncv_lasso = [mse_cv(Lasso(alpha = alpha)).mean() \n            for alpha in alphas]"]}, {"cell_type": "code", "execution_count": 1, "id": "f2704993", "metadata": {}, "outputs": [], "source": ["# Plot MSE mean for each cross validation and hyperparameter\ncv_lasso = pd.Series(cv_lasso, index = alphas)\ncv_lasso.plot(title = \"Hypertuning-Lasso\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"MSE\")"]}, {"cell_type": "code", "execution_count": 1, "id": "99f5d208", "metadata": {}, "outputs": [], "source": ["cv_lasso.min()"]}, {"cell_type": "code", "execution_count": 1, "id": "9f3274bf", "metadata": {}, "outputs": [], "source": ["# Fit LASSO regression cross validation\nmodel_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "f16c254b", "metadata": {}, "outputs": [], "source": ["mse_cv(model_lasso).mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "464b9818", "metadata": {}, "outputs": [], "source": ["coef = pd.Series(model_lasso.coef_, index = X_train.columns)"]}, {"cell_type": "code", "execution_count": 1, "id": "86b70663", "metadata": {}, "outputs": [], "source": ["print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"]}, {"cell_type": "code", "execution_count": 1, "id": "0fd59fdf", "metadata": {}, "outputs": [], "source": ["imp_coef = pd.concat([coef.sort_values().head(10)])"]}, {"cell_type": "code", "execution_count": 1, "id": "ef632b29", "metadata": {}, "outputs": [], "source": ["# visualize the weighted coefficients\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")"]}, {"cell_type": "code", "execution_count": 1, "id": "9c808a6f", "metadata": {}, "outputs": [], "source": ["#let's look at the residuals as well:\nmatplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n\npreds = pd.DataFrame({\"preds\":model_lasso.predict(X_train), \"true\":y})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4306a33a", "metadata": {}, "outputs": [], "source": ["# Predict using LASSO on test set\nlasso_preds = np.expm1(model_lasso.predict(X_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "774727f5", "metadata": {}, "outputs": [], "source": ["# Calculate MSE for test set\nmse = MSE(y_test, lasso_preds)\nprint(\"MSE : % f\" %(mse))"]}, {"cell_type": "code", "execution_count": 1, "id": "f799b32b", "metadata": {}, "outputs": [], "source": ["min(abs(y_test - lasso_preds)), max(abs(y_test - lasso_preds))"]}, {"cell_type": "markdown", "id": "c3c5910a", "metadata": {}, "source": ["# ANN"]}, {"cell_type": "code", "execution_count": 1, "id": "ef4a5d5e", "metadata": {}, "outputs": [], "source": ["# Import for ANN\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.regularizers import l1\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split"]}, {"cell_type": "code", "execution_count": 1, "id": "89bb4746", "metadata": {}, "outputs": [], "source": ["#creating matrices for sklearn:\nX_train = all_data[:train_df.shape[0]]\nX_test = all_data[train_df.shape[0]:]\ny_train = train_df.Withdraw\ny_test = test_df.iloc[:,-1]"]}, {"cell_type": "code", "execution_count": 1, "id": "ba710636", "metadata": {}, "outputs": [], "source": ["# Scaler Transform\nscalerX = StandardScaler().fit(X_train)\nscalery = StandardScaler().fit(pd.array(y_train).reshape(-1, 1))\nX_train = scalerX.transform(X_train)\ny_train = scalery.transform(pd.array(y_train).reshape(-1, 1))"]}, {"cell_type": "code", "execution_count": 1, "id": "742f3335", "metadata": {}, "outputs": [], "source": ["X_train, X_val, y_train, y_val = train_test_split(X_train, y, random_state = 3, train_size = 0.8)"]}, {"cell_type": "code", "execution_count": 1, "id": "df8910f6", "metadata": {}, "outputs": [], "source": ["# Creating the model\nmodel = Sequential()\n\n# input layer\nmodel.add(Dense(19,activation='relu'))\n\n# hidden layers\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\n\n# output layer\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam',loss='mse')"]}, {"cell_type": "code", "execution_count": 1, "id": "1cfbc61f", "metadata": {}, "outputs": [], "source": ["hist = model.fit(X_train, y_train, validation_data = (X_val, y_val))"]}, {"cell_type": "code", "execution_count": 1, "id": "0774ab7c", "metadata": {}, "outputs": [], "source": ["pd.Series(model.predict(X_test)[:,0]).hist()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "f5957503", "metadata": {}, "outputs": [], "source": ["predictions = pd.Series(model.predict(X_test)[:,0])\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e32bc6db", "metadata": {}, "outputs": [], "source": ["predictions = scalery.inverse_transform(predictions)"]}, {"cell_type": "code", "execution_count": 1, "id": "951520ab", "metadata": {}, "outputs": [], "source": ["# predictions on the test set\n\nprint('MAE: ',mean_absolute_error(y_test,predictions))\nprint('MSE: ',MSE(y_test,predictions))\nprint('RMSE: ',np.sqrt(MSE(y_test,predictions)))\nprint('Variance Regression Score: ',explained_variance_score(y_test,predictions))\n\nprint('\\n\\nDescriptive Statistics:\\n',train_df['Withdraw'].describe())"]}, {"cell_type": "code", "execution_count": 1, "id": "3e8f0297", "metadata": {}, "outputs": [], "source": ["f, axes = plt.subplots(1, 2,figsize=(15,5))\n\n# Our model predictions\nplt.scatter(y_test,predictions)\n\n# Perfect predictions\nplt.plot(y_test,y_test,'r')\n\nerrors = y_test.values.reshape(20, 1) - predictions\nsns.distplot(errors, ax=axes[0])\n\nsns.despine(left=True, bottom=True)\naxes[0].set(xlabel='Error', ylabel='', title='Error Histogram')\naxes[1].set(xlabel='Test True Y', ylabel='Model Predictions', title='Model Predictions vs Perfect Fit')"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}