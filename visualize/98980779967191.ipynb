{"cells": [{"cell_type": "markdown", "id": "585d37ce", "metadata": {}, "source": ["# Changelog:\n\n* 14 september 2020: Submitted notebook\n* 15 september 2020: Changed title and minor fix. (notebook re-runned)\n* 15 september 2020: Improved confusion matrix graphs to exclude invalid features"]}, {"cell_type": "code", "execution_count": 1, "id": "ae24c72f", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom scipy import stats\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "d5208629", "metadata": {}, "outputs": [], "source": ["bcell_data = pd.read_csv(r'/kaggle/input/epitope-prediction/input_bcell.csv')\nsars_data = pd.read_csv(r'/kaggle/input/epitope-prediction/input_sars.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "c2f7658f", "metadata": {}, "outputs": [], "source": ["bcell_data.head()"]}, {"cell_type": "markdown", "id": "8075ff87", "metadata": {}, "source": ["# Simple feature engineering"]}, {"cell_type": "code", "execution_count": 1, "id": "d60124d8", "metadata": {}, "outputs": [], "source": ["bcell_data['peptide_length'] = bcell_data.end_position - bcell_data.start_position \nsars_data['peptide_length'] = sars_data.end_position - sars_data.start_position\n\nbcell_data['protein_length'] = bcell_data['protein_seq'].astype(str).map(len)\nsars_data['protein_length'] = sars_data['protein_seq'].astype(str).map(len)\n\nbcell_data['parent_protein_length'] = bcell_data['parent_protein_id'].astype(str).map(len)\nsars_data['parent_protein_length'] = sars_data['parent_protein_id'].astype(str).map(len)\n\nbcell_data['peptide_position_inprotein'] = bcell_data['start_position'] / bcell_data['protein_seq'].astype(str).map(len)\nsars_data['peptide_position_inprotein'] = sars_data['start_position'] / sars_data['protein_seq'].astype(str).map(len)"]}, {"cell_type": "markdown", "id": "b1fa2109", "metadata": {}, "source": ["# Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "b588b500", "metadata": {}, "outputs": [], "source": ["bcell_data_train, bcell_data_test = train_test_split(bcell_data, test_size=0.2, random_state=None)"]}, {"cell_type": "code", "execution_count": 1, "id": "7d2c4806", "metadata": {}, "outputs": [], "source": ["features = ['chou_fasman', 'kolaskar_tongaonkar', 'parker',\n       'isoelectric_point', 'aromaticity', 'hydrophobicity', 'stability',\n       'peptide_length']"]}, {"cell_type": "code", "execution_count": 1, "id": "6cb9dde7", "metadata": {}, "outputs": [], "source": ["X_train = bcell_data_train[features]\ny_train = bcell_data_train.target\nX_val = bcell_data_test[features]\ny_val = bcell_data_test.target\n\nsars_X = sars_data[features]\nsars_y = sars_data.target"]}, {"cell_type": "markdown", "id": "08e85c69", "metadata": {}, "source": ["# Model Building"]}, {"cell_type": "code", "execution_count": 1, "id": "ce86ba9d", "metadata": {}, "outputs": [], "source": ["params = {\n    \"n_estimators\" : 1000,\n    \"n_jobs\" : 4,\n    \"verbose\" : 1,\n    \"criterion\" : \"entropy\",\n    \"random_state\" : None,\n    \"min_samples_split\" : 8,\n    \"min_weight_fraction_leaf\" : 0.0,\n    \"max_features\" : \"sqrt\",\n    \"bootstrap\" : True,\n    \"oob_score\" : True,\n    \"class_weight\" : \"balanced\"\n}"]}, {"cell_type": "code", "execution_count": 1, "id": "dcb5a808", "metadata": {}, "outputs": [], "source": ["model = RandomForestClassifier(**params)"]}, {"cell_type": "code", "execution_count": 1, "id": "8061dc12", "metadata": {}, "outputs": [], "source": ["model.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "94c6e4ff", "metadata": {}, "outputs": [], "source": ["bcell_predictions = model.predict(X_val)\nsars_predictions = model.predict(sars_data[features])"]}, {"cell_type": "markdown", "id": "9d985304", "metadata": {}, "source": ["# Post-prediction analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "d4318c08", "metadata": {}, "outputs": [], "source": ["#confusion matrix\nplt.figure(figsize = (10,10))\ncm = confusion_matrix(y_val, bcell_predictions)\nsns.heatmap(cm,cmap= \"Blues\", linecolor = 'black', linewidth = 1, annot = True, fmt='', \n            xticklabels = ['False', 'True'], yticklabels = ['False', 'True'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")"]}, {"cell_type": "code", "execution_count": 1, "id": "7db9c9aa", "metadata": {}, "outputs": [], "source": ["#confusion matrix\nplt.figure(figsize = (10,10))\ncm = confusion_matrix(sars_data.target, sars_predictions)\nsns.heatmap(cm,cmap= \"Blues\", linecolor = 'black', linewidth = 1, annot = True, fmt='', \n            xticklabels = ['False', 'True'], yticklabels = ['False', 'True'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4320e284", "metadata": {}, "outputs": [], "source": ["sars_data['status'] = 'NoStatus'\nsars_data['status'][(sars_data.target == sars_predictions) & (sars_data.target == 1)] = 'True_Positive'\nsars_data['status'][(sars_data.target != sars_predictions) & (sars_data.target == 1)] = 'False_Positive' \nsars_data['status'][(sars_data.target == sars_predictions) & (sars_data.target == 0)] = 'True_Negative'\nsars_data['status'][(sars_data.target != sars_predictions) & (sars_data.target == 0)] = 'False_Negative'\n\nconfusionMatrixCols = ['True_Positive', 'False_Negative', 'True_Negative', 'False_Positive']"]}, {"cell_type": "code", "execution_count": 1, "id": "d82d763b", "metadata": {}, "outputs": [], "source": ["#Some features are excluded here because all values are the same.\n\nfor feature in features:\n    if sars_data[feature].min() != sars_data[feature].max():\n        try: \n            plt.figure(figsize=(16,5))\n\n            for cm in confusionMatrixCols:\n                \n                subset = sars_data[sars_data['status'] == cm]\n\n                sns.distplot(subset[feature], hist = False, kde = True,\n                             kde_kws = {'linewidth': 2},\n                             label = cm)\n                \n            plt.legend(prop={'size': 16}, title = 'status')\n            plt.xlabel(feature)\n            plt.ylabel('Density')\n        except:\n            pass"]}, {"cell_type": "code", "execution_count": 1, "id": "740e7c4d", "metadata": {}, "outputs": [], "source": ["print(f\"Bcell prediction accuracy score: {accuracy_score(bcell_predictions, y_val)}\")\nprint(f\"SARS prediction accuracy score: {accuracy_score(sars_predictions, sars_data.target)}\")"]}, {"cell_type": "markdown", "id": "4788aa3d", "metadata": {}, "source": ["# Conclusion\n\nIn conclusion, without too much effort and the right features a nice accuracy is easily achievable.\nThis is my first submission/notebook on this topic. The next problem I'll have too solve is the great amout of false positives,\nany tips are welcome! If anyone is interested in how I selected my features leave a comment please.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}