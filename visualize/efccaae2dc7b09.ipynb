{"cells": [{"cell_type": "markdown", "id": "a7a9d5d6", "metadata": {}, "source": ["# Try using Keras"]}, {"cell_type": "markdown", "id": "683eedfb", "metadata": {}, "source": ["### Imports"]}, {"cell_type": "code", "execution_count": 1, "id": "09c1bfa3", "metadata": {}, "outputs": [], "source": ["from keras.utils import to_categorical\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.regularizers import l2"]}, {"cell_type": "markdown", "id": "6fb4f3e1", "metadata": {}, "source": ["### Read the dataframe"]}, {"cell_type": "code", "execution_count": 1, "id": "f5547958", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\ntest= pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "64413649", "metadata": {}, "outputs": [], "source": ["#Define the target and the features\nx_train = train.drop(columns=['label'])\ny_train = train.label\n\nx_test = test.drop(columns=['label'])\ny_test = test.label"]}, {"cell_type": "code", "execution_count": 1, "id": "f4ac4b89", "metadata": {}, "outputs": [], "source": ["#Print the shape of target\ny_train.shape , y_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "feaa3861", "metadata": {}, "outputs": [], "source": ["#Print the number of class in the train target\nlist(y_train.unique())"]}, {"cell_type": "code", "execution_count": 1, "id": "e7d0f5f0", "metadata": {}, "outputs": [], "source": ["#Print the number of class in the test target\nlist(y_test.unique())"]}, {"cell_type": "markdown", "id": "2326693d", "metadata": {}, "source": ["### Scale Pixel image\nFirst off all, let's identify that the max number in pixel image\n\nSo, after that I'll divide the target by this number to scale the target in this model"]}, {"cell_type": "code", "execution_count": 1, "id": "9cb7d994", "metadata": {}, "outputs": [], "source": ["x_train.max().sort_values().tail(1)"]}, {"cell_type": "code", "execution_count": 1, "id": "a1ba3f49", "metadata": {}, "outputs": [], "source": ["x_test.max().sort_values().tail(1)"]}, {"cell_type": "code", "execution_count": 1, "id": "ae0e7aad", "metadata": {}, "outputs": [], "source": ["#The max number is 255, so lets divide the target by this number\nx_train = x_train/255\nx_test = x_test/255"]}, {"cell_type": "markdown", "id": "cd59cc24", "metadata": {}, "source": ["### Transform features in float\nAfter scaling the target let's transform the feature in float in order to reduce the risk of It converting in integer number "]}, {"cell_type": "code", "execution_count": 1, "id": "148e8987", "metadata": {}, "outputs": [], "source": ["x_train = x_train.astype(float) \nx_test = x_test.astype(float)"]}, {"cell_type": "code", "execution_count": 1, "id": "eafc692e", "metadata": {}, "outputs": [], "source": ["#Finally, lets get dummies of the target using the function presents in keras\nfrom keras.utils import to_categorical\n\ny_train = to_categorical(y_train,10) #10 levels of image\ny_test =  to_categorical(y_test,10) #10 levels of image"]}, {"cell_type": "markdown", "id": "2c09cfe0", "metadata": {}, "source": ["### Applying Deep learning model to predict the image"]}, {"cell_type": "code", "execution_count": 1, "id": "7eee09a4", "metadata": {}, "outputs": [], "source": ["#Starting a neural network\nmodelo = Sequential()\n\n#Input the first layer in model with 50 neurals and the activation function will be Relu\nmodelo.add(Dense(50 #number os neurals\n                ,activation = 'relu' #activation function\n                ,input_shape = (784,) #Number of features in dataframe, let's pay attention, because keras need to receive a tuple, its the reason of (784,0)\n                ,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n                ))\n\n#Input the second layer in model with 50 neurals and the same activation function\nmodelo.add(Dense(30 \n                ,activation = 'relu' \n                ,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) \n                ))\n\n#Input the third layer in model with 20 neurals and the same activation function\nmodelo.add(Dense(20\n                ,activation = 'relu' \n                ,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) \n                ))\n\n#The final layes will be with 10 neurals because we have 10 class in this dataframe\n#The activation function is softmax because its will be normalize the output of neurals and it will be easier identify the probably of each class\nmodelo.add(Dense(10 #numero de classs\n                ,activation = 'softmax' #Vai normaliza as probabilidades por exponencial\n                ))\n\n#Finally, lets see the summary of the model and see how many parameters its have.\nmodelo.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "c3d0289c", "metadata": {}, "outputs": [], "source": ["#I use the croos entropy, because its penalty high error for bad clasification and a loss error for good erro, its a commum metric using in classification problems\nmodelo.compile(\n                loss='categorical_crossentropy' \n               ,optimizer='adam' \n               ,metrics=['accuracy'] )"]}, {"cell_type": "code", "execution_count": 1, "id": "70af7d15", "metadata": {}, "outputs": [], "source": ["history = modelo.fit(x_train,y_train\n         ,epochs=30 #number of times that model will through in train \n         ,batch_size = 128 #number of rows that will be consider to update the weights of layers\n         ,verbose = 1\n         ,validation_data=(x_test,y_test)\n         )"]}, {"cell_type": "code", "execution_count": 1, "id": "4265ed3c", "metadata": {}, "outputs": [], "source": ["#Print loss and accuracy\nmodelo.evaluate(x_test,y_test,verbose = 0)"]}, {"cell_type": "markdown", "id": "06df211d", "metadata": {}, "source": ["### PLotting the accuracy and loss during the increment of epochs"]}, {"cell_type": "code", "execution_count": 1, "id": "b2037d3a", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(13, 8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "8b08f742", "metadata": {}, "outputs": [], "source": ["plt.subplots(figsize=(13, 8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()"]}, {"cell_type": "markdown", "id": "a5c4ba6c", "metadata": {}, "source": ["### Classification report of each class"]}, {"cell_type": "code", "execution_count": 1, "id": "19ddf697", "metadata": {}, "outputs": [], "source": ["#Predict the x_test\np = modelo.predict(x_test)\np = (p > 0.5)\nprint('ACC: %.3f%%' % (accuracy_score(y_test, p)*100))\nprint('---------')\nprint(classification_report(y_test, p))"]}, {"cell_type": "markdown", "id": "ee684483", "metadata": {}, "source": ["# Try to do the same model in Scikit-learn"]}, {"cell_type": "code", "execution_count": 1, "id": "b8848bd5", "metadata": {}, "outputs": [], "source": ["from sklearn.neural_network import MLPClassifier\nmodel = MLPClassifier(hidden_layer_sizes=(50,30,20) #define 3 layers with 50, 30 and 20 neurals\n                      , batch_size=32 #Define the same bacth_size\n                      , solver = 'adam' #Define the optimization\n                      ,activation='relu' #Activation function\n                      , max_iter=30 #Number of epochs\n                      ,verbose=1\n                      , random_state=42)\n\nmodel.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "c2d80b50", "metadata": {}, "outputs": [], "source": ["#Print the accuracy\nprint('Accuracy:', model.score(x_test, y_test))"]}, {"cell_type": "markdown", "id": "854216ff", "metadata": {}, "source": ["### PLotting the loss during the increment of epochs"]}, {"cell_type": "code", "execution_count": 1, "id": "80d084a7", "metadata": {}, "outputs": [], "source": ["plt.rcParams['figure.figsize'] = 10, 10\n\nplt.plot(list(range(len(model.loss_curve_))), model.loss_curve_)"]}, {"cell_type": "code", "execution_count": 1, "id": "0cbbb763", "metadata": {}, "outputs": [], "source": ["#Predict the x_test\np = model.predict(x_test)\np = (p > 0.5)\nprint('ACC: %.3f%%' % (accuracy_score(y_test, p)*100))\nprint('---------')\nprint(classification_report(y_test, p))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}