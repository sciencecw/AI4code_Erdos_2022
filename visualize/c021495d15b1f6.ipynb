{"cells": [{"cell_type": "markdown", "id": "5d9db2f5", "metadata": {}, "source": [" Private Score = 0.95075"]}, {"cell_type": "markdown", "id": "bdadea40", "metadata": {}, "source": ["\u0e2a\u0e21\u0e32\u0e0a\u0e34\u0e01   \n6220422022\t\u0e19\u0e20\u0e31\u0e2a\u0e2a\u0e23\t\u0e15\u0e31\u0e19\u0e15\u0e32\u0e28\u0e19\u0e35   \n6220422053\t\u0e01\u0e0a\u0e01\u0e23\t\u0e2a\u0e23\u0e32\u0e27\u0e38\u0e12\u0e34\u0e19\u0e31\u0e19\u0e17\u0e4c\t   \n6220422054\t\u0e20\u0e32\u0e04\u0e20\u0e39\u0e21\u0e34\t\u0e40\u0e25\u0e34\u0e28\u0e2a\u0e27\u0e31\u0e2a\u0e14\u0e34\u0e4c\u0e27\u0e34\u0e0a\u0e32\t \n6310422077\t\u0e42\u0e2a\u0e27\u0e23\u0e23\u0e13\t\u0e22\u0e38\u0e17\u0e18\u0e22\u0e37\u0e19\u0e22\u0e07\t "]}, {"cell_type": "code", "execution_count": 1, "id": "dfc2fb53", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom scipy.stats import uniform, randint\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nimport xgboost as xgb\nfrom sklearn.impute import KNNImputer\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom xgboost import plot_tree\n\ndef one_hot(X):\n    return pd.get_dummies(X)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "5679e340", "metadata": {}, "source": ["# 1. Collect Date"]}, {"cell_type": "code", "execution_count": 1, "id": "5a015e70", "metadata": {}, "outputs": [], "source": ["#1. Data collection\n# Read CSV train data file into DataFrame\ntrain_df = pd.read_csv(\"../input/nida-competition1/train.csv\")\n\n# Read CSV test data file into DataFrame\ntest_df = pd.read_csv(\"../input/nida-competition1/test.csv\")\n\n# preview train data\ntrain_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d3c3be89", "metadata": {}, "outputs": [], "source": ["train_df.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "485c4634", "metadata": {}, "outputs": [], "source": ["train_df.describe(include=['O'])"]}, {"cell_type": "markdown", "id": "50df1eba", "metadata": {}, "source": ["# 2. Cleaning Data"]}, {"cell_type": "code", "execution_count": 1, "id": "ee623fce", "metadata": {}, "outputs": [], "source": ["train_df = train_df.replace('unknown',np.nan)\ntest_df = test_df.replace('unknown',np.nan)\n\ntrain_df[\"y\"] = train_df[\"y\"].replace(\"no\",0)\ntrain_df[\"y\"] = train_df[\"y\"].replace(\"yes\",1)\n\ntrain_df.isnull().sum()"]}, {"cell_type": "markdown", "id": "7bd9a348", "metadata": {}, "source": ["2.1 marital"]}, {"cell_type": "code", "execution_count": 1, "id": "88dcd22a", "metadata": {}, "outputs": [], "source": ["train_df['marital'] = train_df['marital'].replace(np.nan,'unknown')\ntest_df['marital'] = test_df['marital'].replace(np.nan,'unknown')\n\ntrain_df[['marital', 'y']].groupby(['marital'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "23934edb", "metadata": {}, "outputs": [], "source": ["freq = train_df.marital.dropna().mode()[0]\nfreq"]}, {"cell_type": "code", "execution_count": 1, "id": "f591fd0d", "metadata": {}, "outputs": [], "source": ["train_df['marital'] = train_df['marital'].replace('unknown','married')\ntest_df['marital'] = test_df['marital'].replace('unknown','married')\n\ntrain_df[['marital', 'y']].groupby(['marital'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "markdown", "id": "52760485", "metadata": {}, "source": ["2.2 job"]}, {"cell_type": "code", "execution_count": 1, "id": "2230a33e", "metadata": {}, "outputs": [], "source": ["train_df['job'] = train_df['job'].replace(np.nan,'unknown')\ntest_df['job'] = test_df['job'].replace(np.nan,'unknown')\n\ntrain_df[['job', 'y']].groupby(['job'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "45bb766a", "metadata": {}, "outputs": [], "source": ["freq = train_df.job.dropna().mode()[0]\nfreq"]}, {"cell_type": "code", "execution_count": 1, "id": "e002546b", "metadata": {}, "outputs": [], "source": ["train_df['job'] = train_df['job'].replace('unknown','admin.')\ntest_df['job'] = test_df['job'].replace('unknown','admin.')\n\ntrain_df[['job', 'y']].groupby(['job'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "9636cb63", "metadata": {}, "outputs": [], "source": ["train_df[['job', 'y']].groupby(['job'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "bfb8b5d0", "metadata": {}, "outputs": [], "source": ["combine = [train_df, test_df]"]}, {"cell_type": "markdown", "id": "b2090242", "metadata": {}, "source": ["2.3 education"]}, {"cell_type": "code", "execution_count": 1, "id": "3472b4c3", "metadata": {}, "outputs": [], "source": ["train_df['education'] = train_df['education'].replace(np.nan,'unknown')\ntest_df['education'] = test_df['education'].replace(np.nan,'unknown')\n\ntrain_df[['education', 'y']].groupby(['education'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "94a2acd0", "metadata": {}, "outputs": [], "source": ["train_df['education'] = train_df['education'].replace('unknown',np.nan)\ntest_df['education'] = test_df['education'].replace('unknown',np.nan)\n\nfreq = train_df.education.dropna().mode()[0]\nfreq"]}, {"cell_type": "code", "execution_count": 1, "id": "d53b3ff2", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['education'] = dataset['education'].fillna(freq)\n    \ntrain_df[['education', 'y']].groupby(['education'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "b0f8b1b9", "metadata": {}, "outputs": [], "source": ["combine = [train_df, test_df]"]}, {"cell_type": "markdown", "id": "510f20a2", "metadata": {}, "source": ["2.4 housing"]}, {"cell_type": "code", "execution_count": 1, "id": "3e9347f2", "metadata": {}, "outputs": [], "source": ["train_df['housing'] = train_df['housing'].replace(np.nan,'unknown')\ntest_df['housing'] = test_df['housing'].replace(np.nan,'unknown')\n\ntrain_df[['housing', 'y']].groupby(['housing'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "8ca8bcaf", "metadata": {}, "outputs": [], "source": ["train_df['housing'] = train_df['housing'].replace('unknown',np.nan)\ntest_df['housing'] = test_df['housing'].replace('unknown',np.nan)\n\nfreq = train_df.housing.dropna().mode()[0]\nfreq"]}, {"cell_type": "code", "execution_count": 1, "id": "bade73db", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['housing'] = dataset['housing'].fillna(freq)\n    \ntrain_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "2132f5c5", "metadata": {}, "outputs": [], "source": ["train_df[['housing', 'y']].groupby(['housing'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "markdown", "id": "6d1b82d9", "metadata": {}, "source": ["2.4 loan"]}, {"cell_type": "code", "execution_count": 1, "id": "30e71d09", "metadata": {}, "outputs": [], "source": ["train_df['loan'] = train_df['loan'].replace(np.nan,'unknown')\ntest_df['loan'] = test_df['loan'].replace(np.nan,'unknown')\n\n\ntrain_df[['loan', 'y']].groupby(['loan'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "cc74d8f0", "metadata": {}, "outputs": [], "source": ["train_df['loan'] = train_df['loan'].replace('unknown',np.nan)\ntest_df['loan'] = test_df['loan'].replace('unknown',np.nan)\n\nfreq = train_df.loan.dropna().mode()[0]\nfreq"]}, {"cell_type": "code", "execution_count": 1, "id": "d634fcba", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['loan'] = dataset['loan'].fillna(freq)\n    \ntrain_df[['loan', 'y']].groupby(['loan'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "markdown", "id": "f8dd93d3", "metadata": {}, "source": ["2.5 default   \nDrop Default \u0e40\u0e19\u0e37\u0e48\u0e2d\u0e07\u0e08\u0e32\u0e01 \u0e21\u0e35 Missing Data \u0e40\u0e22\u0e2d\u0e30"]}, {"cell_type": "code", "execution_count": 1, "id": "2acf848e", "metadata": {}, "outputs": [], "source": ["train_df = train_df.drop(columns='default')\ntest_df = test_df.drop(columns='default')"]}, {"cell_type": "markdown", "id": "ca65c960", "metadata": {}, "source": ["\u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a Missing data"]}, {"cell_type": "code", "execution_count": 1, "id": "ece9eb4b", "metadata": {}, "outputs": [], "source": ["train_df.isnull().sum()"]}, {"cell_type": "markdown", "id": "8edb0cf0", "metadata": {}, "source": ["# 3. Feature Engineering"]}, {"cell_type": "markdown", "id": "1f90b51b", "metadata": {}, "source": ["3.1 Age"]}, {"cell_type": "code", "execution_count": 1, "id": "6e997bd7", "metadata": {}, "outputs": [], "source": ["combine = [train_df, test_df]\n\ntrain_df['AgeBand'] = pd.cut(train_df['age'], 6)\ntrain_df[['AgeBand', 'y']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "4371ea71", "metadata": {}, "outputs": [], "source": ["for dataset in combine:    \n    dataset.loc[ dataset['age'] <= 30.5, 'age'] = 0\n    dataset.loc[(dataset['age'] > 30.5) & (dataset['age'] <= 44), 'age'] = 1\n    dataset.loc[(dataset['age'] > 44) & (dataset['age'] <= 57.5), 'age'] = 2\n    dataset.loc[(dataset['age'] > 57.5) & (dataset['age'] <= 71), 'age'] = 3\n    dataset.loc[(dataset['age'] > 71) & (dataset['age'] <= 84.5), 'age'] = 4\n    dataset.loc[ dataset['age'] > 84.5, 'age'] = 5\n\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "75bea2a8", "metadata": {}, "source": ["3.2 Job"]}, {"cell_type": "code", "execution_count": 1, "id": "5f09af6f", "metadata": {}, "outputs": [], "source": ["train_df[['job', 'y']].groupby(['job'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "8d3532c0", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['job'] = dataset['job'].map( {'student': 0, 'retired': 1, 'unemployed': 2,'admin.': 3,'self-employed' :4,'technician':5,'management':6,'housemaid':7,'entrepreneur':8,'services':9,'blue-collar':10} )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "1255154a", "metadata": {}, "source": ["3.3 contact"]}, {"cell_type": "code", "execution_count": 1, "id": "d6346c9b", "metadata": {}, "outputs": [], "source": ["train_df[['contact', 'y']].groupby(['contact'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "bedb5fc5", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['contact'] = dataset['contact'].map( {'cellular': 0, 'telephone': 1} )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "692f5a5f", "metadata": {}, "source": ["3.4 month"]}, {"cell_type": "code", "execution_count": 1, "id": "b453fc40", "metadata": {}, "outputs": [], "source": ["train_df[['month', 'y']].groupby(['month'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "43fb2a9c", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['month'] = dataset['month'].map( {'dec': 4, 'nov':4,'oct':4,'mar': 1,'jan':1,'feb':1,'aug':5,'sep':3,'jun':2,'jul':3,'apr':3,'may':2} )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "a1a94520", "metadata": {}, "source": ["3.5 day_of_week"]}, {"cell_type": "code", "execution_count": 1, "id": "53c29bd0", "metadata": {}, "outputs": [], "source": ["train_df[['day_of_week', 'y']].groupby(['day_of_week'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "ae328327", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['day_of_week'] = dataset['day_of_week'].map( {'thu': 0, 'wed': 1,'tue':2,'fri':3,'mon':4} )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "681b22b1", "metadata": {}, "source": ["3.6 poutcome"]}, {"cell_type": "code", "execution_count": 1, "id": "13a3733f", "metadata": {}, "outputs": [], "source": ["train_df[['poutcome', 'y']].groupby(['poutcome'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "233b09b4", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['poutcome'] = dataset['poutcome'].map( {'success': 2, 'failure': 1, 'nonexistent': 0} )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "9aafa886", "metadata": {}, "source": ["3.8 marital"]}, {"cell_type": "code", "execution_count": 1, "id": "69c7d52c", "metadata": {}, "outputs": [], "source": ["train_df[['marital', 'y']].groupby(['marital'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "3379686a", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['marital'] = dataset['marital'].map( {'single': 1, 'divorced': 0, 'married':0 } )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "024ce831", "metadata": {}, "source": ["3.9 education"]}, {"cell_type": "code", "execution_count": 1, "id": "a0ee11f0", "metadata": {}, "outputs": [], "source": ["train_df[['education', 'y']].groupby(['education'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "718bd1ee", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['education'] = dataset['education'].map( {'university.degree': 6, 'illiterate': 5, 'professional.course': 4,'high.school': 3,'basic.4y' :2,'basic.6y':1,'basic.9y':0} )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "4fcf2a05", "metadata": {}, "source": ["3.10 previous"]}, {"cell_type": "code", "execution_count": 1, "id": "208ef28f", "metadata": {}, "outputs": [], "source": ["train_df[['previous', 'y']].groupby(['previous'], as_index=False).mean().sort_values(by='y', ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "a79c7732", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['previous'] = dataset['previous'].replace(7, -1)\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "31a66101", "metadata": {}, "source": ["3.11 loan"]}, {"cell_type": "code", "execution_count": 1, "id": "c0a45beb", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['loan'] = dataset['loan'].map( {'yes': 1, 'no': 0} )\n\ntrain_df.head()"]}, {"cell_type": "markdown", "id": "a3885936", "metadata": {}, "source": ["3.12 housing"]}, {"cell_type": "code", "execution_count": 1, "id": "297671b7", "metadata": {}, "outputs": [], "source": ["for dataset in combine:\n    dataset['housing'] = dataset['housing'].map( {'yes': 0, 'no': 1} )\n\ntrain_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "7ad7d2d5", "metadata": {}, "outputs": [], "source": ["X_train = train_df.drop(\"y\", axis=1)\nY_train = train_df[\"y\"]\nX_test  = test_df"]}, {"cell_type": "markdown", "id": "47837478", "metadata": {}, "source": ["3.13 scale"]}, {"cell_type": "code", "execution_count": 1, "id": "7cbc7bd6", "metadata": {}, "outputs": [], "source": ["from sklearn import preprocessing\n\ntemp = X_train.copy()\ntemp2 = X_test.copy()\n\nduration_train = preprocessing.scale(X_train['duration']) \nduration_test = preprocessing.scale(X_test['duration']) \nX_train['duration'] = duration_train\nX_test['duration'] = duration_test\n\nconspriceidx_train = preprocessing.scale(X_train['cons.price.idx']) \nconspriceidx_test = preprocessing.scale(X_test['cons.price.idx']) \nX_train['cons.price.idx'] = conspriceidx_train\nX_test['cons.price.idx'] = conspriceidx_test\n\nemp_train= preprocessing.scale(X_train['emp.var.rate']) \nemp_test = preprocessing.scale(X_test['emp.var.rate']) \nX_train['emp.var.rate'] = emp_train\nX_test['emp.var.rate'] = emp_test\n\nconf_train= preprocessing.scale(X_train['cons.conf.idx']) \nconf_test = preprocessing.scale(X_test['cons.conf.idx']) \nX_train['cons.conf.idx'] = conf_train\nX_test['cons.conf.idx'] = conf_test\n\nedu_train = preprocessing.scale(X_train['education']) \nedu_test = preprocessing.scale(X_test['education']) \nX_train['education'] = edu_train\nX_test['education'] = edu_test\n\ncampaign_train = preprocessing.scale(X_train['campaign']) \ncampaign_test = preprocessing.scale(X_test['campaign']) \nX_train['campaign'] = campaign_train\nX_test['campaign'] = campaign_test\n\nprevious_train = preprocessing.scale(X_train['previous']) \nprevious_test = preprocessing.scale(X_test['previous']) \nX_train['previous'] = previous_train\nX_test['previous'] = previous_test\n\nnr_train = preprocessing.scale(X_train['nr.employed']) \nnr_test = preprocessing.scale(X_test['nr.employed']) \nX_train['nr.employed'] = nr_train\nX_test['nr.employed'] = nr_test\n\nage_train = preprocessing.scale(X_train['age']) \nage_test = preprocessing.scale(X_test['age']) \nX_train['age'] = nr_train\nX_test['age'] = nr_test\n\njob_train = preprocessing.scale(X_train['job']) \njob_test = preprocessing.scale(X_test['job']) \nX_train['job'] = nr_train\nX_test['job'] = nr_test"]}, {"cell_type": "markdown", "id": "efe73087", "metadata": {}, "source": ["3.15 Imbalance Data"]}, {"cell_type": "code", "execution_count": 1, "id": "a0155b4e", "metadata": {}, "outputs": [], "source": ["#Imbalance Data\nfrom sklearn.utils import resample\n\n# setting up testing and training sets\nX_1, X_2, y_1, y_2 = train_test_split(X_train, Y_train, test_size=0.25, random_state=27)\n\n# concatenate our training data back together\nX = pd.concat([X_1, y_1], axis=1)\n\n# separate minority and majority classes\nnot_fraud = X[X.y==0]\nfraud = X[X.y==1]\n\n# upsample minority\nfraud_upsampled = resample(fraud,\n                          replace=True, # sample with replacement\n                          n_samples=len(not_fraud), # match number in majority class\n                          random_state=27) # reproducible results\n\n# combine majority and upsampled minority\nupsampled = pd.concat([not_fraud, fraud_upsampled])\n\n# check new class counts\nupsampled.y.value_counts()\n\n# trying logistic regression again with the balanced dataset\ny_3 = upsampled.y\nX_3 = upsampled.drop('y', axis=1)\n\ny_4 = y_2\nX_4 = X_2"]}, {"cell_type": "markdown", "id": "c7acdd0d", "metadata": {}, "source": ["3.16 Feature Selection  \n\u0e40\u0e19\u0e37\u0e48\u0e2d\u0e07\u0e08\u0e32\u0e01 Model \u0e17\u0e35\u0e48\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e43\u0e0a\u0e49\u0e40\u0e1b\u0e47\u0e19 tree based model \u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14 \u0e0b\u0e36\u0e48\u0e07\u0e01\u0e32\u0e23\u0e40\u0e25\u0e37\u0e2d\u0e01 Variable \u0e43\u0e19\u0e01\u0e32\u0e23\u0e41\u0e15\u0e01\u0e01\u0e34\u0e48\u0e07\u0e02\u0e2d\u0e07 tree based model \u0e08\u0e30\u0e40\u0e1b\u0e47\u0e19\u0e01\u0e32\u0e23 Feature Selection \u0e2d\u0e22\u0e39\u0e48\u0e41\u0e25\u0e49\u0e27"]}, {"cell_type": "markdown", "id": "cc02a91a", "metadata": {}, "source": ["# 4. Model"]}, {"cell_type": "code", "execution_count": 1, "id": "16641229", "metadata": {}, "outputs": [], "source": ["from IPython.display import Image\nimport os\n\nImage(\"../input/picture/L2Jaqm8.png\")"]}, {"cell_type": "markdown", "id": "3e7a6a07", "metadata": {}, "source": ["Model \u0e17\u0e35\u0e48\u0e43\u0e0a\u0e49\n- Random Forest\n- LightGBM\n- CatBoost\n- Gradient Boosting Classifer\n- XGBClassifier"]}, {"cell_type": "markdown", "id": "f7a54b83", "metadata": {}, "source": ["4.1 Random Forest   \nBagging (random with replacement) \n\nParameter   \n* n_estimators : The number of trees in the forest.   \n* min_samples_split : \nThe minimum number of samples required to split an internal node\n* criterion : The function to measure the quality of a split.   \n* min_samples_leaf : \nThe minimum number of samples required to be at a leaf node.\n* max_features : The number of features to consider when looking for the best split."]}, {"cell_type": "code", "execution_count": 1, "id": "5b2cc6ec", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\n#170,5 ,190\n\nrandom_forest = RandomForestClassifier(n_estimators=190,\n                                       min_samples_split=2,\n                                       min_samples_leaf=5,\n                                       criterion ='entropy',\n                                       max_features=True,\n\n                                       random_state=42)\nrandom_forest.fit(X_3, y_3,)\n\noutput = pd.DataFrame()\noutput['y_forest'] = random_forest.predict_proba(X_test)[:,1]\n\nprint('roc_auc_score:',roc_auc_score(y_4, random_forest.predict_proba(X_4)[:,1]))"]}, {"cell_type": "markdown", "id": "40651a0a", "metadata": {}, "source": ["4.2 LightGBM   \nweak classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "6e1f4666", "metadata": {}, "outputs": [], "source": ["import lightgbm as lgb\n\nmdl = lgb.LGBMClassifier(boosting_type= 'gbdt',\n                         objective = 'binary',\n                         num_leaves = 31,\n                         max_depth=19,\n                         silent = True,\n#                          random_state=42,\n                         learning_rate=0.06,\n                         n_estimators=90)\nlgbm = mdl.fit(X_3,y_3, eval_set=[(X_2, y_2)]\n                 ,early_stopping_rounds= 40\n                 )\n\noutput['y_lgb'] = lgbm.predict_proba(X_test)[:,1]\nprint('roc_auc_score:',roc_auc_score(y_4, lgbm.predict_proba(X_4)[:,1]))"]}, {"cell_type": "markdown", "id": "c58cd864", "metadata": {}, "source": ["4.3 Catboost"]}, {"cell_type": "code", "execution_count": 1, "id": "6ceb6b64", "metadata": {}, "outputs": [], "source": ["from catboost import CatBoostClassifier\ncat = CatBoostClassifier(\n    iterations=150, \n    learning_rate=0.20,\n    random_state=42,\n    verbose=5\n)\ncat.fit(\n    X_3, y_3\n)\noutput['y_cat'] = cat.predict_proba(X_test)[:,1]\nprint('roc_auc_score:',roc_auc_score(y_4, cat.predict_proba(X_4)[:,1]))"]}, {"cell_type": "markdown", "id": "d94874cb", "metadata": {}, "source": ["4.4 Gradient Boosting Classifer"]}, {"cell_type": "code", "execution_count": 1, "id": "1d14b3d1", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingClassifier\n#200\ngdbt = GradientBoostingClassifier(n_estimators=200,\n                                  learning_rate=0.1,\n                                  random_state =42)\ngdbt.fit(X_3, y_3)\noutput['y_gdbt']= gdbt.predict_proba(X_test)[:,1]\n\nprint('roc_auc_score:',roc_auc_score(y_4, gdbt.predict_proba(X_4)[:,1]))"]}, {"cell_type": "markdown", "id": "b9ce3fe3", "metadata": {}, "source": ["4.5 XGBClassifier    \n* XGBoost is a workhorse gradient boosted decision tree algorithm.     \n* weak classifier\n\nparameter   \n* objective : Specify the learning task and the corresponding learning objective   \n   * \"binary:logistic\" : logistic regression for binary classification, output probability\n* eta : learning rate   \n* eval_metric : Evaluation metrics for validation data\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7255c263", "metadata": {}, "outputs": [], "source": ["xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", \n                              random_state=42, \n                              eval_metric=\"auc\",\n                              eta=0.20)\n\nxgb_model.fit(X_3,y_3,early_stopping_rounds=20, eval_set=[(X_2, y_2)])\n\noutput['y_xgb']  = xgb_model.predict_proba(X_test)[:,1]\n\nprint('roc_auc_score:',roc_auc_score(y_4, xgb_model.predict_proba(X_4)[:,1]))"]}, {"cell_type": "markdown", "id": "6666627b", "metadata": {}, "source": ["4.6 Ensemble - weighted average"]}, {"cell_type": "markdown", "id": "99ca9218", "metadata": {}, "source": ["Types of ensembling :\n\nBasic Ensemble Techniques\n\n* Max Voting   \n* Averaging   \n* Weighted Average   "]}, {"cell_type": "code", "execution_count": 1, "id": "4598fcaa", "metadata": {}, "outputs": [], "source": ["output"]}, {"cell_type": "code", "execution_count": 1, "id": "f3a7c0c6", "metadata": {}, "outputs": [], "source": ["output['y'] = ( 1.5*output['y_forest'] +0.8*output['y_xgb'] + 4.0*output['y_lgb']+ 4.0*output['y_cat']+1.7*output['y_gdbt']) /12\noutput['Id'] = test_df.index + 1"]}, {"cell_type": "markdown", "id": "3f84a615", "metadata": {}, "source": ["Output File"]}, {"cell_type": "code", "execution_count": 1, "id": "9b4c1b5f", "metadata": {}, "outputs": [], "source": ["submission = output[['Id','y']]\n \nsubmission.to_csv(\"submission.csv\", index=False)\n \nsubmission.tail()"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}