{"cells": [{"cell_type": "code", "execution_count": 1, "id": "45f2c822", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D"]}, {"cell_type": "code", "execution_count": 1, "id": "cacb880e", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv(\"../input/trainData3D.csv\")\ndx = data.X.values \ndy = data.Y.values\ndz = data.Z.values\nX = np.append(dx.reshape(-1,1),dy.reshape(-1,1), axis =1)\nY = dz\nX.shape, Y.shape"]}, {"cell_type": "markdown", "id": "9561e1a0", "metadata": {}, "source": ["# Visualizing the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "827a08a7", "metadata": {}, "outputs": [], "source": ["ax = Axes3D(plt.figure())\nax.scatter(X[:,0],X[:,1],Y)\nax"]}, {"cell_type": "markdown", "id": "27b16aa8", "metadata": {}, "source": ["# Clearly, locally weighted regression is one solution"]}, {"cell_type": "code", "execution_count": 1, "id": "4ae751cc", "metadata": {}, "outputs": [], "source": ["def getW(X,q,tau):\n    \n    #Create W\n    m = X.shape[0]\n    W = np.eye(m) \n    \n    for i in range(m):\n        W[i,i] = np.exp(-np.dot((X[i]-q),(X[i]-q).T)/(2*tau*tau))\n    \n    return W\n    \ndef getTheta(X,Y,q,tau):\n    m = X.shape[0]\n    ones = np.ones((m,1))\n    q = np.append(np.array([1]), q, axis = 0)\n    X = np.append(ones, X, axis = 1)\n    W = getW(X,q,tau)\n    Y = Y.reshape((-1,1))\n    \n    theta = np.dot(np.linalg.pinv(np.dot(np.dot(X.T,W),X)),np.dot(np.dot(X.T,W),Y))\n    return theta,W\n    \n    "]}, {"cell_type": "code", "execution_count": 1, "id": "815d4df8", "metadata": {}, "outputs": [], "source": ["theta,W = getTheta(X,Y,[0.6,0.7],0.1)"]}, {"cell_type": "code", "execution_count": 1, "id": "7e27b644", "metadata": {}, "outputs": [], "source": ["print(theta.shape)\nprint(W)"]}, {"cell_type": "code", "execution_count": 1, "id": "f13c3722", "metadata": {}, "outputs": [], "source": ["# X_Test = np.linspace(-20,20,100)\nX_Test = pd.read_csv(\"../input/testData3D.csv\").values\n# print(X_Test)\nY_Test = []\n\nfor xt in X_Test:\n#     print(xt)\n    theta,W = getTheta(X,Y,xt,0.73)\n#     print(xt)\n    pred = theta[0][0]*1 + theta[1][0]*xt[0] + theta[2][0]*xt[1]\n    Y_Test.append(pred)\n    \nY_Test = np.array(Y_Test)\nY_actual = pd.read_csv(\"../input/actualYTest3D.csv\").values\nY_Test.shape, Y_actual.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "68773b54", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import r2_score\nr2_score(Y_actual,Y_Test)\n"]}, {"cell_type": "markdown", "id": "d97e0cf0", "metadata": {}, "source": ["# Locally weighted really performs well, it adapts to the function quickly.\n\nOne thing you will notice is that as you increase tau, the training accuracy is actually behaving abnormally. There is a good reason for that. Can you figure it out?\n\nHint: Implement linear regression to see"]}, {"cell_type": "code", "execution_count": 1, "id": "e0adb254", "metadata": {}, "outputs": [], "source": ["\nax = Axes3D(plt.figure())\nax.scatter(\n    X_Test[:,0],\n    X_Test[:,1],\n    Y_actual.reshape(-1,1)\n)\nplt.title(\"Redrawn predictions!\")\n\nX_Test[:,1].shape,X_Test[:,0].shape, Y.shape"]}, {"cell_type": "markdown", "id": "2536baab", "metadata": {}, "source": ["Above is weighted_regression in practice. It is a deterministic approach."]}, {"cell_type": "code", "execution_count": 1, "id": "dd08355d", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split as tts\nxtrain,xtest,ytrain,ytest = tts(X,Y, random_state = 1)\n"]}, {"cell_type": "markdown", "id": "69123edd", "metadata": {}, "source": ["# Can you figure out why linear regression works so well?"]}, {"cell_type": "code", "execution_count": 1, "id": "50bb9584", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression as LR\nreg = LR()\nreg.fit(xtrain,ytrain)\nreg.score(xtest,ytest)"]}, {"cell_type": "markdown", "id": "2de72eb4", "metadata": {}, "source": ["# Can you figure out why support vector regressor performs so badly?\n#### Hint, draw plot, see decision boundary"]}, {"cell_type": "code", "execution_count": 1, "id": "2dda024b", "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVR\nreg = SVR()\nreg.fit(xtrain,ytrain)\nreg.score(xtest,ytest)"]}, {"cell_type": "markdown", "id": "9db4010b", "metadata": {}, "source": ["# Just another ensemble technique you can read about."]}, {"cell_type": "code", "execution_count": 1, "id": "ffca72ee", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingRegressor as GBR\nreg = GBR()\nreg.fit(xtrain,ytrain)\nreg.score(xtest,ytest)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}