{"cells": [{"cell_type": "code", "execution_count": 1, "id": "9c62e1dd", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "e02f9078", "metadata": {}, "outputs": [], "source": ["df=pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\")\ndf"]}, {"cell_type": "code", "execution_count": 1, "id": "032e9631", "metadata": {}, "outputs": [], "source": ["df[\"id\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "3ceebf9e", "metadata": {}, "outputs": [], "source": ["df.drop(\"id\",axis=1, inplace=True)\ndf"]}, {"cell_type": "code", "execution_count": 1, "id": "dc9d1539", "metadata": {}, "outputs": [], "source": ["df.drop(\"Unnamed: 32\",axis=1, inplace=True)\ndf\n"]}, {"cell_type": "code", "execution_count": 1, "id": "030fd9f1", "metadata": {}, "outputs": [], "source": ["df.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "d4556e78", "metadata": {}, "outputs": [], "source": ["df.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "99330c45", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import LabelEncoder"]}, {"cell_type": "code", "execution_count": 1, "id": "fa3a0fcc", "metadata": {}, "outputs": [], "source": ["le=LabelEncoder()"]}, {"cell_type": "code", "execution_count": 1, "id": "2f42b45d", "metadata": {}, "outputs": [], "source": ["le.fit_transform(df[\"diagnosis\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "e5ed2a6f", "metadata": {}, "outputs": [], "source": ["df[\"diagnosis\"]=le.fit_transform(df[\"diagnosis\"])\ndf"]}, {"cell_type": "code", "execution_count": 1, "id": "6b710451", "metadata": {}, "outputs": [], "source": ["df[\"diagnosis\"].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "c3328d76", "metadata": {}, "outputs": [], "source": ["df.corr()"]}, {"cell_type": "code", "execution_count": 1, "id": "ce366f36", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport seaborn as sns"]}, {"cell_type": "code", "execution_count": 1, "id": "f08edc5d", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),cmap=\"inferno\")"]}, {"cell_type": "code", "execution_count": 1, "id": "7d70014c", "metadata": {}, "outputs": [], "source": ["df.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "43422fad", "metadata": {}, "outputs": [], "source": ["X=df.drop(\"diagnosis\",axis=1)\nX=X.values\nX"]}, {"cell_type": "code", "execution_count": 1, "id": "3b15fb78", "metadata": {}, "outputs": [], "source": ["y=df[\"diagnosis\"]\ny=y.values\ny"]}, {"cell_type": "code", "execution_count": 1, "id": "00d9b658", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split"]}, {"cell_type": "code", "execution_count": 1, "id": "b41477fa", "metadata": {}, "outputs": [], "source": ["X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2)"]}, {"cell_type": "code", "execution_count": 1, "id": "f9232fb3", "metadata": {}, "outputs": [], "source": ["X_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "f3fa6740", "metadata": {}, "outputs": [], "source": ["y_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "c3e52309", "metadata": {}, "outputs": [], "source": ["X_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "92db95e9", "metadata": {}, "outputs": [], "source": ["y_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "1ef8402d", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler"]}, {"cell_type": "code", "execution_count": 1, "id": "0a6824c2", "metadata": {}, "outputs": [], "source": ["sc=StandardScaler()"]}, {"cell_type": "code", "execution_count": 1, "id": "1472eb9c", "metadata": {}, "outputs": [], "source": ["X_train=sc.fit_transform(X_train)\nX_train"]}, {"cell_type": "code", "execution_count": 1, "id": "0e3f08b4", "metadata": {}, "outputs": [], "source": ["X_test=sc.transform(X_test)\nX_test"]}, {"cell_type": "code", "execution_count": 1, "id": "8b49eaec", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.models import Sequential # creates`Sequential` groups a linear stack of layers into a `tf.keras.Model`.\nfrom tensorflow.keras.layers import Dense #regularly connected neurons)"]}, {"cell_type": "code", "execution_count": 1, "id": "c5f66e19", "metadata": {}, "outputs": [], "source": ["ann=Sequential()"]}, {"cell_type": "code", "execution_count": 1, "id": "7b14dd70", "metadata": {}, "outputs": [], "source": ["ann.add(Dense(units=30, activation=\"relu\")) # here we add a dense layer with 30 neurons"]}, {"cell_type": "code", "execution_count": 1, "id": "341b9564", "metadata": {}, "outputs": [], "source": ["ann.add(Dense(units=15, activation=\"relu\")) # here we add a dense layer with 15 neurons"]}, {"cell_type": "markdown", "id": "986d564b", "metadata": {}, "source": ["The activation function is a mathematical \u201cgate\u201d in between the input feeding the current neuron and its output going to the next layer. It can be as simple as a step function that turns the neuron output on and off, depending on a rule or threshold. Or it can be a transformation that maps the input signals into output signals that are needed for the neural network to function.\n\n\nTypes of Activation Function:\n\n1.Sigmoid / Logistic\n\n2.TanH / Hyperbolic Tangent\n\n3.ReLU (Rectified Linear Unit)\n\n4.Softmax"]}, {"cell_type": "code", "execution_count": 1, "id": "d25ab43c", "metadata": {}, "outputs": [], "source": ["ann.add(Dense(1,activation=\"sigmoid\"))  # here we add output layer with 1 neuron"]}, {"cell_type": "markdown", "id": "d56be158", "metadata": {}, "source": [" optimizer:this determines how we want to perform the gradient descent like adam optimizer loss= represents cost function we want to use\n\nType of Optimizers:\n\n1.Gradient Descent\n\n2.Stochastic Gradient Descent\n\n3.Mini-Batch Gradient Descent\n\n4.Adam:The intuition behind the Adam is that we don\u2019t want to roll so fast just because we can jump over the minimum, we want to decrease the velocity a little bit for a careful search.\n\n\nChoosing an optimizer: Keep in mind what kind of problem we are trying to solve:\n\nFor a multi-class classification problem:\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\nFor a binary classification problem:\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nFor a mean squared error regression problem:\n\nmodel.compile(optimizer='rmsprop', loss='mse')"]}, {"cell_type": "code", "execution_count": 1, "id": "6c2e0f7d", "metadata": {}, "outputs": [], "source": ["ann.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "a26a9a7d", "metadata": {}, "outputs": [], "source": ["ann.fit(x= X_train, y= y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "078699f6", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(ann.history.history)"]}, {"cell_type": "code", "execution_count": 1, "id": "c0b6cc8b", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(ann.history.history).plot(figsize=(15,10))"]}, {"cell_type": "code", "execution_count": 1, "id": "f1e6ab5b", "metadata": {}, "outputs": [], "source": ["ann.evaluate(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "a7e142c1", "metadata": {}, "outputs": [], "source": ["ann.evaluate(X_test, y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "699a66c8", "metadata": {}, "outputs": [], "source": ["X_test"]}, {"cell_type": "code", "execution_count": 1, "id": "e0677c1c", "metadata": {}, "outputs": [], "source": ["X_test[[1]]"]}, {"cell_type": "code", "execution_count": 1, "id": "334e9c76", "metadata": {}, "outputs": [], "source": ["ann.predict(X_test[[1]])"]}, {"cell_type": "code", "execution_count": 1, "id": "9f5eb7df", "metadata": {}, "outputs": [], "source": ["y_test[[1]]"]}, {"cell_type": "code", "execution_count": 1, "id": "7fafaf5b", "metadata": {}, "outputs": [], "source": ["predictions=ann.predict(X_test)\npredictions"]}, {"cell_type": "code", "execution_count": 1, "id": "60bbfca6", "metadata": {}, "outputs": [], "source": ["predictions_df=pd.DataFrame(predictions, columns=[\"Predictions\"])\npredictions_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "5dfc47fa", "metadata": {}, "outputs": [], "source": ["y_test_df=pd.DataFrame(y_test, columns=[\"Diagnosis\"])\ny_test_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d43c6971", "metadata": {}, "outputs": [], "source": ["comparison_df=pd.concat([predictions_df, y_test_df], axis=1)\ncomparison_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "31378e8e", "metadata": {}, "outputs": [], "source": ["ann2=Sequential()"]}, {"cell_type": "code", "execution_count": 1, "id": "cd8376ef", "metadata": {}, "outputs": [], "source": ["ann2.add(Dense(units=1, activation=\"relu\")) # here we add a dense layer with 1 neuron"]}, {"cell_type": "code", "execution_count": 1, "id": "c9458181", "metadata": {}, "outputs": [], "source": ["ann2.add(Dense(1,activation=\"sigmoid\")) "]}, {"cell_type": "code", "execution_count": 1, "id": "21bcedda", "metadata": {}, "outputs": [], "source": ["ann2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "546ef149", "metadata": {}, "outputs": [], "source": ["ann2.fit(x= X_train, y= y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "6f6154b6", "metadata": {}, "outputs": [], "source": ["ann2.evaluate(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "a2efa352", "metadata": {}, "outputs": [], "source": ["ann2.evaluate(X_test, y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "47b3d898", "metadata": {}, "outputs": [], "source": ["ann3=Sequential()"]}, {"cell_type": "markdown", "id": "0037d039", "metadata": {}, "source": ["In order to see the overfitting:"]}, {"cell_type": "code", "execution_count": 1, "id": "e4237639", "metadata": {}, "outputs": [], "source": ["ann3.add(Dense(units=100, activation=\"relu\")) # here we add a dense layer with 100 neurons"]}, {"cell_type": "code", "execution_count": 1, "id": "5753b103", "metadata": {}, "outputs": [], "source": ["ann3.add(Dense(units=100, activation=\"relu\")) # here we add a dense layer with 100 neurons"]}, {"cell_type": "code", "execution_count": 1, "id": "5b16bf18", "metadata": {}, "outputs": [], "source": ["ann3.add(Dense(units=100, activation=\"relu\")) # here we add a dense layer with 100 neurons"]}, {"cell_type": "code", "execution_count": 1, "id": "3c51a3b7", "metadata": {}, "outputs": [], "source": ["ann3.add(Dense(1,activation=\"sigmoid\")) "]}, {"cell_type": "code", "execution_count": 1, "id": "6861032d", "metadata": {}, "outputs": [], "source": ["ann3.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "05ba91c1", "metadata": {}, "outputs": [], "source": ["ann3.fit(x= X_train, y= y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "d5eda546", "metadata": {}, "outputs": [], "source": ["ann3.evaluate(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "9c8f0cea", "metadata": {}, "outputs": [], "source": ["ann3.evaluate(X_test, y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "ba5dac76", "metadata": {}, "outputs": [], "source": ["history=ann3.fit(x= X_train, y= y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "a0356d36", "metadata": {}, "outputs": [], "source": ["ann3.history.history"]}, {"cell_type": "code", "execution_count": 1, "id": "577cf7ed", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(ann3.history.history).plot(figsize=(15,10))"]}, {"cell_type": "markdown", "id": "7612587a", "metadata": {}, "source": ["We can see an expected shape of an overfit model where test accuracy increases to a point and then begins to decrease again."]}, {"cell_type": "markdown", "id": "81739d97", "metadata": {}, "source": ["An overfit model should show accuracy increasing on both train and test and at some point accuracy drops on the test dataset but continues to rise on the training dataset."]}, {"cell_type": "markdown", "id": "4ee22968", "metadata": {}, "source": ["Keras provides a weight regularization API that allows you to add a penalty for weight size to the loss function.\n\nThree different regularizer instances are provided; they are:\n\nL1: Sum of the absolute weights.\nL2: Sum of the squared weights.\nL1L2: Sum of the absolute and the squared weights."]}, {"cell_type": "markdown", "id": "95ceb670", "metadata": {}, "source": ["The most common type of regularization is L2, also called simply \u201cweight decay,\u201d with values often on a logarithmic scale between 0 and 0.1, such as 0.1, 0.001, 0.0001, etc."]}, {"cell_type": "code", "execution_count": 1, "id": "7e8fcc27", "metadata": {}, "outputs": [], "source": ["from keras.regularizers import l2"]}, {"cell_type": "code", "execution_count": 1, "id": "165a8bba", "metadata": {}, "outputs": [], "source": ["ann4=Sequential()"]}, {"cell_type": "code", "execution_count": 1, "id": "3f8eeb0b", "metadata": {}, "outputs": [], "source": ["ann4.add(Dense(100,activation=\"relu\", kernel_regularizer=l2(0.001)))"]}, {"cell_type": "code", "execution_count": 1, "id": "8aad4d04", "metadata": {}, "outputs": [], "source": ["ann4.add(Dense(units=100, activation=\"relu\",kernel_regularizer=l2(0.001)))"]}, {"cell_type": "code", "execution_count": 1, "id": "4118b9fd", "metadata": {}, "outputs": [], "source": ["ann4.add(Dense(units=100, activation=\"relu\",kernel_regularizer=l2(0.001)))"]}, {"cell_type": "code", "execution_count": 1, "id": "53a1d3da", "metadata": {}, "outputs": [], "source": ["ann4.add(Dense(1,activation=\"sigmoid\")) "]}, {"cell_type": "code", "execution_count": 1, "id": "96a2f389", "metadata": {}, "outputs": [], "source": ["ann4.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "ac10eb30", "metadata": {}, "outputs": [], "source": ["history=ann4.fit(x= X_train, y= y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "57b42463", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(ann4.history.history).plot(figsize=(15,10))"]}, {"cell_type": "markdown", "id": "73ae3745", "metadata": {}, "source": ["Thanks to weight decay we got %100 accuracy in the test set after 65 epoch, after that there happens a overfitting.\n\nWe will use early stopping to prevent this problem:"]}, {"cell_type": "code", "execution_count": 1, "id": "ae99ae0e", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.callbacks import EarlyStopping"]}, {"cell_type": "code", "execution_count": 1, "id": "e52e06fd", "metadata": {}, "outputs": [], "source": ["ann5=Sequential()"]}, {"cell_type": "code", "execution_count": 1, "id": "310b07e0", "metadata": {}, "outputs": [], "source": ["ann5.add(Dense(100,activation=\"relu\", kernel_regularizer=l2(0.001)))"]}, {"cell_type": "code", "execution_count": 1, "id": "45fbf081", "metadata": {}, "outputs": [], "source": ["ann5.add(Dense(units=100, activation=\"relu\",kernel_regularizer=l2(0.001)))"]}, {"cell_type": "code", "execution_count": 1, "id": "b8d86af9", "metadata": {}, "outputs": [], "source": ["ann5.add(Dense(units=100, activation=\"relu\",kernel_regularizer=l2(0.001)))"]}, {"cell_type": "code", "execution_count": 1, "id": "1b8d1f7a", "metadata": {}, "outputs": [], "source": ["ann5.add(Dense(1,activation=\"sigmoid\")) "]}, {"cell_type": "code", "execution_count": 1, "id": "d7ee4342", "metadata": {}, "outputs": [], "source": ["ann5.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"]}, {"cell_type": "code", "execution_count": 1, "id": "704afb15", "metadata": {}, "outputs": [], "source": ["history=ann5.fit(x= X_train, y= y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test),callbacks=[EarlyStopping(monitor=\"val_accuracy\",patience=10)])"]}, {"cell_type": "code", "execution_count": 1, "id": "5e2b9a2a", "metadata": {}, "outputs": [], "source": ["pd.DataFrame(ann5.history.history).plot(figsize=(15,10))\n# Now we stopped the training after gettin %100 accuracy in the test set"]}, {"cell_type": "markdown", "id": "e1313976", "metadata": {}, "source": ["Now we will compare the performance of the deep learning with a normal machine learning model"]}, {"cell_type": "code", "execution_count": 1, "id": "a618fc91", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "74fab6c8", "metadata": {}, "outputs": [], "source": ["dtree=DecisionTreeClassifier()"]}, {"cell_type": "code", "execution_count": 1, "id": "d507d18b", "metadata": {}, "outputs": [], "source": ["dtree.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "e6c3559b", "metadata": {}, "outputs": [], "source": ["predictions2=dtree.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "2198c61e", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import classification_report, confusion_matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "81222eb6", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test,predictions2)) "]}, {"cell_type": "markdown", "id": "c5e6ffca", "metadata": {}, "source": ["As we can obviously see, the deep learning model easily outperform normal machine learning algorithms."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}