{"cells": [{"cell_type": "code", "execution_count": 1, "id": "cf85a30f", "metadata": {}, "outputs": [], "source": ["# !pip install --upgrade scikit-image\n# !pip install tqdm\n!pip install tensorflow==1.15.0\n!pip install keras==2.0.0\n"]}, {"cell_type": "code", "execution_count": 1, "id": "91ed68d2", "metadata": {}, "outputs": [], "source": ["!git clone https://github.com/Tony607/efficientnet_keras_transfer_learning\n%cd efficientnet_keras_transfer_learning/"]}, {"cell_type": "code", "execution_count": 1, "id": "90189e14", "metadata": {}, "outputs": [], "source": ["import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm, tqdm_notebook\n\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization,AveragePooling2D\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,ResNet50\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom efficientnet import EfficientNetB0 as Net\nfrom efficientnet import center_crop_and_resize, preprocess_input"]}, {"cell_type": "code", "execution_count": 1, "id": "366bc2c0", "metadata": {}, "outputs": [], "source": ["train_dir='../../input/blood-cells/dataset2-master/dataset2-master/images/TRAIN'\nvalidation_dir='../../input/blood-cells/dataset2-master/dataset2-master/images/TEST'\nheight=200\nwidth=200\nbatch_size=1\nepochs=10\nNUM_TRAIN=50\nNUM_TEST=50\ninput_shape=(200,200,3)\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input\n                                   \n        \n)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator()\n\n# define the ImageNet mean subtraction (in RGB order) and set the\n# the mean subtraction value for each of the data augmentation\n# objects\nmean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\ntrain_datagen.mean = mean\ntest_datagen.mean = mean\n\ntrain_generator = train_datagen.flow_from_directory(\n    # This is the target directory\n    train_dir,\n    # All images will be resized to target height and width.\n    target_size=(height, width),\n    batch_size=batch_size,\n    color_mode=\"rgb\",\n    # Since we use categorical_crossentropy loss, we need categorical labels\n    class_mode=\"categorical\",\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(height, width),\n    batch_size=batch_size,\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n)\n\n\n"]}, {"cell_type": "markdown", "id": "193c4394", "metadata": {}, "source": ["### Using EfficientNet EfficientNetB0"]}, {"cell_type": "code", "execution_count": 1, "id": "d40295b9", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.constraints import max_norm\n# loading pretrained conv base model\nconv_base = Net(weights=\"imagenet\", include_top=False, input_shape=input_shape)\nheadModel = conv_base.output\nheadModel = GlobalAveragePooling2D()(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = BatchNormalization()(headModel)\nheadModel = Dense(256, activation=\"relu\", kernel_constraint=max_norm(3), bias_constraint=max_norm(3))(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(4, activation=\"sigmoid\", kernel_constraint=max_norm(3), bias_constraint=max_norm(3))(headModel)\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = models.Model(inputs=conv_base.input, outputs=headModel)\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the training process\nfor layer in conv_base.layers:\n    layer.trainable = False\n# compile the model\nopt = optimizers.SGD(lr=1e-4, momentum=0.9)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n"]}, {"cell_type": "code", "execution_count": 1, "id": "fbc855fd", "metadata": {}, "outputs": [], "source": ["\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=NUM_TRAIN // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=NUM_TEST // batch_size,\n    verbose=1\n)"]}, {"cell_type": "code", "execution_count": 1, "id": "a1f991cb", "metadata": {}, "outputs": [], "source": ["predictions = model.predict_generator(\n    validation_generator,\n    steps=validation_generator.n / validation_generator.batch_size,\n    verbose=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "8136aff4", "metadata": {}, "outputs": [], "source": ["y_pred = np.argmax(predictions, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['altogrado', 'ascus', 'bajogrado','benigna']\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))"]}, {"cell_type": "markdown", "id": "a0d6f19b", "metadata": {}, "source": ["## ResNet "]}, {"cell_type": "code", "execution_count": 1, "id": "41e6bb84", "metadata": {}, "outputs": [], "source": ["baseModel = ResNet50(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=input_shape))"]}, {"cell_type": "code", "execution_count": 1, "id": "4e5a3be0", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.constraints import max_norm\nheadModel = baseModel.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = BatchNormalization()(headModel)\nheadModel = Dense(4, activation=\"sigmoid\", kernel_constraint=max_norm(3), bias_constraint=max_norm(3))(headModel)\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = models.Model(inputs=baseModel.input, outputs=headModel)\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the training process\n\nfor layer in baseModel.layers:\n    layer.trainable = False\n    \n    if layer.name.startswith('bn'):\n        layer.call(layer.input, training=False)\n# compile the model\nopt = optimizers.SGD(lr=1e-4, momentum=0.9)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])   \n    "]}, {"cell_type": "code", "execution_count": 1, "id": "b2d2f95e", "metadata": {}, "outputs": [], "source": ["es_callback = EarlyStopping(monitor='val_loss', patience=5)\nhistory = model.fit_generator( train_generator,\n                            steps_per_epoch=NUM_TRAIN // batch_size,\n                            epochs=epochs,\n                            validation_data=validation_generator,\n                            validation_steps=NUM_TEST // batch_size,\n                            verbose=1,callbacks=[es_callback]\n                        )"]}, {"cell_type": "code", "execution_count": 1, "id": "8111128a", "metadata": {}, "outputs": [], "source": ["predictions = model.predict_generator(\n    validation_generator,\n    steps=validation_generator.n / validation_generator.batch_size,\n    verbose=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "58cc3716", "metadata": {}, "outputs": [], "source": ["y_pred = np.argmax(predictions, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['altogrado', 'ascus', 'bajogrado','benigna']\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))"]}, {"cell_type": "markdown", "id": "fb499140", "metadata": {}, "source": ["### vgg16 binary classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "287c6b6e", "metadata": {}, "outputs": [], "source": ["base_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\nadd_model = models.Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(1, activation='sigmoid'))\n\nmodel = models.Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "2ffbb073", "metadata": {}, "outputs": [], "source": ["validation_generator.classes=np.where(validation_generator.classes==3,1,0)\ntrain_generator.classes=np.where(train_generator.classes==3,1,0)\nvalidation_generator.class_mode='binary'\ntrain_generator.class_mode='binary'"]}, {"cell_type": "code", "execution_count": 1, "id": "b390686f", "metadata": {}, "outputs": [], "source": ["train_generator.class_indices={'EOSINOPHIL': 0, 'LYMPHOCYTE': 0, 'MONOCYTE': 0, 'NEUTROPHIL': 1}\nvalidation_generator.class_indices={'EOSINOPHIL': 0, 'LYMPHOCYTE': 0, 'MONOCYTE': 0, 'NEUTROPHIL': 1}"]}, {"cell_type": "code", "execution_count": 1, "id": "aa9a3173", "metadata": {}, "outputs": [], "source": ["train_generator.num_classes=2\nvalidation_generator.num_classes=2\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2758ae72", "metadata": {}, "outputs": [], "source": ["history = model.fit_generator( train_generator,\n                            steps_per_epoch=NUM_TRAIN // batch_size,\n                            epochs=1,\n                            validation_data=validation_generator,\n                            validation_steps=NUM_TEST // batch_size,\n                            verbose=1,\n                            use_multiprocessing=True,\n                            workers=4,\n                        )"]}, {"cell_type": "code", "execution_count": 1, "id": "2be18ba7", "metadata": {}, "outputs": [], "source": ["predictions = model.predict_generator(\n    validation_generator,\n    steps=validation_generator.n / validation_generator.batch_size,\n    verbose=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "daaf429f", "metadata": {}, "outputs": [], "source": ["y_pred = np.argmax(predictions, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['altogrado', 'ascus', 'bajogrado','benigna']\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}