{"cells": [{"cell_type": "markdown", "id": "b12859a8", "metadata": {}, "source": ["<a id=\"0\"> <a/>\n# Compare Classifiers <br>\nIn this program, we will read file \"column-2C-weka.csv\"  . This file has class property and 6 numeric features  . Class property has 2 values named \"Abnormal\" and \"Normal\" . We will fit 3 different classfiers for this file and compare 3 models and find which model is most suitable for the data <br>\n\n1. [Read Data](#1)<br>\n2. [Train Test Split](#2)<br>\n3. [Fit Classifiers](#3)<br>\n    3.1. [K Neighbors Classifier ](#3.1)<br>\n    3.2. [Random Forest Classifier](#3.2)<br>\n    3.3. [Logistic Regression ](#3.3)<br>\n4. [Confusion matrixes ](#4)<br>\n5. [ROC Curve](#5)<br>\n6. [Conclusion](#6)<br>"]}, {"cell_type": "code", "execution_count": 1, "id": "7f46e8ed", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# import models \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# metrics \nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve\n\n# graphs \nimport matplotlib.pyplot as plt \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "7ee2bc92", "metadata": {}, "source": ["## <div id=\"1\">1. Read Data <div/>"]}, {"cell_type": "code", "execution_count": 1, "id": "f7035cf1", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv('../input/column_2C_weka.csv')\nprint ( 'distinct class values : ' , data['class'].unique())\n\ndata['class'] = [1 if each == 'Normal' else 0 for each in data['class'] ]\nx = data.loc[:,data.columns != 'class'] # veya data.drop(['class'], axis = 1) \ny = data.loc[:,'class']\n\nx.head()"]}, {"cell_type": "markdown", "id": "d3f34ddd", "metadata": {}, "source": ["## <div id=\"2\">2. Train Test Split<div/>"]}, {"cell_type": "code", "execution_count": 1, "id": "7902e779", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3, random_state = 1)\n\nprint ('x_train shape: {} '.format(x_train.shape))\nprint ('y_train shape: {} '.format(y_train.shape))\nprint ('x_test shape: {} '.format(x_test.shape))\nprint ('y_test shape: {} '.format(y_test.shape))"]}, {"cell_type": "markdown", "id": "4fe98fc7", "metadata": {}, "source": ["## <div id=\"3\">3. Fit Classifiers<div/>\n### <div id=\"3.1\">3.1.K Neighbors Classifier<div/>"]}, {"cell_type": "code", "execution_count": 1, "id": "798ec904", "metadata": {}, "outputs": [], "source": ["\n# find  best k value \nknn_accuracy_list =[]\nfor k in  range (1,25):\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(x_train, y_train)\n    knn_accuracy_list.append(knn.score(x_test, y_test))\n    \nprint ('best k is :{} , best acccuracy is :{} '.format(  knn_accuracy_list.index (np.max(knn_accuracy_list))+1, np.max(knn_accuracy_list)))\n\n#knn classifier \nknn = KNeighborsClassifier(n_neighbors = knn_accuracy_list.index (np.max(knn_accuracy_list))+1 )\nknn.fit(x_train, y_train)\ny_pred_knn = knn.predict(x_test)\nprint ('KNeighborsClassifier test accuracy ' , knn.score(x_test, y_test) )\n"]}, {"cell_type": "markdown", "id": "032a0c68", "metadata": {}, "source": ["### <div id=\"3.2\">3.2. Random Forest Classifier<div/>"]}, {"cell_type": "code", "execution_count": 1, "id": "b0180516", "metadata": {}, "outputs": [], "source": ["rfc_accuracy_list =[]\nfor r in  range (1,25):\n    rfc = RandomForestClassifier(random_state = r)\n    rfc.fit(x_train, y_train)\n    rfc_accuracy_list.append(rfc.score(x_test, y_test))\n    \nprint ('best r is :{} , best acccuracy is :{} '.format(  rfc_accuracy_list.index (np.max(rfc_accuracy_list))+1, np.max(rfc_accuracy_list)))\n    \nrfc = RandomForestClassifier(random_state = rfc_accuracy_list.index (np.max(rfc_accuracy_list))+1)\nrfc.fit(x_train,y_train)\ny_pred_rfc = rfc.predict(x_test)\nprint ('RandomForestClassifier test accuracy ' , rfc.score(x_test, y_test) )"]}, {"cell_type": "markdown", "id": "741582a9", "metadata": {}, "source": ["### <div id=\"3.3\">3.3. Logistic Regression<div/>"]}, {"cell_type": "code", "execution_count": 1, "id": "0ff37740", "metadata": {}, "outputs": [], "source": ["logreg = LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred_logreg = logreg.predict(x_test)\nprint ('LogisticRegression test accuracy ' , logreg.score(x_test, y_test) )"]}, {"cell_type": "markdown", "id": "f134a712", "metadata": {}, "source": ["KNeighborsClassifier test accuracy  **0.8817204301075269**<br>\nRandomForestClassifier test accuracy  **0.8924731182795699**<br>\nLogisticRegression test accuracy  **0.8602150537634409**<br>\n\nAccording to accuracy RandomForestClassifier > KNeighborsClassifier > LogisticRegression"]}, {"cell_type": "markdown", "id": "c5813374", "metadata": {}, "source": ["## <div id=\"4\">4. Confusion matrixes<div/>\n\nA confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known<br><br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Pred No** &nbsp;&nbsp;&nbsp;&nbsp;**Pred Yes**<br>\n**Actual No**  &nbsp;TN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FP <br>\n**Actual Yes** &nbsp;FN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP<br>\n\nThis is a list of rates that are often computed from a confusion matrix for a binary classifier: <br>\n\n**Accuracy:** Overall, how often is the classifier correct?<br>\n    * (TP+TN)/total\n**Misclassification Rate: **Overall, how often is it wrong?<br>\n    * (FP+FN)/total\n    * 1 - Accuracy\n    * also known as \"Error Rate\"\n**True Positive Rate: **When it's actually yes, how often does it predict yes?<br>\n    * TP/actual yes\n    * also known as \"Sensitivity\" or \"Recall\"\n**False Positive Rate:** When it's actually no, how often does it predict yes?<br>\n    * FP/actual no \n**True Negative Rate: **When it's actually no, how often does it predict no?<br>\n    * TN/actual no\n    * 1 - False Positive Rate\n    * also known as \"Specificity\"\n**Precision: **When it predicts yes, how often is it correct?<br>\n    * TP/predicted yes\n**Prevalence:** How often does the yes condition actually occur in our sample?<br>\n    * Actual yes/total"]}, {"cell_type": "code", "execution_count": 1, "id": "92eea927", "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test,y_pred_knn)\nprint('KNN Confusion matrix: \\n',cm)\nprint('KNN Classification report: \\n',classification_report(y_test,y_pred_knn))\n\ncm = confusion_matrix(y_test,y_pred_rfc)\nprint('RandomForestClassifier Confusion matrix: \\n',cm)\nprint('RandomForestClassifier Classification report: \\n',classification_report(y_test,y_pred_rfc))\n\ncm = confusion_matrix(y_test,y_pred_logreg)\nprint('LogisticRegression Confusion matrix: \\n',cm)\nprint('LogisticRegression Classification report: \\n',classification_report(y_test,y_pred_logreg))"]}, {"cell_type": "markdown", "id": "8b21352c", "metadata": {}, "source": ["## <div id=\"5\">5.ROC Curve<div/>\n    \nThe ROC curve is created by plotting the **true positive rate (TPR) ** against the ** false positive rate (FPR)** at various threshold settings. The** true-positive rate** is also known as **sensitivity, recall or probability of detection **in machine learning. "]}, {"cell_type": "code", "execution_count": 1, "id": "98bb2f71", "metadata": {}, "outputs": [], "source": ["\ny_pred_knn_prob = knn.predict_proba(x_test)[:,1]\ny_pred_rfc_prob = rfc.predict_proba(x_test)[:,1]\ny_pred_lr_prob = logreg.predict_proba(x_test)[:,1]\n\nfpr_knn, tpr_knn, thresholds = roc_curve(y_test, y_pred_knn_prob) \nfpr_rfc, tpr_rfc, thresholds = roc_curve(y_test, y_pred_rfc_prob) \nfpr_lr, tpr_lr, thresholds = roc_curve(y_test, y_pred_lr_prob) \n\nplt.figure (figsize=[13 ,8])\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_knn, tpr_knn, label='KNN')\nplt.plot(fpr_rfc, tpr_rfc, label='Random Forest')\nplt.plot(fpr_lr, tpr_lr, label='Logistic Regression')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.title('ROC')\nplt.show()"]}, {"cell_type": "markdown", "id": "4c3de25e", "metadata": {}, "source": ["## <div id=\"6\">6. Conclusion<div/>\n\nAccording to accurancy and precision , for this data , below are classifiers from best to worst :\n\n1. Random Forest Classifier\n2. K Neighbors Classifier\n3. Logistic Regression"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}