{"cells": [{"cell_type": "code", "execution_count": 1, "id": "fc5bb90b", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport json\nimport nltk\nimport re\nimport csv\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split"]}, {"cell_type": "code", "execution_count": 1, "id": "8f43dfe5", "metadata": {}, "outputs": [], "source": ["x_train= pd.read_csv('../input/radix-challenge/train.csv')\nx_test=pd.read_csv('../input/radix-challenge/test.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "75ae5cfe", "metadata": {}, "outputs": [], "source": ["x_train"]}, {"cell_type": "code", "execution_count": 1, "id": "acd32e1f", "metadata": {}, "outputs": [], "source": ["len(pd.unique(x_train.genres))"]}, {"cell_type": "markdown", "id": "7b86fab1", "metadata": {}, "source": ["## DATA PREPARATION "]}, {"cell_type": "code", "execution_count": 1, "id": "e61ee17b", "metadata": {}, "outputs": [], "source": ["# function for text cleaning \ndef clean_text(text):\n    # remove backslash-apostrophe \n    text = re.sub(\"\\'\", \"\", text) \n    # remove everything except alphabets \n    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n    # remove whitespaces \n    text = ' '.join(text.split()) \n    # convert text to lowercase \n    text = text.lower() \n    \n    return text\n\nx_train['clean_plot'] = x_train['synopsis'].apply(lambda x: clean_text(x))\nx_test['clean_plot'] = x_test['synopsis'].apply(lambda x: clean_text(x))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "c57d1be8", "metadata": {}, "outputs": [], "source": ["#function to remove all the stopwords that may affects the prestation of the model\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\n\ndef remove_stopwords(text):\n    no_stopword_text = [w for w in text.split() if not w in stop_words]\n    return ' '.join(no_stopword_text)\n\nx_train['clean_plot'] = x_train['clean_plot'].apply(lambda x: remove_stopwords(x))"]}, {"cell_type": "code", "execution_count": 1, "id": "55f06ae2", "metadata": {}, "outputs": [], "source": ["#estrapolate the genres vector from the train dataset\n\n\n#multilabel\ngen = [x.split(' ') for x in list (x_train['genres'])]    \n    #multiclass\n#gen1 = [[x] for x in list(x_train['genres'])]#"]}, {"cell_type": "code", "execution_count": 1, "id": "19ae5431", "metadata": {}, "outputs": [], "source": ["gen"]}, {"cell_type": "code", "execution_count": 1, "id": "484e57c8", "metadata": {}, "outputs": [], "source": ["set(x for l in gen for x in l)\n#there are in total 19 different categories"]}, {"cell_type": "code", "execution_count": 1, "id": "442094e1", "metadata": {}, "outputs": [], "source": ["#apply the onehot transformation for the genres vector\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmultilabel_binarizer = MultiLabelBinarizer()\ny=multilabel_binarizer.fit_transform(gen)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "7e9fb9b6", "metadata": {}, "outputs": [], "source": ["y.shape\n#this is perfect, cause it takes number of rows x number of different categories"]}, {"cell_type": "code", "execution_count": 1, "id": "cbec9650", "metadata": {}, "outputs": [], "source": ["#using the 10k most frequent words in the synopsis through the Tf-idf features \n\ntfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)"]}, {"cell_type": "code", "execution_count": 1, "id": "8231b57a", "metadata": {}, "outputs": [], "source": ["# applying TF-IDF features to the synopsis\nxtrain_tfidf = tfidf_vectorizer.fit_transform(x_train['clean_plot'])"]}, {"cell_type": "code", "execution_count": 1, "id": "9ee0314a", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n\n# Binary Relevance\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Performance metric\nfrom sklearn.metrics import f1_score"]}, {"cell_type": "markdown", "id": "d943f091", "metadata": {}, "source": ["## THE MODEL"]}, {"cell_type": "code", "execution_count": 1, "id": "2d9c7e45", "metadata": {}, "outputs": [], "source": ["lr = LogisticRegression()\nclf = OneVsRestClassifier(lr)"]}, {"cell_type": "code", "execution_count": 1, "id": "6623a75f", "metadata": {}, "outputs": [], "source": ["# fit model on train data\nclf.fit(xtrain_tfidf,y)"]}, {"cell_type": "code", "execution_count": 1, "id": "804d6941", "metadata": {}, "outputs": [], "source": ["y_pred = clf.predict(tfidf_vectorizer.transform(x_test['clean_plot']))"]}, {"cell_type": "code", "execution_count": 1, "id": "07b246e1", "metadata": {}, "outputs": [], "source": ["y_pred.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "79209897", "metadata": {}, "outputs": [], "source": ["print(len(multilabel_binarizer.inverse_transform(y_pred)))\npred_gen = multilabel_binarizer.inverse_transform(y_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "05bc0eca", "metadata": {}, "outputs": [], "source": ["submission = pd.DataFrame(data= {'movie_id':x_test.movie_id,'predicted_genres':pred_gen})"]}, {"cell_type": "code", "execution_count": 1, "id": "6b651e76", "metadata": {}, "outputs": [], "source": ["for i in range(0,len(submission.predicted_genres)):\n   submission.predicted_genres[i] =(','.join((submission.predicted_genres[i])))"]}, {"cell_type": "code", "execution_count": 1, "id": "3353943d", "metadata": {}, "outputs": [], "source": ["for i in range(0,len(submission.predicted_genres)):\n    submission.predicted_genres[i] = submission.predicted_genres[i].replace(\",\",\" \")"]}, {"cell_type": "code", "execution_count": 1, "id": "3b30dc92", "metadata": {}, "outputs": [], "source": ["submission.to_csv('submission.csv',index=False)"]}, {"cell_type": "markdown", "id": "f1a1c935", "metadata": {}, "source": ["the model does not predict the genres for all the movies, maybe should be a good idea implement a multiclass model instead of multilabel, another option could be change the model, using something else instead of Onevstherest classifier."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}