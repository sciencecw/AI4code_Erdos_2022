{"cells": [{"cell_type": "markdown", "id": "e42a7d49", "metadata": {}, "source": ["### This is the tutorial of deep learning on FashionMNIST dataset using Pytorch. We will build a Convolutional Neural Network for predicting the classes of Dataset. I am assuming you know the basics of deep leanrning like layer architecture... convolution concepts. Without further ado... Lets start the tutorial."]}, {"cell_type": "markdown", "id": "4efc2e51", "metadata": {}, "source": ["# **Importing Important Libraries**"]}, {"cell_type": "code", "execution_count": 1, "id": "92b24502", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import confusion_matrix"]}, {"cell_type": "markdown", "id": "6d07004d", "metadata": {}, "source": ["### If the GPU is available use it for the computation otherwise use the CPU."]}, {"cell_type": "code", "execution_count": 1, "id": "49a5579e", "metadata": {}, "outputs": [], "source": ["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]}, {"cell_type": "markdown", "id": "b18ee437", "metadata": {}, "source": ["There are 2 ways to load the Fashion MNIST dataset. \n\n\n    1.   Load csv and then inherite Pytorch Dataset class .\n    2.   Use Pytorch module torchvision.datasets. It has many popular datasets like MNIST, FashionMNIST, CIFAR10 e.t.c.\n    \n    \n\n*   We use DataLoader class from torch.utils.data to load data in batches  in both method.\n* Comment out the code of a method which you are not using. \n\n\n\n\n"]}, {"cell_type": "markdown", "id": "15e50d57", "metadata": {}, "source": ["### 1.    Using a Dataset class.\n    \n   *   First load the data from the disk using pandas read_csv() method.\n\n   *   Now inherit Dataset class in your own class that you are building,    lets say FashionData.\n\n        *  It has 2 methods: __get_item__( ) and __len__().\n        * __get_item__( ) return the images and labels and __len__( ) returns the number of items in a dataset."]}, {"cell_type": "code", "execution_count": 1, "id": "867d9912", "metadata": {}, "outputs": [], "source": ["train_csv = pd.read_csv(\"../input/fashion-mnist_train.csv\")\ntest_csv = pd.read_csv(\"../input/fashion-mnist_test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "b24a587d", "metadata": {}, "outputs": [], "source": ["class FashionDataset(Dataset):\n    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n    \n    def __init__(self, data, transform = None):\n        \"\"\"Method to initilaize variables.\"\"\" \n        self.fashion_MNIST = list(data.values)\n        self.transform = transform\n        \n        label = []\n        image = []\n        \n        for i in self.fashion_MNIST:\n             # first column is of labels.\n            label.append(i[0])\n            image.append(i[1:])\n        self.labels = np.asarray(label)\n        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n\n    def __getitem__(self, index):\n        label = self.labels[index]\n        image = self.images[index]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.images)"]}, {"cell_type": "code", "execution_count": 1, "id": "fd9b5dae", "metadata": {}, "outputs": [], "source": ["# Transform data into Tensor that has a range from 0 to 1\ntrain_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\ntest_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n\ntrain_loader = DataLoader(train_set, batch_size=100)\ntest_loader = DataLoader(train_set, batch_size=100)"]}, {"cell_type": "markdown", "id": "80152a06", "metadata": {}, "source": ["### 2. Using FashionMNIST class from torchvision module.\n\n\n*   It will download the dataset first time.\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "5a3f1838", "metadata": {}, "outputs": [], "source": ["\"\"\"\ntrain_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n                                                transforms.Compose([transforms.ToTensor()]))\ntest_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n                                               transforms.Compose([transforms.ToTensor()]))  \n\"\"\"                                               "]}, {"cell_type": "code", "execution_count": 1, "id": "77ed5fe1", "metadata": {}, "outputs": [], "source": ["\"\"\"\ntrain_loader = torch.utils.data.DataLoader(train_set, \n                                           batch_size=100)\ntest_loader = torch.utils.data.DataLoader(test_set,\n                                          batch_size=100)\n\"\"\"                                          "]}, {"cell_type": "markdown", "id": "f7517124", "metadata": {}, "source": ["### We have 10 types of clothes in FashionMNIST dataset.\n\n\n> Making a method that return the name of class for the label number.\nex. if the label is 5, we return Sandal.\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "36d111f2", "metadata": {}, "outputs": [], "source": ["def output_label(label):\n    output_mapping = {\n                 0: \"T-shirt/Top\",\n                 1: \"Trouser\",\n                 2: \"Pullover\",\n                 3: \"Dress\",\n                 4: \"Coat\", \n                 5: \"Sandal\", \n                 6: \"Shirt\",\n                 7: \"Sneaker\",\n                 8: \"Bag\",\n                 9: \"Ankle Boot\"\n                 }\n    input = (label.item() if type(label) == torch.Tensor else label)\n    return output_mapping[input]"]}, {"cell_type": "markdown", "id": "085119fe", "metadata": {}, "source": ["### Playing with data and displaying some images using matplotlib imshow() method.\n\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "4a1f3608", "metadata": {}, "outputs": [], "source": ["a = next(iter(train_loader))\na[0].size()"]}, {"cell_type": "code", "execution_count": 1, "id": "861581a8", "metadata": {}, "outputs": [], "source": ["len(train_set)"]}, {"cell_type": "code", "execution_count": 1, "id": "52c298b2", "metadata": {}, "outputs": [], "source": ["image, label = next(iter(train_set))\nplt.imshow(image.squeeze(), cmap=\"gray\")\nprint(label)"]}, {"cell_type": "code", "execution_count": 1, "id": "c2def135", "metadata": {}, "outputs": [], "source": ["demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n\nbatch = next(iter(demo_loader))\nimages, labels = batch\nprint(type(images), type(labels))\nprint(images.shape, labels.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "e0391781", "metadata": {}, "outputs": [], "source": ["grid = torchvision.utils.make_grid(images, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)))\nprint(\"labels: \", end=\" \")\nfor i, label in enumerate(labels):\n    print(output_label(label), end=\", \")\n"]}, {"cell_type": "markdown", "id": "98843861", "metadata": {}, "source": ["## Building a CNN \n\n\n*   Make a model class (FashionCNN in our case)\n    * It inherit nn.Module class that is a super class for all the neural networks in Pytorch.\n* Our Neural Net has following layers:\n    * Two Sequential layers each consists of following layers-\n        * Convolution layer that has kernel size of 3 * 3, padding = 1 (zero_padding) in 1st layer and padding = 0 in second one. Stride of 1 in both layer.\n        * Batch Normalization layer.\n        * Acitvation function: ReLU.\n        * Max Pooling layer with kernel size of 2 * 2 and stride 2.\n     * Flatten out the output for dense layer(a.k.a. fully connected layer).\n     * 3 Fully connected layer  with different in/out features.\n     * 1 Dropout layer that has class probability p = 0.25.\n  \n     * All the functionaltiy is given in forward method that defines the forward pass of CNN.\n     * Our input image is changing in a following way:\n        * First Convulation layer : input: 28 \\* 28 \\* 3, output: 28 \\* 28 \\* 32\n        * First Max Pooling layer : input: 28 \\* 28 \\* 32, output: 14 \\* 14 \\* 32\n        * Second Conv layer : input : 14 \\* 14 \\* 32, output: 12 \\* 12 \\* 64\n        * Second Max Pooling layer : 12 \\* 12 \\* 64, output:  6 \\* 6 \\* 64\n    * Final fully connected layer has 10 output features for 10 types of clothes.\n\n> Lets implementing the network...\n\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "06bf064c", "metadata": {}, "outputs": [], "source": ["class FashionCNN(nn.Module):\n    \n    def __init__(self):\n        super(FashionCNN, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n        self.drop = nn.Dropout2d(0.25)\n        self.fc2 = nn.Linear(in_features=600, out_features=120)\n        self.fc3 = nn.Linear(in_features=120, out_features=10)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        \n        return out\n"]}, {"cell_type": "markdown", "id": "e1a708a9", "metadata": {}, "source": ["### Making a model of our CNN class\n\n*   Creating a object(model in the code)\n*   Transfering it into GPU if available.\n*  Defining a Loss function. we're using CrossEntropyLoss() here.\n*  Using Adam algorithm for optimization purpose.\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "d0930c34", "metadata": {}, "outputs": [], "source": ["model = FashionCNN()\nmodel.to(device)\n\nerror = nn.CrossEntropyLoss()\n\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(model)"]}, {"cell_type": "markdown", "id": "1f55dd60", "metadata": {}, "source": ["## Training a network and Testing it on test dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "9b70a875", "metadata": {}, "outputs": [], "source": ["num_epochs = 5\ncount = 0\n# Lists for visualization of loss and accuracy \nloss_list = []\niteration_list = []\naccuracy_list = []\n\n# Lists for knowing classwise accuracy\npredictions_list = []\nlabels_list = []\n\nfor epoch in range(num_epochs):\n    for images, labels in train_loader:\n        # Transfering images and labels to GPU if available\n        images, labels = images.to(device), labels.to(device)\n    \n        train = Variable(images.view(100, 1, 28, 28))\n        labels = Variable(labels)\n        \n        # Forward pass \n        outputs = model(train)\n        loss = error(outputs, labels)\n        \n        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n        optimizer.zero_grad()\n        \n        #Propagating the error backward\n        loss.backward()\n        \n        # Optimizing the parameters\n        optimizer.step()\n    \n        count += 1\n    \n    # Testing the model\n    \n        if not (count % 50):    # It's same as \"if count % 50 == 0\"\n            total = 0\n            correct = 0\n        \n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n                labels_list.append(labels)\n            \n                test = Variable(images.view(100, 1, 28, 28))\n            \n                outputs = model(test)\n            \n                predictions = torch.max(outputs, 1)[1].to(device)\n                predictions_list.append(predictions)\n                correct += (predictions == labels).sum()\n            \n                total += len(labels)\n            \n            accuracy = correct * 100 / total\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        \n        if not (count % 500):\n            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))\n"]}, {"cell_type": "markdown", "id": "f54f0fcf", "metadata": {}, "source": ["### Visualizing the Loss and Accuracy with Iterations\n"]}, {"cell_type": "code", "execution_count": 1, "id": "f7a7e1fe", "metadata": {}, "outputs": [], "source": ["plt.plot(iteration_list, loss_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Iterations vs Loss\")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "11fe54fe", "metadata": {}, "outputs": [], "source": ["plt.plot(iteration_list, accuracy_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Iterations vs Accuracy\")\nplt.show()"]}, {"cell_type": "markdown", "id": "cce6005b", "metadata": {}, "source": ["### Looking the Accuracy in each class of FashionMNIST dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "1c8fb294", "metadata": {}, "outputs": [], "source": ["class_correct = [0. for _ in range(10)]\ntotal_correct = [0. for _ in range(10)]\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        test = Variable(images)\n        outputs = model(test)\n        predicted = torch.max(outputs, 1)[1]\n        c = (predicted == labels).squeeze()\n        \n        for i in range(100):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            total_correct[label] += 1\n        \nfor i in range(10):\n    print(\"Accuracy of {}: {:.2f}%\".format(output_label(i), class_correct[i] * 100 / total_correct[i]))"]}, {"cell_type": "markdown", "id": "7a1453c6", "metadata": {}, "source": ["### Printing the Confusion Matrix "]}, {"cell_type": "code", "execution_count": 1, "id": "850e8232", "metadata": {}, "outputs": [], "source": ["from itertools import chain \n\npredictions_l = [predictions_list[i].tolist() for i in range(len(predictions_list))]\nlabels_l = [labels_list[i].tolist() for i in range(len(labels_list))]\npredictions_l = list(chain.from_iterable(predictions_l))\nlabels_l = list(chain.from_iterable(labels_l))"]}, {"cell_type": "code", "execution_count": 1, "id": "bff66695", "metadata": {}, "outputs": [], "source": ["import sklearn.metrics as metrics\n\nconfusion_matrix(labels_l, predictions_l)\nprint(\"Classification report for CNN :\\n%s\\n\"\n      % (metrics.classification_report(labels_l, predictions_l)))"]}, {"cell_type": "markdown", "id": "7f64020d", "metadata": {}, "source": ["### This is my implementation of deep learning in FashionMNIST dataset using Pytorch. I've achieved 93% test accuracy. Change those layer architecture or parameters to make it better. \n***I hope you like it. Give your feedback. It helps me to a lot. Thank you. :)***"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}