{"cells": [{"cell_type": "code", "execution_count": 1, "id": "530d1d71", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport re\nfrom nltk.corpus import stopwords\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score \nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "c2493485", "metadata": {}, "outputs": [], "source": ["train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "8fa2278e", "metadata": {}, "outputs": [], "source": ["train.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "0d8e9e99", "metadata": {}, "outputs": [], "source": ["train.question_text[9]"]}, {"cell_type": "code", "execution_count": 1, "id": "dde8da79", "metadata": {}, "outputs": [], "source": ["train.target.value_counts().plot(kind='bar')"]}, {"cell_type": "code", "execution_count": 1, "id": "4c5ceb99", "metadata": {}, "outputs": [], "source": ["def clean_text(text, remove_stopwords = False):\n    text = text.lower()\n    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \") ## remove new line chars\n    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)  ## remove unwanted chars\n    text = re.sub(r'\\'', ' ', text)\n    text = re.sub('[\\d+]', '', text) ## remove numerics\n    text=  re.sub(\"\\s\\s+\", \" \", text)  ## remove white spaces\n    \n    # Optionally, remove stop words\n    if remove_stopwords:\n        text = text.split()\n        stops = set(stopwords.words(\"english\"))\n        text = [w for w in text if not w in stops]\n        text = \" \".join(text)\n\n    return text"]}, {"cell_type": "code", "execution_count": 1, "id": "0f20b9da", "metadata": {}, "outputs": [], "source": ["clean_question=[]\nfor text in tqdm(train.question_text):\n    textt=clean_text(text,remove_stopwords = True)\n    clean_question.append(textt)"]}, {"cell_type": "code", "execution_count": 1, "id": "6520d4c6", "metadata": {}, "outputs": [], "source": ["train['clean_question']=clean_question"]}, {"cell_type": "code", "execution_count": 1, "id": "dbbf8e7c", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "6cfde301", "metadata": {}, "outputs": [], "source": ["sincere = train[train.target==0][\"clean_question\"]\ninsincere = train[train.target==1][\"clean_question\"]\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b0bc4a95", "metadata": {}, "outputs": [], "source": ["wordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=STOPWORDS,\n                          max_words=50000,\n                          max_font_size=30, \n                          random_state=42\n                         ).generate(str(sincere))\n\nprint(wordcloud)\nplt.figure(figsize=(16,13))\n\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n#fig.savefig(\"word1.png\", dpi=900)"]}, {"cell_type": "code", "execution_count": 1, "id": "7ee68abe", "metadata": {}, "outputs": [], "source": ["wordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=STOPWORDS,\n                          max_words=50000,\n                          max_font_size=30, \n                          random_state=42\n                         ).generate(str(insincere))\n\nprint(wordcloud)\nplt.figure(figsize=(16,13))\n\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n#fig.savefig(\"word1.png\", dpi=900)"]}, {"cell_type": "code", "execution_count": 1, "id": "cb63fe31", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(train['clean_question'], \n                                                    train['target'], \n                                                    random_state=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "f6ad22f4", "metadata": {}, "outputs": [], "source": ["tfvect=TfidfVectorizer(stop_words='english',min_df=3).fit(X_train)\nx_train_tfvect=tfvect.transform(X_train)\nx_test_tfvect=tfvect.transform(X_test)\nname=tfvect.get_feature_names()\nfeature_names = np.array(tfvect.get_feature_names())\nsorted_tfidf_index = x_train_tfvect.max(0).toarray()[0].argsort()"]}, {"cell_type": "code", "execution_count": 1, "id": "f0323b75", "metadata": {}, "outputs": [], "source": ["print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-100:-1]]))"]}, {"cell_type": "code", "execution_count": 1, "id": "9261f2ad", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression"]}, {"cell_type": "code", "execution_count": 1, "id": "c88dd577", "metadata": {}, "outputs": [], "source": ["model=LogisticRegression(solver='sag')\nmodel.fit(x_train_tfvect,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "3f5afe69", "metadata": {}, "outputs": [], "source": ["predicted= model.predict(x_test_tfvect)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "6834f1cb", "metadata": {}, "outputs": [], "source": ["accuracy=accuracy_score(y_test, predicted)\n\nreport=classification_report(y_test, predicted)"]}, {"cell_type": "code", "execution_count": 1, "id": "69319c00", "metadata": {}, "outputs": [], "source": ["accuracy"]}, {"cell_type": "code", "execution_count": 1, "id": "d5f63976", "metadata": {}, "outputs": [], "source": ["print(report)"]}, {"cell_type": "markdown", "id": "c7d05df6", "metadata": {}, "source": ["# to be continued...."]}, {"cell_type": "code", "execution_count": 1, "id": "98f1634c", "metadata": {}, "outputs": [], "source": ["clean_question_test=[]\nfor text in tqdm(test.question_text):\n    textt=clean_text(text,remove_stopwords = True)\n    clean_question_test.append(textt)"]}, {"cell_type": "code", "execution_count": 1, "id": "2cc6ebe0", "metadata": {}, "outputs": [], "source": ["x_testt_tfvect=tfvect.transform(clean_question_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "c3bf63ba", "metadata": {}, "outputs": [], "source": ["test_pred=model.predict(x_testt_tfvect)\ntest_pred"]}, {"cell_type": "code", "execution_count": 1, "id": "573086b0", "metadata": {}, "outputs": [], "source": ["out_df = pd.DataFrame({\"qid\":test[\"qid\"].values})\nout_df['prediction'] = test_pred\nout_df.to_csv(\"submission.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}