{"cells": [{"cell_type": "code", "execution_count": 1, "id": "fe961f58", "metadata": {}, "outputs": [], "source": ["import re\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Device:\", tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)"]}, {"cell_type": "code", "execution_count": 1, "id": "cf7b7a6b", "metadata": {}, "outputs": [], "source": ["AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 25 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [180, 180]\nCLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]"]}, {"cell_type": "markdown", "id": "1e609874", "metadata": {}, "source": ["# Load the data"]}, {"cell_type": "code", "execution_count": 1, "id": "f904d57f", "metadata": {}, "outputs": [], "source": ["train_images = tf.data.TFRecordDataset(\n    \"gs://download.tensorflow.org/data/ChestXRay2017/train/images.tfrec\"\n)\ntrain_paths = tf.data.TFRecordDataset(\n    \"gs://download.tensorflow.org/data/ChestXRay2017/train/paths.tfrec\"\n)\n\nds = tf.data.Dataset.zip((train_images, train_paths))"]}, {"cell_type": "code", "execution_count": 1, "id": "e5961076", "metadata": {}, "outputs": [], "source": ["COUNT_NORMAL = len(\n    [\n        filename\n        for filename in train_paths\n        if \"NORMAL\" in filename.numpy().decode(\"utf-8\")\n    ]\n)\nprint(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n\nCOUNT_PNEUMONIA = len(\n    [\n        filename\n        for filename in train_paths\n        if \"PNEUMONIA\" in filename.numpy().decode(\"utf-8\")\n    ]\n)\nprint(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))"]}, {"cell_type": "code", "execution_count": 1, "id": "7aa9e36b", "metadata": {}, "outputs": [], "source": ["def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, \"/\")\n    # The second to last is the class-directory\n    return parts[-2] == \"PNEUMONIA\"\n\n\ndef decode_img(img):\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    # resize the image to the desired size.\n    return tf.image.resize(img, IMAGE_SIZE)\n\n\ndef process_path(image, path):\n    label = get_label(path)\n    # load the raw data from the file as a string\n    img = decode_img(image)\n    return img, label\n\n\nds = ds.map(process_path, num_parallel_calls=AUTOTUNE)"]}, {"cell_type": "code", "execution_count": 1, "id": "4442257e", "metadata": {}, "outputs": [], "source": ["ds = ds.shuffle(10000)\ntrain_ds = ds.take(4200)\nval_ds = ds.skip(4200)"]}, {"cell_type": "code", "execution_count": 1, "id": "03a248f1", "metadata": {}, "outputs": [], "source": ["for image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())"]}, {"cell_type": "code", "execution_count": 1, "id": "b159e390", "metadata": {}, "outputs": [], "source": ["test_images = tf.data.TFRecordDataset(\n    \"gs://download.tensorflow.org/data/ChestXRay2017/test/images.tfrec\"\n)\ntest_paths = tf.data.TFRecordDataset(\n    \"gs://download.tensorflow.org/data/ChestXRay2017/test/paths.tfrec\"\n)\ntest_ds = tf.data.Dataset.zip((test_images, test_paths))\n\ntest_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n"]}, {"cell_type": "markdown", "id": "f0b764bb", "metadata": {}, "source": ["# Visualize the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "5d6e5621", "metadata": {}, "outputs": [], "source": ["def prepare_for_training(ds, cache=True):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.batch(BATCH_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds"]}, {"cell_type": "code", "execution_count": 1, "id": "a7193e3c", "metadata": {}, "outputs": [], "source": ["train_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\n\nimage_batch, label_batch = next(iter(train_ds))"]}, {"cell_type": "code", "execution_count": 1, "id": "583ec28c", "metadata": {}, "outputs": [], "source": ["def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(20, 20))\n    for n in range(36):\n        ax = plt.subplot(6, 6, n + 1)\n        plt.imshow(image_batch[n] / 255)\n        if label_batch[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")"]}, {"cell_type": "code", "execution_count": 1, "id": "a9374473", "metadata": {}, "outputs": [], "source": ["show_batch(image_batch.numpy(), label_batch.numpy())"]}, {"cell_type": "markdown", "id": "3b413d5f", "metadata": {}, "source": ["# Build the CNN"]}, {"cell_type": "code", "execution_count": 1, "id": "68bf7aa0", "metadata": {}, "outputs": [], "source": ["from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\ndef conv_block(filters, inputs):\n    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    outputs = layers.MaxPool2D()(x)\n\n    return outputs\n\n\ndef dense_block(units, dropout_rate, inputs):\n    x = layers.Dense(units, activation=\"relu\")(inputs)\n    x = layers.BatchNormalization()(x)\n    outputs = layers.Dropout(dropout_rate)(x)\n\n    return outputs"]}, {"cell_type": "code", "execution_count": 1, "id": "1c5bfb3f", "metadata": {}, "outputs": [], "source": ["def build_model():\n    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n    x = preprocessing.Rescaling(1.0 / 255)(inputs)\n    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPool2D()(x)\n\n    x = conv_block(32, x)\n    x = conv_block(64, x)\n\n    x = conv_block(128, x)\n    x = layers.Dropout(0.2)(x)\n\n    x = conv_block(256, x)\n    x = layers.Dropout(0.2)(x)\n\n    x = layers.Flatten()(x)\n    x = dense_block(512, 0.7, x)\n    x = dense_block(128, 0.5, x)\n    x = dense_block(64, 0.3, x)\n\n    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model\n"]}, {"cell_type": "markdown", "id": "d31f48c1", "metadata": {}, "source": ["# Correct for data imbalance"]}, {"cell_type": "code", "execution_count": 1, "id": "324ab57a", "metadata": {}, "outputs": [], "source": ["initial_bias = np.log([COUNT_PNEUMONIA / COUNT_NORMAL])\nprint(\"Initial bias: {:.5f}\".format(initial_bias[0]))\n\nTRAIN_IMG_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA\nweight_for_0 = (1 / COUNT_NORMAL) * (TRAIN_IMG_COUNT) / 2.0\nweight_for_1 = (1 / COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) / 2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(\"Weight for class 0: {:.2f}\".format(weight_for_0))\nprint(\"Weight for class 1: {:.2f}\".format(weight_for_1))"]}, {"cell_type": "markdown", "id": "6bbd86d2", "metadata": {}, "source": ["# Train the model"]}, {"cell_type": "markdown", "id": "829cbd8a", "metadata": {}, "source": ["## Defining callbacks"]}, {"cell_type": "code", "execution_count": 1, "id": "a2ac319f", "metadata": {}, "outputs": [], "source": ["checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\", save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(\n    patience=10, restore_best_weights=True\n)"]}, {"cell_type": "code", "execution_count": 1, "id": "669261a6", "metadata": {}, "outputs": [], "source": ["initial_learning_rate = 0.015\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100, decay_rate=0.99, staircase=True\n)"]}, {"cell_type": "markdown", "id": "0919af4b", "metadata": {}, "source": ["# Fit the model"]}, {"cell_type": "code", "execution_count": 1, "id": "3ef32f24", "metadata": {}, "outputs": [], "source": ["with strategy.scope():\n    model = build_model()\n\n    METRICS = [\n        tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.Precision(name=\"precision\"),\n        tf.keras.metrics.Recall(name=\"recall\"),\n    ]\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss=\"binary_crossentropy\",\n        metrics=METRICS,\n    )\n\nhistory = model.fit(\n    train_ds,\n    epochs=100,\n    validation_data=val_ds,\n    class_weight=class_weight,\n    callbacks=[checkpoint_cb, early_stopping_cb],\n)"]}, {"cell_type": "code", "execution_count": 1, "id": "7807c3c6", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(2, 2, figsize=(20, 10))\nax = ax.ravel()\n\nfor i, met in enumerate([\"precision\", \"recall\", \"binary_accuracy\", \"loss\"]):\n    ax[i].grid()\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history[\"val_\" + met])\n    ax[i].set_title(\"Model {}\".format(met))\n    ax[i].set_xlabel(\"epochs\")\n    ax[i].set_ylabel(met)\n    ax[i].legend([\"train\", \"val\"])"]}, {"cell_type": "markdown", "id": "54ceb0bc", "metadata": {}, "source": ["# Predict and evaluate results"]}, {"cell_type": "code", "execution_count": 1, "id": "9abc264e", "metadata": {}, "outputs": [], "source": ["model.evaluate(test_ds, return_dict=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "c205cb61", "metadata": {}, "outputs": [], "source": ["for image, label in test_ds.take(1):\n    plt.imshow(image[0] / 255.0)\n    plt.title(CLASS_NAMES[label[0].numpy()])\n    plt.axis(\"off\")\n\nprediction = model.predict(test_ds.take(1))[0]\nscores = [1 - prediction, prediction]\n\nfor score, name in zip(scores, CLASS_NAMES):\n    print(\"This image is %.2f percent %s\" % ((100 * score), name))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}