{"cells": [{"cell_type": "code", "execution_count": 1, "id": "ea94aaac", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "6a8d17a2", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Lasso,Ridge,BayesianRidge,ElasticNet,HuberRegressor,LinearRegression,LogisticRegression,SGDRegressor\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import r2_score\nwarnings.filterwarnings(\"ignore\")"]}, {"cell_type": "code", "execution_count": 1, "id": "43c7c9b1", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv')\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "2565700b", "metadata": {}, "outputs": [], "source": ["del df['Serial No.']"]}, {"cell_type": "code", "execution_count": 1, "id": "826260af", "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "id": "541774ca", "metadata": {}, "source": ["DEPENDENCIES AND RELATIONS"]}, {"cell_type": "code", "execution_count": 1, "id": "298625f5", "metadata": {}, "outputs": [], "source": ["%pylab inline"]}, {"cell_type": "code", "execution_count": 1, "id": "c58bf078", "metadata": {}, "outputs": [], "source": ["sns.distplot(df['Chance of Admit '])"]}, {"cell_type": "code", "execution_count": 1, "id": "eac0dcd7", "metadata": {}, "outputs": [], "source": ["pylab.hist(df['GRE Score'])\npylab.xlabel('GRE Score')"]}, {"cell_type": "code", "execution_count": 1, "id": "3f540a99", "metadata": {}, "outputs": [], "source": ["pylab.hist(df['TOEFL Score'])\npylab.xlabel('TOEFL Score')"]}, {"cell_type": "code", "execution_count": 1, "id": "f9677ef7", "metadata": {}, "outputs": [], "source": ["sns.relplot(x=\"GRE Score\", y=\"TOEFL Score\", kind=\"line\", ci=\"sd\", data=df)"]}, {"cell_type": "code", "execution_count": 1, "id": "33047a35", "metadata": {}, "outputs": [], "source": ["sns.relplot(x=\"GRE Score\", y=\"CGPA\", kind=\"line\", ci=\"sd\",data=df)"]}, {"cell_type": "code", "execution_count": 1, "id": "12f0bf8d", "metadata": {}, "outputs": [], "source": ["fig = sns.lmplot(x=\"CGPA\", y=\"LOR \", data=df, hue=\"Research\")\nplt.title(\"GRE Score vs CGPA\")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "0a24d7fd", "metadata": {}, "outputs": [], "source": ["X = df.drop(['Chance of Admit '], axis=1)\ny = df['Chance of Admit ']"]}, {"cell_type": "code", "execution_count": 1, "id": "fc97fab6", "metadata": {}, "outputs": [], "source": ["f,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"]}, {"cell_type": "markdown", "id": "d3a67234", "metadata": {}, "source": ["LOOKING FOR THE BEST MODEL"]}, {"cell_type": "code", "execution_count": 1, "id": "56f618ea", "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, shuffle=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "f0edc269", "metadata": {}, "outputs": [], "source": ["kfolds = 4 \nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\nbase_models = [(\"DT_model\",DecisionTreeRegressor(random_state=42)),\n               (\"RF_model\", RandomForestRegressor(random_state=42,n_jobs=-1)),\n               (\"LR_model\", LinearRegression(n_jobs=-1)),\n               (\"KN_model\", KNeighborsRegressor(n_jobs=-1)),\n              (\"SVR_model\",SVR()),\n              ('ABR_model',AdaBoostRegressor(random_state=42)),\n              ('GBR_model',GradientBoostingRegressor(random_state=42)),\n              ('XGB_model',XGBRegressor(random_state=42,n_jobs=-1))]\nfor name,model in base_models:\n    clf = model\n    cv_results = cross_val_score(clf, \n                                 X, y, \n                                 cv=split,\n                                 scoring=\"neg_mean_absolute_error\",\n                                 n_jobs=-1\n                                 )\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} absolute error: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")"]}, {"cell_type": "code", "execution_count": 1, "id": "550b771a", "metadata": {}, "outputs": [], "source": ["def GetScaledModel(nameOfScaler):\n    scaler = StandardScaler()\n    pipelines = []\n    \n    pipelines.append((nameOfScaler+'DT_model'  , Pipeline([('Scaler', scaler),(\"DT_model\",DecisionTreeRegressor())])))\n    pipelines.append((nameOfScaler+'RF_model' , Pipeline([('Scaler', scaler),(\"RF_model\", RandomForestRegressor())])))\n    pipelines.append((nameOfScaler+'LR_model' , Pipeline([('Scaler', scaler), (\"LR_model\", LinearRegression())])))\n    pipelines.append((nameOfScaler+'KN_model', Pipeline([('Scaler', scaler),(\"KN_model\", KNeighborsRegressor())])))\n    pipelines.append((nameOfScaler+'SVR_model'  , Pipeline([('Scaler', scaler),(\"SVR_model\",SVR())])))\n    pipelines.append((nameOfScaler+'ABR_model'  , Pipeline([('Scaler', scaler),('ABR_model',AdaBoostRegressor())])))\n    pipelines.append((nameOfScaler+'GBR_model' , Pipeline([('Scaler', scaler),('GBR_model',GradientBoostingRegressor())])  ))\n    pipelines.append((nameOfScaler+'XGB_model'  , Pipeline([('Scaler', scaler),('XGB_model',XGBRegressor(random_state=42,n_jobs=-1))]) ))\n    return pipelines"]}, {"cell_type": "code", "execution_count": 1, "id": "98d261a2", "metadata": {}, "outputs": [], "source": ["def BasedLine2(X_train, y_train,models):\n    num_folds = 10\n    scoring=\"neg_mean_absolute_error\"\n\n    results = []\n    names = []\n    for name, model in models:\n        split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n        cv_results = cross_val_score(model, X_train, y_train, cv=split, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        \n    return names, results"]}, {"cell_type": "code", "execution_count": 1, "id": "d06d67ac", "metadata": {}, "outputs": [], "source": ["def ScoreDataFrame(names,results):\n    def floatingDecimals(f_val, dec=3):\n        prc = \"{:.\"+str(dec)+\"f}\" \n    \n        return float(prc.format(f_val))\n\n    scores = []\n    for r in results:\n        scores.append(floatingDecimals(r.mean(),4))\n\n    scoreDataFrame = pd.DataFrame({'Model':names, 'Score': scores})\n    return scoreDataFrame"]}, {"cell_type": "code", "execution_count": 1, "id": "6471a8e2", "metadata": {}, "outputs": [], "source": ["names,results = BasedLine2(X_train, y_train,base_models)\nbasedLineScore = ScoreDataFrame(names,results)\nbasedLineScore"]}, {"cell_type": "code", "execution_count": 1, "id": "72c498dd", "metadata": {}, "outputs": [], "source": ["models = GetScaledModel('standard')\nnames,results = BasedLine2(X_train, y_train,models)\nscaledScoreStandard = ScoreDataFrame(names,results)\ncompareModels = pd.concat([basedLineScore,\n                           scaledScoreStandard], axis=1)\ncompareModels"]}, {"cell_type": "markdown", "id": "3db79c0c", "metadata": {}, "source": ["LinearRegression shows the best result"]}, {"cell_type": "code", "execution_count": 1, "id": "14d5db85", "metadata": {}, "outputs": [], "source": ["lr =  LinearRegression()\nlr.fit(X_train,y_train)\npredict = lr.predict(X_test)\nmean_absolute_error(y_test,predict)"]}, {"cell_type": "code", "execution_count": 1, "id": "2d4dd9b1", "metadata": {}, "outputs": [], "source": ["r2_score(y_test,predict)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}