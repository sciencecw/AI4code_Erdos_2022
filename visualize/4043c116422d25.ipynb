{"cells": [{"cell_type": "code", "execution_count": 1, "id": "4c9576a9", "metadata": {}, "outputs": [], "source": ["import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler"]}, {"cell_type": "markdown", "id": "d8d5cb5f", "metadata": {}, "source": ["# 1. Read Data"]}, {"cell_type": "code", "execution_count": 1, "id": "fa577d8e", "metadata": {}, "outputs": [], "source": ["# /kaggle/input/titanic/train.csv\n# /kaggle/input/titanic/gender_submission.csv\n# /kaggle/input/titanic/test.csv\n\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ntrain.head()"]}, {"cell_type": "markdown", "id": "8a9a3633", "metadata": {}, "source": ["# 2. Anaylsis"]}, {"cell_type": "code", "execution_count": 1, "id": "f2b6838e", "metadata": {}, "outputs": [], "source": ["corrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, annot=True, fmt='.2f', vmax=1, square=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "1419431b", "metadata": {}, "outputs": [], "source": ["sns.set()\nsns.pairplot(train, size = 2.5)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "ae8fb1bb", "metadata": {}, "outputs": [], "source": ["sns.barplot(train['Survived'], train['Sex'])"]}, {"cell_type": "code", "execution_count": 1, "id": "034dc514", "metadata": {}, "outputs": [], "source": ["sns.swarmplot(train['Survived'], train['Fare'])"]}, {"cell_type": "code", "execution_count": 1, "id": "f0de0175", "metadata": {}, "outputs": [], "source": ["sns.barplot(train['Survived'], train['Pclass'])"]}, {"cell_type": "code", "execution_count": 1, "id": "4fc4f941", "metadata": {}, "outputs": [], "source": ["sns.swarmplot(x=\"Survived\", y=\"Fare\", data=train)"]}, {"cell_type": "code", "execution_count": 1, "id": "5e382e39", "metadata": {}, "outputs": [], "source": ["sns.swarmplot(train['Survived'], train['Age'])\n# sns.barplot(train['Survived'], train['Age'])"]}, {"cell_type": "code", "execution_count": 1, "id": "6efda3f6", "metadata": {}, "outputs": [], "source": ["sns.barplot(train['Survived'], (train['Age'] < 15).astype(int))\n"]}, {"cell_type": "markdown", "id": "122559ae", "metadata": {}, "source": ["# 3. Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "c6d2e652", "metadata": {}, "outputs": [], "source": ["train_survived = train['Survived']\ntrain_len = len(train)\nall_data = pd.concat((train, test), ignore_index=True)\n\ntrain_len"]}, {"cell_type": "markdown", "id": "b8b28c8b", "metadata": {}, "source": ["## 3.1 Append & Drop Columns "]}, {"cell_type": "code", "execution_count": 1, "id": "e1f44ba9", "metadata": {}, "outputs": [], "source": ["# FamilyName, Title, Famliy\nall_data['FamilyName'] = all_data['Name'].apply(lambda st: st[0:st.find(\",\")])\nall_data['Title'] = all_data['Name'].apply(lambda st: st[st.find(\",\") + 1:st.find(\".\")])\nall_data['Family'] = all_data['SibSp'] + all_data['Parch'] > 0\nall_data['Family'] = all_data['Family'].astype(int)"]}, {"cell_type": "code", "execution_count": 1, "id": "5740238a", "metadata": {}, "outputs": [], "source": ["# IsChild\n# all_data['IsChild'] = (all_data['Age'] < 20).astype(int)\n\n# Sex (trans to int)\n# all_data['Sex'] = (all_data['Sex'] == 'female').astype(int)\n\n# all_data.tail()"]}, {"cell_type": "markdown", "id": "f04c0112", "metadata": {}, "source": ["## 3.2 Missing Data"]}, {"cell_type": "code", "execution_count": 1, "id": "74025a57", "metadata": {}, "outputs": [], "source": ["# missing_train\nmissing = all_data.isnull().sum().sort_values(ascending=False)\nmissing"]}, {"cell_type": "code", "execution_count": 1, "id": "036271d1", "metadata": {}, "outputs": [], "source": ["# Cabin => None\nall_data['Cabin'] = all_data['Cabin'].fillna('None')\n\n# Age => Drop\nall_data.drop(['Age'], axis=1, inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "59d29104", "metadata": {}, "outputs": [], "source": ["# Fare => mean (Pclass, Embarked, Famliy)\nfare_nan_data = all_data[all_data['Fare'].isnull()]\nfare_nan_data_id = fare_nan_data['PassengerId']\nfare_nan_data"]}, {"cell_type": "code", "execution_count": 1, "id": "d1d881d2", "metadata": {}, "outputs": [], "source": ["\nfare_nan_data_input = all_data[(all_data['Embarked'] == fare_nan_data['Embarked'].values[0]) & \n                               (all_data['Family'] == fare_nan_data['Family'].values[0]) & \n                            (all_data['Pclass'] == fare_nan_data['Pclass'].values[0])].mean()\nall_data.loc[fare_nan_data.index, 'Fare'] = fare_nan_data_input['Fare']\nall_data.loc[fare_nan_data.index, 'Fare']"]}, {"cell_type": "code", "execution_count": 1, "id": "34137a06", "metadata": {}, "outputs": [], "source": ["# Embarked => Drop        \nall_data[all_data['Embarked'].isnull()]"]}, {"cell_type": "code", "execution_count": 1, "id": "c0b59be2", "metadata": {}, "outputs": [], "source": ["all_data = all_data.drop(index=[61, 829])\nall_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "cef0fc8d", "metadata": {}, "outputs": [], "source": ["# Scaler(Age, Fare)\nscaler = MinMaxScaler()\nall_data['Fare'] = scaler.fit_transform(all_data['Fare'].to_numpy().reshape(-1, 1))\nall_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "6f7fe3cb", "metadata": {}, "outputs": [], "source": ["all_data['Sex'] = all_data['Sex'] == 'female'\nall_data['Sex'] = all_data['Sex'].astype(int)\nall_data.head()"]}, {"cell_type": "markdown", "id": "35695a30", "metadata": {}, "source": ["## 3.3 Drop Data (Un Use Data)"]}, {"cell_type": "code", "execution_count": 1, "id": "652bb09b", "metadata": {}, "outputs": [], "source": ["all_data.drop(['Name', 'SibSp', 'Parch', 'Cabin', 'FamilyName', 'Embarked', 'Title'], axis=1, inplace=True)\nall_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "57229fc1", "metadata": {}, "outputs": [], "source": ["# all_data['Pclass'] = all_data['Pclass'].astype(str)\n\nall_data = pd.get_dummies(all_data)\nall_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "8cce2003", "metadata": {}, "outputs": [], "source": ["# Split Train and Test\ntrain = all_data[:train_len - 2] # remove 2 rows (by Embarked)\ntest = all_data[train_len - 2:]\n\n# Test Id\ntest_id = test['PassengerId']\ny_train = train.Survived.values\n\n# Drop Id\ntrain.drop(['PassengerId'], axis=1, inplace=True)\ntest.drop(['PassengerId'], axis=1, inplace=True)\n\n# Drop Survived\ntrain.drop(['Survived'], axis=1, inplace=True)\ntest.drop(['Survived'], axis=1, inplace=True)\n\nprint(len(all_data), len(train), len(test))"]}, {"cell_type": "markdown", "id": "105b7e6a", "metadata": {}, "source": ["# 4. Modeling"]}, {"cell_type": "code", "execution_count": 1, "id": "5e1b77af", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb"]}, {"cell_type": "code", "execution_count": 1, "id": "a55e3cbd", "metadata": {}, "outputs": [], "source": ["#Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)"]}, {"cell_type": "code", "execution_count": 1, "id": "d30df21f", "metadata": {}, "outputs": [], "source": ["ridge = make_pipeline(RobustScaler(), Ridge(alpha =0.0005, random_state=1))\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\nGBoost1 = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\n# GBoost with different option\nGBoost2 = GradientBoostingRegressor(n_estimators=6000,\n                                learning_rate=0.01,\n                                max_depth=4,\n                                max_features='sqrt',\n                                min_samples_leaf=15,\n                                min_samples_split=10,\n                                loss='huber',\n                                random_state=5)\nRF = make_pipeline(RobustScaler(), RandomForestRegressor(n_estimators=1200,\n                          max_depth=15,\n                          min_samples_split=5,\n                          min_samples_leaf=5,\n                          max_features=None,\n                          oob_score=True,\n                          random_state=5))\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"]}, {"cell_type": "code", "execution_count": 1, "id": "11f44743", "metadata": {}, "outputs": [], "source": ["ridge_score = rmsle_cv(ridge)\nlasso_score = rmsle_cv(lasso)\nenet_score = rmsle_cv(ENet)\nkrr_score = rmsle_cv(KRR)\ngboost1_score = rmsle_cv(GBoost1)\ngboost2_score = rmsle_cv(GBoost2)\nrf_score = rmsle_cv(RF)\nxgb_score = rmsle_cv(model_xgb)\nlgb_score = rmsle_cv(model_lgb)\nprint(\"Ridge score: {:.4f} ({:.4f})\\n\".format(ridge_score.mean(), ridge_score.std()))\nprint(\"Lasso score: {:.4f} ({:.4f})\\n\".format(lasso_score.mean(), lasso_score.std()))\nprint(\"ENet score: {:.4f} ({:.4f})\\n\".format(enet_score.mean(), enet_score.std()))\nprint(\"KRR score: {:.4f} ({:.4f})\\n\".format(krr_score.mean(), krr_score.std()))\nprint(\"Gradient Boosting1 score: {:.4f} ({:.4f})\\n\".format(gboost1_score.mean(), gboost1_score.std()))\nprint(\"Gradient Boosting2 score: {:.4f} ({:.4f})\\n\".format(gboost2_score.mean(), gboost2_score.std()))\nprint(\"Random Forest score: {:.4f} ({:.4f})\\n\".format(rf_score.mean(), rf_score.std()))\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(xgb_score.mean(), xgb_score.std()))\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(lgb_score.mean(), lgb_score.std()))\nprint(\"totalAVG: {:.4f}\\n\".format((ridge_score.mean() +\n                                   lasso_score.mean() +\n                                   enet_score.mean()+\n                                   krr_score.mean() +\n                                   gboost1_score.mean() +\n                                   gboost2_score.mean() +\n                                   rf_score.mean() +\n                                   xgb_score.mean() +\n                                   lgb_score.mean()) / 9))"]}, {"cell_type": "code", "execution_count": 1, "id": "bdfe45fe", "metadata": {}, "outputs": [], "source": ["class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=200)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)"]}, {"cell_type": "code", "execution_count": 1, "id": "d3f0f645", "metadata": {}, "outputs": [], "source": ["stacked_averaged_models = StackingAveragedModels(base_models = (ENet, KRR, GBoost1, lasso),\n                                                 meta_model = RF)\n\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"]}, {"cell_type": "code", "execution_count": 1, "id": "d5e81a4e", "metadata": {}, "outputs": [], "source": ["def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "ea5717c9", "metadata": {}, "outputs": [], "source": ["stacked_averaged_models.fit(train.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(train.values)\nstacked_pred = stacked_averaged_models.predict(test.values)\nprint(rmsle(y_train, stacked_train_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "56a0b630", "metadata": {}, "outputs": [], "source": ["model_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = model_xgb.predict(test)\nprint(rmsle(y_train, xgb_train_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "564ea821", "metadata": {}, "outputs": [], "source": ["model_lgb.fit(train, y_train)\nlgb_train_pred = model_lgb.predict(train)\nlgb_pred = model_lgb.predict(test.values)\nprint(rmsle(y_train, lgb_train_pred))"]}, {"cell_type": "code", "execution_count": 1, "id": "3f73154c", "metadata": {}, "outputs": [], "source": ["ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15\n# print(ensemble)"]}, {"cell_type": "code", "execution_count": 1, "id": "e4d83949", "metadata": {}, "outputs": [], "source": ["for n, i in enumerate(ensemble):\n    if i >= 0.5:\n        ensemble[n] = 1\n    else:\n        ensemble[n] = 0\nprint(ensemble)"]}, {"cell_type": "code", "execution_count": 1, "id": "911a62c8", "metadata": {}, "outputs": [], "source": ["result = pd.DataFrame()\nresult['PassengerId'] = test_id\nresult['Survived'] = np.asarray(ensemble, dtype=int)\n\nresult.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "cf6b82c3", "metadata": {}, "outputs": [], "source": ["result.to_csv('submission_sex_to_num.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}