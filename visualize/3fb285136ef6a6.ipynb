{"cells": [{"cell_type": "markdown", "id": "93f9edbb", "metadata": {}, "source": ["# Business Problem"]}, {"cell_type": "markdown", "id": "4acd48f6", "metadata": {}, "source": ["Employee is one of the most important resource in company, where a high attrition rate indicates that the company is unable to maintain their employees. In a short term, with high attrition rate, company must pay a great money to cover the cost of turnover. While in a long term, this will affect the company's performance as employees come and go the company's performance will decline."]}, {"cell_type": "markdown", "id": "fad96d08", "metadata": {}, "source": ["# Goals"]}, {"cell_type": "markdown", "id": "9fc0b1cb", "metadata": {}, "source": ["To analyze the factors lead to employee attrition and make prediction of it, therefore company could give an appropriate treatment for the likely attrition employee."]}, {"cell_type": "markdown", "id": "63486708", "metadata": {}, "source": ["# Mechanism"]}, {"cell_type": "markdown", "id": "0b28d8f7", "metadata": {}, "source": ["The modeling will be implemented in 2 phases:\n1. Phase 1 <br>\nSince the target is imbalance, in this phase I would create 4 different datasets (imbalance, undersampling, oversampling random, and oversampling smote) to see which treatment is best for imbalance class.\n2. Phase 2 <br>\nIn this phase, I would focusing on improving model's performance through feature engineering and feature selection."]}, {"cell_type": "markdown", "id": "a2483b79", "metadata": {}, "source": ["# Import Package and Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "f72e22fe", "metadata": {}, "outputs": [], "source": ["import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom imblearn import under_sampling, over_sampling\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\nfrom mlxtend.evaluate import bias_variance_decomp\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import confusion_matrix\nimport shap\nfrom shap import summary_plot\n\npd.set_option(\"max_column\",100)\npd.set_option(\"max_colwidth\",1000)\npd.set_option(\"max_row\",1000)"]}, {"cell_type": "code", "execution_count": 1, "id": "a6bed3eb", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('../input/employee-attrition/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "86f4b5aa", "metadata": {}, "outputs": [], "source": ["#Change values of features Attrition and Overtime, where Yes=1 and No=0\ndf['Attrition'] = np.where(df['Attrition']=='Yes', 1, 0)\ndf['OverTime'] = np.where(df['OverTime']=='Yes', 1, 0)"]}, {"cell_type": "code", "execution_count": 1, "id": "16b828a1", "metadata": {}, "outputs": [], "source": ["#Categorize numerical and categorical features\nnums_features1 = ['Age','DailyRate','DistanceFromHome','Education','EmployeeCount','EmployeeNumber',\n                 'EnvironmentSatisfaction', 'HourlyRate','JobInvolvement','JobLevel', 'JobSatisfaction','MonthlyIncome',\n                 'MonthlyRate','NumCompaniesWorked','OverTime']\n\nnums_features2 = ['PercentSalaryHike','PerformanceRating','RelationshipSatisfaction','StandardHours','StockOptionLevel',\n                 'TotalWorkingYears','TrainingTimesLastYear','WorkLifeBalance','YearsAtCompany','YearsInCurrentRole',\n                 'YearsSinceLastPromotion','YearsWithCurrManager']\n\ncats_features = ['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','Over18']"]}, {"cell_type": "markdown", "id": "dc2189ea", "metadata": {}, "source": ["---\n# EDA"]}, {"cell_type": "markdown", "id": "e7806b37", "metadata": {}, "source": ["## Descriptive Statistic"]}, {"cell_type": "code", "execution_count": 1, "id": "b144a77f", "metadata": {}, "outputs": [], "source": ["df[nums_features1].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "ddcba54b", "metadata": {}, "outputs": [], "source": ["df[nums_features2].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "a1b818be", "metadata": {}, "outputs": [], "source": ["df[cats_features].describe()"]}, {"cell_type": "markdown", "id": "06cf0c43", "metadata": {}, "source": ["Most of numerical features with nominal data type has a high variation therefore it's positively skewed. And for categorical features, the unique value is only a few."]}, {"cell_type": "markdown", "id": "f390eb6b", "metadata": {}, "source": ["## Univariate Analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "eca7460c", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(8,5))\nsns.countplot(x='Attrition', data=df, palette = 'RdGy')\nplt.title('Attrition Rate', fontsize=14, weight='bold')\nplt.xlabel('Attrition', fontsize = 12)\nplt.ylabel('Total Employee', fontsize = 12);"]}, {"cell_type": "markdown", "id": "e52c75fb", "metadata": {}, "source": ["As we can see, the target is imbalanced"]}, {"cell_type": "markdown", "id": "972aafa9", "metadata": {}, "source": ["## Multivariate Analysis"]}, {"cell_type": "markdown", "id": "2832bbe2", "metadata": {}, "source": ["### 1. Heatmap"]}, {"cell_type": "code", "execution_count": 1, "id": "cf21a723", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20, 20))\nsns.heatmap(df.corr(), cmap='Reds', annot=True, fmt='.2f');"]}, {"cell_type": "markdown", "id": "1a7b0cc1", "metadata": {}, "source": ["The relation between features and target is kinda weak, where the highest correlation is with OverTime "]}, {"cell_type": "markdown", "id": "8c09cd4c", "metadata": {}, "source": ["### 2. Attrition x Numerical Features"]}, {"cell_type": "code", "execution_count": 1, "id": "b5c907e5", "metadata": {}, "outputs": [], "source": ["numerical_features = []\nfor column in df.columns:\n    if df[column].dtype != object:\n        numerical_features.append(column)\n        \nnumerical_features.remove('Attrition')\n\nplt.figure(figsize=(20, 40))\n\nfor i, feature in enumerate(numerical_features, 1):\n    plt.subplot(9, 3, i)\n    df[df[\"Attrition\"] == 0][feature].hist(bins=35, color='blue', label='Not Attrition', alpha=0.6)\n    df[df[\"Attrition\"] == 1][feature].hist(bins=35, color='red', label='Attrition', alpha=0.6)\n    plt.legend()\n    plt.xlabel(feature)\n    plt.ylabel('count')"]}, {"cell_type": "markdown", "id": "1629cd81", "metadata": {}, "source": ["There are some insights:\n1. Employees with low satisfaction (indicated by EnvironmentSatisfaction, JobSatisfaction, RelationshipSatisfaction) tend to resign\n2. Employees with low benefit (indicated by MonthlyIncome, StockOptionLevel tend to resign\n3. Young employees tend to resign\n4. Employees with high number of company worked tend to resign\n5. Overtime employees tend to resign"]}, {"cell_type": "markdown", "id": "526bc0b5", "metadata": {}, "source": ["### 3. Attrition x Categorical Features"]}, {"cell_type": "code", "execution_count": 1, "id": "e81bfe1a", "metadata": {}, "outputs": [], "source": ["categorical_features = []\nfor column in df.columns:\n    if df[column].dtype == object:\n        categorical_features.append(column)\n\nplt.figure(figsize=(20, 15))\n\nfor i, feature in enumerate(categorical_features, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"Attrition\"] == 0][feature].hist(bins=35, color='blue', label='Not Attrition', alpha=0.6)\n    df[df[\"Attrition\"] == 1][feature].hist(bins=35, color='red', label='Attrition', alpha=0.6)\n    plt.legend()\n    plt.xlabel(feature)\n    plt.ylabel('count')"]}, {"cell_type": "markdown", "id": "fd187d8c", "metadata": {}, "source": ["There are some insights:\n1. Employees who travel frequently tend to resign\n2. Sales employees tend to resign\n3. Single employees tend to resign\n4. Female employees tend to resign"]}, {"cell_type": "markdown", "id": "140f27be", "metadata": {}, "source": ["---\n# Phase 1 \nI'll be using Decision Tree for 4 datasets (imbalance, undersampling, oversampling random, oversampling smote)"]}, {"cell_type": "code", "execution_count": 1, "id": "5af056be", "metadata": {}, "outputs": [], "source": ["df_s1 = df.copy()"]}, {"cell_type": "markdown", "id": "a5bd94ed", "metadata": {}, "source": ["## Data Pre-Processing"]}, {"cell_type": "code", "execution_count": 1, "id": "9f75326d", "metadata": {}, "outputs": [], "source": ["#Check if there are missing values and whether the data type is appopriate\ndf_s1.info()"]}, {"cell_type": "markdown", "id": "28dbe8fd", "metadata": {}, "source": ["There are no missing values and all data types are appropriate"]}, {"cell_type": "code", "execution_count": 1, "id": "1e3cfaa3", "metadata": {}, "outputs": [], "source": ["#Check if there is any duplicate data\ndf_s1.duplicated().sum()"]}, {"cell_type": "markdown", "id": "dc471d1b", "metadata": {}, "source": ["## Feature Encoding"]}, {"cell_type": "code", "execution_count": 1, "id": "e9febd67", "metadata": {}, "outputs": [], "source": ["cats_onehot = ['BusinessTravel','Department', 'EducationField', 'Gender','JobRole','MaritalStatus']\n\n#Feature encoding for categorical data using onehots\nfor cat in cats_onehot:\n    onehots = pd.get_dummies(df_s1[cat], prefix=cat)\n    df_s1 = df_s1.join(onehots)\n\ndf_s1.head()"]}, {"cell_type": "markdown", "id": "ae425582", "metadata": {}, "source": ["## Feature Selection"]}, {"cell_type": "code", "execution_count": 1, "id": "a823a4e2", "metadata": {}, "outputs": [], "source": ["#Drop categorical data and unnecessary features\ndf_s1 = df_s1.drop(['BusinessTravel','Department', 'EducationField', 'EmployeeCount', 'EmployeeNumber', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'StandardHours'], axis = 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "352ec00c", "metadata": {}, "outputs": [], "source": ["df_s1.info()"]}, {"cell_type": "markdown", "id": "f39fb096", "metadata": {}, "source": ["There are no duplicate data"]}, {"cell_type": "markdown", "id": "0008471d", "metadata": {}, "source": ["## Modeling"]}, {"cell_type": "code", "execution_count": 1, "id": "09b15c6d", "metadata": {}, "outputs": [], "source": ["#Split features and target\nX = df_s1.drop(columns=['Attrition'])\ny = df_s1['Attrition']\nprint(X.shape)\nprint(y.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "5224d3ed", "metadata": {}, "outputs": [], "source": ["#Create undersampling and oversampling datasets\nX_under, y_under = under_sampling.RandomUnderSampler(random_state=42).fit_resample(X, y)\nX_over, y_over = over_sampling.RandomOverSampler(random_state=42).fit_resample(X, y)\nX_over_smote, y_over_smote = over_sampling.SMOTE(random_state=42).fit_resample(X, y)"]}, {"cell_type": "code", "execution_count": 1, "id": "78382a98", "metadata": {}, "outputs": [], "source": ["print(pd.Series(y).value_counts())\nprint(pd.Series(y_under).value_counts())\nprint(pd.Series(y_over).value_counts())\nprint(pd.Series(y_over_smote).value_counts())"]}, {"cell_type": "code", "execution_count": 1, "id": "f119fcae", "metadata": {}, "outputs": [], "source": ["#Split data training and data test\n\n#Imbalance\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size = 0.3, random_state = 42)\n\n#Undersampling\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X_under, y_under, test_size = 0.3, random_state = 42)\n\n#Oversampling random\nX_train3, X_test3, y_train3, y_test3 = train_test_split(X_over, y_over, test_size = 0.3, random_state = 42)\n\n#Oversampling smote\nX_train4, X_test4, y_train4, y_test4 = train_test_split(X_over_smote, y_over_smote, test_size = 0.3, random_state = 42)"]}, {"cell_type": "code", "execution_count": 1, "id": "cbf3b051", "metadata": {}, "outputs": [], "source": ["def eval_classification(model, pred, proba, xtrain, ytrain, xtest, ytest):\n    print(\"Accuracy (Test Set): %.2f\" % accuracy_score(ytest, pred))\n    print(\"Precision (Test Set): %.2f\" % precision_score(ytest, pred))\n    print(\"Recall (Test Set): %.2f\" % recall_score(ytest, pred))\n    print(\"F1-Score (Test Set): %.2f\" % f1_score(ytest, pred))\n    \n    fpr, tpr, thresholds = roc_curve(ytest, proba, pos_label=1)\n    print(\"AUC: %.2f\" % auc(fpr, tpr))"]}, {"cell_type": "markdown", "id": "94526e58", "metadata": {}, "source": ["### **Imbalance Dataset**"]}, {"cell_type": "code", "execution_count": 1, "id": "64c794b8", "metadata": {}, "outputs": [], "source": ["#Training\nmodel = DecisionTreeClassifier(random_state=42)\nmodel.fit(X_train1,y_train1)\n\n#Predict\ny_pred = model.predict(X_test1)\ny_proba = model.predict_proba(X_test1)\ny_proba = y_proba[:,1]\n\n#Eval\neval_classification(model, y_pred, y_proba, X_train1, y_train1, X_test1, y_test1)"]}, {"cell_type": "code", "execution_count": 1, "id": "380f0393", "metadata": {}, "outputs": [], "source": ["#Checking accuracy of data training and data test\nprint('Train score: ' + str(model.score(X_train1, y_train1))) \nprint('Test score:' + str(model.score(X_test1, y_test1)))"]}, {"cell_type": "markdown", "id": "b6290644", "metadata": {}, "source": ["### **Undersampling Dataset**"]}, {"cell_type": "code", "execution_count": 1, "id": "ccb6ceed", "metadata": {}, "outputs": [], "source": ["#Training\nmodel = DecisionTreeClassifier(random_state=42)\nmodel.fit(X_train2,y_train2)\n\n#Predict\ny_pred = model.predict(X_test2)\ny_proba = model.predict_proba(X_test2)\ny_proba = y_proba[:,1]\n\n#Eval\neval_classification(model, y_pred, y_proba, X_train2, y_train2, X_test2, y_test2)"]}, {"cell_type": "code", "execution_count": 1, "id": "ea1aa44e", "metadata": {}, "outputs": [], "source": ["#Checking accuracy of data training and data test\nprint('Train score: ' + str(model.score(X_train2, y_train2))) \nprint('Test score:' + str(model.score(X_test2, y_test2)))"]}, {"cell_type": "markdown", "id": "34a92606", "metadata": {}, "source": ["### **Oversampling Random Dataset**"]}, {"cell_type": "code", "execution_count": 1, "id": "45cdcb98", "metadata": {}, "outputs": [], "source": ["#Training\nmodel = DecisionTreeClassifier(random_state=42)\nmodel.fit(X_train3,y_train3)\n\n#Predict\ny_pred = model.predict(X_test3)\ny_proba = model.predict_proba(X_test3)\ny_proba = y_proba[:,1]\n\n#Eval\neval_classification(model, y_pred, y_proba, X_train3, y_train3, X_test3, y_test3)"]}, {"cell_type": "code", "execution_count": 1, "id": "2977f464", "metadata": {}, "outputs": [], "source": ["#Checking accuracy of data training and data test\nprint('Train score: ' + str(model.score(X_train3, y_train3))) \nprint('Test score:' + str(model.score(X_test3, y_test3)))"]}, {"cell_type": "markdown", "id": "423b0e3f", "metadata": {}, "source": ["### **Oversampling SMOTE Dataset**"]}, {"cell_type": "code", "execution_count": 1, "id": "baaa1525", "metadata": {}, "outputs": [], "source": ["#Training\nmodel = DecisionTreeClassifier(random_state=42)\nmodel.fit(X_train4,y_train4)\n\n#Predict\ny_pred = model.predict(X_test4)\ny_proba = model.predict_proba(X_test4)\ny_proba = y_proba[:,1]\n\n#Eval\neval_classification(model, y_pred, y_proba, X_train4, y_train4, X_test4, y_test4)"]}, {"cell_type": "code", "execution_count": 1, "id": "1827967b", "metadata": {}, "outputs": [], "source": ["#Checking accuracy of data training and data test\nprint('Train score: ' + str(model.score(X_train4, y_train4))) \nprint('Test score:' + str(model.score(X_test4, y_test4)))"]}, {"cell_type": "markdown", "id": "b91d8e72", "metadata": {}, "source": ["Based on the results, random oversampling show the best performance from all. Therefore, I'll proceed the prediction using random oversampling dataset."]}, {"cell_type": "markdown", "id": "33bd077f", "metadata": {}, "source": ["---\n# Phase 2\nUsing CatBoost for random oversampling dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "161d7058", "metadata": {}, "outputs": [], "source": ["df_s2 = df.copy()"]}, {"cell_type": "markdown", "id": "cf16935f", "metadata": {}, "source": ["## Data Pre-Processing"]}, {"cell_type": "markdown", "id": "66dd82a0", "metadata": {}, "source": ["### 1. Feature Engineering\n- Grouping job role based on job level\n- Grouping age generation"]}, {"cell_type": "code", "execution_count": 1, "id": "1a0de881", "metadata": {}, "outputs": [], "source": ["list_roles = []\n\nfor index, kolom in df_s2.iterrows():\n    if kolom['JobRole'] == 'Sales Executive' or kolom['JobRole'] == 'Laboratory Technician' or kolom['JobRole'] == 'Human Resources':\n        result = 'Staff'\n    elif kolom['JobRole'] == 'Sales Representative' or kolom['JobRole'] == 'Healthcare Representative' or kolom['JobRole'] == 'Research Scientist':\n        result = 'Middle'\n    else:\n        result = 'Executive'\n        \n    list_roles.append(result)\n\ndf_s2['JobRole'] = list_roles\ndf_s2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "b2cb1ade", "metadata": {}, "outputs": [], "source": ["list_gen = []\n\nfor index, kolom in df_s2.iterrows():\n    if kolom['Age'] >= 55:\n        result = 'Boomers'\n    elif kolom['Age'] >= 40 and kolom['Age'] <= 54:\n        result = 'Gen X'\n    elif kolom['Age'] >= 23 and kolom['Age'] <= 39:\n        result = 'Gen Y'\n    else:\n        result = 'Gen Z'\n    list_gen.append(result)\n\ndf_s2['Generation'] = list_gen\ndf_s2.head()"]}, {"cell_type": "markdown", "id": "e0854cce", "metadata": {}, "source": ["### 2. Feature Selection\nIn addition of unnecessary features before (EmployeeCount, EmployeeNumber, Over18, StandardHours) I decided to drop Rate features (DailyRate, HourlyRate, MonthlyRate) because it's the rate that company must pay not the employee received."]}, {"cell_type": "code", "execution_count": 1, "id": "80a9b881", "metadata": {}, "outputs": [], "source": ["#Drop unnecessary features\ndf_s2 = df_s2.drop(['DailyRate', 'EmployeeCount', 'EmployeeNumber', 'HourlyRate', 'Over18', 'MonthlyRate', 'StandardHours'], axis = 1)\ndf_s2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "ecec0906", "metadata": {}, "outputs": [], "source": ["df_s2.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "cadaca33", "metadata": {}, "outputs": [], "source": ["#Define categorical features for modelling\ncat_features = ['BusinessTravel','Department','EducationField', 'Gender', 'Generation','JobRole','MaritalStatus']"]}, {"cell_type": "markdown", "id": "505e46c3", "metadata": {}, "source": ["## Modeling\nSince I'll be using oversampling method for training the model, I'll be using 2 kind of dataset for evaluation:\n1. Data test (oversampling)\n2. Data eval (imbalance)\n\nThis is to make sure the model is able to predict imbalance data as well, because in the production most likely the data will be imbalanced"]}, {"cell_type": "code", "execution_count": 1, "id": "8753b54e", "metadata": {}, "outputs": [], "source": ["#Split features and target\nX = df_s2.drop(columns=['Attrition'])\ny = df_s2['Attrition']\nprint(X.shape)\nprint(y.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "debafa7d", "metadata": {}, "outputs": [], "source": ["#Split data training and data eval (before oversampling)\nX1_train, X_eval, y1_train, y_eval = train_test_split(X, y, test_size = 0.1, random_state = 42)"]}, {"cell_type": "code", "execution_count": 1, "id": "fe984fd9", "metadata": {}, "outputs": [], "source": ["#Oversampling data training\nX_over, y_over = over_sampling.RandomOverSampler(random_state=42).fit_resample(X1_train, y1_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "030fc3b4", "metadata": {}, "outputs": [], "source": ["#Split data training and data test (after oversampling)\nX2_train, X_test, y2_train, y_test = train_test_split(X_over, y_over, test_size = 0.3, random_state = 42)"]}, {"cell_type": "markdown", "id": "62d59b48", "metadata": {}, "source": ["### Evaluate with data eval"]}, {"cell_type": "code", "execution_count": 1, "id": "03ca0078", "metadata": {}, "outputs": [], "source": ["from catboost import CatBoostClassifier\nclf = CatBoostClassifier(learning_rate=0.05, random_state=42, iterations=300, eval_metric='AUC')\n\nclf.fit(X2_train, y2_train, cat_features= cat_features, plot=False, eval_set=(X_eval, y_eval), verbose=True)\n\ny_pred = clf.predict(X_eval)\ny_proba = clf.predict_proba(X_eval)\ny_proba = y_proba[:,1]\neval_classification(clf, y_pred, y_proba, X2_train, y2_train, X_eval, y_eval)"]}, {"cell_type": "code", "execution_count": 1, "id": "e1523042", "metadata": {}, "outputs": [], "source": ["print('Train score: ' + str(clf.score(X2_train, y2_train))) \nprint('Test score:' + str(clf.score(X_eval, y_eval))) "]}, {"cell_type": "markdown", "id": "d3f0f182", "metadata": {}, "source": ["The result of evaluation with imbalance dataset is good enough, but the model shows the sign of overfitting"]}, {"cell_type": "markdown", "id": "52d41126", "metadata": {}, "source": ["### Evaluate with data test"]}, {"cell_type": "code", "execution_count": 1, "id": "742a5c4f", "metadata": {}, "outputs": [], "source": ["from catboost import CatBoostClassifier\nclf = CatBoostClassifier(learning_rate=0.05, random_state=42, iterations=300, eval_metric='Accuracy')\n\nclf.fit(X2_train, y2_train, cat_features= cat_features, plot=False, eval_set=(X_test, y_test), verbose=True)\n\ny_pred = clf.predict(X_test)\ny_proba = clf.predict_proba(X_test)\ny_proba = y_proba[:,1]\neval_classification(clf, y_pred, y_proba, X2_train, y2_train, X_test, y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "5b0ed44c", "metadata": {}, "outputs": [], "source": ["#Checking accuracy of data training and data test\nprint('Train score: ' + str(clf.score(X2_train, y2_train))) \nprint('Test score:' + str(clf.score(X_test, y_test))) "]}, {"cell_type": "code", "execution_count": 1, "id": "51dc64ff", "metadata": {}, "outputs": [], "source": ["cf = confusion_matrix(y_test, y_pred)\ncf"]}, {"cell_type": "code", "execution_count": 1, "id": "4f5ffd59", "metadata": {}, "outputs": [], "source": ["group_names = ['TN','FP','FN','TP']\ngroup_counts = ['{0:0.0f}'.format(value) for value in\n                cf.flatten()]\ngroup_percentages = ['{0:.2%}'.format(value) for value in\n                     cf.flatten()/np.sum(cf)]\nlabels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf, annot=labels, fmt='', cmap='rocket');"]}, {"cell_type": "markdown", "id": "89a9c197", "metadata": {}, "source": ["The result of evaluation with oversampling dataset is excellent, with no signs of overfitting"]}, {"cell_type": "markdown", "id": "1d54da7c", "metadata": {}, "source": ["### Interpretation with SHAP"]}, {"cell_type": "code", "execution_count": 1, "id": "afa3bbdb", "metadata": {}, "outputs": [], "source": ["explainer = shap.Explainer(clf)\nshap_values = explainer(X)"]}, {"cell_type": "code", "execution_count": 1, "id": "ac282e1a", "metadata": {}, "outputs": [], "source": ["shap.plots.beeswarm(shap_values)"]}, {"cell_type": "markdown", "id": "ad9eb06b", "metadata": {}, "source": ["The plot above shows the 9 features that affecting employee's decision to resign or not. As we can see OverTime, StockOptionLevel, and MonthlyIncome are highly affecting employee's attrition. Therefore, with these insights I came up with some strategies:\n1. Evaluate the workload of employees, why do they get overtime? And even if they have to do overtime, the benefit needed to be re-evaluated\n2. Build an appropriate culture and create a good work environment in order to increase EnvironmentSatisfaction and JobSatisfaction\n3. Give or increase StockOptionLevel to high value employees who tend to attrition"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}