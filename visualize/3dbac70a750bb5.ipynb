{"cells": [{"cell_type": "markdown", "id": "2f33f0a5", "metadata": {}, "source": ["![image.png](attachment:image.png)\n\nFIFA 19 is a football simulation video game developed by EA Vancouver as part of Electronic Arts' FIFA series. It is the 26th installment in the FIFA series, and was released on 28 September 2018 for PlayStation 3, PlayStation 4, Xbox 360, Xbox One, Nintendo Switch, and Microsoft Windows.\n\nAs with FIFA 18, Cristiano Ronaldo featured as the cover athlete of the regular edition: however, following his unanticipated transfer from Spanish club Real Madrid to Italian side Juventus, new cover art was released. He also appeared with Neymar in the cover of the Champions edition. From February 2019, an updated version featured Neymar, Kevin De Bruyne and Paulo Dybala on the cover of the regular edition.\n\nThe game features the UEFA club competitions for the first time, including the UEFA Champions League and UEFA Europa League and the UEFA Super Cup as well. Martin Tyler and Alan Smith return as regular commentators, while the new commentary team of Derek Rae and Lee Dixon feature in the UEFA competitions mode. Composer Hans Zimmer and rapper Vince Staples recorded a new remix of the UEFA Champions League anthem specifically for the game.\n\nThe character Alex Hunter, who first appeared in FIFA 17, returns for the third and final installment of \"The Journey\", entitled, \"The Journey: Champions\". In June 2019, a free update added the FIFA Women's World Cup as a separate game mode. It is the last FIFA game to be available on a seventh-generation console, and the last known game to be physically available for the PlayStation 3 worldwide."]}, {"cell_type": "markdown", "id": "d57072a6", "metadata": {}, "source": ["## Importing Required Libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "e77ca039", "metadata": {}, "outputs": [], "source": ["import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport missingno as msno\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.impute import KNNImputer"]}, {"cell_type": "markdown", "id": "cb53967a", "metadata": {}, "source": ["## Reading Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "dd7e8ad3", "metadata": {}, "outputs": [], "source": ["pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\ndata = pd.read_csv('../input/fifa19/data.csv')\ndata.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "24e343dd", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "90458b54", "metadata": {}, "outputs": [], "source": ["# Required Features....\nworking_col = ['Name', 'Age', 'Nationality', 'Overall', 'Potential', 'Club', 'Value',\n                'Wage', 'Special', 'Preferred Foot', 'International Reputation', 'Weak Foot',\n                'Skill Moves', 'Work Rate', 'Body Type', 'Position', 'Height', 'Weight','Crossing',\n                'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys', 'Dribbling',\n                'Curve', 'FKAccuracy', 'LongPassing', 'BallControl', 'Acceleration',\n                'SprintSpeed', 'Agility', 'Reactions', 'Balance', 'ShotPower',\n                'Jumping', 'Stamina', 'Strength', 'LongShots', 'Aggression',\n                'Interceptions', 'Positioning', 'Vision', 'Penalties', 'Composure',\n                'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving', 'GKHandling',\n                'GKKicking', 'GKPositioning', 'GKReflexes', 'Release Clause']"]}, {"cell_type": "code", "execution_count": 1, "id": "8850522e", "metadata": {}, "outputs": [], "source": ["# Working DataFrame....\ndf = data[working_col]\ndf.head()"]}, {"cell_type": "markdown", "id": "c11584b6", "metadata": {}, "source": ["## Data Cleaning"]}, {"cell_type": "code", "execution_count": 1, "id": "73b7257f", "metadata": {}, "outputs": [], "source": ["# Cleaning the Value column\ndef clean_money(column):\n    values = []\n    for value in data[column]:\n        if value[-1]=='M':\n            money = 1000000\n            money *= float(value[1:-1])\n        elif value[-1]=='K':\n            money = 1000\n            money *= float(value[1:-1])\n        else: \n            money = 0\n        values.append(money/1000000)\n    return values\n\n# Cleaning Weight column\ndef clean_weight():\n    weights = []\n    for weight in data['Weight'].fillna(''):\n        if weight != '':\n            weights.append(int(weight[:-3]))\n        else:\n            weights.append(np.nan)\n    return weights\n\n# Cleaning Height Column\ndef clean_height():\n    heights = []\n    for height in data['Height'].fillna(''):\n        if height != '':\n            height =int(height[0])*12 + int(height[2])\n            heights.append(height)\n        else:\n            heights.append(np.nan)\n    return heights\n\n# # Cleaning Release Clause\ndef clean_release_clause():\n    release_clause = []\n    for clause in data['Release Clause'].fillna(''):\n        if clause == '':\n            money=0.0\n        elif clause[-1]=='M':\n            money = 1000000\n            money *= float(clause[1:-1])\n        elif clause[-1]=='K':\n            money = 1000\n            money *= float(clause[1:-1])\n        else: \n            money = 0\n        release_clause.append(money/1000000)\n    return release_clause"]}, {"cell_type": "code", "execution_count": 1, "id": "a0d0f836", "metadata": {}, "outputs": [], "source": ["df['Value'] =  clean_money('Value')\ndf['Wage'] = clean_money('Wage')\ndf['Weight'] = clean_weight()\ndf['Height'] = clean_height()\ndf['Release Clause'] = clean_release_clause()"]}, {"cell_type": "code", "execution_count": 1, "id": "bed8fc3b", "metadata": {}, "outputs": [], "source": ["df.isna().sum()"]}, {"cell_type": "markdown", "id": "7e314441", "metadata": {}, "source": ["## Seperating Categorical and Numerical Values"]}, {"cell_type": "code", "execution_count": 1, "id": "d6707a1b", "metadata": {}, "outputs": [], "source": ["numerical_features =['Age', 'Overall', 'Potential', 'Value', 'Wage', 'Special', 'Height',\n                   'Weight', 'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing',\n                   'Volleys', 'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing',\n                   'BallControl', 'Acceleration', 'SprintSpeed', 'Agility', 'Reactions',\n                   'Balance', 'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots',\n                   'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties',\n                   'Composure', 'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving',\n                   'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes','Release Clause']\n\ncategorical_features = ['Name','Nationality', 'Club', 'Preferred Foot', 'Work Rate','Body Type', \n                        'Position','International Reputation', 'Weak Foot', 'Skill Moves']"]}, {"cell_type": "code", "execution_count": 1, "id": "7f2d81fb", "metadata": {}, "outputs": [], "source": ["df[numerical_features].describe().T"]}, {"cell_type": "markdown", "id": "d4188fe5", "metadata": {}, "source": ["* We can see much variablity in S.D. in dataset"]}, {"cell_type": "markdown", "id": "4f940005", "metadata": {}, "source": ["## Data Visualisation"]}, {"cell_type": "markdown", "id": "82b33678", "metadata": {}, "source": ["* Missing Values Visualisation"]}, {"cell_type": "code", "execution_count": 1, "id": "dd4d3985", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15,7))\nsns.heatmap(df.isna(), yticklabels=False, cmap='YlGnBu')"]}, {"cell_type": "markdown", "id": "dbf0e607", "metadata": {}, "source": ["The club has no relation with the other features and imputing it wiht any club names will be bias. So i am imputing it with the 'no Club'.\nWe can also see there is an line showing missing values in rows of different features both categorical and numerical. \nSo let's view categorical and numerical variable seperately"]}, {"cell_type": "markdown", "id": "851048ef", "metadata": {}, "source": ["* Missing Categorical Values Visualisation"]}, {"cell_type": "code", "execution_count": 1, "id": "ec50bf14", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(100,100))\nfig.subplots_adjust(hspace=0.4, wspace=0.1)\n\nax = fig.add_subplot(7, 7, 1)\nsns.heatmap(df[categorical_features].isna(), yticklabels=False, cmap='YlGnBu')\n\nax = fig.add_subplot(7, 7, 2)\nsns.heatmap(df[numerical_features].isna(), yticklabels=False, cmap='YlGnBu')"]}, {"cell_type": "markdown", "id": "6f90b188", "metadata": {}, "source": ["We can clearly see that some of the rows of numerical features having missing values and that same rows also continued to categorical features.\n* **So the question is how we can impute this missing values??**"]}, {"cell_type": "code", "execution_count": 1, "id": "7398d2c5", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(20,30))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\ncount=1\nfor feature in numerical_features:\n    ax = fig.add_subplot(len(numerical_features)//4+1, 4, count)\n    sns.boxplot(x=df[feature])\n    count +=1"]}, {"cell_type": "markdown", "id": "0b3a8e9d", "metadata": {}, "source": ["* If we try to statistically impute these missing values then it will be biased imputation for many features.\n* There are many features with outliers so if we try to impute the missing values using any imputer models then model will provide incorrect results.\n* But if we try to remove these outliers or correct the outliers, then the models will be somewhat provide meaningful results.\n* But again a question arise weather to remove or correct the outliers??\n* "]}, {"cell_type": "code", "execution_count": 1, "id": "1ae801ab", "metadata": {}, "outputs": [], "source": ["corr_ = df[numerical_features].corr()\n\nf,ax = plt.subplots(figsize=(25, 10))\nsns.heatmap(corr_,annot=True, linewidths=0.5, cmap=\"YlGnBu\", fmt= '.1f',ax=ax)\nplt.show()"]}, {"cell_type": "markdown", "id": "47519901", "metadata": {}, "source": ["* We can clearly see from these heatmap that 'Special' feature of the dataset is somewhat strongly correlated with many features which are having missing values. \n        *  'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing','Volleys', 'Dribbling', 'Curve', \n           'FKAccuracy', 'LongPassing','BallControl', 'Acceleration', 'SprintSpeed', 'Agility', \n           'Reactions','Balance', 'ShotPower','Stamina','LongShots','Aggression', 'Interceptions', \n           'Positioning', 'Vision', 'Penalties','Composure', 'Marking','GKDiving','GKHandling', 'GKKicking', \n           'GKPositioning', 'GKReflexes'\n* **Height** and **Weight** doesn't have good correlation with any other features. So we will impute this using some stats imputations technique after getting some visual view of the data below.\n* Weight is Correlation(0.7) with  \n        * 'Balence'       \n* Marking is Correlation(0.9) with\n        * 'StandingTackle', 'SlidingTackle'"]}, {"cell_type": "markdown", "id": "8e434281", "metadata": {}, "source": ["## So let's Visualise these features in Comparison with the respected Corrected features"]}, {"cell_type": "markdown", "id": "bfc2c895", "metadata": {}, "source": ["* 'Special' Vs\n        * 'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing','Volleys', 'Dribbling', 'Curve', \n          'FKAccuracy', 'LongPassing','BallControl', 'Acceleration', 'SprintSpeed', 'Agility', \n          'Reactions','Balance', 'ShotPower','Stamina','LongShots','Aggression', 'Interceptions', \n          'Positioning', 'Vision', 'Penalties','Composure', 'Marking','GKDiving','GKHandling', 'GKKicking', \n          'GKPositioning', 'GKReflexes'"]}, {"cell_type": "code", "execution_count": 1, "id": "06c90d3d", "metadata": {}, "outputs": [], "source": ["features =  ['Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing','Volleys', 'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing','BallControl', \n            'Acceleration', 'SprintSpeed', 'Agility', 'Reactions','Balance', 'ShotPower','Stamina','LongShots','Aggression', 'Interceptions', \n            'Positioning', 'Vision', 'Penalties','Composure', 'Marking','GKDiving','GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes']\n\nfig = plt.figure(figsize=(20,30))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\ncount=1\nfor feature in features:\n    ax = fig.add_subplot(len(features)//4+1, 4, count)\n    sns.scatterplot(x=df['Special'], y=df[feature])\n    count +=1"]}, {"cell_type": "markdown", "id": "15000af9", "metadata": {}, "source": ["> We don't see any outliers effecting."]}, {"cell_type": "markdown", "id": "39c4de87", "metadata": {}, "source": ["* Let's visualise Balance and Weight"]}, {"cell_type": "code", "execution_count": 1, "id": "989ca57f", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(df['Balance'], df['Weight'])"]}, {"cell_type": "markdown", "id": "b86e7e88", "metadata": {}, "source": ["* Let's visualise Marking vs (StandingTackle and SlidingTackle)"]}, {"cell_type": "code", "execution_count": 1, "id": "adce29d7", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\n\nax = fig.add_subplot(1, 3, 1)\nsns.scatterplot(x=df['Marking'], y=df['StandingTackle'])\n\nax = fig.add_subplot(1, 3, 2)\nsns.scatterplot(x=df['Marking'], y=df['SlidingTackle'])\n\nax = fig.add_subplot(1, 3, 3)\nsns.scatterplot(x=df['StandingTackle'], y=df['SlidingTackle'])"]}, {"cell_type": "markdown", "id": "93135dbd", "metadata": {}, "source": ["* Let's Visuslise Height"]}, {"cell_type": "code", "execution_count": 1, "id": "c5f7ebda", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(5,5))\nsns.distplot(df['Height'])"]}, {"cell_type": "markdown", "id": "8d9144f4", "metadata": {}, "source": ["## So let's now Impute the the feature using Linear Imputer and KNN Imputer\n\n* **Before proceeding let's list down what Imputer will be used in which feature**\n\n    1. As we can see from above scatter plots in which many features are compaired from 'Special' features. We see a linear relationship except some  features('GKDiving','GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes'). So these feature can be imputed by Linear Imputation. \n    2. And we can see features like :- ('GKDiving','GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes') are making 2 group. So we can imputed this by KNN imputation.\n    3. We can impute the Weights by Balance using Linear Imputation.\n    4. We can impute the StandingTackle and SlidingTackle by Marking using Linear Imputation.\n    5. The height will be imputed through Stats imputation techniques."]}, {"cell_type": "markdown", "id": "49b50eba", "metadata": {}, "source": ["###  Splitting train and test data"]}, {"cell_type": "markdown", "id": "ebed9166", "metadata": {}, "source": ["* Let's create a traning and testing set for Linear Imputation and use LinearRegression model to predict the values for features"]}, {"cell_type": "code", "execution_count": 1, "id": "f19863e9", "metadata": {}, "outputs": [], "source": ["train_df = df[['Special']+features[:-5]].dropna()\ntest_df = df[df[['Special']+features[:-5]].isnull().any(axis=1)]"]}, {"cell_type": "code", "execution_count": 1, "id": "78d001db", "metadata": {}, "outputs": [], "source": ["for feature in features[:-5]:\n    \n    polyreg=make_pipeline(PolynomialFeatures(2),LinearRegression())\n    polyreg.fit(X = train_df[['Special']], y = train_df[feature])\n    \n    predicted_output = polyreg.predict(test_df[['Special']])\n    test_df[feature] = np.round(predicted_output)\n    df[feature].fillna(test_df[feature], inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "bdbf1646", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(20,30))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\ncount=1\nfor feature in features[:-5]:\n    ax = fig.add_subplot(len(features[:-5])//4+1, 4, count)\n    sns.scatterplot(x=train_df[feature], y=train_df['Special'])\n    sns.scatterplot(x=test_df[feature], y=test_df['Special'])\n    count +=1"]}, {"cell_type": "markdown", "id": "e08d65da", "metadata": {}, "source": ["> As we can see that the imputation is quit good. So let's now do the KNN imputation for remanining numerical variables."]}, {"cell_type": "markdown", "id": "a937b5e5", "metadata": {}, "source": ["* Let's create a traning and testing set for KNN Imputation and use KNNImputer model to predict the values for features"]}, {"cell_type": "code", "execution_count": 1, "id": "5861f25b", "metadata": {}, "outputs": [], "source": ["train_df = df[['Special']+features[-5:]].dropna()\ntest_df = df[df[features[-5:]].isnull().any(axis=1)][['Special']+features[-5:]]\n"]}, {"cell_type": "code", "execution_count": 1, "id": "bab96002", "metadata": {}, "outputs": [], "source": ["imputer = KNNImputer(n_neighbors=1)\nimputer.fit(train_df)\npredicted_df = pd.DataFrame(np.round(imputer.transform(test_df)), columns=test_df.columns,index=test_df.index)"]}, {"cell_type": "code", "execution_count": 1, "id": "ab0a8b87", "metadata": {}, "outputs": [], "source": ["for col in test_df.columns[1:]:\n    df[col].fillna(predicted_df[col], inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "691de7ab", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(20, 10))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\ncount=1\nfor feature in features[-5:]:\n    ax = fig.add_subplot(2, 3, count)\n    sns.scatterplot(x=train_df[feature], y=train_df['Special'])\n    sns.scatterplot(x=predicted_df[feature], y=predicted_df['Special'])\n    count +=1"]}, {"cell_type": "markdown", "id": "3a8b6ab5", "metadata": {}, "source": ["* Let's impute Weight feature by Balance using LinearRegression"]}, {"cell_type": "code", "execution_count": 1, "id": "5516562a", "metadata": {}, "outputs": [], "source": ["train_df = df[['Weight', 'Balance']].dropna()\ntest_df = df[df['Weight'].isna()][['Weight', 'Balance']]"]}, {"cell_type": "code", "execution_count": 1, "id": "2d3b6987", "metadata": {}, "outputs": [], "source": ["polyreg=make_pipeline(PolynomialFeatures(2),LinearRegression())\npolyreg.fit(X = train_df[['Balance']], y = train_df['Weight'])\n\ntest_df['Weight'] = np.round(polyreg.predict(test_df[['Balance']]))"]}, {"cell_type": "code", "execution_count": 1, "id": "e0792ebc", "metadata": {}, "outputs": [], "source": ["df['Weight'].fillna(test_df['Weight'], inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "7bbc7dd9", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(train_df['Weight'], train_df['Balance'])\nsns.scatterplot(test_df['Weight'], test_df['Balance'])"]}, {"cell_type": "markdown", "id": "dad162c7", "metadata": {}, "source": ["* Let's impute StandingTackle and SlidingTackle feature by Marking using LinearRegression"]}, {"cell_type": "code", "execution_count": 1, "id": "28b23cad", "metadata": {}, "outputs": [], "source": ["train_df = df[['StandingTackle', 'SlidingTackle', 'Marking']].dropna()\ntest_df = df[df['SlidingTackle'].isna()][['StandingTackle', 'SlidingTackle', 'Marking']]"]}, {"cell_type": "code", "execution_count": 1, "id": "0f213d93", "metadata": {}, "outputs": [], "source": ["for feature in ['StandingTackle', 'SlidingTackle']:\n    polyreg=make_pipeline(PolynomialFeatures(2),LinearRegression())\n    polyreg.fit(X = train_df[['Marking']], y = train_df[feature])\n\n    test_df[feature] = np.round(polyreg.predict(test_df[['Marking']]))\n    df[feature].fillna(test_df[feature], inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "4d0b7a59", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(20, 5))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\ncount=1\nfor feature in ['StandingTackle', 'SlidingTackle']:\n    ax = fig.add_subplot(1, 2, count)\n    sns.scatterplot(train_df['Marking'], train_df[feature])\n    sns.scatterplot(test_df['Marking'], test_df[feature])\n    count +=1\n\n"]}, {"cell_type": "markdown", "id": "0f107f7a", "metadata": {}, "source": ["* Let's impute the height,stamina and Jumping using stats imputation technique\n"]}, {"cell_type": "code", "execution_count": 1, "id": "d2ec993b", "metadata": {}, "outputs": [], "source": ["df['Height'].fillna(61.0, inplace=True)\ndf['Jumping'].fillna(df['Jumping'].mean(), inplace=True)\ndf['Strength'].fillna(df['Strength'].mean(), inplace=True)"]}, {"cell_type": "markdown", "id": "9d94ef94", "metadata": {}, "source": ["## As all the Numerical features are been imputed. Let's fill the Categorical features"]}, {"cell_type": "markdown", "id": "049589b3", "metadata": {}, "source": ["### Let's first visualise the category features distribution."]}, {"cell_type": "code", "execution_count": 1, "id": "f65644df", "metadata": {}, "outputs": [], "source": ["df[categorical_features].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "1decc7fd", "metadata": {}, "outputs": [], "source": ["sns.countplot(df['International Reputation'])"]}, {"cell_type": "code", "execution_count": 1, "id": "30f86683", "metadata": {}, "outputs": [], "source": ["sns.countplot(df['Skill Moves'])"]}, {"cell_type": "code", "execution_count": 1, "id": "ed759ddb", "metadata": {}, "outputs": [], "source": ["sns.countplot(df['Preferred Foot'])"]}, {"cell_type": "code", "execution_count": 1, "id": "7b9b8cce", "metadata": {}, "outputs": [], "source": ["sns.countplot(df['Weak Foot'])"]}, {"cell_type": "code", "execution_count": 1, "id": "e5b62971", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15,5))\nsns.countplot(df['Position'])"]}, {"cell_type": "code", "execution_count": 1, "id": "be4e83a5", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15,5))\nsns.countplot(df['Body Type'])"]}, {"cell_type": "code", "execution_count": 1, "id": "75c28a13", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 5))\nsns.countplot(df['Work Rate'])"]}, {"cell_type": "markdown", "id": "d93b5c7c", "metadata": {}, "source": ["### Imputing some Categorical variable by viewing the graphs above."]}, {"cell_type": "code", "execution_count": 1, "id": "8964b623", "metadata": {}, "outputs": [], "source": ["df['Club'].fillna('No Club', inplace=True)\ndf['Preferred Foot'].fillna('Right', inplace=True)\ndf['Weak Foot'].fillna(3.0, inplace=True)\ndf['International Reputation'].fillna(1.0, inplace=True)\ndf['Body Type'].fillna('Normal',inplace=True)\ndf['Work Rate'].fillna('Medium/Medium', inplace=True)\ndf['Position'].fillna('NA', inplace=True)\ndf['Skill Moves'].fillna(2.0, inplace=True)"]}, {"cell_type": "markdown", "id": "bddcd86a", "metadata": {}, "source": ["### After all imputations let's visualise the Dataset using Heatmap"]}, {"cell_type": "code", "execution_count": 1, "id": "737a4d5c", "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15,7))\nsns.heatmap(df.isna(), yticklabels=False, cmap='YlGnBu')"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}