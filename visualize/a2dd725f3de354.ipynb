{"cells": [{"cell_type": "markdown", "id": "faaf495b", "metadata": {}, "source": ["# Amazon Fine Food Reviews Analysis\n\n\nData Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n\n\n<h4> Objective:</h4>\nGiven a review, determine whether the review is positive or negative.\n\n<h4><li>How to determine if a review is positive or negative?</li></h4>\nWe could use the Score/Rating. A rating of 4 or 5 could be cosnidered a positive review. A review of 1 or 2 could be considered negative. A review of 3 is nuetral and ignored. This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n\n\n<h1>Dataset</h1><br>\nThis dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n\n<h4>Attribute Information:</h4>\n\nThere are a total of 10 columns in total in the Amazon Fine Food review dataset.\n\n- Id :  Row Id\n- ProductId : Unique identifier for the product.\n- UserId : Unique identifier for the user.\n- ProfileName : Profile Name of the User.\n- HelpfulnessNumerator : Number of users who found the review            helpful.\n- HelpfulnessDenominator : Number of users who indicated whether they found the review helpful or not.\n- Score : Rating between 1 and 5.\n- Time : Timestamp for the review.\n- Summary : Brief summary of the review.\n- Text : Text of the review."]}, {"cell_type": "markdown", "id": "deb844bd", "metadata": {}, "source": ["### Importing the necessary libraries."]}, {"cell_type": "code", "execution_count": 1, "id": "79c420fb", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport sqlite3\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set(style='white', color_codes=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")"]}, {"cell_type": "markdown", "id": "e5bede5d", "metadata": {}, "source": ["### Load the data from SQLite Database."]}, {"cell_type": "code", "execution_count": 1, "id": "0dae3376", "metadata": {}, "outputs": [], "source": ["# using the SQLite Table to read data.\ncon = sqlite3.connect('../input/amazon-fine-food-reviews/database.sqlite') "]}, {"cell_type": "code", "execution_count": 1, "id": "d5cd902d", "metadata": {}, "outputs": [], "source": ["con_rev = pd.read_sql_query(\"\"\" SELECT * FROM Reviews\"\"\", con) \nprint(con_rev.shape)\ncon_rev.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "63767816", "metadata": {}, "outputs": [], "source": ["#filtering only positive and negative reviews i.e. not taking into consideration those reviews with Score=3\n\nfiltered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", con) \nprint(filtered_data.shape)\nfiltered_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "f44420d0", "metadata": {}, "outputs": [], "source": ["# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\ndef partition(x):\n    if x < 3:\n        return 0\n    return 1"]}, {"cell_type": "code", "execution_count": 1, "id": "a3bc7590", "metadata": {}, "outputs": [], "source": ["#changing reviews with score less than 3 to be positive and vice-versa\nactualScore = filtered_data['Score']\npositiveNegative = actualScore.map(partition) \nfiltered_data['Score'] = positiveNegative\nprint(\"Number of data points in our data\", filtered_data.shape)\nfiltered_data.head(3)"]}, {"cell_type": "markdown", "id": "21bcf55c", "metadata": {}, "source": ["## Exploratory Data Analysis\n\n#### Data Cleaning: Deduplication\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e213dad9", "metadata": {}, "outputs": [], "source": ["subset = {\"UserId\", \"ProfileName\", \"Time\", \"Text\"}\ndata = filtered_data.drop_duplicates(subset=subset, keep=\"first\")\nprint(data.shape)\ndata.head(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "293248c9", "metadata": {}, "outputs": [], "source": ["#Checking to see how much % of data still remains\n(data['Id'].size)/(filtered_data['Id'].size)*100"]}, {"cell_type": "markdown", "id": "821580fb", "metadata": {}, "source": ["HelpfulnessNumerator - number of users who found the review helpful <br>\nHelpfulnessDenominator - number of users who indicated whether they found the review helpful or not"]}, {"cell_type": "code", "execution_count": 1, "id": "bb316d14", "metadata": {}, "outputs": [], "source": ["#Checking IS 'HelpfulnessNumerator' always less than or equal to 'HelpfulnessDenominator' ?\ndata[data['HelpfulnessNumerator'] > data['HelpfulnessDenominator']]"]}, {"cell_type": "code", "execution_count": 1, "id": "94edb8c5", "metadata": {}, "outputs": [], "source": ["#\"HelpfulnessNumerator\" can't be grater than \"HelpfulnessDenominator\"\n#so taking dataframe inwhich \"HelpfulnessNumerator\" less than or equal to \"HelpfulnessDenominator\"\n\ndata = data[data['HelpfulnessNumerator'] <= data['HelpfulnessDenominator']]\ndata.reset_index(drop = True, inplace=True)\nprint(data.shape)\ndata.head(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "a017df11", "metadata": {}, "outputs": [], "source": ["#Identifing missing Values\nmiss_val = data.isna().sum()\nmiss_val"]}, {"cell_type": "code", "execution_count": 1, "id": "330ade3c", "metadata": {}, "outputs": [], "source": ["#data points for each class\nprint(data['Score'].value_counts())\nprint(\"*\"*50)\n\n#Count plot for Score\nsns.countplot('Score',data = data)\nplt.title(\"Score distribution\")"]}, {"cell_type": "markdown", "id": "ac564a30", "metadata": {}, "source": ["## Text Preprocessing: Stemming, stop-word removal and Lemmatization."]}, {"cell_type": "code", "execution_count": 1, "id": "fe2d3fa1", "metadata": {}, "outputs": [], "source": ["#set of stopwords\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\n\n#initialising the snowball stemmer\nsno = nltk.stem.SnowballStemmer('english')                      \n\n\n#function to clean the word of any html-tags\ndef cleanhtml(sentence): \n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\n\n\n\n#function to clean the word of any punctuation or special characters\ndef cleanpunc(sentence): \n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n    return  cleaned\n\n\n#function to text summarization\ndef final_sentence(text):\n    \n    text = text.split()\n    text = [cleanhtml(x) for x in text]\n    text = [cleanpunc(x) for x in text]\n    \n    def test(word):\n        if word.isalpha() and len(word) > 2 and word.lower() not in stop:\n            s=(sno.stem(word.lower()))\n            return s\n        else:\n            pass\n    \n    text = [test(x) for x in text if test(x)]\n    \n    return ' '.join(text)"]}, {"cell_type": "code", "execution_count": 1, "id": "c39b1d9b", "metadata": {}, "outputs": [], "source": ["data.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "cf6e21f5", "metadata": {}, "outputs": [], "source": ["from tqdm import tqdm\ntqdm.pandas()\n\ndata['CleanedText'] = data['Text'].progress_apply(final_sentence)\nprint(data.shape)\ndata.head()"]}, {"cell_type": "markdown", "id": "548c9dc3", "metadata": {}, "source": ["### Converting Text data into vector "]}, {"cell_type": "code", "execution_count": 1, "id": "ade3cd9d", "metadata": {}, "outputs": [], "source": ["def Text_Into_Vector(model,data):\n    model_vect = model(ngram_range=(1,2)) #in scikit-learn\n    final_array = model_vect.fit_transform(data.values)\n\n    print(\"the type of count vectorizer \",type(final_array))\n    print(\"the shape of out text BOW vectorizer \",final_array.get_shape())\n    print(\"the number of unique words including both unigrams and bigrams \", final_array.get_shape()[1])\n    \n    return model_vect, final_array"]}, {"cell_type": "markdown", "id": "5ab35ad2", "metadata": {}, "source": ["## Spliting data"]}, {"cell_type": "code", "execution_count": 1, "id": "ecc46bb7", "metadata": {}, "outputs": [], "source": ["#split data into train, cross validate and test \nfrom sklearn.model_selection import train_test_split\n\ndef Split_data(x_vec, y_vec):\n    X_train, X_test, Y_train, Y_test = train_test_split(x_vec, y_vec, test_size=.33, random_state=0)\n    X_tr, X_cv, Y_tr, Y_cv = train_test_split(X_train, Y_train, test_size=.33, random_state=0)\n    return X_tr, X_cv, X_test, Y_tr, Y_test, Y_cv, X_train, Y_train"]}, {"cell_type": "markdown", "id": "827cfe73", "metadata": {}, "source": ["## Normalize Data"]}, {"cell_type": "code", "execution_count": 1, "id": "a275ce82", "metadata": {}, "outputs": [], "source": ["#Normalize Data\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Normalizer\n\ndef Normalization(train, cv, test):\n    train=preprocessing.normalize(train)\n    cv=preprocessing.normalize(cv)\n    test=preprocessing.normalize(test)\n\n    print(\"Train Data Size \",train.get_shape())\n    print(\"CV Data Size: \",cv.shape)\n    print(\"Test Data Size: \",test.shape)\n    \n    return train, cv, test"]}, {"cell_type": "markdown", "id": "ceb746c3", "metadata": {}, "source": ["### Training Multinomial Naive Bayes Model"]}, {"cell_type": "code", "execution_count": 1, "id": "3a92a713", "metadata": {}, "outputs": [], "source": ["from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pylab as pyplt\n\ndef Multinomial_NB(X_train,X_cv,Y_train,Y_cv):\n    #############################################################################\n    best_alpha=0\n    max_roc_auc=-1\n    pred_cv = []\n    pred_train = []\n    alpha=[10000,5000,1000,500,100,50,10,5,1,0.5,0.1,0.05,0.01,0.005,0.001,0.0005,0.0001,0.00005,0.00001]\n    #############################################################################\n\n    for i in alpha:\n        mulbnb = MultinomialNB(alpha=i)\n        mulbnb.fit(X_train,Y_train)\n        probs = mulbnb.predict_proba(X_cv)[:,1]     \n        prob = mulbnb.predict_proba(X_train)[:,1]\n        #############################################################################\n\n        auc_score_cv = roc_auc_score(Y_cv,probs)            #auc roc for cv\n        auc_score_train = roc_auc_score(Y_train,prob)       #auc roc for train\n        #############################################################################\n\n        print(i,\" ------> \",auc_score_cv)\n        #############################################################################\n\n        pred_cv.append(auc_score_cv)\n        pred_train.append(auc_score_train)\n        #############################################################################\n\n        if(max_roc_auc<auc_score_cv):\n            max_roc_auc=auc_score_cv\n            best_alpha=i\n\n    print(\"*\"*100)\n    print(f\"\\n Best alpha Value {best_alpha} with highest roc_auc Score is {max_roc_auc}\")\n    print(\"*\"*100)\n    #############################################################################\n\n    sns.set_style(\"darkgrid\")\n    plt.xscale('log')\n    plt.plot(alpha, pred_cv,'r-', label = 'CV Data')\n    plt.plot(alpha,pred_train,'g-', label ='Train Data')\n    plt.legend(loc='upper right')\n    plt.title(r'Auc Score v/s $\\alpha$')\n    plt.xlabel(r\"alpha values\",fontsize=12)\n    plt.ylabel(\"roc_auc\",fontsize=12)\n    plt.show()\n    print(\"*\"*100)\n    #############################################################################\n\n    # calculate roc curve\n    fpr, tpr, thresholds = roc_curve(Y_cv,probs)\n    # plot no skill\n    pyplt.plot([0, 1], [0, 1], linestyle='--')\n    # plot the roc curve for the model\n    pyplt.plot(fpr, tpr, marker='.')\n    pyplt.title(\"Line Plot of ROC Curve on Train Data\")\n    pyplt.ylabel('True Positive Rate')\n    pyplt.xlabel('False Positive Rate')\n    pyplt.show()\n    print(\"*\"*100)\n    \n    #############################################################################\n    return best_alpha"]}, {"cell_type": "markdown", "id": "a0862b3f", "metadata": {}, "source": ["### Testing Multinomial Naive Bayes Model"]}, {"cell_type": "code", "execution_count": 1, "id": "4880999f", "metadata": {}, "outputs": [], "source": ["import scikitplot.metrics as skplt\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\n\n\ndef Testing_model(X_train,Y_train,X_test,Y_test,best_alpha):\n    \n    #############################################################################\n    bnb = MultinomialNB(alpha = best_alpha, fit_prior=True, class_prior=None)\n    bnb.fit(X_train,Y_train)\n    probs = bnb.predict_proba(X_test)[:,1]            # keep probabilities for the positive outcome only\n\n    #############################################################################\n    roc_auc = roc_auc_score(Y_test,probs)\n    print(\"AUC Score\",roc_auc)\n    print(\"*\"*70)\n    #############################################################################'\n\n    # calculate roc curve\n    fpr, tpr, thresholds = roc_curve(Y_test,probs)\n    # plot no skill\n    plt.plot([0, 1], [0, 1], linestyle='--')\n    # plot the roc curve for the model\n    plt.plot(fpr, tpr, marker='.')\n    plt.title(\"Line Plot of ROC Curve on Test Data\")\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')    \n    plt.show()\n\n    #############################################################################\n    prediction=bnb.predict(X_test)\n    skplt.plot_confusion_matrix(Y_test,prediction)\n    #############################################################################\n\n    print(\"macro f1 score for data :\",metrics.f1_score(Y_test, prediction, average = 'macro'))\n    print(\"micro f1 score for data:\",metrics.f1_score(Y_test, prediction, average = 'micro'))\n    print(\"hamming loss for data:\",metrics.hamming_loss(Y_test,prediction))\n    print(\"*\"*70)\n    print(\"Precision recall report for data:\\n\",metrics.classification_report(Y_test, prediction))\n    print(\"*\"*70)\n    \n    return bnb,roc_auc\n\n    #############################################################################"]}, {"cell_type": "markdown", "id": "7dff6e9a", "metadata": {}, "source": ["### Top features"]}, {"cell_type": "code", "execution_count": 1, "id": "6f09c03e", "metadata": {}, "outputs": [], "source": ["def Important_features(model, classifier):\n    neg = classifier.feature_log_prob_[0].argsort()\n    pos = classifier.feature_log_prob_[1].argsort()\n    top_pos_words = np.take(model.get_feature_names(),pos)\n    top_neg_words = np.take(model.get_feature_names(),neg)\n    imp_df = pd.DataFrame(columns = ['Pos_Words','Pos_Importance','Neg_Words','Neg_Importance'])\n    imp_df['Pos_Words'] = top_pos_words[::-1]\n    imp_df['Pos_Importance'] = np.take(classifier.feature_log_prob_[1],pos)[::-1]\n    imp_df['Neg_Words'] = top_neg_words[::-1]\n    imp_df['Neg_Importance'] = np.take(classifier.feature_log_prob_[0],neg)[::-1]\n    return imp_df"]}, {"cell_type": "markdown", "id": "83385865", "metadata": {}, "source": ["### Individual Prediction"]}, {"cell_type": "code", "execution_count": 1, "id": "392cac9e", "metadata": {}, "outputs": [], "source": ["def Individual_Prediction(model, classifier, review):\n    review = final_sentence(review)\n    review_vec = model.transform([review])\n    review_vec = preprocessing.normalize(review_vec)\n    pred = classifier.predict(review_vec)\n\n    return \"positive review\" if pred[0] == 1 else \"negative review\""]}, {"cell_type": "markdown", "id": "63567fa6", "metadata": {}, "source": ["## Bag of Words (BoW)"]}, {"cell_type": "code", "execution_count": 1, "id": "b04b45e4", "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import CountVectorizer\n\nBOW, X = Text_Into_Vector(CountVectorizer,data['CleanedText'])"]}, {"cell_type": "code", "execution_count": 1, "id": "31a261c3", "metadata": {}, "outputs": [], "source": ["BOW.get_feature_names()[:20]"]}, {"cell_type": "code", "execution_count": 1, "id": "49721c63", "metadata": {}, "outputs": [], "source": ["BOW.get_params()"]}, {"cell_type": "code", "execution_count": 1, "id": "af3dae5c", "metadata": {}, "outputs": [], "source": ["#split data into train, cross validate and test \n\nX_tr, X_cv, X_test, Y_tr, Y_test, Y_cv, X_train, Y_train = Split_data(X, data['Score'])"]}, {"cell_type": "code", "execution_count": 1, "id": "18fedd02", "metadata": {}, "outputs": [], "source": ["print('X_test, Y_test', X_test.shape, Y_test.shape)\nprint('X_tr, Y_tr', X_tr.shape, Y_tr.shape)\nprint('X_cv, Y_cv', X_cv.shape, Y_cv.shape)\nprint('X_Train, Y_Train', X_train.shape, Y_train.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "757130e9", "metadata": {}, "outputs": [], "source": ["# Normalization\n\nX_tr, X_cv, X_test = Normalization(X_tr, X_cv, X_test)"]}, {"cell_type": "markdown", "id": "b193f091", "metadata": {}, "source": ["#### Navie Bayes for BOW"]}, {"cell_type": "code", "execution_count": 1, "id": "3f874a2a", "metadata": {}, "outputs": [], "source": ["#training NB \n\nbest_alpha_bow = Multinomial_NB(X_tr,X_cv,Y_tr,Y_cv)"]}, {"cell_type": "code", "execution_count": 1, "id": "6adb13ad", "metadata": {}, "outputs": [], "source": ["# Testing NB Model\n\nNB_bow, roc_auc_bow = Testing_model(X_tr,Y_tr,X_test,Y_test,best_alpha_bow)"]}, {"cell_type": "code", "execution_count": 1, "id": "8ca9a883", "metadata": {}, "outputs": [], "source": ["# Top features using NB and BOW\n\nImportant_features(BOW, NB_bow)"]}, {"cell_type": "markdown", "id": "b8e656aa", "metadata": {}, "source": ["## TF-IDF"]}, {"cell_type": "code", "execution_count": 1, "id": "a1d24358", "metadata": {}, "outputs": [], "source": ["## TFidf Vectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nTfIdf, X = Text_Into_Vector(TfidfVectorizer,data['CleanedText'])"]}, {"cell_type": "code", "execution_count": 1, "id": "870820a1", "metadata": {}, "outputs": [], "source": ["TfIdf.get_feature_names()[:20]"]}, {"cell_type": "code", "execution_count": 1, "id": "afa32adf", "metadata": {}, "outputs": [], "source": ["TfIdf.get_params()"]}, {"cell_type": "code", "execution_count": 1, "id": "52ce90e4", "metadata": {}, "outputs": [], "source": ["#split data into train, cross validate and test \n\nX_tr, X_cv, X_test, Y_tr, Y_test, Y_cv, X_train, Y_train = Split_data(X, data['Score'])"]}, {"cell_type": "code", "execution_count": 1, "id": "b01c8ff6", "metadata": {}, "outputs": [], "source": ["print('X_test, Y_test', X_test.shape, Y_test.shape)\nprint('X_tr, Y_tr', X_tr.shape, Y_tr.shape)\nprint('X_cv, Y_cv', X_cv.shape, Y_cv.shape)\nprint('X_Train, Y_Train', X_train.shape, Y_train.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "994bf6b4", "metadata": {}, "outputs": [], "source": ["# Normalize Data\n\nX_tr, X_cv, X_test = Normalization(X_tr, X_cv, X_test)"]}, {"cell_type": "markdown", "id": "9a13074b", "metadata": {}, "source": ["#### Naive bayes for TF-idf"]}, {"cell_type": "code", "execution_count": 1, "id": "ae133c73", "metadata": {}, "outputs": [], "source": ["#Training NB model\n\nbest_alpha_idf = Multinomial_NB(X_tr,X_cv,Y_tr,Y_cv)"]}, {"cell_type": "code", "execution_count": 1, "id": "588bace3", "metadata": {}, "outputs": [], "source": ["# Testing NB Model\n\nNB_tfidf, roc_auc_idf = Testing_model(X_tr,Y_tr,X_test,Y_test,best_alpha_idf)"]}, {"cell_type": "code", "execution_count": 1, "id": "78e1c530", "metadata": {}, "outputs": [], "source": ["# Top features using NB and tfidf\n\nImportant_features(TfIdf, NB_tfidf)"]}, {"cell_type": "markdown", "id": "6529a7ce", "metadata": {}, "source": ["## Conclusion"]}, {"cell_type": "code", "execution_count": 1, "id": "5885a53a", "metadata": {}, "outputs": [], "source": ["from prettytable import PrettyTable\n\nx = PrettyTable()\nx.field_names = [\"Vectorizer\", \"Model\", \"Hyperameter(alpha)\",\"Test Auc Score\"]\n\n####################################################################################\nx.add_row([\"BoW\",\"MultinomialNB\",best_alpha_bow, roc_auc_bow])\nx.add_row([\"Tf-Idf\",\"MultinomialNB\",best_alpha_idf, roc_auc_idf])\n\n####################################################################################\nfrom IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown(string))\n    \n####################################################################################\nprintmd('****Final Conclusion for MultiNomialNB Model:****')\nprint(x)"]}, {"cell_type": "markdown", "id": "5b717337", "metadata": {}, "source": ["# ============================================================="]}, {"cell_type": "markdown", "id": "4bf1c32c", "metadata": {}, "source": ["### Individual prediction"]}, {"cell_type": "code", "execution_count": 1, "id": "27e738a1", "metadata": {}, "outputs": [], "source": ["# Individual prediction\nreview = \"\"\"Great, healthier alternative to the usual bhujia we Indians are used to having along with our tea or our beer.\n            Much less salt than traditional tea snacks as well. I love the variety of texture as well with the very \n            crunchy peas to soft cheese bits, the sesame seed coated snack to good old roasted peanuts. It is pretty \n            expensive though, at 600rs at a kilo perhaps the most expensive tea snack Ive ever had.\"\"\"\n\nprint(\"Prediction using BOW:\", Individual_Prediction(BOW, NB_bow, review))\nprint(\"Prediction using TF-Idf:\", Individual_Prediction(TfIdf, NB_tfidf, review))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}