{"cells": [{"cell_type": "markdown", "id": "58587068", "metadata": {}, "source": ["## Objective: To explore various AutoEDA capabilities and perform analysis on a given dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "d35b7995", "metadata": {}, "outputs": [], "source": ["from IPython.display import Image\nImage(\"../input/autoedaimage/AutoEDA.png\")"]}, {"cell_type": "markdown", "id": "848b23d6", "metadata": {}, "source": ["# 1. AutoEDA - Pandas Profiling\n\n### Dataset Reference: Loan Prediction dataset from Kaggle"]}, {"cell_type": "markdown", "id": "fd52a984", "metadata": {}, "source": ["### Features:\n\n* General Overview - Quick insights of all variables in the dataset\n* Details about each variables / features in the dataset\n* Interactions between numeric variables\n* Correlations between variables - Pearson's Correlation Coefficient, Spearman's Rank Correlation Coefficient, Kendall's Rank Correlation Coefficient, Phik Correlation Coefficient, Cramer's V for displaying association measure for nominal random variables\n* Missing Values - Count, Matrix, Heatmap, Dendogram representations\n* Sample data - first and last 10 rows\n\n\n### When To Use?\n\n* Dataset size is not very large\n* Need some quick insights about an unknown dataset\n* Use this as a basis for your further EDA analysis on top of it"]}, {"cell_type": "code", "execution_count": 1, "id": "9f00192f", "metadata": {}, "outputs": [], "source": ["import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas_profiling as pp"]}, {"cell_type": "code", "execution_count": 1, "id": "e42700b6", "metadata": {}, "outputs": [], "source": ["df_train = pd.read_csv(\"../input/loan-eligible-dataset/loan-train.csv\")\n\ndf_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "84a06c1e", "metadata": {}, "outputs": [], "source": ["df_test = pd.read_csv(\"../input/loan-eligible-dataset/loan-test.csv\")\n\ndf_test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "1ece96d1", "metadata": {}, "outputs": [], "source": ["df_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "8b9c0f8a", "metadata": {}, "outputs": [], "source": ["df_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "1ac93319", "metadata": {}, "outputs": [], "source": ["pp.ProfileReport(df_train)"]}, {"cell_type": "markdown", "id": "5476f894", "metadata": {}, "source": ["# 2. AutoEDA - DataPrep"]}, {"cell_type": "markdown", "id": "d0f04fac", "metadata": {}, "source": ["### Features:\n\n* General Overview - Quick insights of all variables in the dataset using the plot dataframe.\n* Details about each variables / features in the dataset by using create_report - overview, variables, interactions, correlations, missing values\n* Interactions - based on x-axis and y-axis scatter plots\n* Correlations between variables - Pearson's Correlation Coefficient, Spearman's Rank Correlation Coefficient, Kendall's Rank Correlation Coefficient\n* Missing Values - Bar chart, Spectrum, Heatmap, Dendogram representations\n* We can pick one particular feature and analyze - Stats, Bar chart, Pie chart, Word Count, Word Frequency etc as per applicability\n\n\n### When To Use?\n\n* Dataset size is fairly very large (this seems to be 10X faster than Pandas Profiling tools due to it's highly optimized Dask-based computing module)\n* Need some quick insights about an unknown dataset\n* Use this as a basis for your further EDA analysis on top of it"]}, {"cell_type": "code", "execution_count": 1, "id": "957462c3", "metadata": {}, "outputs": [], "source": ["!pip install dataprep  # Please use it for the first time if it is not installed in your environment\n\nfrom dataprep.eda import create_report, plot, plot_correlation, plot_missing"]}, {"cell_type": "code", "execution_count": 1, "id": "aaf344a2", "metadata": {}, "outputs": [], "source": ["plot(df_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "1d7f398c", "metadata": {}, "outputs": [], "source": ["create_report(df_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "fbb21b38", "metadata": {}, "outputs": [], "source": ["plot(df_train, \"Property_Area\")"]}, {"cell_type": "markdown", "id": "edc53d87", "metadata": {}, "source": ["# 3. AutoEDA - SweetViz"]}, {"cell_type": "markdown", "id": "1e60c6a9", "metadata": {}, "source": ["### Features:\n\n* General Overview - Quick insights of all variables in the dataset using the associations / correlation in the form of a heatmap (including how many duplicates, categorical/numerical/text variables etc.)\n* Details about each variables / features in the dataset - missing values, distinct etc.\n* Compares Train and Test datasets\n* Provides visualization of target variable in context of train dataset\n\n\n### When To Use?\n\n* Need some quick insights about an unknown dataset\n* Use this as a basis for your further EDA analysis on top of it\n* Need to compare some quick statistical insights between train and test datasets"]}, {"cell_type": "code", "execution_count": 1, "id": "639f6645", "metadata": {}, "outputs": [], "source": ["!pip install sweetviz # Please use it for the first time if it is not installed in your environment"]}, {"cell_type": "code", "execution_count": 1, "id": "dbf6179d", "metadata": {}, "outputs": [], "source": ["import sweetviz as sv"]}, {"cell_type": "code", "execution_count": 1, "id": "8f31da29", "metadata": {}, "outputs": [], "source": ["analysis_report = sv.analyze(df_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "66ddc248", "metadata": {}, "outputs": [], "source": ["# analysis_report.show_html() # This will generate a separate report named SWEETVIZ_REPORT.html\nanalysis_report.show_notebook(w=\"100%\",h=\"full\")"]}, {"cell_type": "code", "execution_count": 1, "id": "484696a3", "metadata": {}, "outputs": [], "source": ["analysis_report2 = sv.analyze([df_train,'Train'], target_feat='Loan_Status')"]}, {"cell_type": "code", "execution_count": 1, "id": "d2d9a901", "metadata": {}, "outputs": [], "source": ["analysis_report2.show_notebook(w=\"100%\",h=\"full\")"]}, {"cell_type": "code", "execution_count": 1, "id": "cebccd07", "metadata": {}, "outputs": [], "source": ["analysis_report3 = sv.compare([df_train,'Train'],[df_test,'Test'],target_feat='Loan_Status')\n\nanalysis_report3.show_notebook(w=\"100%\",h=\"full\")"]}, {"cell_type": "markdown", "id": "62a38da7", "metadata": {}, "source": ["# Final Interpretation - AutoEDA:\n\n* If we want to get quick insights on statistical inferences, missing values, duplicates, categorical/numerical/text features, correlations, interactions, top and bottom 10 rows, comparision between train and test datasets, then we can leverage some of these AutoEDA libraries and their capabilities.\n\n* This helps in saving time significantly as we quickly generate some statistical inferences, insights as part of these reports / outcomes.\n\n* If the dataset is large, we may use \"DataPrep\" which seems to be 10X faster than Pandas Profiling as it uses Dask based computing methods.\n\n* We have used one sample dataset (Loan Eligible / Loan Prediction dataset) for the analysis to demonstrate features of various techniques. These can be used based on scenarios, data context, business need, feasibility etc. These are non-exhaustive list.\n\n* Some of the AutoEDA libraries in Python are as follows:\n    * Pandas Profiling\n    * DataPrep\n    * SweetViz\n    * AutoViz\n    * LUX\n    * DTale\n\n\nWe will keep adding more experiments."]}, {"cell_type": "markdown", "id": "79d1c5ed", "metadata": {}, "source": ["### Please do provide your feedback, comments and any specific experiences around AutoEDA techniques, what has worked for you, for which industry use cases etc."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}