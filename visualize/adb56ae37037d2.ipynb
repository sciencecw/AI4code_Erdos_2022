{"cells": [{"cell_type": "markdown", "id": "9c573aa3", "metadata": {}, "source": ["![alt text](https://cdn.discordapp.com/attachments/693138332166914077/698275109416206486/bootcamp.png)"]}, {"cell_type": "markdown", "id": "e4ab550b", "metadata": {}, "source": ["# GENETIC VARIANT CLASSIFICATION"]}, {"cell_type": "markdown", "id": "043c41ac", "metadata": {}, "source": ["Clinic Variant is a public resource containing annotations about human genetic variants. These variants are (usually manually) classified by clinical laboratories on a categorical spectrum ranging from **benign, likely benign, uncertain significance, likely pathogenic, and pathogenic.** Variants that have conflicting classifications (from laboratory to laboratory) can cause confusion when clinicians or researchers try to interpret whether the variant has an impact on the disease of a given patient."]}, {"cell_type": "markdown", "id": "7a1442b5", "metadata": {}, "source": ["The objective is to predict whether a Clinic Variant  will have conflicting classifications. This is presented here as a binary classification problem, where each record in the dataset is a genetic variant.\n"]}, {"cell_type": "markdown", "id": "c99d26b3", "metadata": {}, "source": ["![alt text](https://cdn.discordapp.com/attachments/693138332166914077/698141745719935036/concordant_variant.png)"]}, {"cell_type": "markdown", "id": "8d1c5b89", "metadata": {}, "source": ["![alt text](https://cdn.discordapp.com/attachments/693138332166914077/698141746902597662/conflicting_variant.png)"]}, {"cell_type": "markdown", "id": "b1f419bc", "metadata": {}, "source": ["# **Distribution of Target**"]}, {"cell_type": "markdown", "id": "3e8b17d1", "metadata": {}, "source": ["![alt text](https://cdn.discordapp.com/attachments/693138332166914077/698141755178221629/target_histogram.png)"]}, {"cell_type": "markdown", "id": "f7f8c47a", "metadata": {}, "source": ["**The CLASS distribution is skewed a bit to the 0 class, meaning there are fewer variants with conflicting submissions.**"]}, {"cell_type": "markdown", "id": "e6dadd8b", "metadata": {}, "source": ["Since our target variable is binary (categorical), we will use both old and new models. These can be listed as follows:\n\n\n\n*   Logistic Regression\n*   XGBoost Classifier\n*   KNeighbors Classifier\n*   Decision Tree Classifier\n*   LigthGBM Classifier\n*   Gradient Boosting Classifier\n*   Hist Gradient Boosting Classifier\n\n"]}, {"cell_type": "markdown", "id": "a1f512f0", "metadata": {}, "source": ["# **Models Histogram**"]}, {"cell_type": "markdown", "id": "d321058b", "metadata": {}, "source": ["![alt text](https://cdn.discordapp.com/attachments/693138332166914077/698263762855002164/Ekran_Resmi_2020-04-10_23.08.13.png)"]}, {"cell_type": "code", "execution_count": 1, "id": "7f4ea2e4", "metadata": {}, "outputs": [], "source": ["#Import Libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport missingno as msno\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import base\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPRegressor, MLPClassifier\n!pip install category_encoders\n!pip install rfpimp\nfrom category_encoders import BinaryEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,roc_auc_score,classification_report,confusion_matrix\nfrom IPython.display import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")"]}, {"cell_type": "code", "execution_count": 1, "id": "1f62361a", "metadata": {}, "outputs": [], "source": ["#Read The Dataset\n\nurl = \"https://drive.google.com/uc?id=1TiEhIjpjB6KUxvqqgVeps9SkKTff1hvY\"\n\ndata = pd.read_csv(url)"]}, {"cell_type": "code", "execution_count": 1, "id": "ec4586eb", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "b34c90ec", "metadata": {}, "outputs": [], "source": ["data.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "071ff996", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "24631198", "metadata": {}, "outputs": [], "source": ["#Inserting KEY\n\n#In this data, we define a column with a unique value of 65188 as a key.\n\ndata.insert(0,\"KEY\",data.CLNHGVS)"]}, {"cell_type": "code", "execution_count": 1, "id": "2e66a3bc", "metadata": {}, "outputs": [], "source": ["data['KEY'].nunique()==len(data)"]}, {"cell_type": "code", "execution_count": 1, "id": "7382cff0", "metadata": {}, "outputs": [], "source": ["data.describe()"]}, {"cell_type": "markdown", "id": "1ef8337e", "metadata": {}, "source": ["## **Histogram of Binary Target Categories**"]}, {"cell_type": "code", "execution_count": 1, "id": "bc65570a", "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n# Histogram of the target categories\ndef histogram(df,feature):\n    ncount = len(df)\n    ax = sns.countplot(x = feature, data=df ,palette=\"hls\")\n    sns.set(font_scale=1)\n    ax.set_xlabel('Target Segments')\n    plt.xticks(rotation=90)\n    ax.set_ylabel('Number of Observations')\n    fig = plt.gcf()\n    fig.set_size_inches(12,5)\n    # Make twin axis\n    ax2=ax.twinx()\n    # Switch so count axis is on right, frequency on left\n    ax2.yaxis.tick_left()\n    ax.yaxis.tick_right()\n    # Also switch the labels over\n    ax.yaxis.set_label_position('right')\n    ax2.yaxis.set_label_position('left')\n    ax2.set_ylabel('Frequency [%]')\n    for p in ax.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n        ax.annotate('{:.2f}%'.format(100.*y/ncount), (x.mean(), y), \n                ha='center', va='bottom') # set the alignment of the text\n    # Use a LinearLocator to ensure the correct number of ticks\n    ax.yaxis.set_major_locator(ticker.LinearLocator(11))\n    # Fix the frequency range to 0-100\n    ax2.set_ylim(0,100)\n    ax.set_ylim(0,ncount)\n    # And use a MultipleLocator to ensure a tick spacing of 10\n    ax2.yaxis.set_major_locator(ticker.MultipleLocator(10))\n    # Need to turn the grid on ax2 off, otherwise the gridlines end up on top of the bars\n    ax2.grid(None)\n    plt.title('Histogram of Binary Target Categories', fontsize=20, y=1.08)\n    plt.show()\n    plt.savefig('target_histogram.png')\n    del ncount, x, y"]}, {"cell_type": "code", "execution_count": 1, "id": "83701fac", "metadata": {}, "outputs": [], "source": ["histogram(data,\"CLASS\")"]}, {"cell_type": "markdown", "id": "8fcb3e2b", "metadata": {}, "source": ["**The CLASS distribution is skewed a bit to the 0 class, meaning there are fewer variants with conflicting submissions.**\n\n"]}, {"cell_type": "markdown", "id": "a285172e", "metadata": {}, "source": ["### **Information function about missing values**"]}, {"cell_type": "code", "execution_count": 1, "id": "19b192ff", "metadata": {}, "outputs": [], "source": ["def MissingUniqueStatistics(df):\n  \n  total_entry_list = []\n  total_missing_value_list = []\n  missing_value_ratio_list = []\n  data_type_list = []\n  unique_values_list = []\n  number_of_unique_values_list = []\n  variable_name_list = []\n  \n  for col in df.columns:\n\n    variable_name_list.append(col)\n    missing_value_ratio = round((df[col].isna().sum()/len(df[col])),4)\n    total_entry_list.append(df[col].shape[0] - df[col].isna().sum())\n    total_missing_value_list.append(df[col].isna().sum())\n    missing_value_ratio_list.append(missing_value_ratio)\n    data_type_list.append(df[col].dtype)\n    unique_values_list.append(list(df[col].unique()))\n    number_of_unique_values_list.append(len(df[col].unique()))\n\n  data_info_df = pd.DataFrame({'Variable':variable_name_list,'#_Total_Entry':total_entry_list,\\\n                           '#_Missing_Value':total_missing_value_list,'%_Missing_Value':missing_value_ratio_list,\\\n                           'Data_Type':data_type_list,'Unique_Values':unique_values_list,\\\n                           '#_Uniques_Values':number_of_unique_values_list})\n  \n  return data_info_df.sort_values(by=\"#_Missing_Value\",ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "ee00ea37", "metadata": {}, "outputs": [], "source": ["data_info = MissingUniqueStatistics(data)\ndata_info = data_info.set_index(\"Variable\")\ndata_info"]}, {"cell_type": "markdown", "id": "76214b8c", "metadata": {}, "source": ["### When we analyze the missing value statistics, we see that our 9 columns are larger than 99%. These columns do not contain information. That's why we drop these columns."]}, {"cell_type": "code", "execution_count": 1, "id": "5d9e9c40", "metadata": {}, "outputs": [], "source": ["drop_list = list(data_info[data_info[\"%_Missing_Value\"] >= 0.99].index)\n\ndata.drop(drop_list,axis = 1,inplace = True) # --> MAIN DF CHANGED"]}, {"cell_type": "markdown", "id": "af08e380", "metadata": {}, "source": ["### When we continue to analyze the missing data statistics, we see that there are 3 different columns with numerical data, but the data type is an object."]}, {"cell_type": "code", "execution_count": 1, "id": "20e91534", "metadata": {}, "outputs": [], "source": ["data[\"Protein_position\"].unique() , data[\"CDS_position\"].unique()  , data[\"cDNA_position\"].unique()"]}, {"cell_type": "markdown", "id": "e4f7bb68", "metadata": {}, "source": ["### We see that some data is separated by \"-\". And these numbers are very close to each other. Based on this information, we can only use the first number."]}, {"cell_type": "code", "execution_count": 1, "id": "7bdaea2b", "metadata": {}, "outputs": [], "source": ["def value_correction(df,columns):\n  \n  for col in columns:\n\n    value_correction = pd.DataFrame(df[col][df[col].notnull()].str.split(\"-\").tolist(),columns=[\"X\",\"Y\"])\n    value_correction[\"X\"][value_correction[\"X\"]==\"?\"] = value_correction[\"Y\"]\n    key = df[[col,\"KEY\"]][df[col].notnull()][\"KEY\"]\n\n    counter = 0\n\n    for i in key.index:\n\n      df[col][i] = value_correction[\"X\"][counter]\n      counter += 1\n\n    df[col] = df[col].astype(float)\n  return df"]}, {"cell_type": "code", "execution_count": 1, "id": "15625052", "metadata": {}, "outputs": [], "source": ["data = value_correction(data,[\"CDS_position\",\"cDNA_position\",\"Protein_position\"]) # --> MAIN DF CHANGED"]}, {"cell_type": "markdown", "id": "31439ce2", "metadata": {}, "source": ["# Showing the correlation map of the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "c7d2fdbe", "metadata": {}, "outputs": [], "source": ["f, ax = plt.subplots(figsize=(20, 9))\nsns.heatmap(data.corr(), annot=True)\nplt.show()"]}, {"cell_type": "markdown", "id": "8c55f817", "metadata": {}, "source": ["When we analyze this map, we see that the correlation of cDNA_position, CDS_position, Protein_position columns with each other is 1.And more than 85% of the CDS_position values \u200b\u200bare filled with 3 times the Protein_position value.Also, the value of cDNA_position is 50 numbers larger than CDS_position.\n\nTherefore, we dropped the cDNA_position and CDS_position columns."]}, {"cell_type": "code", "execution_count": 1, "id": "56c009a5", "metadata": {}, "outputs": [], "source": ["data.drop([\"CDS_position\",\"cDNA_position\"],axis = 1, inplace = True) # --> MAIN DF CHANGED"]}, {"cell_type": "markdown", "id": "b71c8f94", "metadata": {}, "source": ["When we continue to analyze the table of missing values \u200b\u200bstatistics, we see that we have two columns with fractional numbers but the data type is an object.These are \"EXON\" and \"INTRON\" columns.\n\nWe make the data type of these columns \"float\".\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2e652327", "metadata": {}, "outputs": [], "source": ["data[[\"EXON\",\"INTRON\"]][data[\"INTRON\"].notnull() & data[\"EXON\"].notnull()].head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "992d7566", "metadata": {}, "outputs": [], "source": ["def convert_to_float(df,columns):\n  \n  for col in columns:\n       \n    convert_to_float = pd.DataFrame(df[col][df[col].notnull()].str.split(\"/\").tolist(),columns=[\"Numerator\",\"Denominator\"])\n    convert_to_float = convert_to_float.astype(\"float\")\n    convert_to_float[\"Result\"] = convert_to_float[\"Numerator\"] / convert_to_float[\"Denominator\"]\n    key =df[[col,\"KEY\"]][df[col].notnull()][\"KEY\"]\n\n    counter = 0\n    for i in key.index:\n\n      df[col][i] = convert_to_float[\"Result\"][counter]\n      counter += 1\n    df[col] = df[col].astype(float)\n\n  return df"]}, {"cell_type": "code", "execution_count": 1, "id": "00cc0015", "metadata": {}, "outputs": [], "source": ["data = convert_to_float(data,[\"INTRON\",\"EXON\"]) # --> MAIN DF CHANGED"]}, {"cell_type": "code", "execution_count": 1, "id": "39970b7d", "metadata": {}, "outputs": [], "source": ["MissingUniqueStatistics(data)"]}, {"cell_type": "markdown", "id": "2ffd2e43", "metadata": {}, "source": ["# Showing missing values on the bar graphic"]}, {"cell_type": "code", "execution_count": 1, "id": "ec2c40b4", "metadata": {}, "outputs": [], "source": ["msno.bar(data,color='#79ccb3',sort='descending')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "6eec9d84", "metadata": {}, "outputs": [], "source": ["msno.matrix(data,color=(0.45,0.45,0.64),figsize=(27, 10), width_ratios=(10, 0))\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "73ee144e", "metadata": {}, "outputs": [], "source": ["msno.dendrogram(data);"]}, {"cell_type": "code", "execution_count": 1, "id": "2ca5cad3", "metadata": {}, "outputs": [], "source": ["msno.heatmap(data)\nplt.show()"]}, {"cell_type": "markdown", "id": "47c82c18", "metadata": {}, "source": ["We have a heapmap showing the relationship of missing values \u200b\u200bwith each other. On this map, we see that the \"EXON\" and \"INTRON\" columns are inversely related to each other. Therefore, we fill in the missing values \u200b\u200bof the column \"EXON\" with the values \u200b\u200bof the column \"INTRON\"."]}, {"cell_type": "code", "execution_count": 1, "id": "519e81f1", "metadata": {}, "outputs": [], "source": ["data[\"EXON\"][data[\"EXON\"].isnull()]"]}, {"cell_type": "code", "execution_count": 1, "id": "25a4ccc7", "metadata": {}, "outputs": [], "source": ["data[\"INTRON\"][data[\"INTRON\"].notnull()]"]}, {"cell_type": "code", "execution_count": 1, "id": "ee8fd0d7", "metadata": {}, "outputs": [], "source": ["data[\"EXON\"][data[\"EXON\"].isnull()] = data[\"INTRON\"][data[\"INTRON\"].notnull()] # --> MAIN DF CHANGED"]}, {"cell_type": "markdown", "id": "89fa7eaa", "metadata": {}, "source": ["Then we drop the \"INTRON\" column."]}, {"cell_type": "code", "execution_count": 1, "id": "83ec5cb7", "metadata": {}, "outputs": [], "source": ["data.drop([\"INTRON\"], axis = 1, inplace = True) # --> MAIN DF CHANGED"]}, {"cell_type": "code", "execution_count": 1, "id": "305032b0", "metadata": {}, "outputs": [], "source": ["data_info = MissingUniqueStatistics(data)\ndata_info = data_info.set_index(\"Variable\")\ndata_info"]}, {"cell_type": "code", "execution_count": 1, "id": "a10339bf", "metadata": {}, "outputs": [], "source": ["#Creating new column for add of variable type\ndata_info[\"Variable_Type\"] = [\"Ordinal\",\"Ordinal\",\"Nominal\",\"Nominal\",\"Nominal\",\"Nominal\",\"Nominal\",\"Continuous\",\"Nominal\",\n                              \"Continuous\",\"Continuous\",\"Continuous\",\"Continuous\",\"Continuous\",\"Nominal\",\"Nominal\",\"Nominal\",\n                              \"Nominal\",\"Nominal\",\"Nominal\",\"Nominal\",\"Ordinal\",\"Nominal\",\"Nominal\",\"Nominal\",\"Nominal\",\"Nominal\",\"Nominal\",\n                              \"Continuous\",\"Continuous\",\"Continuous\",\"Nominal\",\"Nominal\",\"Cardinal\",\"Ordinal\"]\ndata_info"]}, {"cell_type": "markdown", "id": "4cc81270", "metadata": {}, "source": ["## **Data Controlling**"]}, {"cell_type": "code", "execution_count": 1, "id": "be2dbbeb", "metadata": {}, "outputs": [], "source": ["# 1- Row Uniqueness (Drop Duplicates) \nlen(data_info.index) == data_info.shape[0]"]}, {"cell_type": "code", "execution_count": 1, "id": "06995307", "metadata": {}, "outputs": [], "source": ["# 2- Column Uniqueness (Drop Singletons)\nnumerical_columns = list(data_info.loc[(data_info.loc[:,\"Variable_Type\"]==\"Cardinal\") |\n                                       (data_info.loc[:,\"Variable_Type\"]==\"Continuous\")].index)\nlen(numerical_columns), numerical_columns"]}, {"cell_type": "code", "execution_count": 1, "id": "1cebb18a", "metadata": {}, "outputs": [], "source": ["categorical_columns = list(data_info.loc[(data_info.loc[:,\"Variable_Type\"]==\"Nominal\") |\n                                       (data_info.loc[:,\"Variable_Type\"]==\"Ordinal\")].index)\nlen(categorical_columns), categorical_columns"]}, {"cell_type": "code", "execution_count": 1, "id": "19ad074c", "metadata": {}, "outputs": [], "source": ["def ZeroVarianceFinder(df, numerical_columns):\n  \n  import pandas as pd\n  import numpy as np\n\n  zerovariance_numerical_features=[]\n  for col in numerical_columns:\n      try:\n          if pd.DataFrame(df[col]).describe().loc['std'][0] == 0.00 or \\\n          np.isnan(pd.DataFrame(df[col]).describe().loc['std'][0]):\n              zerovariance_numerical_features.append(col)\n      except:\n          print(\"Error:\",col)\n  return zerovariance_numerical_features"]}, {"cell_type": "code", "execution_count": 1, "id": "99d7da50", "metadata": {}, "outputs": [], "source": ["zerovariance_numerical_features = ZeroVarianceFinder(data,numerical_columns)\nzerovariance_numerical_features"]}, {"cell_type": "code", "execution_count": 1, "id": "b2106877", "metadata": {}, "outputs": [], "source": ["singleton_categorical_features=[]\nfor col in categorical_columns:\n    if len(data[col].unique()) <= 1:\n        singleton_categorical_features.append(col)\nlen(singleton_categorical_features), singleton_categorical_features"]}, {"cell_type": "markdown", "id": "3d3c0a13", "metadata": {}, "source": ["# **Train/Test Split**"]}, {"cell_type": "code", "execution_count": 1, "id": "830ae4ad", "metadata": {}, "outputs": [], "source": ["y = data.loc[:,\"CLASS\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "b4143419", "metadata": {}, "outputs": [], "source": ["x1 = data.iloc[:,1:15]\nx2 = data.iloc[:,16:]\nx = pd.concat([x1,x2],axis = 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "6645068a", "metadata": {}, "outputs": [], "source": ["X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.33,random_state=42)\n\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape"]}, {"cell_type": "markdown", "id": "61fbea00", "metadata": {}, "source": ["#### **Histogram of Binary Target Categories for Train**"]}, {"cell_type": "code", "execution_count": 1, "id": "16f9f63a", "metadata": {}, "outputs": [], "source": ["histogram(X_train,Y_train)"]}, {"cell_type": "markdown", "id": "490d5943", "metadata": {}, "source": ["After the separation of the train and test data we made, we see that the target distribution does not deteriorate."]}, {"cell_type": "markdown", "id": "ba0f7f4b", "metadata": {}, "source": ["#### **Histogram of Binary Target Categories for Test**\n"]}, {"cell_type": "code", "execution_count": 1, "id": "9b78bdd4", "metadata": {}, "outputs": [], "source": ["histogram(X_test,Y_test)"]}, {"cell_type": "markdown", "id": "b19fd9cb", "metadata": {}, "source": ["## **Outlier Detection**"]}, {"cell_type": "markdown", "id": "85bda7b5", "metadata": {}, "source": ["### Finding sparse columns"]}, {"cell_type": "code", "execution_count": 1, "id": "31eb8db5", "metadata": {}, "outputs": [], "source": ["df_train = data.copy()\nnumerical_columns_remains = numerical_columns\n        \nsparse_columns = []\nfor col in numerical_columns_remains:\n    if (df_train[col].quantile(0.01)==df_train[col].quantile(0.25)==df_train[col].mode()[0]):\n        sparse_columns.append(col)\n\nsparse_columns_2 = []\nfor col in numerical_columns_remains:\n    if (df_train[col].quantile(0.01)==df_train[col].quantile(0.25)):\n        sparse_columns_2.append(col)\n\nlen(numerical_columns_remains), len(sparse_columns), len(sparse_columns_2)"]}, {"cell_type": "markdown", "id": "57e3452c", "metadata": {}, "source": ["## **Visualization Before Cleaning Outlier**"]}, {"cell_type": "code", "execution_count": 1, "id": "02721454", "metadata": {}, "outputs": [], "source": ["from pylab import rcParams\n\ndef box_plot(x,y,data):\n\n  rcParams['figure.figsize'] = 20, 10\n  fig, axs = plt.subplots(2,5)\n  plt.tight_layout()\n  fig.subplots_adjust(top=0.7)\n  sns.set(style=\"ticks\", palette=\"rainbow\")\n\n  j = 0\n  k = 0\n  for i in range(len(y)):\n    sns.boxplot(x=x, y=y[i], data=data,ax=axs[j,k])\n    if(k==4):\n      k = 0\n      j += 1\n    else:\n      k += 1\n\n  plt.tight_layout()\n  plt.show()\n\nbox_plot(Y_train,numerical_columns,X_train)"]}, {"cell_type": "markdown", "id": "6be8f4dc", "metadata": {}, "source": ["## **Cleaning Outliers for Train Dataset**\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b9ce4f37", "metadata": {}, "outputs": [], "source": ["\"\"\"\nAlgorithm 'HER(Hard-Edges Method)' applies induction to the elements of a value line which are:\n\n    - lower than the 1th quantile to that quantile and\n    - upper than the 99th quantile to that quantile.\n    \nMain aim is to diminish negative effects of outlier values on analytical operations being performed.\n\"\"\"\n\ndef HardEdgeReduction(df,numerical_columns,sparse_columns,upper_quantile=0.99,lower_quantile=0.01):\n    \n    import pandas as pd\n\n    import psutil, os, gc, time\n    print(\"HardEdgeReduction process has began:\\n\")\n    proc = psutil.Process(os.getpid())\n    gc.collect()\n    mem_0 = proc.memory_info().rss\n    start_time = time.time()\n    \n    # Do outlier cleaning in only one loop\n    epsilon = 0.0001 # for zero divisions\n\n    # Define boundaries that we will use for Reduction operation\n\n    df_outlier_cleaned = df.copy()\n\n\n    print(\"Detected outliers will be replaced with edged quantiles/percentiles: 1% and 99%!\\n\")\n    print(\"Total number of rows is: %s\\n\"%df_outlier_cleaned.shape[0])\n\n    outlier_boundries_dict={}\n\n    for col in numerical_columns:\n\n        if col in sparse_columns:\n\n            # First ignore the 'sparse' data points:\n            nonsparse_data = pd.DataFrame(df_outlier_cleaned[df_outlier_cleaned[col] !=\\\n                                                             df_outlier_cleaned[col].mode()[0]][col]) \n            \n            #we used only mode to catch sparse points, since we know/proved it is enough to do that.\n\n            # Find Outlier Thresholds:\n            # Note: All columns are right-skewed\n            # For lower threshold (left-hand-side)\n            if nonsparse_data[col].quantile(lower_quantile) < df_outlier_cleaned[col].mode()[0]: #Unexpected case\n                lower_bound_sparse = nonsparse_data[col].quantile(lower_quantile)\n            else:\n                lower_bound_sparse = df_outlier_cleaned[col].mode()[0]\n            \n            # For upper threshold (right-hand-side)\n            if nonsparse_data[col].quantile(upper_quantile) < df_outlier_cleaned[col].mode()[0]: #Unexpected case\n                upper_bound_sparse = df_outlier_cleaned[col].mode()[0]\n            else:\n                upper_bound_sparse = nonsparse_data[col].quantile(upper_quantile)\n\n            outlier_boundries_dict[col]=(lower_bound_sparse,upper_bound_sparse)\n\n            # Inform user about the cardinality of Outlier existence:\n            number_of_outliers = len(df_outlier_cleaned[(df_outlier_cleaned[col] < lower_bound_sparse) |\\\n                                                        (df_outlier_cleaned[col] > upper_bound_sparse)][col])\n            print(\"Sparse: Outlier number in {} is equal to: \".format(col),round(number_of_outliers/(nonsparse_data.shape[0] -\n                                                                                       nonsparse_data.isnull().sum()),2))\n\n            # Replace Outliers with Edges --> 1% and 99%:\n            if number_of_outliers > 0:\n\n                # Replace 'left-hand-side' outliers with its 1% quantile value\n                df_outlier_cleaned.loc[df_outlier_cleaned[col] < lower_bound_sparse,col] = lower_bound_sparse - epsilon # --> MAIN DF CHANGED\n\n                # Replace 'right-hand-side' outliers with its 99% quantile value\n                df_outlier_cleaned.loc[df_outlier_cleaned[col] > upper_bound_sparse,col] = upper_bound_sparse + epsilon # --> MAIN DF CHANGED\n\n        else:\n            # Find Edges:\n            number_of_outliers = len(df_outlier_cleaned[(df_outlier_cleaned[col] < \\\n                                                         df_outlier_cleaned[col].quantile(lower_quantile))|\\\n                                                        (df_outlier_cleaned[col] > \\\n                                                         df_outlier_cleaned[col].quantile(upper_quantile))]\\\n                                     [col])\n            print(\"Other: Outlier number in {} is equal to: \".format(col),round(number_of_outliers/(df[col].shape[0] -\n                                                                                       df[col].isnull().sum()),2)) \n\n            # Replace 'Standard' outliers:\n            if number_of_outliers > 0:\n                # Replace all outliers with its %99 quartile\n                lower_bound_sparse = df_outlier_cleaned[col].quantile(lower_quantile)\n                df_outlier_cleaned.loc[df_outlier_cleaned[col] < \\\n                                       lower_bound_sparse,col] \\\n                = lower_bound_sparse  - epsilon\n\n                upper_bound_sparse = df_outlier_cleaned[col].quantile(upper_quantile)\n                df_outlier_cleaned.loc[df_outlier_cleaned[col] > \\\n                                       upper_bound_sparse,col] \\\n                = upper_bound_sparse  + epsilon\n\n            outlier_boundries_dict[col]=(lower_bound_sparse,upper_bound_sparse)\n\n\n    print('HardEdgeReduction process has been completed!')\n    print(\"--- in %s minutes ---\" % ((time.time() - start_time)/60))\n\n    return df_outlier_cleaned, outlier_boundries_dict\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "eb3b348f", "metadata": {}, "outputs": [], "source": ["X_train, outlier_boundries_dict = HardEdgeReduction(X_train,numerical_columns,sparse_columns)"]}, {"cell_type": "code", "execution_count": 1, "id": "69e1fe25", "metadata": {}, "outputs": [], "source": ["outlier_boundries_dict"]}, {"cell_type": "markdown", "id": "ccee2277", "metadata": {}, "source": ["## **Cleaning Outliers for Test Dataset**"]}, {"cell_type": "code", "execution_count": 1, "id": "c20f96e4", "metadata": {}, "outputs": [], "source": ["# Do outlier cleaning in only one loop\nepsilon = 0.0001 # for zero divisions\n\n# Define boundaries that we will use for Reduction operation\nupper_quantile = 0.99\nlower_quantile = 0.01\n\ndf_test_outlier_cleaned = X_test.copy()\n\nprint(\"Detected outliers will be replaced with edged quantiles/percentiles: 1% and 99%!\\n\")\nprint(\"Total number of rows is: %s\\n\"%df_test_outlier_cleaned.shape[0])\n\nfor col in numerical_columns_remains:\n\n      lower_bound = outlier_boundries_dict[col][0]\n      upper_bound = outlier_boundries_dict[col][1]\n        \n      # Inform user about the cardinality of Outlier existence:\n      number_of_outliers = len(df_test_outlier_cleaned[(df_test_outlier_cleaned[col] < lower_bound) |\\\n                                                        (df_test_outlier_cleaned[col] > upper_bound)][col])\n      print(\"Outlier number in {} is equal to: \".format(col), round(number_of_outliers/\n            (df_test_outlier_cleaned[col].shape[0] - df_test_outlier_cleaned[col].isnull().sum()),2))\n\n      # Replace Outliers with Edges --> 1% and 99%:\n      if number_of_outliers > 0:\n\n          # Replace 'left-hand-side' outliers with its 1% quantile value\n          df_test_outlier_cleaned.loc[df_test_outlier_cleaned[col] < lower_bound,col] = lower_bound  - epsilon # --> MAIN DF CHANGED\n          \n          # Replace 'right-hand-side' outliers with its 99% quantile value\n          df_test_outlier_cleaned.loc[df_test_outlier_cleaned[col] > upper_bound,col] = upper_bound  + epsilon # --> MAIN DF CHANGED\n        \n"]}, {"cell_type": "markdown", "id": "106d0665", "metadata": {}, "source": ["## **Visualization After Cleaning Outlier**"]}, {"cell_type": "code", "execution_count": 1, "id": "a0ee34e6", "metadata": {}, "outputs": [], "source": ["box_plot(Y_train,numerical_columns,X_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "c59d73d0", "metadata": {}, "outputs": [], "source": ["X_test = df_test_outlier_cleaned"]}, {"cell_type": "markdown", "id": "9bb7dbb3", "metadata": {}, "source": ["# **Imputation for Missing Values**"]}, {"cell_type": "markdown", "id": "8da0d296", "metadata": {}, "source": ["<img src=\"https://cdn.discordapp.com/attachments/693138332166914077/698142092865830922/Missing_Value.png\">"]}, {"cell_type": "markdown", "id": "13202d00", "metadata": {}, "source": ["## **Specifying a range for missing values**"]}, {"cell_type": "code", "execution_count": 1, "id": "9e3abc5b", "metadata": {}, "outputs": [], "source": ["Zero_MR_variables_list = list(data_info[data_info['%_Missing_Value']==0].index)\nLow_MR_variables_list = list(data_info[(data_info['%_Missing_Value']>0)&\n                                       (data_info['%_Missing_Value']<=0.05)].index)\nModerate_MR_variables_list = list(data_info[(data_info['%_Missing_Value']>0.05)&\\\n                                                      (data_info['%_Missing_Value']<=0.25)].index)\nHigh_MR_variables_list = list(data_info[(data_info['%_Missing_Value']>0.25)&\\\n                                                  (data_info['%_Missing_Value']<=0.50)].index)\nExtreme_MR_variables_list = list(data_info[(data_info['%_Missing_Value']>0.50)&\n                                           (data_info['%_Missing_Value']<=0.95)].index)\nDrop_MR_variables_list = list(data_info[data_info['%_Missing_Value']>0.95].index)\n\nlen(Zero_MR_variables_list),len(Low_MR_variables_list),len(Moderate_MR_variables_list),len(High_MR_variables_list),\\\nlen(Extreme_MR_variables_list),\\\nlen(Zero_MR_variables_list)+len(Low_MR_variables_list)+len(Moderate_MR_variables_list)+len(High_MR_variables_list)+\\\nlen(Extreme_MR_variables_list) == len(data_info)"]}, {"cell_type": "markdown", "id": "8cb91108", "metadata": {}, "source": ["# **Simple Imputer for Low Missing Values**"]}, {"cell_type": "markdown", "id": "4a9b574f", "metadata": {}, "source": ["Filling in the null values \u200b\u200bof columns with a missing value statistic less than 0.05\n\nIt does this according to the frequency of the data."]}, {"cell_type": "code", "execution_count": 1, "id": "e45d4137", "metadata": {}, "outputs": [], "source": ["Low_MR_variables_list"]}, {"cell_type": "code", "execution_count": 1, "id": "045ceb8f", "metadata": {}, "outputs": [], "source": ["def SimpleImputer(df,data_info,variable_list):\n  for col in variable_list:\n    \n    if(col in numerical_columns):\n      \n      print(\"Total null values: {}\".format(df[[str(col)]].isnull().sum()))\n\n      average = float(df[col].mean())\n      std = float(df[col].std())\n      count_nan = int(df[col].isnull().sum())\n      rand = np.random.normal(loc=average,scale=std,size =count_nan)\n      slice_col = pd.Series(df[col].copy())\n      slice_col[pd.isnull(slice_col)] = rand\n      df[col] = slice_col\n\n      print(\"Numerical variable {} have been imputed.\".format(col))\n\n    else:\n\n      print(\"Total null values: {}\".format(df[[str(col)]].isnull().sum()))\n      df.loc[df.loc[:,col].isnull(),col] = np.random.choice(sorted(list(df.loc[:,col].dropna().unique())),\n                                                            size=int(df.loc[df.loc[:,col].isnull(),col].shape[0]),\n                                                            p=[pd.Series(df.groupby(col).size()/df.loc[:,col].dropna().shape[0]).iloc[i] for i in \n                                                               np.arange(0,len(df.loc[:,col].dropna().unique()))])\n      \n      print(\"Categorical variable {} have been imputed.\".format(col))"]}, {"cell_type": "code", "execution_count": 1, "id": "8e04b024", "metadata": {}, "outputs": [], "source": ["SimpleImputer(X_train, data_info, Low_MR_variables_list)"]}, {"cell_type": "code", "execution_count": 1, "id": "0bc7a3a0", "metadata": {}, "outputs": [], "source": ["SimpleImputer(X_test,data_info,Low_MR_variables_list)"]}, {"cell_type": "code", "execution_count": 1, "id": "049a094c", "metadata": {}, "outputs": [], "source": ["MissingUniqueStatistics(X_train.loc[:,Low_MR_variables_list])"]}, {"cell_type": "code", "execution_count": 1, "id": "737fab1f", "metadata": {}, "outputs": [], "source": ["MissingUniqueStatistics(X_test.loc[:,Low_MR_variables_list])"]}, {"cell_type": "markdown", "id": "3bbcbe81", "metadata": {}, "source": ["## **STRING CONVERSION**"]}, {"cell_type": "markdown", "id": "37b3809e", "metadata": {}, "source": ["Categorizes empty cells and converts them into numerical variables by using mean encoding."]}, {"cell_type": "markdown", "id": "cf6ba519", "metadata": {}, "source": ["## MEAN ENCODING"]}, {"cell_type": "code", "execution_count": 1, "id": "2906c2d2", "metadata": {}, "outputs": [], "source": ["class KFoldTargetEncoderTrain(base.BaseEstimator,\n                               base.TransformerMixin):\n    def __init__(self,colnames,targetName,\n                  n_fold=5, verbosity=True,\n                  discardOriginal_col=False):\n        self.colnames = colnames\n        self.targetName = targetName\n        self.n_fold = n_fold\n        self.verbosity = verbosity\n        self.discardOriginal_col = discardOriginal_col\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self,X):\n        assert(type(self.targetName) == str)\n        assert(type(self.colnames) == str)\n        assert(self.colnames in X.columns)\n        assert(self.targetName in X.columns)\n        \n        mean_of_target = X[self.targetName].mean()\n        kf = KFold(n_splits = self.n_fold,\n                   shuffle = False, random_state=2020)\n        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n        X[col_mean_name] = np.nan\n        for tr_ind, val_ind in kf.split(X):\n            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n            X.loc[X.index[val_ind], col_mean_name] = \\\n            X_val[self.colnames].map(X_tr.groupby(self.colnames)\n                                     [self.targetName].mean())\n            X[col_mean_name].fillna(mean_of_target, inplace = True)\n        if self.verbosity:\n            encoded_feature = X[col_mean_name].values\n            print('Correlation between the new feature, {} and, {} is {}.'\\\n                  .format(col_mean_name,self.targetName,\n                          np.corrcoef(X[self.targetName].values,\n                                      encoded_feature)[0][1]))\n        if self.discardOriginal_col:\n            X = X.drop(self.targetName, axis=1)\n        return X"]}, {"cell_type": "code", "execution_count": 1, "id": "2c232761", "metadata": {}, "outputs": [], "source": ["def StringConverterTrain(df,target_name,variable_list):\n    for col in variable_list:\n      targetc = KFoldTargetEncoderTrain(col,target_name,n_fold=4)\n      new_train = targetc.fit_transform(df)\n    return new_train"]}, {"cell_type": "code", "execution_count": 1, "id": "bcbfd08c", "metadata": {}, "outputs": [], "source": ["nominal_variable = list(data_info[data_info[\"Variable_Type\"]==\"Nominal\"].index)\nnominal_lst = [item for item in Moderate_MR_variables_list+High_MR_variables_list+Extreme_MR_variables_list if item in nominal_variable]\nnominal_lst"]}, {"cell_type": "code", "execution_count": 1, "id": "d50a2531", "metadata": {}, "outputs": [], "source": ["df_trial = pd.concat([X_train,Y_train],axis=1).copy()\ndf_output_train = StringConverterTrain(df=df_trial,target_name=\"CLASS\",variable_list=nominal_lst)"]}, {"cell_type": "code", "execution_count": 1, "id": "da842472", "metadata": {}, "outputs": [], "source": ["for item in nominal_lst:\n  print(df_output_train.loc[:,[item+\"_Kfold_Target_Enc\"]].isnull().sum())"]}, {"cell_type": "code", "execution_count": 1, "id": "237ee78d", "metadata": {}, "outputs": [], "source": ["for item in nominal_lst:\n  X_train[item] = df_output_train[item+\"_Kfold_Target_Enc\"]"]}, {"cell_type": "markdown", "id": "e2d2513b", "metadata": {}, "source": ["# Mean Encoding for nominal variables(non missing value)"]}, {"cell_type": "code", "execution_count": 1, "id": "4139db18", "metadata": {}, "outputs": [], "source": ["nominal_encoding_variable_lst =[\"Consequence\",\"REF\",\"ALT\",\"CLNDISDB\",\"CLNDN\",\"Allele\",\"Feature\",\"SYMBOL\"]\n\ndf_encoding = pd.concat([X_train,Y_train],axis=1).copy()\ndf_encoding_train = StringConverterTrain(df=df_encoding,target_name=\"CLASS\",variable_list=nominal_encoding_variable_lst)"]}, {"cell_type": "code", "execution_count": 1, "id": "df77d7f6", "metadata": {}, "outputs": [], "source": ["for item in nominal_encoding_variable_lst:\n  print(df_encoding_train.loc[:,[item+\"_Kfold_Target_Enc\"]].isnull().sum())"]}, {"cell_type": "code", "execution_count": 1, "id": "fef207b9", "metadata": {}, "outputs": [], "source": ["for item in nominal_encoding_variable_lst:\n  X_train[item] = df_encoding_train[item+\"_Kfold_Target_Enc\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "bf7c1ca0", "metadata": {}, "outputs": [], "source": ["MissingUniqueStatistics(X_train)"]}, {"cell_type": "markdown", "id": "ea7eae71", "metadata": {}, "source": ["# **String Converter for Test Dataset**"]}, {"cell_type": "code", "execution_count": 1, "id": "e7285188", "metadata": {}, "outputs": [], "source": ["df_output_test = X_test.copy()\nmean_of_target = df_output_train['CLASS'].copy().mean()\ntarget_mean_list = nominal_lst                                                 \nfor col in target_mean_list:\n    df_output_test[col] = df_output_test[col].map(df_output_train.groupby(col)[col+'_Kfold_Target_Enc'].mean())\n    df_output_test[col].fillna(mean_of_target, inplace = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "2a0dd8ee", "metadata": {}, "outputs": [], "source": ["for item in nominal_lst:\n  print(df_output_test.loc[:,[item]].isnull().sum())"]}, {"cell_type": "code", "execution_count": 1, "id": "c9a1a952", "metadata": {}, "outputs": [], "source": ["X_test[nominal_lst] = df_output_test[nominal_lst]"]}, {"cell_type": "code", "execution_count": 1, "id": "3eb80951", "metadata": {}, "outputs": [], "source": ["X_test_encoder = X_test.copy()\nmean_of_target = df_encoding_train['CLASS'].copy().mean()\ntarget_mean_list = nominal_encoding_variable_lst                                                 \nfor col in target_mean_list:\n    X_test_encoder[col+'_Kfold_Target_Enc'] = X_test_encoder[col].map(df_encoding_train.groupby(col)[col+'_Kfold_Target_Enc'].mean())\n    X_test_encoder[col+'_Kfold_Target_Enc'].fillna(mean_of_target, inplace = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "34a184ef", "metadata": {}, "outputs": [], "source": ["for item in nominal_encoding_variable_lst:\n  X_test[item] = X_test_encoder[item+\"_Kfold_Target_Enc\"]\n  \nMissingUniqueStatistics(X_test[nominal_encoding_variable_lst])"]}, {"cell_type": "markdown", "id": "2f9500b4", "metadata": {}, "source": ["Our column \"CLNHGVS\" in the table has 65188 values \u200b\u200band all values \u200b\u200bare unique. Therefore, we drop this column as it does not carry any information."]}, {"cell_type": "code", "execution_count": 1, "id": "0af9a389", "metadata": {}, "outputs": [], "source": ["X_train.drop(\"CLNHGVS\", axis = 1, inplace = True)\nX_test.drop(\"CLNHGVS\", axis = 1, inplace = True)"]}, {"cell_type": "markdown", "id": "8439cd34", "metadata": {}, "source": ["# Modal Based Imputation"]}, {"cell_type": "code", "execution_count": 1, "id": "60025997", "metadata": {}, "outputs": [], "source": ["def MBI(df,columns,train_or_test,lst_numerical):\n\n  data_binary_encoded=df.copy()\n  le=LabelEncoder()\n\n  for col in columns:\n    \n    if(train_or_test == \"test\"):\n\n      le.fit(X_train[col].copy().astype(str))\n      data_binary_encoded[col]=le.transform(df[col].copy().astype(str))\n\n    else:\n\n      data_binary_encoded[col] = le.fit_transform(df[col].copy().astype(str))\n\n  data_scaled=data_binary_encoded.copy()\n\n  for col in numerical_columns:\n\n    scaler = StandardScaler()\n\n    if(train_or_test == \"test\"):\n\n      scaler.fit(np.array(X_train.loc[:,col]).reshape(-1,1))\n      data_scaled.loc[:,col] = scaler.transform(np.array(data_scaled.loc[:,col]).reshape(-1,1))\n\n    else:\n      data_scaled.loc[:,col] = scaler.fit_transform(np.array(data_scaled.loc[:,col]).reshape(-1,1))\n\n  for col in lst_numerical:\n\n    target_dropped_fullcases = data_scaled.drop(col,axis=1).loc[:,list(set(Zero_MR_variables_list+Low_MR_variables_list)-\n                                                                                  set([\"CLASS\",\"KEY\",\"CLNHGVS\"]))].copy()\n    \n    target = data_scaled.loc[:,col]\n    null_mask = target.isna()\n    print(col)\n\n    if(col in numerical_columns):\n      \n      mlp = MLPRegressor(hidden_layer_sizes=(100,10,),\n                        activation='tanh',\n                        solver='adam',\n                        learning_rate='adaptive',\n                        max_iter=1000,\n                        learning_rate_init=0.01,\n                        alpha=0.01,\n                        early_stopping = False)\n    else:\n      mlp = MLPClassifier(hidden_layer_sizes=(100,10,),\n                        activation='tanh',\n                        solver='adam',\n                        learning_rate='adaptive',\n                        max_iter=1000,\n                        learning_rate_init=0.01,\n                        alpha=0.01,\n                        early_stopping = False)\n    \n    mlp.fit(target_dropped_fullcases[~null_mask],target[~null_mask])\n    data_scaled.loc[null_mask,col] = mlp.predict(target_dropped_fullcases[null_mask])\n\n  print(data_scaled.loc[:,lst_numerical].isnull().sum());\n  return data_scaled"]}, {"cell_type": "code", "execution_count": 1, "id": "80a54030", "metadata": {}, "outputs": [], "source": ["lst_numerical = [item for item in Moderate_MR_variables_list if item in numerical_columns]\nlst_numerical.append(\"SIFT\")\nlst_numerical.append(\"PolyPhen\")\nlst_numerical"]}, {"cell_type": "code", "execution_count": 1, "id": "580d04fa", "metadata": {}, "outputs": [], "source": ["encoding_col_list =[\"CHROM\",\"CLNVC\",\"Feature_type\",\"BIOTYPE\",\"IMPACT\"]\n"]}, {"cell_type": "markdown", "id": "e3a1d55b", "metadata": {}, "source": ["# **Scaling**"]}, {"cell_type": "code", "execution_count": 1, "id": "1c546133", "metadata": {}, "outputs": [], "source": ["X_train_scaled = MBI(X_train,encoding_col_list,\"train\",lst_numerical)"]}, {"cell_type": "code", "execution_count": 1, "id": "fecdd077", "metadata": {}, "outputs": [], "source": ["X_train_scaled"]}, {"cell_type": "code", "execution_count": 1, "id": "c902356a", "metadata": {}, "outputs": [], "source": ["X_test_scaled = MBI(X_test,encoding_col_list,\"test\",lst_numerical)"]}, {"cell_type": "code", "execution_count": 1, "id": "3f430eb3", "metadata": {}, "outputs": [], "source": ["def Label_Encoder(df,columns,train_or_test):\n  le = LabelEncoder()\n  for col in columns:\n    if(train_or_test == \"test\"):\n\n      le.fit(X_train_scaled[col].copy().astype(str))\n      df[col] = le.transform(df[col].copy().astype(str))\n\n    else:\n      df[col] = le.fit_transform(df[col].copy().astype(str))\n\n  return df"]}, {"cell_type": "code", "execution_count": 1, "id": "ed83ed0a", "metadata": {}, "outputs": [], "source": ["X_test_scaled = Label_Encoder(X_test_scaled,[\"SIFT\",\"PolyPhen\"],\"test\")"]}, {"cell_type": "code", "execution_count": 1, "id": "62f72ee9", "metadata": {}, "outputs": [], "source": ["X_train_scaled = Label_Encoder(X_train_scaled,[\"SIFT\",\"PolyPhen\"],\"train\")"]}, {"cell_type": "markdown", "id": "e8f5db2a", "metadata": {}, "source": ["# Feature Importance"]}, {"cell_type": "code", "execution_count": 1, "id": "8329e238", "metadata": {}, "outputs": [], "source": ["rnd_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\nrnd_clf.fit(X_train_scaled, Y_train)\n\nfeatures = X_train_scaled.columns\nimportances = rnd_clf.feature_importances_\nindices = np.argsort(importances)"]}, {"cell_type": "code", "execution_count": 1, "id": "f6408cbd", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(20,10))\nfeat_importances = pd.Series(importances, index=features)\nfeat_importances.nlargest(len(indices)).plot(kind='bar',color = '#79CCB3');"]}, {"cell_type": "markdown", "id": "06811e19", "metadata": {}, "source": ["# MODELLING"]}, {"cell_type": "code", "execution_count": 1, "id": "85acb765", "metadata": {}, "outputs": [], "source": ["# Creating an empty Dataframe with Scores\ndf_accur_roc_score = pd.DataFrame(columns=['Roc_Auc_Score'])"]}, {"cell_type": "markdown", "id": "d6dd0d5d", "metadata": {}, "source": ["## **Logistic Regression**"]}, {"cell_type": "code", "execution_count": 1, "id": "68e8210a", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(random_state=0)\nclf.fit(X_train_scaled, Y_train)\n\ny_preds = clf.predict_proba(X_test_scaled)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score.loc['Logistic_regression'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='Logistic R. AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "fe10bc0b", "metadata": {}, "source": ["## **XGBoost Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "3e0dd2c2", "metadata": {}, "outputs": [], "source": ["import xgboost as xgb\n\nxgb_model = xgb.XGBClassifier(n_estimators=150,random_state=0,learning_rate=0.25,eta=0.4,booster=\"gbtree\",base_score=0.8,colsample_bylevel=0.9009229642844634,gamma=0.49967765132613584,\n                        max_depth=6,min_child_weight=7,reg_lambda=0.27611902459972926,subsample=0.9300916052594785)\n\nxgb_model.fit(X_train_scaled, Y_train)\n\ny_preds = xgb_model.predict_proba(X_test_scaled)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score.loc['XGBoost_Classifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='XGBoost Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()\n"]}, {"cell_type": "markdown", "id": "2f1dad4a", "metadata": {}, "source": ["## **KNeighbors Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "6b215b3c", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train_scaled,Y_train)\ny_preds = knn.predict_proba(X_test_scaled)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score.loc['KNeighborsClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='KNeighbors Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "0b2c4a7a", "metadata": {}, "source": ["## **Decision Tree Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "25129079", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n\nreg_dtr = DecisionTreeClassifier(random_state=0)\nreg_dtr.fit(X_train_scaled,Y_train)\n\ny_preds = reg_dtr.predict_proba(X_test_scaled)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score.loc['DecisionTreeClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='DecisionTree Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "399bb3d1", "metadata": {}, "source": ["##  **LightGBM Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "b16e1f34", "metadata": {}, "outputs": [], "source": ["from lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(\n        max_depth=6,\n        n_estimators=100,random_state=0,learning_rate=0.1,eta=0.4,base_score=0.8,colsample_bylevel=0.9009229642844634,gamma=0.49967765132613584,\n                        min_child_weight=9,reg_lambda=0.27611902459972926,subsample=0.9300916052594785,min_samples_split=2,min_samples_leaf=0.1)\n\nlgbm.fit(X_train_scaled, Y_train)\n\ny_preds = lgbm.predict_proba(X_test_scaled)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score.loc['LGBMClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='LGBM Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "d851c619", "metadata": {}, "source": ["## Gradient Boosting Classifier"]}, {"cell_type": "code", "execution_count": 1, "id": "98038532", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingClassifier\n\ngradient_boosting_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n                                                   max_depth=7, random_state=0).fit(X_train_scaled, Y_train)\n\ny_preds = gradient_boosting_clf.predict_proba(X_test_scaled)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score.loc['GradientBoostingClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='GradientBoosting Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "57dff129", "metadata": {}, "source": ["## **Hist Gradient Boosting Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "7291befb", "metadata": {}, "outputs": [], "source": ["from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n\nhist_gradient_boosting_clf = HistGradientBoostingClassifier(learning_rate=0.25,\n                                                   max_depth=4, random_state=0).fit(X_train_scaled, Y_train)\n\ny_preds = hist_gradient_boosting_clf.predict_proba(X_test_scaled)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score.loc['HistGradientBoostingClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.plot(fpr, tpr, label='HistGradientBoosting Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\nplt.title('ROC Curve')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "adbd334b", "metadata": {}, "outputs": [], "source": ["df_accur_roc_score\n"]}, {"cell_type": "markdown", "id": "7cc2856b", "metadata": {}, "source": ["# **Visualization Model Outputs**"]}, {"cell_type": "code", "execution_count": 1, "id": "740241c4", "metadata": {}, "outputs": [], "source": ["df_accur_roc_score.sort_values(by=['Roc_Auc_Score'],ascending=False).plot(kind='bar', y='Roc_Auc_Score',figsize=(20,8),color='#79ccb3', rot=0,title=\"Model outputs by roc score before feature importance\");"]}, {"cell_type": "markdown", "id": "696bf968", "metadata": {}, "source": ["# **Changing Dataset using Feature Importance** "]}, {"cell_type": "code", "execution_count": 1, "id": "60c91b08", "metadata": {}, "outputs": [], "source": ["lst_importance_drop = []\n\nfor item in range(0,feat_importances.shape[0]):\n  \n  if(feat_importances[item] < 0.004):\n    lst_importance_drop.append(features[item])\n\nX_train_importance = X_train_scaled.drop(lst_importance_drop,axis=1)\nX_test_importance = X_test_scaled.drop(lst_importance_drop,axis=1)\n\nlst_importance_drop"]}, {"cell_type": "code", "execution_count": 1, "id": "8b1864f1", "metadata": {}, "outputs": [], "source": ["# Creating an empty Dataframe with Scores\ndf_accur_roc_score_importance = pd.DataFrame(columns=['Roc_Auc_Score'])"]}, {"cell_type": "markdown", "id": "fb30993a", "metadata": {}, "source": ["### **Logistic Regression**"]}, {"cell_type": "code", "execution_count": 1, "id": "569efd30", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(random_state=0)\nclf = logreg.fit(X_train_importance, Y_train)\n\ny_preds = clf.predict_proba(X_test_importance)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score_importance.loc['Logistic_regression'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='Logistic Regression AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "6f682cc3", "metadata": {}, "source": ["### **XGBoost Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "40b2eef7", "metadata": {}, "outputs": [], "source": ["import xgboost as xgb\n\nxgb_model = xgb.XGBClassifier(n_estimators=150,random_state=0,learning_rate=0.1,eta=0.4,booster=\"gbtree\",base_score=0.8,colsample_bylevel=0.9009229642844634,gamma=0.49967765132613584,\n                        max_depth=6,min_child_weight=7,reg_lambda=0.27611902459972926,subsample=0.9300916052594785)\n\nxgb_model.fit(X_train_importance, Y_train)\ny_preds = xgb_model.predict_proba(X_test_importance)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score_importance.loc['XGBoost_Classifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='XGBoost Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "2bd52bb7", "metadata": {}, "source": ["### **KNeighbors Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "d97d680f", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train_importance,Y_train)\ny_preds = knn.predict_proba(X_test_importance)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score_importance.loc['KNeighborsClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='KNeighbors Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "7b40cb61", "metadata": {}, "source": ["### **Decision Tree Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "85258207", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n\nreg_dtr = DecisionTreeClassifier(random_state=0)\nreg_dtr.fit(X_train_importance,Y_train)\n\ny_preds = reg_dtr.predict_proba(X_test_importance)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score_importance.loc['DecisionTreeClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='DecisionTree Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "785f0663", "metadata": {}, "source": ["### **LightGBM Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "febe2dc4", "metadata": {}, "outputs": [], "source": ["from lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(\n        max_depth=6,\n        n_estimators=100,random_state=0,learning_rate=0.25,eta=0.4,base_score=0.8,colsample_bylevel=0.9009229642844634,gamma=0.49967765132613584,\n                        min_child_weight=7,reg_lambda=0.27611902459972926,subsample=0.9300916052594785,min_sample_split=2)\n\nlgbm.fit(X_train_importance, Y_train)\n\ny_preds = lgbm.predict_proba(X_test_importance)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score_importance.loc['LGBMClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='LGBM Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "51a34938", "metadata": {}, "source": ["### **Gradient Boosting Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "2a185c69", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingClassifier\n\ngradient_boosting_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n                                                   max_depth=5, random_state=0).fit(X_train_importance, Y_train)\n\n\ny_preds = gradient_boosting_clf.predict_proba(X_test_importance)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score_importance.loc['GradientBoostingClassifier'] = [auc_score]\n\nplt.subplots(figsize=(8, 6))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, label='GradientBoosting Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "markdown", "id": "d4168526", "metadata": {}, "source": ["### **Hist Gradient Boosting Classifier**"]}, {"cell_type": "code", "execution_count": 1, "id": "68448734", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import HistGradientBoostingClassifier\n\nhist_gradient_boosting_clf = HistGradientBoostingClassifier(learning_rate=0.1,\n                                                   max_depth=7, random_state=0).fit(X_train_importance, Y_train)\n\ny_preds = hist_gradient_boosting_clf.predict_proba(X_test_importance)\npreds = y_preds[:,1]\n\nfpr, tpr, _ = metrics.roc_curve(Y_test, preds)\n\nauc_score = metrics.auc(fpr, tpr)\ndf_accur_roc_score_importance.loc['HistGradientBoostingClassifier'] = [auc_score]\nplt.subplots(figsize=(8, 6))\nplt.plot(fpr, tpr, label='HistGradientBoosting Classifier AUC = {:.2f}'.format(auc_score))\nplt.plot([0,1],[0,1],'r--')\nplt.title('ROC Curve')\n\n\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nplt.legend(loc='lower right')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "2af2eb78", "metadata": {}, "outputs": [], "source": ["df_accur_roc_score_importance.sort_values(by=['Roc_Auc_Score'],ascending=False).plot(kind='bar', y='Roc_Auc_Score',figsize=(20,8),color='#79ccb3', rot=0,title=\"Model outputs by roc score before feature importance\");"]}, {"cell_type": "markdown", "id": "1452577c", "metadata": {}, "source": ["### **Visualization for After Feature Importance and Before Feature Importance**"]}, {"cell_type": "code", "execution_count": 1, "id": "6558fa0d", "metadata": {}, "outputs": [], "source": ["f,ax = plt.subplots(figsize = (9,10))\nsns.barplot(x=df_accur_roc_score_importance.Roc_Auc_Score,y=df_accur_roc_score_importance.index,color='red',alpha = 0.5,label='After Feature Importance' )\nsns.barplot(x=df_accur_roc_score.Roc_Auc_Score,y=df_accur_roc_score.index,color='blue',alpha = 0.7,label='Before Feature Importance')\n\nax.legend(frameon = True)\nax.set(xlabel='Scores', ylabel='Models',title = \"Auc Score \")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "7850fb89", "metadata": {}, "outputs": [], "source": ["import plotly.graph_objects as go\n\nfig = go.Figure(data=[\n    go.Bar(name='Before Feature Importance', y=df_accur_roc_score.Roc_Auc_Score, x=df_accur_roc_score.index,text=round(df_accur_roc_score.Roc_Auc_Score,3),textposition='auto'),\n    go.Bar(name='After Feature Importance', y=df_accur_roc_score_importance.Roc_Auc_Score, x=df_accur_roc_score_importance.index,text=round(df_accur_roc_score_importance.Roc_Auc_Score,3),textposition='auto',)\n    \n])\nfig.update_layout(barmode='group')\nfig.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}