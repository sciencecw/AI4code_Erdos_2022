{"cells": [{"cell_type": "code", "execution_count": 1, "id": "6bbcf268", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "2ed8a310", "metadata": {}, "source": ["![](https://www.debt.org/wp-content/uploads/2012/12/Credit-Card.gif)"]}, {"cell_type": "markdown", "id": "de7a358a", "metadata": {}, "source": ["# Import the libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "97d940ae", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"]}, {"cell_type": "markdown", "id": "426889e7", "metadata": {}, "source": ["# Load the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "c37be4e4", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv(\"../input/creditcardfraud/creditcard.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "6225bbda", "metadata": {}, "outputs": [], "source": ["data.head() #Display the first 5 rows"]}, {"cell_type": "code", "execution_count": 1, "id": "a8fd2df7", "metadata": {}, "outputs": [], "source": ["data['Class'].value_counts() # count unique values in class clumns"]}, {"cell_type": "code", "execution_count": 1, "id": "1ee3c7b2", "metadata": {}, "outputs": [], "source": ["data.columns #All columns of dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "efae4496", "metadata": {}, "outputs": [], "source": ["data.info() #Information about the dataset like number of null values and data types"]}, {"cell_type": "code", "execution_count": 1, "id": "a4724bd7", "metadata": {}, "outputs": [], "source": ["data.isnull().sum() # Function return the total number of null values for each columns"]}, {"cell_type": "code", "execution_count": 1, "id": "b43bb2b0", "metadata": {}, "outputs": [], "source": ["data[data.duplicated()] # Display all the duplicates rows"]}, {"cell_type": "code", "execution_count": 1, "id": "7061496f", "metadata": {}, "outputs": [], "source": ["data.duplicated().sum() #Returns total number of duplicates rows of our dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "24b8226c", "metadata": {}, "outputs": [], "source": ["data = data.drop_duplicates(keep='first') #Keep the first rows and drop the duplicates rows"]}, {"cell_type": "code", "execution_count": 1, "id": "21dea6f8", "metadata": {}, "outputs": [], "source": ["data.duplicated().sum()#Check for is still duplicates values are there or not"]}, {"cell_type": "code", "execution_count": 1, "id": "7c93e187", "metadata": {}, "outputs": [], "source": ["data = data.drop(\"Time\",axis=1) #Drop the time columns, for this model time columns are not importance"]}, {"cell_type": "code", "execution_count": 1, "id": "603d31a1", "metadata": {}, "outputs": [], "source": ["data.describe() #Function display the count,mean,std,min,max and quartiles values"]}, {"cell_type": "markdown", "id": "952ea0c5", "metadata": {}, "source": ["# Feature selection"]}, {"cell_type": "code", "execution_count": 1, "id": "3ad1811d", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(29,13))\ncor = data.drop(\"Class\",axis=1).corr()\nsns.heatmap(cor,annot = True)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "30653f64", "metadata": {}, "outputs": [], "source": ["def correlation(dataset,threshold):\n    col_corr = set()\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i,j])>threshold:\n                colname = corr_matrix.columns[i]\n                col_corr.add(colname)\n    return col_corr"]}, {"cell_type": "code", "execution_count": 1, "id": "ad8a7c41", "metadata": {}, "outputs": [], "source": ["corr_fea = correlation(data.drop(\"Class\",axis=1),0.8)\nprint(corr_fea)"]}, {"cell_type": "markdown", "id": "6893803b", "metadata": {}, "source": ["**By this correlation we give threshold value 0.8 and we trying to find is any columns are correlated with each other,if correlated then we drop any of this**"]}, {"cell_type": "markdown", "id": "0459c29d", "metadata": {}, "source": ["# import the dataset, here x is independent and y represented as dependent variable"]}, {"cell_type": "code", "execution_count": 1, "id": "694a5162", "metadata": {}, "outputs": [], "source": ["x = data.drop(\"Class\",axis=1)\ny = data['Class']"]}, {"cell_type": "markdown", "id": "8f0807e2", "metadata": {}, "source": ["# Splitting the dataset into the Training set and Test set"]}, {"cell_type": "code", "execution_count": 1, "id": "07e2f0cf", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"]}, {"cell_type": "code", "execution_count": 1, "id": "52ea30f6", "metadata": {}, "outputs": [], "source": ["print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)"]}, {"cell_type": "markdown", "id": "7e3b426e", "metadata": {}, "source": ["# Logistic Regression"]}, {"cell_type": "markdown", "id": "2b02c4b7", "metadata": {}, "source": ["**Training the Logistic Regression model on the Training set**"]}, {"cell_type": "code", "execution_count": 1, "id": "dbbb5f79", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression"]}, {"cell_type": "code", "execution_count": 1, "id": "3a260bc2", "metadata": {}, "outputs": [], "source": ["classifier = LogisticRegression(solver='liblinear',random_state = 0)"]}, {"cell_type": "code", "execution_count": 1, "id": "1bda98ca", "metadata": {}, "outputs": [], "source": ["classifier.fit(x_train,y_train)"]}, {"cell_type": "markdown", "id": "c32edbe4", "metadata": {}, "source": ["# Predicting the Test set results"]}, {"cell_type": "code", "execution_count": 1, "id": "48b45ef7", "metadata": {}, "outputs": [], "source": ["log_y_pred = classifier.predict(x_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "fb74d2a9", "metadata": {}, "outputs": [], "source": ["print(log_y_pred)"]}, {"cell_type": "markdown", "id": "7c993a01", "metadata": {}, "source": ["# Making the Confusion Matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "eeaf6e7c", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, log_y_pred)\nprint(cm)"]}, {"cell_type": "markdown", "id": "02cc3819", "metadata": {}, "source": ["# Computing the accuracy with k-Fold Cross Validation"]}, {"cell_type": "code", "execution_count": 1, "id": "005fda69", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))"]}, {"cell_type": "code", "execution_count": 1, "id": "3c977a9d", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\nlog_acc_score = accuracy_score(y_test, log_y_pred)\nprint(log_acc_score)"]}, {"cell_type": "markdown", "id": "fdb755ea", "metadata": {}, "source": ["# Training the K-NN model on the Training set"]}, {"cell_type": "code", "execution_count": 1, "id": "4be04082", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "c1375bf7", "metadata": {}, "outputs": [], "source": ["knn_y_pred = classifier.predict(x_test)"]}, {"cell_type": "markdown", "id": "36934294", "metadata": {}, "source": ["# Making the Confusion Matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "6827512a", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, knn_y_pred)\nprint(cm)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a37cb515", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(6,6))\nplt.title('Confusion matrix on test data')\nsns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Greens, cbar=False)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "8debaf50", "metadata": {}, "outputs": [], "source": ["acc_score = accuracy_score(y_test, knn_y_pred)\nprint(f\"Accuracy score by KNN model is: {acc_score}\")"]}, {"cell_type": "markdown", "id": "b42df7ff", "metadata": {}, "source": ["# Training the Kernel SVM model on the Training set"]}, {"cell_type": "code", "execution_count": 1, "id": "61d67d49", "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(x_train, y_train)"]}, {"cell_type": "markdown", "id": "86437db4", "metadata": {}, "source": ["# Predicting the Test set results"]}, {"cell_type": "code", "execution_count": 1, "id": "71537f79", "metadata": {}, "outputs": [], "source": ["svm_y_pred = classifier.predict(x_test)"]}, {"cell_type": "markdown", "id": "3b131de9", "metadata": {}, "source": ["# confusion matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "d5f62600", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, svm_y_pred)\nprint(cm)"]}, {"cell_type": "code", "execution_count": 1, "id": "01ef34c1", "metadata": {}, "outputs": [], "source": ["acc_score_svm = accuracy_score(y_test, svm_y_pred)\nprint(f\"Accuracy score by KNN model is: {acc_score_svm}\")"]}, {"cell_type": "markdown", "id": "a6cb3615", "metadata": {}, "source": ["# Training the Naive Bayes model on the Training set"]}, {"cell_type": "code", "execution_count": 1, "id": "8f63e8be", "metadata": {}, "outputs": [], "source": ["from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)"]}, {"cell_type": "markdown", "id": "5444b154", "metadata": {}, "source": ["# Predicting the Test set results"]}, {"cell_type": "code", "execution_count": 1, "id": "dd017bf3", "metadata": {}, "outputs": [], "source": ["naive_y_pred = classifier.predict(x_test)\nprint(naive_y_pred)"]}, {"cell_type": "markdown", "id": "357ba8ad", "metadata": {}, "source": ["# Confusion matrix and accuracy"]}, {"cell_type": "code", "execution_count": 1, "id": "02bd9fc4", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, naive_y_pred)\nprint(cm)"]}, {"cell_type": "code", "execution_count": 1, "id": "574464ec", "metadata": {}, "outputs": [], "source": ["acc_score_naive = accuracy_score(y_test, naive_y_pred)\nprint(f\"Accuracy score by KNN model is: {acc_score_naive}\")"]}, {"cell_type": "markdown", "id": "69e72976", "metadata": {}, "source": ["# Training the Decision Tree Regression model on training dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "6cacd335", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "4d9c64b4", "metadata": {}, "outputs": [], "source": ["dtr_y_pred = regressor.predict(x_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "94da4edc", "metadata": {}, "outputs": [], "source": ["dtr_cm = confusion_matrix(y_test, naive_y_pred)\nprint(dtr_cm)"]}, {"cell_type": "code", "execution_count": 1, "id": "cfd7ea02", "metadata": {}, "outputs": [], "source": ["dtr_acc =accuracy_score(y_test,dtr_y_pred)\nprint(f\"Accuracy score by DTR is: {dtr_acc}\")"]}, {"cell_type": "markdown", "id": "422c39a1", "metadata": {}, "source": ["# Visualization of all model that are applied in this dataset, by bar chart"]}, {"cell_type": "code", "execution_count": 1, "id": "2f995417", "metadata": {}, "outputs": [], "source": ["mylist=[]\nmylist2=[]\nmylist.append(log_acc_score)\nmylist2.append(\"Logistic Regression\")\nmylist.append(acc_score)\nmylist2.append(\"KNN\")\nmylist.append(acc_score_svm)\nmylist2.append(\"SVM\")\nmylist.append(acc_score_naive)\nmylist2.append(\"Naive Bayes\")\nmylist.append(dtr_acc)\nmylist2.append(\"DTR\")"]}, {"cell_type": "code", "execution_count": 1, "id": "e19138c1", "metadata": {}, "outputs": [], "source": ["plt.rcParams['figure.figsize']=8,6\nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mylist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Regressor Models\", fontsize = 20 )\nplt.ylabel(\"Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Regreesor Models\", fontsize = 20)\nplt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()"]}, {"cell_type": "markdown", "id": "03140892", "metadata": {}, "source": ["![](https://c.tenor.com/eds_JFXceWoAAAAC/aww-sweet.gif)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}