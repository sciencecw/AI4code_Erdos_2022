{"cells": [{"cell_type": "markdown", "id": "1b822300", "metadata": {}, "source": ["**Hi. I will mention some machine learning algorithms (SVM,Naive Bayes,Decision Tree,Random Forest) in kernel. I hope you like.**"]}, {"cell_type": "code", "execution_count": 1, "id": "3615614e", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "f98ee01c", "metadata": {}, "outputs": [], "source": ["#import data\ndata = pd.read_csv(\"../input/data.csv\")"]}, {"cell_type": "markdown", "id": "7819a7c3", "metadata": {}, "source": ["We always start with analysis to work."]}, {"cell_type": "code", "execution_count": 1, "id": "0b059e7a", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "17df92ed", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "1dd2cd9b", "metadata": {}, "outputs": [], "source": ["data.drop([\"id\",\"Unnamed: 32\"],axis = 1,inplace = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "2c4cd37c", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "0a944f5f", "metadata": {}, "outputs": [], "source": ["# binary classification\ndata.diagnosis.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "8341fc2d", "metadata": {}, "outputs": [], "source": ["# list comprehention\ndata.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]"]}, {"cell_type": "code", "execution_count": 1, "id": "b9b3e810", "metadata": {}, "outputs": [], "source": ["data.diagnosis.unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "4fbfb249", "metadata": {}, "outputs": [], "source": ["y = data.diagnosis.values\nx_data = data.drop([\"diagnosis\"],axis = 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "dddfbb5f", "metadata": {}, "outputs": [], "source": ["# normalization\nx = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data))"]}, {"cell_type": "code", "execution_count": 1, "id": "22b5f057", "metadata": {}, "outputs": [], "source": ["# train test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3 , random_state = 1)"]}, {"cell_type": "markdown", "id": "f15d1b75", "metadata": {}, "source": ["**Support Vector Machine**\n\nThe learning of the hyperplane in linear SVM is done by transforming the problem using some linear algebra, which is out of the scope of this introduction to SVM.\n\n!![image.png](attachment:image.png)[](http://)"]}, {"cell_type": "code", "execution_count": 1, "id": "54047ec3", "metadata": {}, "outputs": [], "source": ["# svm\nfrom sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "bb04ff05", "metadata": {}, "outputs": [], "source": ["# accuracy score\nprint(\"accuracy of svm algo:\",svm.score(x_test,y_test))"]}, {"cell_type": "markdown", "id": "c35790cd", "metadata": {}, "source": ["**Naive Bayes**\n\nNaive Bayes methods are a set of supervised learning algorithms based on applying Bayes\u2019 theorem with the \u201cnaive\u201d assumption of independence between every pair of features.\n\n!![image.png](attachment:image.png)[](http://)"]}, {"cell_type": "code", "execution_count": 1, "id": "07f6478a", "metadata": {}, "outputs": [], "source": ["# naive bayes\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "a2e74e68", "metadata": {}, "outputs": [], "source": ["# accuracy score\nprint(\"accuracy of naive bayes algo:\",nb.score(x_test,y_test))"]}, {"cell_type": "markdown", "id": "3d50d9fb", "metadata": {}, "source": ["**Decision Tree**\n\nDecision Trees are a type of Supervised Machine Learning, where data is constantly divided according to a certain parameter. The tree can be explained by two entities, decision nodes and leaves. Leaves are decisions or final results. And the decision nodes show where the data is divided.\n\n!![image.png](attachment:image.png)[](http://)"]}, {"cell_type": "code", "execution_count": 1, "id": "fbba37fd", "metadata": {}, "outputs": [], "source": ["# decision tree\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "d7fb0424", "metadata": {}, "outputs": [], "source": ["# accuracy score\nprint(\"accuracy of decision tree algo:\",dt.score(x_test,y_test))"]}, {"cell_type": "markdown", "id": "86f63878", "metadata": {}, "source": ["**Random Forest**\n\nRandom forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.\n\n!![image.png](attachment:image.png)[](http://)"]}, {"cell_type": "code", "execution_count": 1, "id": "2411f089", "metadata": {}, "outputs": [], "source": ["# random forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 100,random_state = 1)\nrf.fit(x_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "01a3000e", "metadata": {}, "outputs": [], "source": ["# accuracy score\nprint(\"accuracy of random forest algo:\",rf.score(x_test,y_test))"]}, {"cell_type": "markdown", "id": "fcf9c1c5", "metadata": {}, "source": ["**Confusion Matrix**\n\nA confusion matrix is a table that is often used to describe the performance of a classification model  on a set of test data for which the true values are known.\n!![image.png](attachment:image.png)[](http://)\n\nTP:  true positives\n\nTN:  true negatives\n\nFP : false positives\n\n\nFN : false negatives \n"]}, {"cell_type": "code", "execution_count": 1, "id": "77cd6735", "metadata": {}, "outputs": [], "source": ["# confusion matrix\ny_pred = rf.predict(x_test)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nimport seaborn as sns\nsns.heatmap(cm, annot = True, linewidths = 0.5 , linecolor = \"yellow\", fmt =\".0f\")\nplt.xlabel(\"y_true\")\nplt.ylabel(\"y_pred\")\nplt.show()"]}, {"cell_type": "markdown", "id": "08bc1b35", "metadata": {}, "source": ["We can compare the success rates of different algorithms in this kernel."]}, {"cell_type": "markdown", "id": "6ff776f4", "metadata": {}, "source": ["Thank you for reviewing. Please remember to comment."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}