{"cells": [{"cell_type": "markdown", "id": "16ca2aeb", "metadata": {}, "source": ["## Different Classification with Python\n\n### *By Rohit Kumar Singh and Bavalpreet Singh*"]}, {"cell_type": "markdown", "id": "77578f20", "metadata": {}, "source": ["<a href=\"https://www.bigdatauniversity.com\"><img src=\"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width=\"400\" align=\"center\"></a>\n\n<h1 align=\"center\"><font size=\"5\">Classification with Python</font></h1>"]}, {"cell_type": "markdown", "id": "68d2fe3b", "metadata": {}, "source": ["In this notebook we try to practice all the classification algorithms that we learned in this course.\n\nWe load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n\nLets first load required libraries:"]}, {"cell_type": "code", "execution_count": 1, "id": "26c468ce", "metadata": {}, "outputs": [], "source": ["import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline"]}, {"cell_type": "markdown", "id": "f13d1efe", "metadata": {}, "source": ["<img src=\"https://miro.medium.com/fit/c/1730/520/1*glrB0KgjOcTiKUEx7T8tcA.png\" width=\"600\" align=\"center\">"]}, {"cell_type": "markdown", "id": "79f83e27", "metadata": {}, "source": ["### About dataset"]}, {"cell_type": "markdown", "id": "8307efa6", "metadata": {}, "source": ["This dataset is about past loans. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| Loan_status    | Whether a loan is paid off on in collection                                           |\n| Principal      | Basic principal loan amount at the                                                    |\n| Terms          | Origination terms which can be weekly (7 days), biweekly, and monthly payoff schedule |\n| Effective_date | When the loan got originated and took effects                                         |\n| Due_date       | Since it\u2019s one-time payoff schedule, each loan has one single due date                |\n| Age            | Age of applicant                                                                      |\n| Education      | Education of applicant                                                                |\n| Gender         | The gender of applicant                                                               |"]}, {"cell_type": "markdown", "id": "08f4dc60", "metadata": {}, "source": ["Lets download the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "2fd042e7", "metadata": {}, "outputs": [], "source": ["!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"]}, {"cell_type": "markdown", "id": "ed7a6a3c", "metadata": {}, "source": ["### Load Data From CSV File  "]}, {"cell_type": "code", "execution_count": 1, "id": "63236373", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('loan_train.csv')\ndf.head().style.background_gradient(cmap='RdGy')"]}, {"cell_type": "code", "execution_count": 1, "id": "6d4185b2", "metadata": {}, "outputs": [], "source": ["df.shape"]}, {"cell_type": "markdown", "id": "9b8e84b1", "metadata": {}, "source": ["### Convert to date time object "]}, {"cell_type": "code", "execution_count": 1, "id": "4beedc14", "metadata": {}, "outputs": [], "source": ["df['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf.head().style.background_gradient(cmap='RdGy')"]}, {"cell_type": "markdown", "id": "3c969020", "metadata": {}, "source": ["# Data visualization and pre-processing\n\n"]}, {"cell_type": "markdown", "id": "d21f6b8b", "metadata": {}, "source": ["Let\u2019s see how many of each class is in our data set "]}, {"cell_type": "code", "execution_count": 1, "id": "1c34bb5a", "metadata": {}, "outputs": [], "source": ["df['loan_status'].value_counts()"]}, {"cell_type": "markdown", "id": "672db1e8", "metadata": {}, "source": ["260 people have paid off the loan on time while 86 have gone into collection \n"]}, {"cell_type": "markdown", "id": "34a56651", "metadata": {}, "source": ["Lets plot some columns to underestand data better:"]}, {"cell_type": "code", "execution_count": 1, "id": "9796d1d6", "metadata": {}, "outputs": [], "source": ["import seaborn as sns\n\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "bf602e9d", "metadata": {}, "outputs": [], "source": ["bins = np.linspace(df.age.min(), df.age.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()"]}, {"cell_type": "markdown", "id": "de399d22", "metadata": {}, "source": ["# Pre-processing:  Feature selection/extraction"]}, {"cell_type": "markdown", "id": "d5d6d3fb", "metadata": {}, "source": ["### Lets look at the day of the week people get the loan "]}, {"cell_type": "code", "execution_count": 1, "id": "ea64fe7b", "metadata": {}, "outputs": [], "source": ["df['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n"]}, {"cell_type": "markdown", "id": "f5cabc9b", "metadata": {}, "source": ["We see that people who get the loan at the end of the week dont pay it off, so lets use Feature binarization to set a threshold values less then day 4 "]}, {"cell_type": "code", "execution_count": 1, "id": "ac561755", "metadata": {}, "outputs": [], "source": ["df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head().style.background_gradient(cmap='RdGy')"]}, {"cell_type": "markdown", "id": "1ef20b5e", "metadata": {}, "source": ["## Convert Categorical features to numerical values"]}, {"cell_type": "markdown", "id": "cbf9256a", "metadata": {}, "source": ["Lets look at gender:"]}, {"cell_type": "code", "execution_count": 1, "id": "644d3fbc", "metadata": {}, "outputs": [], "source": ["df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)"]}, {"cell_type": "markdown", "id": "cf6f8fce", "metadata": {}, "source": ["86 % of female pay there loans while only 73 % of males pay there loan\n"]}, {"cell_type": "markdown", "id": "f0787e6a", "metadata": {}, "source": ["Lets convert male to 0 and female to 1:\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3652141b", "metadata": {}, "outputs": [], "source": ["df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf.head().style.background_gradient(cmap='RdGy')"]}, {"cell_type": "markdown", "id": "c9e2a527", "metadata": {}, "source": ["## One Hot Encoding  \n#### How about education?"]}, {"cell_type": "code", "execution_count": 1, "id": "5beb6fac", "metadata": {}, "outputs": [], "source": ["df.groupby(['education'])['loan_status'].value_counts(normalize=True)"]}, {"cell_type": "markdown", "id": "77e45ed7", "metadata": {}, "source": ["#### Feature befor One Hot Encoding"]}, {"cell_type": "code", "execution_count": 1, "id": "4d2194e6", "metadata": {}, "outputs": [], "source": ["df[['Principal','terms','age','Gender','education']].head().style.background_gradient(cmap='RdGy')"]}, {"cell_type": "markdown", "id": "f6ce199e", "metadata": {}, "source": ["#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame "]}, {"cell_type": "code", "execution_count": 1, "id": "721b3fc0", "metadata": {}, "outputs": [], "source": ["Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head().style.background_gradient(cmap='RdGy')\n"]}, {"cell_type": "markdown", "id": "89ef01fc", "metadata": {}, "source": ["### Feature selection"]}, {"cell_type": "markdown", "id": "0a482582", "metadata": {}, "source": ["Lets defind feature sets, X:"]}, {"cell_type": "code", "execution_count": 1, "id": "e864a4cd", "metadata": {}, "outputs": [], "source": ["X = Feature\nX1 = X\nX[0:5]"]}, {"cell_type": "code", "execution_count": 1, "id": "127cd35c", "metadata": {}, "outputs": [], "source": ["print(X.columns)"]}, {"cell_type": "markdown", "id": "f7cf4db5", "metadata": {}, "source": ["What are our lables?"]}, {"cell_type": "code", "execution_count": 1, "id": "fd250a13", "metadata": {}, "outputs": [], "source": ["y = df['loan_status'].values\ny[0:5]"]}, {"cell_type": "markdown", "id": "a4252c14", "metadata": {}, "source": ["## Normalize Data "]}, {"cell_type": "markdown", "id": "19b28f30", "metadata": {}, "source": ["Data Standardization give data zero mean and unit variance (technically should be done after train test split )"]}, {"cell_type": "code", "execution_count": 1, "id": "6dfc8c74", "metadata": {}, "outputs": [], "source": ["X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]"]}, {"cell_type": "markdown", "id": "e847fc4a", "metadata": {}, "source": ["# Classification "]}, {"cell_type": "markdown", "id": "76bcb993", "metadata": {}, "source": ["Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells."]}, {"cell_type": "code", "execution_count": 1, "id": "2b2ee1cc", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"]}, {"cell_type": "markdown", "id": "f5e46812", "metadata": {}, "source": ["# K Nearest Neighbor(KNN)\nNotice: You should find the best k to build the model with the best accuracy.  \n**warning:** You should not use the __loan_test.csv__ for finding the best k, however, you can split your train_loan.csv into train and test to find the best __k__."]}, {"cell_type": "code", "execution_count": 1, "id": "b5b4ad38", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\nmean_acc\n#Plot model accuracy for Different number of Neighbors\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Neighbors (K)')\nplt.tight_layout()\nplt.show()\nprint( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "c44683d1", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nk = 7 # For best K\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nyhat = neigh.predict(X_test)\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"]}, {"cell_type": "markdown", "id": "02481e9e", "metadata": {}, "source": ["# Decision Tree"]}, {"cell_type": "code", "execution_count": 1, "id": "d73fa8bd", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\ndrugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\ndrugTree # it shows the default parameters\ndrugTree.fit(X_train,y_train)\npredTree = drugTree.predict(X_test)\n\nfrom sklearn import metrics\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, predTree))"]}, {"cell_type": "code", "execution_count": 1, "id": "5a683fce", "metadata": {}, "outputs": [], "source": ["#INSTALLATIONS TO VIEW THE DECISION TREE\n!conda install -c conda-forge pydotplus -y"]}, {"cell_type": "code", "execution_count": 1, "id": "405c1c21", "metadata": {}, "outputs": [], "source": ["from sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n\n%matplotlib inline \ndot_data = StringIO()\nfilename = \"drugtree.png\"\nfeatureNames = df.columns[3: 11]\ntargetNames = df[\"loan_status\"].unique().tolist()\nout=tree.export_graphviz(drugTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_train), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')"]}, {"cell_type": "markdown", "id": "db096541", "metadata": {}, "source": ["# Support Vector Machine"]}, {"cell_type": "markdown", "id": "5a225c85", "metadata": {}, "source": ["### **For visualization purpose, using linear kernel for SVM.**"]}, {"cell_type": "code", "execution_count": 1, "id": "02a91899", "metadata": {}, "outputs": [], "source": ["from sklearn import svm\nfrom sklearn import metrics\nclf2 = svm.SVC(kernel='linear')\nclf2.fit(X_train, y_train) \nyhat2 = clf2.predict(X_test)\nprint(\"SVM \", metrics.accuracy_score(y_test, yhat2))"]}, {"cell_type": "code", "execution_count": 1, "id": "3acd9b66", "metadata": {}, "outputs": [], "source": ["clf2.support_vectors_"]}, {"cell_type": "code", "execution_count": 1, "id": "82af0f89", "metadata": {}, "outputs": [], "source": ["print(X1.columns)"]}, {"cell_type": "code", "execution_count": 1, "id": "bcc0bf7e", "metadata": {}, "outputs": [], "source": ["# Determining the most contributing features for SVM classifier\n\npd.Series(abs(clf2.coef_[0]), index=X1.columns).nlargest(10).plot(kind='barh',figsize=(8, 6))"]}, {"cell_type": "code", "execution_count": 1, "id": "e7bc8f1d", "metadata": {}, "outputs": [], "source": ["clf2 = svm.SVC(kernel='rbf')\nclf2.fit(X_train, y_train) \nyhat2 = clf2.predict(X_test)\nprint(\"SVM \", metrics.accuracy_score(y_test, yhat2))"]}, {"cell_type": "markdown", "id": "3d569f5e", "metadata": {}, "source": ["# Logistic Regression"]}, {"cell_type": "code", "execution_count": 1, "id": "dc960ee2", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import jaccard_similarity_score\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nyhat = LR.predict(X_test)\nyhat_prob = LR.predict_proba(X_test)\nprint(\"Logistic Regression's Log Loss Accuracy: \", log_loss(y_test, yhat_prob))\nprint(\"Logistic Regression's Jaccard Similarity Accuracy: \", jaccard_similarity_score(y_test, yhat))\n"]}, {"cell_type": "markdown", "id": "5726c4e7", "metadata": {}, "source": ["# Model Evaluation using Test set"]}, {"cell_type": "code", "execution_count": 1, "id": "2cf619a7", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss"]}, {"cell_type": "markdown", "id": "6b54606b", "metadata": {}, "source": ["First, download and load the test set:"]}, {"cell_type": "code", "execution_count": 1, "id": "61beac6f", "metadata": {}, "outputs": [], "source": ["!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv"]}, {"cell_type": "markdown", "id": "6c93579e", "metadata": {}, "source": ["### Load Test set for evaluation "]}, {"cell_type": "code", "execution_count": 1, "id": "50933c0c", "metadata": {}, "outputs": [], "source": ["test_df = pd.read_csv('loan_test.csv')\ntest_df.head().style.background_gradient(cmap='RdGy')"]}, {"cell_type": "code", "execution_count": 1, "id": "04f21426", "metadata": {}, "outputs": [], "source": ["# Preprocessing the test data set\ntest_df['due_date'] = pd.to_datetime(test_df['due_date'])\ntest_df['effective_date'] = pd.to_datetime(test_df['effective_date'])\ntest_df['loan_status'].value_counts()\ntest_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\ntest_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ntest_df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)\ntest_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ntest_df.groupby(['education'])['loan_status'].value_counts(normalize=True)\ntest_df[['Principal','terms','age','Gender','education']].head()\ntest_df[['Principal','terms','age','Gender','education']].head()\nFeature = test_df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(test_df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nX = Feature\ny_test = test_df['loan_status'].values\nX_test= preprocessing.StandardScaler().fit(X).transform(X)"]}, {"cell_type": "code", "execution_count": 1, "id": "e518f7b0", "metadata": {}, "outputs": [], "source": ["# K Nearest Neighbor(KNN) Prediction\nyhat = neigh.predict(X_test)\nprint(\"KNN's Jaccard Similarity Accuracy: %.2f\" % jaccard_similarity_score(y_test, yhat))\nprint(\"KNN Avg F1-score: %.2f\" % f1_score(y_test, yhat, average='weighted'))"]}, {"cell_type": "code", "execution_count": 1, "id": "6bb85839", "metadata": {}, "outputs": [], "source": ["# Support Vector Machine Prediction\nyhat2 = clf2.predict(X_test)\nprint(\"SVM's Jaccard Similarity Accuracy: %.2f\" % jaccard_similarity_score(y_test, yhat2))\nprint(\"SVM Avg F1-score: %.2f\" % f1_score(y_test, yhat2, average='weighted'))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "21e2ad04", "metadata": {}, "outputs": [], "source": ["# Logistic Regression Prediction\nyhat3 = LR.predict(X_test)\nyhat_prob3 = LR.predict_proba(X_test)\nprint(\"Logistic Regression's Jaccard Similarity Accuracy:  %.2f\" % jaccard_similarity_score(y_test, yhat3))\nprint(\"LRP Avg F1-score: %.2f\" % f1_score(y_test, yhat3, average='weighted'))\nprint(\"Logistic Regression's Log Loss Accuracy: %.2f\" % log_loss(y_test, yhat_prob3))"]}, {"cell_type": "code", "execution_count": 1, "id": "7f11febd", "metadata": {}, "outputs": [], "source": ["# Decision Tree Prediction\npredTree = drugTree.predict(X_test)\nprint(\"DecisionTrees's Jaccard Similarity Accuracy: %.2f\" % jaccard_similarity_score(y_test, predTree))\nprint(\"DecisionTrees Avg F1-score: %.2f\" % f1_score(y_test, predTree, average='weighted'))"]}, {"cell_type": "markdown", "id": "937a34ab", "metadata": {}, "source": ["# Report\nYou should be able to report the accuracy of the built model using different evaluation metrics:"]}, {"cell_type": "markdown", "id": "d8440d4c", "metadata": {}, "source": ["| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.67    |  0.63    | NA      |\n| Decision Tree      | 0.72    | 0.74     | NA      |\n| SVM                | 0.80    | 0.76     | NA      |\n| LogisticRegression | 0.74    | 0.66     | 0.57    |"]}, {"cell_type": "markdown", "id": "3dbf18f0", "metadata": {}, "source": ["After complete evaluation of the models using the 4 above said algorithms, the SVM - Support Vector Machine holds the highest accuracy rate of 80% and 76% in both the evaluation models say Jaccard Index and F1-Score."]}, {"cell_type": "markdown", "id": "57ca8f3c", "metadata": {}, "source": ["<img src=\"https://d31bgfoj87qaaj.cloudfront.net/blog/wp-content/uploads/2019/04/Blog-Loan-Approved-Feature-min.jpg\" width=\"500\" align=\"center\">"]}, {"cell_type": "markdown", "id": "43ae875a", "metadata": {}, "source": ["<h3>Thanks for completing this lesson!</h3>\n\nCredit :-\n<h4>Author of Solution and Visualization:  <a href=\"https://www.linkedin.com/in/rohit-kumar-singh1996/\"> Rohit Kumar Singh </a> and  <a href=\"https://www.linkedin.com/in/bavalpreet-singh-a7b627172/\"> Bavalpreet Singh </a></h4>\n<h4>Author of Format:  <a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a></h4>\n<p>Copyright &copy; 2018 <a href=\"https://cocl.us/DX0108EN_CC\">Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.</p>"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}