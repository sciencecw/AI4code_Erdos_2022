{"cells": [{"cell_type": "code", "execution_count": 1, "id": "3a556abf", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import chi2_contingency\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split, GridSearchCV \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, Lasso, MultiTaskLasso\nfrom sklearn.metrics import r2_score\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "ce12b7fd", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('../input/video-game-sales-with-ratings/Video_Games_Sales_as_at_22_Dec_2016.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "1f9cb428", "metadata": {}, "outputs": [], "source": ["df.isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "0f86f589", "metadata": {}, "outputs": [], "source": ["df.rename(columns={'Name': 'name',\n                    'Platform': 'platform',\n                    'Year_of_Release': 'year',\n                    'Genre': 'genre',\n                    'Publisher': 'publisher',\n                    'NA_Sales': 'na_sales',\n                    'EU_Sales': 'eu_sales',\n                    'JP_Sales': 'jp_sales',\n                    'Other_Sales': 'other_sales',\n                    'Global_Sales': 'global_sales',\n                    'Critic_Score': 'critic_score',\n                    'Critic_Count': 'critic_count',\n                    'User_Score': 'user_score',\n                    'User_Count': 'user_count',\n                    'Developer': 'developer',\n                    'Rating': 'rating'},inplace=True)"]}, {"cell_type": "markdown", "id": "99dfd678", "metadata": {}, "source": ["Correlation"]}, {"cell_type": "code", "execution_count": 1, "id": "c9b9e1cc", "metadata": {}, "outputs": [], "source": ["df.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "50323cd5", "metadata": {}, "outputs": [], "source": ["cat = ['platform','genre','publisher','developer','rating']\nnum = ['year','na_sales',\n       'eu_sales', 'jp_sales', 'other_sales', 'global_sales', 'critic_score',\n       'critic_count', 'user_score', 'user_count']"]}, {"cell_type": "code", "execution_count": 1, "id": "66317ce2", "metadata": {}, "outputs": [], "source": ["corr_matrix = df[num].corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr_matrix,annot=True)"]}, {"cell_type": "markdown", "id": "df168e9c", "metadata": {}, "source": ["Check corr matrix "]}, {"cell_type": "code", "execution_count": 1, "id": "62f07bfc", "metadata": {}, "outputs": [], "source": ["df['global_sales'].describe()"]}, {"cell_type": "markdown", "id": "c5a96df7", "metadata": {}, "source": ["Check outlier in global_sales"]}, {"cell_type": "code", "execution_count": 1, "id": "68f01930", "metadata": {}, "outputs": [], "source": ["# sns.lmplot(x='critic_count',y='global_sales', data=df)\nvalues = df[~df['global_sales'].isna()]['global_sales']\nvalues = shuffle(values)\nx = list(range(len(values)))\nplt.figure(figsize=(20,20))\nplt.plot(x, values, 'D')\nplt.show()"]}, {"cell_type": "markdown", "id": "d66bb250", "metadata": {}, "source": ["delete otlier"]}, {"cell_type": "code", "execution_count": 1, "id": "2d868f62", "metadata": {}, "outputs": [], "source": ["df = df[df['global_sales']<50]"]}, {"cell_type": "markdown", "id": "c7cf4d01", "metadata": {}, "source": ["Check outlier in na_sales"]}, {"cell_type": "code", "execution_count": 1, "id": "e08664bc", "metadata": {}, "outputs": [], "source": ["values = df[~df['na_sales'].isna()]['na_sales']\nvalues = shuffle(values)\nx = list(range(len(values)))\nplt.figure(figsize=(20,20))\nplt.plot(x, values, 'D')\nplt.show()"]}, {"cell_type": "markdown", "id": "6e04aa2a", "metadata": {}, "source": ["Delete outlier"]}, {"cell_type": "code", "execution_count": 1, "id": "b2dfc077", "metadata": {}, "outputs": [], "source": ["df = df[df['na_sales']<16]"]}, {"cell_type": "markdown", "id": "bc3cb38f", "metadata": {}, "source": ["Check outlier in eu_sales"]}, {"cell_type": "code", "execution_count": 1, "id": "1c88ce3b", "metadata": {}, "outputs": [], "source": ["values = df[~df['eu_sales'].isna()]['eu_sales']\nvalues = shuffle(values)\nx = list(range(len(values)))\nplt.figure(figsize=(20,20))\nplt.plot(x, values, 'D')\nplt.show()"]}, {"cell_type": "markdown", "id": "4ba24270", "metadata": {}, "source": ["Delete outlier"]}, {"cell_type": "code", "execution_count": 1, "id": "03320c1f", "metadata": {}, "outputs": [], "source": ["df = df[df['eu_sales']<10]"]}, {"cell_type": "markdown", "id": "30312372", "metadata": {}, "source": ["check otlier in jp sales"]}, {"cell_type": "code", "execution_count": 1, "id": "598353f1", "metadata": {}, "outputs": [], "source": ["values = df[~df['jp_sales'].isna()]['jp_sales']\nvalues = shuffle(values)\nx = list(range(len(values)))\nplt.figure(figsize=(20,20))\nplt.plot(x, values, 'D')\nplt.show()"]}, {"cell_type": "markdown", "id": "ca03c389", "metadata": {}, "source": ["Delete outlier"]}, {"cell_type": "code", "execution_count": 1, "id": "acfa1d62", "metadata": {}, "outputs": [], "source": ["df = df[df['jp_sales']<6]"]}, {"cell_type": "markdown", "id": "629319bc", "metadata": {}, "source": ["Check outlier in other sales"]}, {"cell_type": "code", "execution_count": 1, "id": "ab855e1f", "metadata": {}, "outputs": [], "source": ["values = df[~df['other_sales'].isna()]['other_sales']\nvalues = shuffle(values)\nx = list(range(len(values)))\nplt.figure(figsize=(20,20))\nplt.plot(x, values, 'D')\nplt.show()"]}, {"cell_type": "markdown", "id": "53f9e40f", "metadata": {}, "source": ["Delete otlier"]}, {"cell_type": "code", "execution_count": 1, "id": "2c796f73", "metadata": {}, "outputs": [], "source": ["df = df[df['other_sales']<4]"]}, {"cell_type": "markdown", "id": "58dba5fa", "metadata": {}, "source": ["The next step, check correlation between na, eu, jp and other sales."]}, {"cell_type": "code", "execution_count": 1, "id": "652399a7", "metadata": {}, "outputs": [], "source": ["sns.pairplot(df[['na_sales','eu_sales','jp_sales','other_sales']])"]}, {"cell_type": "markdown", "id": "a594ac7a", "metadata": {}, "source": ["Check chi2 for outher categorical variables"]}, {"cell_type": "code", "execution_count": 1, "id": "bb62b5cb", "metadata": {}, "outputs": [], "source": ["name_sales = ['na_sales','eu_sales','jp_sales','other_sales','global_sales']"]}, {"cell_type": "code", "execution_count": 1, "id": "a4def63b", "metadata": {}, "outputs": [], "source": ["result = {sale_name : {c_name: chi2_contingency(pd.crosstab(df[sale_name], df[c_name]))[1] for c_name in cat} for sale_name in name_sales}"]}, {"cell_type": "code", "execution_count": 1, "id": "4c5ca41f", "metadata": {}, "outputs": [], "source": ["result"]}, {"cell_type": "markdown", "id": "d5c62564", "metadata": {}, "source": ["We can say that platform, genre, rating have smaller p-value than 0.05. So we can reject our null hypothesis"]}, {"cell_type": "markdown", "id": "8a36573e", "metadata": {}, "source": ["Vizualizations"]}, {"cell_type": "code", "execution_count": 1, "id": "537a9ca7", "metadata": {}, "outputs": [], "source": ["df['na_sales']"]}, {"cell_type": "code", "execution_count": 1, "id": "8994879e", "metadata": {}, "outputs": [], "source": ["# plt.figure(figsize=(10,10))\n\n# sns.distplot(df['na_sales'])\n# # sns.distplot(df['eu_sales'])\n# # sns.distplot(df['jp_sales'])"]}, {"cell_type": "markdown", "id": "bc2be080", "metadata": {}, "source": ["Check and fill missing values"]}, {"cell_type": "markdown", "id": "2dc945ab", "metadata": {}, "source": ["Work with missing values Name"]}, {"cell_type": "code", "execution_count": 1, "id": "5210f8c1", "metadata": {}, "outputs": [], "source": ["df[df['name'].isna()]"]}, {"cell_type": "markdown", "id": "6176fea7", "metadata": {}, "source": ["Delete these 2 rows from our dataframe"]}, {"cell_type": "code", "execution_count": 1, "id": "e4d9e3d2", "metadata": {}, "outputs": [], "source": ["df = df[~df['name'].isna()]"]}, {"cell_type": "code", "execution_count": 1, "id": "e23f5e3d", "metadata": {}, "outputs": [], "source": ["df['name'].isna().sum()"]}, {"cell_type": "markdown", "id": "16dfc5e4", "metadata": {}, "source": ["Work with missing values Year of release"]}, {"cell_type": "code", "execution_count": 1, "id": "488257c5", "metadata": {}, "outputs": [], "source": ["df[df['year'].isna()]"]}, {"cell_type": "code", "execution_count": 1, "id": "495c71df", "metadata": {}, "outputs": [], "source": ["df.loc[:,'year'] = df.loc[:,'year'].fillna(df['year'].median())"]}, {"cell_type": "code", "execution_count": 1, "id": "a04eb735", "metadata": {}, "outputs": [], "source": ["df['year'].isna().sum()"]}, {"cell_type": "markdown", "id": "8bfc825a", "metadata": {}, "source": ["Work with publisher missing values"]}, {"cell_type": "code", "execution_count": 1, "id": "c9f99bbe", "metadata": {}, "outputs": [], "source": ["df['publisher'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "81019102", "metadata": {}, "outputs": [], "source": ["df.loc[:,'publisher'] = df.loc[:,'publisher'].fillna(df['publisher'].mode()[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "65df723d", "metadata": {}, "outputs": [], "source": ["df['publisher'].isna().sum()"]}, {"cell_type": "markdown", "id": "48c1e50f", "metadata": {}, "source": ["Work with missing values critic score"]}, {"cell_type": "code", "execution_count": 1, "id": "cec4a290", "metadata": {}, "outputs": [], "source": ["df['critic_score'].isna().sum()"]}, {"cell_type": "markdown", "id": "0dc694de", "metadata": {}, "source": ["We fill na with median"]}, {"cell_type": "code", "execution_count": 1, "id": "ff70c5dd", "metadata": {}, "outputs": [], "source": ["df.loc[:,'critic_score'] = df.loc[:,'critic_score'].fillna(df['critic_score'].median())"]}, {"cell_type": "code", "execution_count": 1, "id": "f4d8a125", "metadata": {}, "outputs": [], "source": ["df['critic_score'].isna().sum()"]}, {"cell_type": "markdown", "id": "8a130b7e", "metadata": {}, "source": ["Work with critic_count"]}, {"cell_type": "code", "execution_count": 1, "id": "fe136532", "metadata": {}, "outputs": [], "source": ["df['critic_count'].isna().sum()"]}, {"cell_type": "markdown", "id": "9c375da1", "metadata": {}, "source": ["We will fill na with median"]}, {"cell_type": "code", "execution_count": 1, "id": "00b36a92", "metadata": {}, "outputs": [], "source": ["df.loc[:,'critic_count'] = df.loc[:,'critic_count'].fillna(df['critic_count'].median())"]}, {"cell_type": "code", "execution_count": 1, "id": "1b9b0c71", "metadata": {}, "outputs": [], "source": ["df['critic_count'].isna().sum()"]}, {"cell_type": "markdown", "id": "2681ebef", "metadata": {}, "source": ["Work with user_score missing values"]}, {"cell_type": "code", "execution_count": 1, "id": "8f5bcd87", "metadata": {}, "outputs": [], "source": ["df['user_score'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "0753863c", "metadata": {}, "outputs": [], "source": ["df['user_score'].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "71d94a31", "metadata": {}, "outputs": [], "source": ["df.loc[:,'user_score'] = df.loc[:,'user_score'].apply(lambda x: None if x=='tbd' else x)"]}, {"cell_type": "code", "execution_count": 1, "id": "48bd6dd0", "metadata": {}, "outputs": [], "source": ["df['user_score'] = df['user_score'].astype('float')"]}, {"cell_type": "code", "execution_count": 1, "id": "8483091a", "metadata": {}, "outputs": [], "source": ["df.loc[:,'user_score'] = df.loc[:,'user_score'].fillna(df['user_score'].median())"]}, {"cell_type": "code", "execution_count": 1, "id": "ef138491", "metadata": {}, "outputs": [], "source": ["df['user_score'].isna().sum()"]}, {"cell_type": "markdown", "id": "4a2a3c5d", "metadata": {}, "source": ["Work with missing values in user_count"]}, {"cell_type": "code", "execution_count": 1, "id": "f34674c5", "metadata": {}, "outputs": [], "source": ["df['user_count'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "5e2636d6", "metadata": {}, "outputs": [], "source": ["df['user_count'].describe()"]}, {"cell_type": "markdown", "id": "96fa699b", "metadata": {}, "source": ["Fill missing values median"]}, {"cell_type": "code", "execution_count": 1, "id": "977ed396", "metadata": {}, "outputs": [], "source": ["df.loc[:,'user_count'] = df.loc[:,'user_count'].fillna(df['user_count'].median())"]}, {"cell_type": "code", "execution_count": 1, "id": "ee74ebd8", "metadata": {}, "outputs": [], "source": ["df['user_count'].isna().sum()"]}, {"cell_type": "markdown", "id": "f126138e", "metadata": {}, "source": ["Work with missing values in developer. In my prediction model, we don't use this variable, so i will fill na values by string 'unknown'"]}, {"cell_type": "code", "execution_count": 1, "id": "7924cfea", "metadata": {}, "outputs": [], "source": ["df['developer'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "b64bff44", "metadata": {}, "outputs": [], "source": ["df.loc[:,'developer'] = df.loc[:,'developer'].fillna('Unknown')"]}, {"cell_type": "code", "execution_count": 1, "id": "0f16da2f", "metadata": {}, "outputs": [], "source": ["df['developer'].isna().sum()"]}, {"cell_type": "markdown", "id": "9f6ff7e4", "metadata": {}, "source": ["Work with missing values in rating"]}, {"cell_type": "code", "execution_count": 1, "id": "f55e8dfb", "metadata": {}, "outputs": [], "source": ["df['rating'].isna().sum()"]}, {"cell_type": "markdown", "id": "a9e75c08", "metadata": {}, "source": ["We will fill na by mode"]}, {"cell_type": "code", "execution_count": 1, "id": "4a19f2eb", "metadata": {}, "outputs": [], "source": ["df['rating'].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "f2f5b74f", "metadata": {}, "outputs": [], "source": ["df['rating'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "27994032", "metadata": {}, "outputs": [], "source": ["df.loc[:,'rating'] = df.loc[:,'rating'].fillna(df['rating'].mode()[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "5bc7b5a3", "metadata": {}, "outputs": [], "source": ["df['rating'].isna().sum()"]}, {"cell_type": "markdown", "id": "0ed2f020", "metadata": {}, "source": ["Build prediction model "]}, {"cell_type": "markdown", "id": "6cff863b", "metadata": {}, "source": ["We predict na, eu, jp and other sales. "]}, {"cell_type": "code", "execution_count": 1, "id": "649ba087", "metadata": {}, "outputs": [], "source": ["df_model = df.drop(['name','publisher','developer','other_sales','global_sales'],axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "3b5064ab", "metadata": {}, "outputs": [], "source": ["df_model = pd.get_dummies(df_model)"]}, {"cell_type": "code", "execution_count": 1, "id": "5d4aa83a", "metadata": {}, "outputs": [], "source": ["df_model"]}, {"cell_type": "markdown", "id": "401d506a", "metadata": {}, "source": ["make df to predict global_sales"]}, {"cell_type": "code", "execution_count": 1, "id": "88adf9c3", "metadata": {}, "outputs": [], "source": ["corr_matrix = df[['na_sales',\n       'eu_sales', 'jp_sales', 'other_sales']].corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr_matrix,annot=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "9e127209", "metadata": {}, "outputs": [], "source": ["def prepare_data(y_name):    \n    labels = df_model[y_name].to_numpy()\n    if y_name!='jp_name':   \n        features = df_model.drop([y_name],axis=1)\n    else:\n        features = df_model.drop([y_name,'na_sales'],axis=1)\n    features_names = list(features.columns)\n    features = features.to_numpy()\n    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.25, random_state=42)\n    return train_features, test_features, train_labels, test_labels"]}, {"cell_type": "code", "execution_count": 1, "id": "3df22463", "metadata": {}, "outputs": [], "source": ["# # Create the parameter grid based on the results of random search \n# param_grid = {\n#     'bootstrap': [True],\n#     'max_depth': [80, 90, 100, 110],\n#     'max_features': [2, 3],\n#     'min_samples_leaf': [3, 4, 5],\n#     'min_samples_split': [8, 10, 12],\n#     'n_estimators': [100, 200, 300, 1000]\n#     }\n# # Create a based model\n# rf = RandomForestRegressor()\n# # Instantiate the grid search model\n# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n#                           cv = 3,  verbose = 2)"]}, {"cell_type": "code", "execution_count": 1, "id": "001842e2", "metadata": {}, "outputs": [], "source": ["predict_values_names = ['na_sales','eu_sales','jp_sales']"]}, {"cell_type": "code", "execution_count": 1, "id": "cfa2ebbf", "metadata": {}, "outputs": [], "source": ["param_grid_rfr = {'bootstrap': [True],\n 'max_depth': [90],\n 'max_features': [3],\n 'min_samples_leaf': [3],\n 'min_samples_split': [8],\n 'n_estimators': [100]}\n\n\nparam_grid_lin = {'alpha': [0.01+i*0.05 for i in range(20)]}\nmodels = {\n            'Lasso': GridSearchCV(estimator = Lasso(), param_grid = param_grid_lin, cv = 3),\n            'Ridge': GridSearchCV(estimator = Ridge(), param_grid = param_grid_lin, cv = 3),\n            'RFR': GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid_rfr, cv = 3)\n         }"]}, {"cell_type": "code", "execution_count": 1, "id": "16188420", "metadata": {}, "outputs": [], "source": ["result = {}\nfor predict_name in predict_values_names:\n    result[predict_name] = {}\n    train_features, test_features, train_labels, test_labels = prepare_data(predict_name)\n    for key in models.keys():\n        models[key].fit(train_features, train_labels)\n        result[predict_name][key] = {}\n        result[predict_name][key]['r^2 train data'] = r2_score(train_labels,models[key].best_estimator_.predict(train_features))\n        predictions = models[key].best_estimator_.predict(test_features)\n        result[predict_name][key]['r^2 test data'] = r2_score(test_labels,predictions)\n        se_predict = predictions.std()/len(predictions)**0.5\n        result[predict_name][key]['confidence_interval'] =  [predictions.mean()-1.96*se_predict,predictions.mean()+1.96*se_predict]\n        result[predict_name][key]['test_mean'] = test_labels.mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "74562553", "metadata": {}, "outputs": [], "source": ["# grid_search.fit(train_features, train_labels)\n# grid_search.best_params_\n# # best_grid = grid_search.best_estimator_\n# # grid_accuracy = evaluate(best_grid, test_features, test_labels)"]}, {"cell_type": "code", "execution_count": 1, "id": "ed3ac8eb", "metadata": {}, "outputs": [], "source": ["result_list = []\nfor key in result.keys():\n    \n    result_list.append((key,pd.DataFrame(result[key])))"]}, {"cell_type": "code", "execution_count": 1, "id": "de3136ac", "metadata": {}, "outputs": [], "source": ["print(result_list[0][0])\nresult_list[0][1]\n"]}, {"cell_type": "code", "execution_count": 1, "id": "01b74b24", "metadata": {}, "outputs": [], "source": ["print(result_list[1][0])\nresult_list[1][1]"]}, {"cell_type": "code", "execution_count": 1, "id": "24da09c6", "metadata": {}, "outputs": [], "source": ["print(result_list[2][0])\nresult_list[2][1]"]}, {"cell_type": "markdown", "id": "b129c029", "metadata": {}, "source": ["Conclution: The best result show a randomforestregressor and this case \n\nWe can say that with a probability of 95% the true estimate is in this range. it should be noted that then we try to predict jp_sales, only in one case test_mean in confidence interval. And this case is randomforest regresor\n\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}