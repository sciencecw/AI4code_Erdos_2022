{"cells": [{"cell_type": "code", "execution_count": 1, "id": "e2c275dc", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "c75afeec", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing, impute\nfrom IPython.display import display\n\nfrom sklearn.dummy import DummyRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict, cross_validate\nfrom sklearn.model_selection import train_test_split, GroupKFold\nfrom sklearn.metrics import mean_absolute_error, make_scorer\nfrom sklearn.linear_model import Ridge, RidgeCV\n\nfrom fbprophet import Prophet\nimport optuna\nimport statsmodels.api as sm\nimport scipy.stats as stats\n\nplt.style.use('ggplot')"]}, {"cell_type": "code", "execution_count": 1, "id": "b20d7b1b", "metadata": {}, "outputs": [], "source": ["random_state = 42\nrng = np.random.RandomState(random_state)"]}, {"cell_type": "code", "execution_count": 1, "id": "3baaf89e", "metadata": {}, "outputs": [], "source": ["X = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/train.csv', index_col=0)\nX_test = pd.read_csv('/kaggle/input/ventilator-pressure-prediction/test.csv', index_col=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "4371d496", "metadata": {}, "outputs": [], "source": ["print(X.columns.difference(X_test.columns))\ny = X.pop('pressure')"]}, {"cell_type": "code", "execution_count": 1, "id": "36b11ec8", "metadata": {}, "outputs": [], "source": ["num_columns = ['R', 'C', 'u_in', 'u_out']\nds = 'time_step'\nts_id = 'breath_id'"]}, {"cell_type": "markdown", "id": "13009e42", "metadata": {}, "source": ["# Quick EDA"]}, {"cell_type": "code", "execution_count": 1, "id": "257eeb86", "metadata": {}, "outputs": [], "source": ["X[ts_id].unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "00c78b07", "metadata": {}, "outputs": [], "source": ["(X.isna().sum() > 0).any(), (X_test.isna().sum() > 0).any()"]}, {"cell_type": "code", "execution_count": 1, "id": "8d89a90e", "metadata": {}, "outputs": [], "source": ["X[num_columns].describe(), X_test[num_columns].describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "3d1416ae", "metadata": {}, "outputs": [], "source": ["X[num_columns].nunique()"]}, {"cell_type": "code", "execution_count": 1, "id": "b048e809", "metadata": {}, "outputs": [], "source": ["X.groupby('breath_id')['R'].nunique().max(), X.groupby('breath_id')['C'].nunique().max()"]}, {"cell_type": "markdown", "id": "9f3b5445", "metadata": {}, "source": ["R and C are physical parameters which change at every breath"]}, {"cell_type": "code", "execution_count": 1, "id": "6dfd3a06", "metadata": {}, "outputs": [], "source": ["pd.concat([X.groupby('breath_id')[ds].max().rename('train ts'),\n           X_test.groupby('breath_id')[ds].max().rename('test ts')], axis=1)\\\n    .plot.hist(bins=20, density=True, alpha=0.5)"]}, {"cell_type": "markdown", "id": "6b32a71a", "metadata": {}, "source": ["breath duration is between 2.5s and 2.8s"]}, {"cell_type": "code", "execution_count": 1, "id": "f39498a5", "metadata": {}, "outputs": [], "source": ["pd.concat([X.groupby('breath_id')['u_in'].mean().rename('train u_in'),\n           X_test.groupby('breath_id')['u_in'].mean().rename('test u_in')], axis=1)\\\n    .plot.hist(bins=20, density=True, alpha=0.5)"]}, {"cell_type": "code", "execution_count": 1, "id": "ea4f0ca4", "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(nrows=3, figsize=(12, 12))\n\ndf_combined = pd.concat([X.assign(set='train'),\n                         X_test.assign(set='test')], axis=0)\n\ndef plot_counts_cst(col, ax, X=X, X_test=X_test):\n    df_plot = pd.concat([(X[col].value_counts() / X.shape[0]).rename('ratio train'),\n                         (X_test[col].value_counts() / X_test.shape[0]).rename('ratio test')], axis=1)\n    return df_plot.plot.bar(ax=ax)\n\nplot_counts_cst('R', axs[0])\nplot_counts_cst('C', axs[1])\nplot_counts_cst('u_out', axs[2])"]}, {"cell_type": "code", "execution_count": 1, "id": "0a86bfd9", "metadata": {}, "outputs": [], "source": ["ds_diff = X.groupby(ts_id)[ds].transform(lambda x: x.diff())"]}, {"cell_type": "code", "execution_count": 1, "id": "6434b468", "metadata": {}, "outputs": [], "source": ["ds_diff.describe(percentiles=np.arange(0.1, 1.0, 0.1))"]}, {"cell_type": "code", "execution_count": 1, "id": "f075dbe8", "metadata": {}, "outputs": [], "source": ["issue_ts_id = X.assign(time_diff=lambda x: x['time_step'].diff())\\\n               .query('time_diff > 0.2 and u_out == 0')\\\n               [ts_id].unique()"]}, {"cell_type": "code", "execution_count": 1, "id": "18f5d54d", "metadata": {}, "outputs": [], "source": ["X\\\n.loc[X[ts_id] == 36175, :]\\\n.assign(time_diff=lambda x: x[ds].diff(),\n        y=y)\\\n.plot(x='time_step', subplots=True, figsize=(12, 12))"]}, {"cell_type": "markdown", "id": "2fa8f4c5", "metadata": {}, "source": ["Some issue with the time_step for \"breath_id\":\n24127,  36175,  38415,  46324,  54129,  55244,  55851,  72104, 74766, 104001, 109693, 119689"]}, {"cell_type": "code", "execution_count": 1, "id": "495578f7", "metadata": {}, "outputs": [], "source": ["# plt.hist(y, bins='auto')\nplt.hist(y.groupby(X[ts_id]).max(), bins='auto')\n\nplt.show()"]}, {"cell_type": "markdown", "id": "901033c2", "metadata": {}, "source": ["# Baseline"]}, {"cell_type": "code", "execution_count": 1, "id": "cf96616e", "metadata": {}, "outputs": [], "source": ["def get_folds(X, y, n_splits=5, ts_id=ts_id):\n    # return fixed list of CV index (for XGB, LGB compability to groups)\n    folds = GroupKFold(n_splits=n_splits)\n    return list(folds.split(X, y, groups=X[ts_id]))\n\n\ndef score_model(model, X=X, y=y, folds=None, fit_as_score=True):\n    if folds is None:\n        folds = get_folds(X, y)\n        \n    sample_weight = X.mask(lambda x: x['u_out'] == 0).isna().any(axis=1).astype(int)\n    \n    def scorer(y_true, y_pred, sample_weight=sample_weight):\n        return mean_absolute_error(y_true.values, y_pred, sample_weight=sample_weight.loc[y_true.index].values)\n    scoring = make_scorer(scorer, greater_is_better=False, sample_weight=sample_weight)\n    \n    if fit_as_score:\n        fit_params = {'sample_weight':sample_weight}\n    else:\n        fit_params = {}\n        \n    d = cross_validate(model, X, y, scoring=scoring, cv=folds, n_jobs=1, fit_params=fit_params, return_train_score=True)\n    d['train_score'] = -d['train_score']\n    d['test_score'] = -d['test_score']\n    return pd.DataFrame(d).style.bar(subset=['fit_time', 'score_time'], vmin=0, vmax=30)\\\n                                .bar(subset=['test_score', 'train_score'], vmin=0, vmax=7.5)"]}, {"cell_type": "code", "execution_count": 1, "id": "bfcab94f", "metadata": {}, "outputs": [], "source": ["score_model(Ridge(), X=X, y=y)"]}, {"cell_type": "code", "execution_count": 1, "id": "68e8c701", "metadata": {}, "outputs": [], "source": ["score_model(Ridge(max_iter=100_000), X=X.loc[X['u_out'] == 0], y=y.loc[X['u_out'] == 0])"]}, {"cell_type": "code", "execution_count": 1, "id": "9afd3346", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=X, y=y)"]}, {"cell_type": "code", "execution_count": 1, "id": "117d8ed0", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=X.loc[X['u_out'] == 0], y=y.loc[X['u_out'] == 0])"]}, {"cell_type": "markdown", "id": "bcc9065a", "metadata": {}, "source": ["# Trial - Processing"]}, {"cell_type": "code", "execution_count": 1, "id": "c5157418", "metadata": {}, "outputs": [], "source": ["columns_discrete = [ts_id, 'u_out', 'R', 'C']\n\ndef add_lag(X, k=1, fill=0):\n    X = X.copy()\n    if isinstance(k, int):\n        k = list(range(1, k+1))  \n    \n    for i in k:\n        X_lag = X.drop(columns=columns_discrete).groupby(X[ts_id]).shift(i)\n        if fill is not None:\n            X_lag = X_lag.fillna(fill)\n        X = X.join(X_lag.add_prefix(f'lag_{i}_'))\n        \n    return X\n\ndef proc0(X):\n    pi = np.pi\n    X = X.query('u_out==0')\\\n         .eval('''RC=R*C/1000\n                  tau=2 * @pi * RC\n                  t=time_step/tau\n                  et=1-exp(-t)\n                  uet=u_in*et''')\\\n         .assign(time_diff=lambda x: x.groupby(ts_id)['time_step'].diff().fillna(0),\n                 int_u_in=lambda x: x.eval('u_in*time_diff').groupby(x[ts_id]).cumsum(),\n                 sum_u_in=lambda x: x.groupby(ts_id)['u_in'].cumsum(),\n                 diff_u_in=lambda x: x.groupby(ts_id)['u_in'].diff().fillna(0),)\n    return X\n\ncolumns_ts = ['t', 'et', 'uet', 'u_in', 'int_u_in']\n\nX0 = proc0(X)\ny0 = y.loc[X['u_out'] == 0]"]}, {"cell_type": "markdown", "id": "151bba36", "metadata": {}, "source": ["# EDA (Univariate)"]}, {"cell_type": "code", "execution_count": 1, "id": "c806ca6f", "metadata": {}, "outputs": [], "source": ["n_rows = 10_000"]}, {"cell_type": "code", "execution_count": 1, "id": "880c3718", "metadata": {}, "outputs": [], "source": ["y_ts = y.set_axis(X[ds]).iloc[:n_rows]\nX_ts = X.set_axis(X[ds], axis='index').iloc[:n_rows]\n\nX_ts0 = proc0(X_ts)\nX_ts0_lag = add_lag(proc0(X.iloc[:n_rows]))\nX_ts0_lag = X_ts0_lag.set_axis(X_ts0_lag[ds], axis='index')\n\ny_ts0 = y_ts.loc[X_ts['u_out'] == 0]"]}, {"cell_type": "code", "execution_count": 1, "id": "fe1d8c98", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(10, 10))\n\ny_ts.groupby(X_ts[ts_id])\\\n .plot(style='-k', alpha=0.1, ax=ax)\n\ny_ts.loc[lambda x: x.groupby(X_ts[ts_id]).transform('max') == x]\\\n.plot(style='.r', ax=ax, alpha=0.4)"]}, {"cell_type": "code", "execution_count": 1, "id": "7a58f488", "metadata": {}, "outputs": [], "source": ["from sklearn.feature_selection import mutual_info_regression, f_regression\n\ndef show_mi(X, y=y, random_state=random_state, columns_discrete=[]):\n    mi = mutual_info_regression(X, y,\n                                random_state=random_state,\n                                discrete_features=X.columns.isin(columns_discrete))\n\n    s = pd.Series(mi, index=X.columns, name='mutual_info_regression')\\\n          .sort_values(ascending=False)\n          \n    return s, s.to_frame().style.bar(vmin=0, vmax=1)\n\n\ndef show_f(X, y=y, center=False):\n    f = f_regression(X, y, center=center)[0]\n\n    s = pd.Series(f, index=X.columns, name='f_regression F-score')\\\n          .sort_values(ascending=False)\n          \n    return s, s.to_frame().style.bar()"]}, {"cell_type": "code", "execution_count": 1, "id": "77659579", "metadata": {}, "outputs": [], "source": ["show_mi(X_ts, y_ts, columns_discrete=['u_out'])[1]"]}, {"cell_type": "code", "execution_count": 1, "id": "75c4eb54", "metadata": {}, "outputs": [], "source": ["show_mi(X_ts0_lag, y_ts0)[1]"]}, {"cell_type": "code", "execution_count": 1, "id": "6cc52ddf", "metadata": {}, "outputs": [], "source": ["show_f(X_ts0_lag, y_ts0, center=True)[1]"]}, {"cell_type": "code", "execution_count": 1, "id": "c7a8157d", "metadata": {}, "outputs": [], "source": ["show_mi(X_ts0.groupby(ts_id).max(), y_ts0.groupby(X_ts0[ts_id]).max())[1]"]}, {"cell_type": "code", "execution_count": 1, "id": "3ae99547", "metadata": {}, "outputs": [], "source": ["show_mi(X_ts0.groupby(ts_id).first(), y_ts0.groupby(X_ts0[ts_id]).first())[1]"]}, {"cell_type": "code", "execution_count": 1, "id": "ad3d0176", "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 10), sharex=False)\n\nfor c, ax in zip(['u_out', 'R', 'C', 'RC'], axs.flat):\n    if c == 'u_out':\n        sns.boxplot(x=X[c], y=y, ax=ax)\n    else:\n        sns.boxplot(x=X0[c], y=y0, ax=ax)\n    \nplt.tight_layout()"]}, {"cell_type": "code", "execution_count": 1, "id": "cbc3dfe4", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(10, 10))\n\ny_ts0.groupby(X_ts0[ts_id])\\\n .plot(style='-k', alpha=0.1, ax=ax)\n\ny_ts0.loc[lambda x: x.groupby(X_ts0[ts_id]).transform('max') == x]\\\n.plot(style='.r', ax=ax, alpha=0.4)"]}, {"cell_type": "code", "execution_count": 1, "id": "006134b3", "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(nrows=len(columns_ts), figsize=(10, 5*len(columns_ts)), sharex=False)\n\nfor c, ax in zip(columns_ts, axs):\n    X_ts0[c].groupby(X_ts0[ts_id])\\\n            .plot(style='-k', alpha=0.1, ax=ax)\n    ax.set(ylabel=c)\n    \nplt.tight_layout()"]}, {"cell_type": "code", "execution_count": 1, "id": "a40c6fbe", "metadata": {}, "outputs": [], "source": ["n_plot = 5\n\nfrom cycler import cycler\nfig, axs = plt.subplots(nrows=n_plot, figsize=(10, 8*n_plot))\n\nbreath_ids = X_ts0['breath_id'].drop_duplicates().sample(n_plot, random_state=random_state)\n\nfor i, ax in zip(breath_ids, axs, ):\n    X_ts0.assign(y=y_ts0)\\\n         .query(f'breath_id=={i}')[columns_ts+['y']]\\\n         .plot(secondary_y=['u_in', 'int_u_in', 'y'], ax=ax, style=['--', '--', '--', '-.', ':', 'k-'])\n    ax.set_title(i)"]}, {"cell_type": "code", "execution_count": 1, "id": "327ef7d5", "metadata": {}, "outputs": [], "source": ["to_delete = 'X0, y0, X_ts, y_ts, X_ts0, y_ts0, X_ts0_lag'.split(', ')\nfor x in to_delete:\n    globals().pop(x, None);"]}, {"cell_type": "markdown", "id": "3015a9f1", "metadata": {}, "source": ["# Processing"]}, {"cell_type": "code", "execution_count": 1, "id": "785db66f", "metadata": {}, "outputs": [], "source": ["def add_lag(X, k=1, columns=['u_in', 'time_step'], fill=0):\n    X = X.copy()\n    if isinstance(k, int):\n        k = list(range(1, k+1))\n    if columns is None:\n        columns = X.columns.tolist()\n    \n    for i in k:\n        X_lag = X[columns].groupby(X[ts_id]).shift(i)\n        if fill is not None:\n            X_lag = X_lag.fillna(fill)\n        X = X.join(X_lag.add_prefix(f'lag_{i}_'))\n        \n    return X\n\n\ndef proc(X):\n    pi = np.pi\n    X = X.eval('''RC=R*C/1000\n                  tau=2 * @pi * RC\n                  t=time_step/tau\n                  et=1-exp(-t)\n                  uet=u_in*et''')\\\n         .assign(time_diff=lambda x: x.groupby(ts_id)['time_step'].diff().fillna(0),\n                 int_u_in=lambda x: x.eval('u_in*time_diff').groupby(x[ts_id]).cumsum(),\n                 sum_u_in=lambda x: x.groupby(ts_id)['u_in'].cumsum(),\n                 diff_u_in=lambda x: x.groupby(ts_id)['u_in'].diff().fillna(0),\n                 max_u_in=lambda x: x.groupby(ts_id)['u_in'].transform('max'),)\n    return X"]}, {"cell_type": "markdown", "id": "111f8fb8", "metadata": {}, "source": ["# Compare to baseline"]}, {"cell_type": "code", "execution_count": 1, "id": "45226919", "metadata": {}, "outputs": [], "source": ["X_proc = proc(X).query('u_out==0')\ny_proc = y.loc[X['u_out'] == 0]"]}, {"cell_type": "code", "execution_count": 1, "id": "8a9ab663", "metadata": {}, "outputs": [], "source": ["X_proc.isna().any(axis=None)"]}, {"cell_type": "markdown", "id": "30a42604", "metadata": {}, "source": ["## With lags"]}, {"cell_type": "code", "execution_count": 1, "id": "9970ad73", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(X), y=y)"]}, {"cell_type": "code", "execution_count": 1, "id": "7c94a513", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(X, k=2), y=y)"]}, {"cell_type": "code", "execution_count": 1, "id": "eec33378", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(X, k=3), y=y)"]}, {"cell_type": "markdown", "id": "ebc13545", "metadata": {}, "source": ["## With processing (and lag)"]}, {"cell_type": "code", "execution_count": 1, "id": "7d4f2a8a", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=X_proc, y=y_proc)"]}, {"cell_type": "code", "execution_count": 1, "id": "a954b1b2", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(X_proc, columns=['u_in', 'time_step', 'int_u_in', 'sum_u_in']), y=y_proc)"]}, {"cell_type": "code", "execution_count": 1, "id": "dcd8b6ca", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(proc(X), columns=['u_in', 'time_step', 'int_u_in', 'sum_u_in']), y=y)"]}, {"cell_type": "code", "execution_count": 1, "id": "52299177", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(X_proc, k=2, columns=['u_in', 'time_step', 'int_u_in', 'sum_u_in']), y=y_proc)"]}, {"cell_type": "code", "execution_count": 1, "id": "8b9c4b6a", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(X_proc, k=3, columns=['u_in', 'time_step', 'int_u_in', 'sum_u_in']), y=y_proc)"]}, {"cell_type": "code", "execution_count": 1, "id": "3a440b5e", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4), X=add_lag(X_proc, k=[2], columns=['u_in', 'time_step', 'int_u_in', 'sum_u_in']), y=y_proc)"]}, {"cell_type": "markdown", "id": "376f4c80", "metadata": {}, "source": ["# Hyperparameter tuning - manual"]}, {"cell_type": "code", "execution_count": 1, "id": "1853cb15", "metadata": {}, "outputs": [], "source": ["X_proc = add_lag(proc(X).query('u_out==0'), k=[2], columns=['u_in', 'time_step', 'int_u_in', 'sum_u_in'])\ny_proc = y.loc[X['u_out'] == 0]\n\n# select categorical as 1 value at each \"breath_id\"\ncategorical_feature = [ts_id] + (X_proc.groupby(ts_id).nunique().mean() == 1).loc[lambda x: x].index.tolist()\n# X_post[categorical_features] = pd.Categorical(X_post[categorical_features])"]}, {"cell_type": "code", "execution_count": 1, "id": "13953277", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4, random_state=random_state), X=X_proc, y=y_proc)"]}, {"cell_type": "code", "execution_count": 1, "id": "13e70f0e", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4, objective=\"regression_l1\", random_state=random_state), X=X_proc, y=y_proc)"]}, {"cell_type": "code", "execution_count": 1, "id": "b72ca3af", "metadata": {}, "outputs": [], "source": ["score_model(lgb.LGBMRegressor(n_jobs=4, objective=\"regression_l1\", random_state=random_state, n_estimators=1_000), X=X_proc, y=y_proc)"]}, {"cell_type": "markdown", "id": "6aa47643", "metadata": {}, "source": ["## Best \"learning_rate\""]}, {"cell_type": "code", "execution_count": 1, "id": "32d20d1c", "metadata": {}, "outputs": [], "source": ["import optuna.integration.lightgbm as opt_lgb\n\ndtrain = lgb.Dataset(data=X_proc, label=y_proc)\n\neval_hist = {}\nfor learning_rate in np.geomspace(1e-1, 1, 10):\n    eval_hist[learning_rate] = lgb.cv(\n        params={\"objective\":\"regression_l1\", \"learning_rate\":learning_rate, \"verbose\":-1, 'num_threads':4},\n        train_set=dtrain,\n        num_boost_round=500,\n        early_stopping_rounds=50,\n        folds=get_folds(X_proc, y_proc),\n        stratified=False,\n        shuffle=False,\n        metrics='l1',\n        verbose_eval=False,\n        #eval_train_metric=True,\n        seed=random_state,\n    )"]}, {"cell_type": "code", "execution_count": 1, "id": "febb3ce5", "metadata": {}, "outputs": [], "source": ["r_eval_hist = {}\nfor eta, d in eval_hist.items():\n    r_eval_hist[eta] = pd.Series(d['l1-mean'])\n    \nr_eval_hist = pd.DataFrame(r_eval_hist)\nr_eval_hist.plot()\n\ndisplay(pd.concat([r_eval_hist.idxmin().rename('num_boost'),\n                   r_eval_hist.min().rename('min_test_score')], axis=1))"]}, {"cell_type": "markdown", "id": "b3ca9626", "metadata": {}, "source": ["# Next steps - Hyperparameter fine-tuning  \n[Ventilator Pressure Prediction - LGB Optuna](https://www.kaggle.com/squarex/ventilator-pressure-prediction-lgb-optuna)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}