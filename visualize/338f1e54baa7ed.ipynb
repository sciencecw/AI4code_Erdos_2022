{"cells": [{"cell_type": "code", "execution_count": 1, "id": "c4d9467f", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.applications import VGG16"]}, {"cell_type": "code", "execution_count": 1, "id": "8ce1e008", "metadata": {}, "outputs": [], "source": ["!pip install split-folders\n"]}, {"cell_type": "code", "execution_count": 1, "id": "6a28c0c6", "metadata": {}, "outputs": [], "source": ["import splitfolders\nsplitfolders.ratio('/kaggle/input/flowers-recognition/flowers',output=\"/kaggle/output/data\",seed=1337,ratio=(0.5,0.25,0.25))"]}, {"cell_type": "markdown", "id": "552d4fee", "metadata": {}, "source": ["#### Define convolutional base"]}, {"cell_type": "code", "execution_count": 1, "id": "9467a912", "metadata": {}, "outputs": [], "source": ["conv_base = VGG16(\n    weights='imagenet',        # checkpoints from when to initialize the model\n    include_top=False,         # when True, includes the fully connected classifier network\n    input_shape=(150, 150, 3)  # shape of the image tensors to feed the network with\n)\nconv_base.summary()"]}, {"cell_type": "markdown", "id": "e5bf18db", "metadata": {}, "source": ["### Fast feature extraction _without_ data augmentation"]}, {"cell_type": "code", "execution_count": 1, "id": "33083ec7", "metadata": {}, "outputs": [], "source": ["import os\nimport numpy as np\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator"]}, {"cell_type": "code", "execution_count": 1, "id": "5fa3b472", "metadata": {}, "outputs": [], "source": ["import os\n\nbase_dir = '/kaggle/output/data'\n\nTRAIN_DIR = os.path.join(base_dir, 'train')\nVALIDATION_DIR = os.path.join(base_dir, 'val')\nTEST_DIR = os.path.join(base_dir, 'test')\nprint(TRAIN_DIR)\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size=20"]}, {"cell_type": "markdown", "id": "db9645ac", "metadata": {}, "source": ["#### Extract features from convolution base"]}, {"cell_type": "code", "execution_count": 1, "id": "d5478211", "metadata": {}, "outputs": [], "source": ["def extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512)) # shape of the output of the last layer of the conv_base\n    labels = np.zeros(shape=(sample_count,5))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='categorical'\n    )\n    \n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch \n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size >= sample_count:\n        # Since generators yield data indefinitely in a loop, we must `break` after every image has been seen once.\n            break\n    return features, labels\n    \ntrain_features, train_labels = extract_features(TRAIN_DIR, 2158)\nvalidation_features, validation_labels = extract_features(VALIDATION_DIR, 1079)\ntest_features, test_labels = extract_features(TEST_DIR, 1080)"]}, {"cell_type": "code", "execution_count": 1, "id": "be59e4d8", "metadata": {}, "outputs": [], "source": ["print(train_features.shape, validation_features.shape, test_features.shape,train_labels.shape, validation_labels.shape, test_labels.shape)"]}, {"cell_type": "markdown", "id": "b1bc18e1", "metadata": {}, "source": ["At this point we need to flatten the feature array in order to feed the classifier, exactly as a `Flatted` layer would do. Currently, the features have shape (`samples, 4, 4, 512`), so new array will have a shape equal to (`samples, (4 * 4 * 512)`)."]}, {"cell_type": "code", "execution_count": 1, "id": "809fed29", "metadata": {}, "outputs": [], "source": ["train_features = np.reshape(train_features, (2158, 4*4*512))\nvalidation_features = np.reshape(validation_features, (1079, 4*4*512))\ntest_features = np.reshape(test_features, (1080, 4*4*512))"]}, {"cell_type": "code", "execution_count": 1, "id": "5172cbae", "metadata": {}, "outputs": [], "source": ["print(train_features.shape, validation_features.shape, test_features.shape,train_labels.shape, validation_labels.shape, test_labels.shape)"]}, {"cell_type": "markdown", "id": "24a39b43", "metadata": {}, "source": ["#### Define and train the densely connected classifier\n\nThe training should be very fast, since we have to do with a small network."]}, {"cell_type": "code", "execution_count": 1, "id": "b190270a", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras import models, layers, optimizers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5, activation='softmax'))\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer=optimizers.RMSprop(lr=2e-5),\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_features,\n    train_labels,\n    epochs=30,\n    batch_size=20,\n    validation_data=(validation_features, validation_labels)\n)"]}, {"cell_type": "markdown", "id": "4b018f55", "metadata": {}, "source": ["#### Plot loss and accuracy"]}, {"cell_type": "code", "execution_count": 1, "id": "60b5194c", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()"]}, {"cell_type": "markdown", "id": "5c181832", "metadata": {}, "source": ["We obtain a good 90% validation accuracy, which outperforms the CNN from scratch we built in the previous notebook. On the other hand, due to the impossibility to add data augmentation we start also to overfit quite early, despite of using `Dropout` with a fairly large rate."]}, {"cell_type": "markdown", "id": "dc56ecd8", "metadata": {}, "source": ["### Feature extraction _with_ data augmentation\n\nThis technique allows data augmentation during training, but is also expensive. Absolutely not recommended without at least one GPU, since we'll have to do with more than 16 millions parameters."]}, {"cell_type": "markdown", "id": "b5787977", "metadata": {}, "source": ["#### Add a densely connected classifier on top of the convolutional base\n\nBy _freezing_ the `conv_base` we will reduce the amount of weights that will be trained: only those who belong the classifier on top."]}, {"cell_type": "code", "execution_count": 1, "id": "f6de0a46", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras import models, layers, optimizers\nconv_base = VGG16(\n    weights='imagenet',        # checkpoints from when to initialize the model\n    include_top=False,         # when True, includes the fully connected classifier network\n    input_shape=(150, 150, 3)  # shape of the image tensors to feed the network with\n)\n\nconv_base.trainable = False\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5, activation='softmax'))\n          \nmodel.summary()"]}, {"cell_type": "markdown", "id": "664591ac", "metadata": {}, "source": ["#### Setup generators with data augmentation"]}, {"cell_type": "code", "execution_count": 1, "id": "5a68f99d", "metadata": {}, "outputs": [], "source": ["train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n# Do not apply data augmentation on validation\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR, \n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='categorical'\n)\nvalidation_generator = validation_datagen.flow_from_directory(\n    VALIDATION_DIR,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='categorical'\n)"]}, {"cell_type": "markdown", "id": "29e5dd67", "metadata": {}, "source": ["#### Compile and train the model"]}, {"cell_type": "code", "execution_count": 1, "id": "0ef5438e", "metadata": {}, "outputs": [], "source": ["model.compile(\n    optimizer=optimizers.RMSprop(lr=2e-5),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=30,\n      validation_data=validation_generator,\n      validation_steps=50\n)"]}, {"cell_type": "code", "execution_count": 1, "id": "39cdaee7", "metadata": {}, "outputs": [], "source": ["model.save('/kaggle/output/models/PretrainedFlowerRecognition.h5')"]}, {"cell_type": "code", "execution_count": 1, "id": "e67ff007", "metadata": {}, "outputs": [], "source": ["acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()"]}, {"cell_type": "markdown", "id": "93404b10", "metadata": {}, "source": ["#### Unfreeze selected layers"]}, {"cell_type": "code", "execution_count": 1, "id": "4512f8f9", "metadata": {}, "outputs": [], "source": ["# Unfreeze the last 3 layers\nconv_base.trainable = True \nset_trainable = False\n\nfor layer in conv_base.layers:\n    if layer.name == \"block4_conv1\":\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\n        \nconv_base.summary()"]}, {"cell_type": "markdown", "id": "d9ec0cf4", "metadata": {}, "source": ["#### Compile and fine-tune the network"]}, {"cell_type": "markdown", "id": "c5a6c100", "metadata": {}, "source": ["Now we can start fine-tuning our network. We will do this with the RMSprop optimizer, using a very low learning rate. The reason for using a low learning rate is that we want to limit the magnitude of the modifications we make to the representations of the 3 layers that we are fine-tuning. Updates that are too large may harm these representations."]}, {"cell_type": "code", "execution_count": 1, "id": "17453e32", "metadata": {}, "outputs": [], "source": ["model.compile(\n    optimizer=optimizers.RMSprop(lr=1e-5),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n    \n)\n\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=20,\n      validation_data=validation_generator,\n     validation_steps=50\n)"]}, {"cell_type": "code", "execution_count": 1, "id": "dc396f03", "metadata": {}, "outputs": [], "source": ["model.save('/kaggle/output/models/PretrainedFlowerRecognitionFineTuned.h5')"]}, {"cell_type": "markdown", "id": "69c001e2", "metadata": {}, "source": ["#### Plot metrics"]}, {"cell_type": "code", "execution_count": 1, "id": "c4e362cd", "metadata": {}, "outputs": [], "source": ["acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()"]}, {"cell_type": "markdown", "id": "3059f0ab", "metadata": {}, "source": ["These curves look very noisy. To make them more readable, we can smooth them by replacing every loss and accuracy with exponential moving averages of these quantities. Here's a trivial utility function to do this:"]}, {"cell_type": "code", "execution_count": 1, "id": "9b993dbc", "metadata": {}, "outputs": [], "source": ["def smooth_curve(points, factor=0.8):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\n\nplt.plot(epochs, smooth_curve(acc), 'bo', label='Smoothed training acc')\nplt.plot(epochs, smooth_curve(val_acc), 'b', label='Smoothed validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, smooth_curve(loss), 'bo', label='Smoothed training loss')\nplt.plot(epochs, smooth_curve(val_loss), 'b', label='Smoothed validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()"]}, {"cell_type": "markdown", "id": "619501d0", "metadata": {}, "source": ["These curves look much cleaner and more stable. We are seeing a nice 4% absolute improvement.\n\nNote that **the loss curve does not show any real improvement** (in fact, it is deteriorating). How could accuracy improve if the loss isn't decreasing? The answer is simple: what we display is an average of pointwise loss values, but what actually matters for accuracy is the distribution of the loss values, not their average, since accuracy is the result of a binary thresholding of the class probability prediced by the model. The model may still be improving even if this isn't reflected in the average loss."]}, {"cell_type": "markdown", "id": "4e05a11c", "metadata": {}, "source": ["#### Evaluate the model on test data"]}, {"cell_type": "code", "execution_count": 1, "id": "bbd8dc33", "metadata": {}, "outputs": [], "source": ["test_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_directory(\n    TEST_DIR,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='categorical'\n)\n\ntest_loss, test_accuracy = model.evaluate(test_generator, steps=50)\nprint('test accuracy:', test_accuracy)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}