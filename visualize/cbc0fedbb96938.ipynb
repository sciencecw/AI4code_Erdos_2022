{"cells": [{"cell_type": "code", "execution_count": 1, "id": "de81883b", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "dacb8994", "metadata": {}, "source": ["## Bibliotecas"]}, {"cell_type": "code", "execution_count": 1, "id": "02c1d5a5", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.ensemble import RandomForestClassifier"]}, {"cell_type": "markdown", "id": "702e6b45", "metadata": {}, "source": ["## 1. Carregamento dos datasets"]}, {"cell_type": "code", "execution_count": 1, "id": "c586e014", "metadata": {}, "outputs": [], "source": ["# Carregando dados e verificando a quantidade de observa\u00e7\u00f5es\ndf_train = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/costa-rican-household-poverty-prediction/test.csv')\n\ndf_all = df_train.append(df_test)\n\ndf_train.shape, df_test.shape, df_all.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "ba0c739d", "metadata": {}, "outputs": [], "source": ["# verificando os tipos de variaveis\ndf_all.info(max_cols=143)"]}, {"cell_type": "markdown", "id": "82c1b87a", "metadata": {}, "source": ["## 1.1 Verificando duplicidades"]}, {"cell_type": "code", "execution_count": 1, "id": "616d8e5d", "metadata": {}, "outputs": [], "source": ["df_all.duplicated().value_counts()"]}, {"cell_type": "markdown", "id": "abd71c30", "metadata": {}, "source": ["## 1.2 Verificando Missing Values"]}, {"cell_type": "code", "execution_count": 1, "id": "fb1a8b9c", "metadata": {}, "outputs": [], "source": ["## verificando a quantidade de nulos\ndf_all.isna().sum().sort_values(ascending = False)[df_all.isnull().sum() >= 1]"]}, {"cell_type": "markdown", "id": "3566e948", "metadata": {}, "source": ["#### v2a1 = valor do aluguel mensal <br/>v18q1 = quantidade de tablets<br/>rez_esc = anos atrasado na escola<br/> meaneduc = media dos anos de educa\u00e7\u00e3o dos adultos <br/> SQBmeaned = raiz quadrado da m\u00e9dia dos anos de educa\u00e7\u00e3o dos adultos"]}, {"cell_type": "markdown", "id": "520d6e46", "metadata": {}, "source": ["## 1.3 Tratando Missing Values"]}, {"cell_type": "markdown", "id": "f9296f95", "metadata": {}, "source": ["### v18q1"]}, {"cell_type": "code", "execution_count": 1, "id": "731c26b4", "metadata": {}, "outputs": [], "source": ["# An\u00e1lise dos tablets v18q\ndf_all['v18q'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "836370a3", "metadata": {}, "outputs": [], "source": ["# Quantidade de nulos bate com a quantidade de individuos que n\u00e3o possuem tablets\ndf_all['v18q1'].isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "3c3158fd", "metadata": {}, "outputs": [], "source": ["# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)"]}, {"cell_type": "markdown", "id": "284be070", "metadata": {}, "source": ["A quantidade de nulos na vari\u00e1vel v18q1 possuem a mesma quantidade de observa\u00e7\u00f5es da variavel v18q (0). Subentende que os nulos s\u00e3o indiv\u00edduos que n\u00e3o possuem tablets. Logo aplicado tratativa para preencher com 0."]}, {"cell_type": "markdown", "id": "02c3f562", "metadata": {}, "source": ["### v2a1"]}, {"cell_type": "code", "execution_count": 1, "id": "893188af", "metadata": {}, "outputs": [], "source": ["# Verificando os valores de aluguel (v2a1) para os chefes/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "bea9a21e", "metadata": {}, "outputs": [], "source": ["# Prenchendo com -1 os valores nulos de v2a1 (tratativa do outlier)\ndf_all['v2a1'].fillna(-1, inplace=True)"]}, {"cell_type": "markdown", "id": "3e865e88", "metadata": {}, "source": ["Por se tratar de valores de pagamentos, o preenchimento com zero n\u00e3o \u00e9 vi\u00e1vel por se tratar de um valor que pode ser utilizado. Sendo assim, foi optado em identificar os nulos com -1 para serem detectados como outliers"]}, {"cell_type": "markdown", "id": "d92bf10d", "metadata": {}, "source": ["### meaneduc"]}, {"cell_type": "code", "execution_count": 1, "id": "a8368482", "metadata": {}, "outputs": [], "source": ["# Verificando a distancia entre a media e a mediana\ndf_all.meaneduc.mean(), df_all.meaneduc.median()"]}, {"cell_type": "code", "execution_count": 1, "id": "4a1fd885", "metadata": {}, "outputs": [], "source": ["# Preenchendo os valores nulos de meaneduc com o valor de 9 anos de estudos (entre m\u00e9dia e mediana), ou seja, uma tend\u00eancia geral dos dados\ndf_all['meaneduc'].fillna(df_all['meaneduc'].mean(), inplace=True)"]}, {"cell_type": "markdown", "id": "b7c381bf", "metadata": {}, "source": ["Vari\u00e1vel com poucos nulos. Como a m\u00e9dia \u00e9 pr\u00f3ximo da mediana, foi optado por utilizar a m\u00e9dia como m\u00e9todo de tratamento"]}, {"cell_type": "markdown", "id": "44543d29", "metadata": {}, "source": ["### SQBmeaned"]}, {"cell_type": "code", "execution_count": 1, "id": "e041ce1a", "metadata": {}, "outputs": [], "source": ["# Prenchendo com -1 os valores nulos de SQBmeaned (estrat\u00e9gia do outlier)\ndf_all['SQBmeaned'].fillna(-1, inplace=True)"]}, {"cell_type": "markdown", "id": "a06c95f7", "metadata": {}, "source": ["Vari\u00e1vel com poucos nulos. N\u00e3o faz sentido o preenchimento com a m\u00e9dia dos quadrados. Optado em identificar os nulos como outliers"]}, {"cell_type": "markdown", "id": "8a409b4e", "metadata": {}, "source": ["### rez_esc"]}, {"cell_type": "code", "execution_count": 1, "id": "6fff07ee", "metadata": {}, "outputs": [], "source": ["# Prenchendo com -1 os valores nulos de rez_esc (estrat\u00e9gia do outlier)\ndf_all['rez_esc'].fillna(-1, inplace=True)"]}, {"cell_type": "markdown", "id": "0db0a136", "metadata": {}, "source": ["Como o zero \u00e9 uma vari\u00e1vel poss\u00edvel de acontecer (0 anos de atrasos), foi optado em identificar os nulos como outliers"]}, {"cell_type": "markdown", "id": "08653dfe", "metadata": {}, "source": ["### Target"]}, {"cell_type": "code", "execution_count": 1, "id": "b6d565f7", "metadata": {}, "outputs": [], "source": ["df_all['Target'].isna().value_counts()"]}, {"cell_type": "markdown", "id": "13918eb4", "metadata": {}, "source": ["Os valores batem com a divis\u00e3o de base treino e teste. Sendo assim n\u00e3o ser\u00e1 realizado tratativa de missing values pois ser\u00e1 utilizado a mesma divis\u00e3o original e n\u00e3o haver\u00e1 missings."]}, {"cell_type": "markdown", "id": "65421453", "metadata": {}, "source": ["### Verificando resultado do tratamento dos missing values"]}, {"cell_type": "code", "execution_count": 1, "id": "86623188", "metadata": {}, "outputs": [], "source": ["## verificando a quantidade de nulos\ndf_all.isna().sum().sort_values(ascending = False)[df_all.isnull().sum() >= 1]"]}, {"cell_type": "markdown", "id": "a6c824cf", "metadata": {}, "source": ["## 1.4 Utilizando dicion\u00e1rio de dados"]}, {"cell_type": "code", "execution_count": 1, "id": "fc573f55", "metadata": {}, "outputs": [], "source": ["# verificando possiveis variaveis categoricas\ndf_all.select_dtypes('object').head()"]}, {"cell_type": "markdown", "id": "a140aef3", "metadata": {}, "source": ["#### Dicionario de dados\n#### id - Identificador de um membro da fam\u00edlia <br/> idhogar - Identificador de familia <br/> dependency - Taxa de depend\u00eancia<br/> edjefa - anos de escolaridade do chefe de fam\u00edlia do sexo feminino <br/> edjefe - anos de escolaridade do chefe de fam\u00edlia do sexo masculino"]}, {"cell_type": "code", "execution_count": 1, "id": "0e48902b", "metadata": {}, "outputs": [], "source": ["# Tratando valores quantitativos de acordo com o dicion\u00e1rio \nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)"]}, {"cell_type": "code", "execution_count": 1, "id": "714eae2f", "metadata": {}, "outputs": [], "source": ["# verificando possiveis variaveis categoricas\ndf_all.select_dtypes('object').head()"]}, {"cell_type": "markdown", "id": "7f680545", "metadata": {}, "source": ["Analisando dataframe de treino"]}, {"cell_type": "markdown", "id": "fc4b9b3a", "metadata": {}, "source": ["## 2. Separando dataframes"]}, {"cell_type": "code", "execution_count": 1, "id": "5d40c780", "metadata": {}, "outputs": [], "source": ["# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]"]}, {"cell_type": "code", "execution_count": 1, "id": "7ba2e48b", "metadata": {}, "outputs": [], "source": ["# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\nXtrain, Ytrain = train[feats], train[['Target']]\nXtest, Ytest = test[feats], test[['Target']]\n\nXtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape"]}, {"cell_type": "markdown", "id": "c0d3ff26", "metadata": {}, "source": ["## 3. An\u00e1lise Explorat\u00f3ria"]}, {"cell_type": "markdown", "id": "ad52d36a", "metadata": {}, "source": ["### Composi\u00e7\u00e3o da vari\u00e1vel Target"]}, {"cell_type": "code", "execution_count": 1, "id": "a7493452", "metadata": {}, "outputs": [], "source": ["# Analisando vari\u00e1vel Target\nax = sns.countplot(data=Ytrain, x=\"Target\")\nplt.show()"]}, {"cell_type": "markdown", "id": "ccc0853b", "metadata": {}, "source": ["Nota-se enviesamento dos dados da vari\u00e1vel Target"]}, {"cell_type": "code", "execution_count": 1, "id": "90512c49", "metadata": {}, "outputs": [], "source": ["# Verificando valores absolutos\nYtrain['Target'].value_counts()"]}, {"cell_type": "markdown", "id": "1e318379", "metadata": {}, "source": ["### Composi\u00e7\u00e3o do grupo familiar"]}, {"cell_type": "code", "execution_count": 1, "id": "b6b1cd9d", "metadata": {}, "outputs": [], "source": ["# Parentesco dos ocupantes das resid\u00eancias\nvar = 'parentesco1','parentesco2','parentesco3','parentesco4','parentesco5','parentesco6','parentesco7','parentesco8','parentesco9','parentesco10','parentesco11','parentesco12'\nleg = ['Chefe de fam\u00edlia','C\u00f4njuge','Filho(a)','Enteado(a)','Genro/Nora','Neto(a)','Pai/M\u00e3e','Sogro(a)','Irm\u00e3o/Irm\u00e3','Cunhado(a)','Outro familiar','Outro n\u00e3o familiar']\n\ny = []\nfor v in var: \n    y.append(Xtrain[v].value_counts()[1])\n    \nplt.figure(figsize=(18,5))\nsns.barplot(x=leg, y=y).set_title(\"Parentesco\")\nplt.show()"]}, {"cell_type": "markdown", "id": "99720823", "metadata": {}, "source": ["### Perfil do chefe de fam\u00edlia"]}, {"cell_type": "code", "execution_count": 1, "id": "e5791088", "metadata": {}, "outputs": [], "source": ["# Sexo dos ocupantes das resid\u00eancias\nvar = 'male','female'\nleg = ['Masculino','Feminino']\n\ny = []\nfor v in var: \n    y.append(Xtrain[Xtrain['parentesco1'] == 1][v].value_counts()[1])\n    \nplt.figure(figsize=(18,5))\nsns.barplot(x=leg, y=y).set_title(\"Sexo\")\nplt.show()"]}, {"cell_type": "markdown", "id": "3f4694b6", "metadata": {}, "source": ["### Tipo de Moradia"]}, {"cell_type": "code", "execution_count": 1, "id": "f3166b89", "metadata": {}, "outputs": [], "source": ["# Tipo de moradia\nvar = 'tipovivi1','tipovivi2','tipovivi3','tipovivi4','tipovivi5'\nleg = ['Pr\u00f3pria','Financiada','Alugada','Prec\u00e1ria','Outras']\n\ny = []\nfor v in var: \n    y.append(Xtrain[v].value_counts()[1])\n    \nplt.figure(figsize=(18,5))\nsns.barplot(x=leg, y=y).set_title(\"Tipo de Moradia\")\nplt.show()"]}, {"cell_type": "markdown", "id": "920dfc95", "metadata": {}, "source": ["## 4. Balanceamento com Over-Sampling"]}, {"cell_type": "code", "execution_count": 1, "id": "228b68d9", "metadata": {}, "outputs": [], "source": ["# Verificando a distribui\u00e7\u00e3o das classes na vari\u00e1vel Target\nYtrain[\"Target\"].value_counts(normalize = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "3466cc7c", "metadata": {}, "outputs": [], "source": ["# Fazendo o over-sampling\nros = RandomOverSampler(random_state=42)\nX_over,y_over= ros.fit_resample(Xtrain,Ytrain)\n\n# Verificando os dados\ny_over['Target'].value_counts(normalize = True)"]}, {"cell_type": "markdown", "id": "d6e81899", "metadata": {}, "source": ["## 5. Treinando o modelo"]}, {"cell_type": "code", "execution_count": 1, "id": "f268e984", "metadata": {}, "outputs": [], "source": ["rf = RandomForestClassifier(n_jobs=1, n_estimators=200, random_state=42)\nrf.fit(X_over,y_over)"]}, {"cell_type": "code", "execution_count": 1, "id": "e060a229", "metadata": {}, "outputs": [], "source": ["# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)\ntest['Target'].value_counts(normalize=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "73d55067", "metadata": {}, "outputs": [], "source": ["# submitendo\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)"]}, {"cell_type": "markdown", "id": "1fe446e3", "metadata": {}, "source": ["## 6. Utilizando balanceamento Under-sampling"]}, {"cell_type": "code", "execution_count": 1, "id": "c1c657e6", "metadata": {}, "outputs": [], "source": ["# Fazendo o over-sampling\nros = RandomUnderSampler(random_state=42)\nX_under,y_under= ros.fit_resample(Xtrain,Ytrain)\n\n# Verificando os dados\ny_under['Target'].value_counts(normalize = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "bbab8798", "metadata": {}, "outputs": [], "source": ["rf = RandomForestClassifier(n_jobs=1, n_estimators=200, random_state=42)\nrf.fit(X_under,y_under)"]}, {"cell_type": "code", "execution_count": 1, "id": "e185a3c1", "metadata": {}, "outputs": [], "source": ["# Prever o Target de teste usando o modelo treinado\ntest['Target'] = rf.predict(test[feats]).astype(int)\ntest['Target'].value_counts(normalize=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "6c55c00a", "metadata": {}, "outputs": [], "source": ["# submitendo\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)"]}, {"cell_type": "markdown", "id": "73b45019", "metadata": {}, "source": ["## 7. Verificando a import\u00e2ncia de cada vari\u00e1vel"]}, {"cell_type": "code", "execution_count": 1, "id": "1af6c393", "metadata": {}, "outputs": [], "source": ["# Verificando o peso de cada coluna na predi\u00e7\u00e3o\nfig = plt.figure(figsize=(15, 20))\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}