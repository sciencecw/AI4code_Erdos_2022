{"cells": [{"cell_type": "markdown", "id": "05c9796b", "metadata": {}, "source": ["# Seasonal Persistence Model Predictions"]}, {"cell_type": "markdown", "id": "9eee9a72", "metadata": {}, "source": ["![ ](https://i.imgur.com/jSMD7Gj.gif)"]}, {"cell_type": "code", "execution_count": 1, "id": "d23478da", "metadata": {}, "outputs": [], "source": ["# from PIL import Image\n# import imageio\n\n# list_images = []\n\n# for i in range(649):\n#     image = Image.open('../input/seasonal-persistence-model/'+str(i)+'_plot.png')\n#     list_images.append(image)\n\n# list_images[0]\n\n# imageio.mimwrite('baseline_predictions.gif', list_images, fps=3)"]}, {"cell_type": "markdown", "id": "7be43175", "metadata": {}, "source": ["## General Import"]}, {"cell_type": "code", "execution_count": 1, "id": "7a1e6611", "metadata": {}, "outputs": [], "source": ["from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom math import sqrt\n\nimport gc\nimport time\nimport seaborn as sns; sns.set()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "797b507a", "metadata": {}, "outputs": [], "source": ["import geojson\nimport geopandas as gpd\nfrom fiona.crs import from_epsg\nimport os, json\nfrom shapely.geometry import shape, Point, Polygon, MultiPoint\nfrom geopandas.tools import sjoin\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns; sns.set()\nfrom IPython.display import Image\n\nimport pickle\nimport folium\n\n\nfrom branca.colormap import  linear\nimport json\nimport branca.colormap as cm\n\nfrom tqdm.notebook import tqdm"]}, {"cell_type": "markdown", "id": "b084f92e", "metadata": {}, "source": ["# Visualize Streets Network"]}, {"cell_type": "code", "execution_count": 1, "id": "be58830a", "metadata": {}, "outputs": [], "source": ["df_belgium = gpd.read_file('/kaggle/input/belgium-obu/Belgium_streets.json')\n\nm = folium.Map([50.85045, 4.34878], zoom_start=9, tiles='cartodbpositron')\nfolium.GeoJson(df_belgium).add_to(m)\nm"]}, {"cell_type": "code", "execution_count": 1, "id": "193689ca", "metadata": {}, "outputs": [], "source": ["# BXL_timeseries_kaggle.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\nnew_table = pd.read_csv('../input/obu-data-preprocessing/Flow_BEL_street_30min.csv')\nnRow, nCol = new_table.shape\nprint(f'There are {nRow} rows and {nCol} columns')\n"]}, {"cell_type": "markdown", "id": "0e8e6aac", "metadata": {}, "source": ["# SELECT STREETS BASED ON AVERAGE TRAFFIC FLOW"]}, {"cell_type": "code", "execution_count": 1, "id": "4c6f65b4", "metadata": {}, "outputs": [], "source": ["mean_value = 10"]}, {"cell_type": "code", "execution_count": 1, "id": "ffbf028e", "metadata": {}, "outputs": [], "source": ["table_index = new_table.iloc[:,1:]\nALL_STREETS = list(table_index.columns.values)\n\nmean_flow =[]\nnew_street=[]\n\n\nfor street in ALL_STREETS:\n    \n    single_street=table_index[street]\n    mean = np.mean(single_street)\n    mean_flow.append(mean)\n    new_street.append(street)\n    \n    \ndf_mean_flow = pd.DataFrame({'street_index':new_street, 'mean_flow': mean_flow})\nprint('')\nprint(df_mean_flow.head())\nprint('')\n\nSTREETS = df_mean_flow[(df_mean_flow['mean_flow'] >= mean_value)] \nSTREETS = STREETS.sort_values(by=['street_index'])\nSTREETS = list(STREETS.street_index)\n\n\nprint('considering a average traffic flow of ' + str(mean_value)+' per street')\nprint('')\nprint('mean traffic flow '+str(mean_value)+ ' ---> number of street segments: ' + str(len(STREETS)))\n"]}, {"cell_type": "markdown", "id": "c22ed7d5", "metadata": {}, "source": ["# Prepare Data For Multistep-ahead Forecasting, Split in Training and Testing Sets"]}, {"cell_type": "code", "execution_count": 1, "id": "f1d743bb", "metadata": {}, "outputs": [], "source": ["def split_sequences_multistep(sequences, n_steps_in, n_steps_out):\n    X, y = list(), list()\n    for i in range(len(sequences)):\n        # find the end of this pattern\n        end_ix = i + n_steps_in\n        out_end_ix = end_ix + n_steps_out\n        # check if we are beyond the dataset\n        if out_end_ix > len(sequences):\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n        X.append(seq_x)\n        y.append(seq_y)\n    return np.array(X), np.array(y)"]}, {"cell_type": "code", "execution_count": 1, "id": "43c3d7c1", "metadata": {}, "outputs": [], "source": ["# transform series into train and test sets for supervised learning\n\ndef data_mimo_persistent(dataframe, n_train, n_lag, n_output):\n    # extract raw values\n    raw_values = dataframe.values\n    # transform into supervised learning problem X, y\n    X,Y = split_sequences_multistep(raw_values, n_lag, n_output)\n    X_tr,Y_tr, X_val, Y_val = X[:-n_train+23], Y[:-n_train+23], X[-n_train+23:],Y[-n_train+23:]\n    \n    return X_tr,Y_tr, X_val, Y_val"]}, {"cell_type": "code", "execution_count": 1, "id": "444e8472", "metadata": {}, "outputs": [], "source": ["n_LAGS = 12\nn_OUTPUT = 12\n\ntable_date = new_table\ntable_date['datetime'] = pd.to_datetime(table_date['datetime'])\n\n    \nDATAFRAME = table_date\nDATAFRAME = DATAFRAME.drop('datetime',axis=1)\nDATAFRAME = DATAFRAME[DATAFRAME.columns.intersection(STREETS)]\nDATAFRAME['datetime'] = table_date['datetime']\n\nnRow, nCol = DATAFRAME.shape\nprint(f'Consider {nRow} instances (rows) and {nCol} streets segments (columns)')\nprint('')\n\nn_TRAIN = 168*2*2 # 2 weeks\n\nX_tr_pers, Y_tr_pers, X_val_pers, Y_val_pers = data_mimo_persistent(DATAFRAME, n_TRAIN, n_LAGS, n_OUTPUT)\n\ndatetime = X_val_pers[:,:,-1]\n\nx_tr_pers = X_tr_pers[:,:,:-1]\ny_tr_pers = Y_tr_pers[:,:,:-1]\nx_val_pers = X_val_pers[:,:,:-1]\ny_val_pers = Y_val_pers[:,:,:-1]\n\nprint('X_Train: %s, Y_Train: %s' % (x_tr_pers.shape, y_tr_pers.shape))\nprint('')\nprint('X_Valid: %s, Y_Valid: %s' % (x_val_pers.shape, y_val_pers.shape))"]}, {"cell_type": "markdown", "id": "b9f46968", "metadata": {}, "source": ["# Visualize Traffic Flow at time t"]}, {"cell_type": "code", "execution_count": 1, "id": "67c7e5e7", "metadata": {}, "outputs": [], "source": ["\nSTREETS = [int(float(s)) for s in STREETS]\n\n\ndf_belgium = df_belgium[df_belgium.index.isin(STREETS)]\ndf_belgium['Trucks_Flow'] = y_val_pers[12][5]\n\nnbh_count_colormap = linear.YlOrRd_09.scale(0,200)\n\ncolormap_dept = cm.StepColormap(\n    colors=['#00ae53', '#86dc76', '#daf8aa',\n            '#ffe6a4', '#ff9a61', '#ee0028'],\n    vmin = 0,\n    vmax = 200,\n    index=[0, 20, 50, 80, 110, 150, 180])\n\npolygons = df_belgium\nm = folium.Map([50.85045, 4.34878], zoom_start= 9, tiles='cartodbpositron')\n\nstyle_function = lambda x: {\n    'fillColor': colormap_dept(x['properties']['Trucks_Flow']),\n    'color': colormap_dept(x['properties']['Trucks_Flow']),\n    'weight': 1.5,\n    'fillOpacity': 1\n}\nfolium.GeoJson(polygons,\n    style_function=style_function).add_to(m)\n\n\ncolormap_dept.caption = 'Traffic Flow (N#Trucks/30min) at (not real) 12:00 a.m.'\ncolormap_dept.add_to(m)\n\nm"]}, {"cell_type": "markdown", "id": "090c40e4", "metadata": {}, "source": ["# Function defining Seasonal Persistence Model"]}, {"cell_type": "code", "execution_count": 1, "id": "96afb9f2", "metadata": {}, "outputs": [], "source": ["def seasonal_mean(X, seas, n_seq):\n    \n    seas_0 = 168*2*2*2\n    seas_1 = 168*2*2+168*2\n    seas_2 = 168*2*2\n    seas_3 = 168*2\n    \n\n    \n    list_seas_0 = []\n    list_seas_1 = []\n    list_seas_2 = []\n    list_seas_3 = []\n    \n    if seas > X.shape[0]:\n        \n        for i in reversed(range(1,24*2 +1)):\n            season = X[-i][-1]\n            list_seas.append(season)\n    else:\n        \n        for i in reversed(range(seas_1+1,seas_0+1)):\n            season_0 = X[-i][-1]\n            list_seas_0.append(season_0)\n            \n        for i in reversed(range(seas_2+1,seas_1+1)):\n            season_1 = X[-i][-1]\n            list_seas_1.append(season_1)\n            \n        for i in reversed(range(seas_3+1,seas_2+1)):\n            season_2 = X[-i][-1]\n            list_seas_2.append(season_2)\n            \n        for i in reversed(range(1,seas_3+1)):\n            season_3 = X[-i][-1]\n            list_seas_3.append(season_3)\n            \n        list_seas = np.array([np.vstack(list_seas_0),\n                              np.vstack(list_seas_1),\n                              np.vstack(list_seas_2),\n                              np.vstack(list_seas_3)]).mean(axis=0)\n            \n    return list_seas[:n_seq]"]}, {"cell_type": "markdown", "id": "71aa8ad8", "metadata": {}, "source": ["# Test Model"]}, {"cell_type": "code", "execution_count": 1, "id": "aa18315b", "metadata": {}, "outputs": [], "source": ["import math\n\n\ndef evaluate_forecasts(targets, forecasts, n_seq):\n    \n    list_rmse = []\n    list_mae = []\n    \n    for i in range(n_seq):\n        \n        true = np.vstack([target[i] for target in targets])\n        predicted = np.vstack([forecast[i] for forecast in forecasts])\n        \n        rmse = np.sqrt((np.square(true - predicted)).mean(axis=0))\n        mae = np.absolute(true - predicted).mean(axis=0)\n        \n        list_rmse.append(rmse)\n        list_mae.append(mae)\n        \n    list_rmse = np.vstack(list_rmse)\n    list_mae = np.vstack(list_mae)\n    \n    return list_rmse, list_mae"]}, {"cell_type": "code", "execution_count": 1, "id": "4f700a50", "metadata": {}, "outputs": [], "source": ["seas = 168*2*2*2 # weekly season - past 4 weeks \n\nforecasts = []\ntargets = []\n\nrmse_list = []\nmae_list = []\n\nimg_list = []\n\n\nfor i in tqdm(range(len(y_val_pers))):\n\n    \n    x_tr_pers = np.insert(x_tr_pers, x_tr_pers.shape[0], x_val_pers[i], axis=0)\n    Y = y_val_pers[i]\n    \n    # make forecast\n    forecast = seasonal_mean(x_tr_pers, seas, n_OUTPUT).astype(np.int32)\n    \n    # retrieve true value\n    true_value = Y.astype(np.int32)\n\n    forecasts.append(forecast)\n    targets.append(true_value)\n    \n    # evaluate model performance each period\n    rmse, mae = evaluate_forecasts(targets, forecasts, 12)\n           \n    rmse_list.append(rmse)\n    mae_list.append(mae)\n    \n    # Forecast Horizons - H = {1, 2, ..., 12}\n    x = ['t+1','t+2','t+3','t+4','t+5','t+6','t+7','t+8','t+9','t+10','t+11','t+12']\n\n    fig = plt.figure(figsize=(15,7))\n    \n    plt.subplot(311)\n    plt.title('Sum of predictions for all highways in Belgium')\n    plt.plot(np.sum(forecast, axis=1), label='Baseline Prediction') \n    plt.plot(np.sum(true_value, axis=1), label='Truth')\n    plt.ylabel('Trucks Flow')\n    plt.ylim(-1, 350000)\n#     plt.xticks(rotation=45)\n    plt.legend()\n    \n    plt.subplot(312)\n    plt.plot(np.sum(forecast, axis=1), label='Baseline Prediction') \n    plt.plot(np.sum(true_value, axis=1), label='Truth')\n    plt.ylabel('Zoom ')\n#     plt.ylim(-1, 150)\n#     plt.xticks(rotation=45)\n    plt.legend()\n    \n    plt.subplot(313)\n    plt.errorbar(x, np.absolute(true_value - forecast).mean(axis=1), mae_list[-1].std(axis=1),\n                 fmt='o', color='grey',\n                 ecolor='lightblue', elinewidth=3, capsize=0)\n    \n    plt.ylabel('error MAE +- std')\n    plt.xticks(rotation=45)\n    plt.xlabel('Time (t): '+str(datetime[i][-1]))\n\n#     plt.show()\n    fig.savefig(str(i)+'_plot.png')\n#     img_list.append(fig)\n    fig.clear()\n    plt.close(fig)\n\n\n#     print('Prediction Accuracy (MAE) '+str(np.absolute(true_value - forecast).mean()))\n\n    \n    del forecast, true_value, rmse, mae, x\n    gc.collect()\n\n\n# # Saving the objects:\n# with open('list_plots.pickle', 'wb') as f:\n#     pickle.dump([img_list], f)"]}, {"cell_type": "code", "execution_count": 1, "id": "89f2a9bc", "metadata": {}, "outputs": [], "source": ["RMSE_MEAN = np.mean(rmse_list,axis=0).mean(axis=1)\nRMSE_STD =  np.std(rmse_list,axis=0).std(axis=1)\n\nfor i in range(len(RMSE_MEAN)):\n    print('t+'+str(i+1)+' RMSE MEAN ' +str(np.round(RMSE_MEAN[i],3))+' +- '+str(np.round(RMSE_STD[i],3)))\n    print('')\n    "]}, {"cell_type": "code", "execution_count": 1, "id": "707431e7", "metadata": {}, "outputs": [], "source": ["MAE_MEAN = np.mean(mae_list,axis=0).mean(axis=1)\nMAE_STD =  np.std(mae_list,axis=0).std(axis=1)\n\nfor i in range(len(MAE_MEAN)):\n    print('t+'+str(i+1)+' MAE MEAN ' +str(np.round(MAE_MEAN[i],3))+' +- '+str(np.round(MAE_STD[i],3)))\n    print('')\n    "]}, {"cell_type": "code", "execution_count": 1, "id": "4ef01fd4", "metadata": {}, "outputs": [], "source": ["import pickle\n\n# Saving the objects:\nwith open('save_predictions_results.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n    pickle.dump([rmse_list, mae_list], f)"]}, {"cell_type": "markdown", "id": "d33c0591", "metadata": {}, "source": ["# Results Comparison between Seasonal model (baseline) and LSTM encoder decoder model"]}, {"cell_type": "code", "execution_count": 1, "id": "935f5483", "metadata": {}, "outputs": [], "source": ["# mean_rmse_seas = [12.432, 12.42, 12.421, 12.425, 12.437, 12.463, 12.522, 10.868, 10.387, 10.321, 10.264, 10.199]\n# std_rmse_seas = [2.34, 2.448, 2.584, 2.74, 2.936, 3.23, 3.815, 2.107, 1.749, 1.767, 1.759, 1.7]\n\n# mean_rmse_ed = [11.618, 11.485, 11.646, 11.626, 11.693, 11.576, 11.625, 9.712, 9.081, 9.035, 9.009, 8.988]\n# std_rmse_ed = [2.286, 2.57, 2.998, 3.143, 3.281, 3.472, 4.122, 2.175, 1.526, 1.528, 1.517, 1.471]\n\n# mean_mae_seas = [7.592, 7.566, 7.552, 7.541, 7.536, 7.55, 7.614, 6.977, 6.727, 6.677, 6.636, 6.587]\n# std_mae_seas = [1.674, 1.746, 1.861, 1.998, 2.153, 2.465, 3.361, 1.865, 1.395, 1.379, 1.343, 1.214]\n\n# mean_mae_ed = [7.266, 6.988, 6.997, 6.983, 6.992, 6.967, 7.028, 6.336, 6.052, 6.027, 6.02, 6.013]\n# std_mae_ed = [1.65, 1.699, 1.983, 2.155, 2.312, 2.563, 3.529, 1.919, 1.26, 1.235, 1.201, 1.125]\n\n# ax = ['t+1', 't+2', 't+3', 't+4', 't+5', 't+6', 't+7', 't+8','t+9','t+10','t+11','t+12']\n\n\n# mean_rmse = pd.DataFrame(list(zip(mean_rmse_seas, mean_rmse_ed)), \n#                columns = ['SW', 'ED'], index=ax)\n\n\n# std_rmse = pd.DataFrame(list(zip(std_rmse_seas, std_rmse_ed)),\n#                    columns = ['SW', 'ED'],index=ax)\n\n\n# mean_mae = pd.DataFrame(list(zip(mean_mae_seas, mean_mae_ed)), \n#                columns = ['SW', 'ED'], index=ax)\n\n\n# std_mae = pd.DataFrame(list(zip(std_mae_seas, std_mae_ed)),\n#                    columns = ['SW', 'ED'],index=ax)\n\n\n# fig, ax = plt.subplots(figsize=(12, 5))\n# mean_rmse.plot.bar(yerr=std_rmse, ax=ax, capsize=3, rot=45, grid=True, color=['green', 'orange'])\n# fig.suptitle('Multi-horizon RMSE', fontsize=20)\n# plt.show()\n \n# fig, ax = plt.subplots(figsize=(12, 5))\n# mean_mae.plot.bar(yerr=std_mae, ax=ax, capsize=3, rot=45, grid=True, color=['limegreen', 'goldenrod'])\n# fig.suptitle('Multi-horizon MAE', fontsize=20)\n# plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}