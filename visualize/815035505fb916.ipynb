{"cells": [{"cell_type": "code", "execution_count": 1, "id": "1eee74a5", "metadata": {}, "outputs": [], "source": ["import os\nimport tempfile\nfrom dipy.segment.mask import median_otsu\nfrom dipy.core.gradients import gradient_table\nfrom dipy.reconst.shm import CsaOdfModel\nfrom dipy.direction import peaks_from_model\nfrom dipy.direction import ProbabilisticDirectionGetter\nfrom dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel\nfrom dipy.direction import peaks_from_model\nfrom dipy.tracking.local import LocalTracking, ThresholdTissueClassifier\nfrom dipy.tracking import utils\nfrom dipy.reconst import peaks, shm\nfrom dipy.viz import window, actor\nfrom dipy.viz.colormap import line_colors\nfrom dipy.tracking.streamline import Streamlines\nfrom dipy.tracking.eudx import EuDX\nfrom nilearn.plotting import plot_anat, plot_roi, plot_stat_map\nfrom nilearn.image import index_img, iter_img, new_img_like, math_img\nfrom IPython.display import Image\nfrom xvfbwrapper import Xvfb\nimport nibabel as nb\nimport pylab as plt\nimport numpy as np"]}, {"cell_type": "code", "execution_count": 1, "id": "552685a6", "metadata": {}, "outputs": [], "source": ["# helper function for plotting woth dipy and VTK on a headless system\ndef show_image(actor, size=(1000,1000)):\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        temp_filename = os.path.join(tmp_dir, 'tmp.png')\n        with Xvfb() as xvfb:\n            ren = window.Renderer()\n            ren.add(actor)\n            window.record(ren, n_frames=1, out_path=temp_filename, size=size)\n            window.clear(ren)\n        return Image(filename=temp_filename) "]}, {"cell_type": "markdown", "id": "4f49df8b", "metadata": {}, "source": ["This tutorial has been adopted from materials available at http://nipy.org/dipy/examples_index.html\n# Exploring the data\nLets start by exploring the diffusion weighted data. We will start by loading the NIfTI file."]}, {"cell_type": "code", "execution_count": 1, "id": "7d689d2b", "metadata": {}, "outputs": [], "source": ["img = nb.load('../input/hardi150.nii/HARDI150.nii')\ndata = img.get_data()\ndata.shape"]}, {"cell_type": "markdown", "id": "22246a15", "metadata": {}, "source": ["The file is four dimensional. The fourth dimension corresponds to the different diffusion orientation probed during the scan. In addition to the NIfTI file we will need two more files - one with diffusion weights and one with orientations."]}, {"cell_type": "code", "execution_count": 1, "id": "5ac1c69b", "metadata": {}, "outputs": [], "source": ["gtab = gradient_table('../input/HARDI150.bval', '../input/HARDI150.bvec')\n(gtab.bvals == 0).sum()"]}, {"cell_type": "markdown", "id": "83de898c", "metadata": {}, "source": ["As you can see the first 10 volumes are not diffusion weighted and the rest are probing diffusion at different orientations described in the `bvecs` file."]}, {"cell_type": "code", "execution_count": 1, "id": "62d55383", "metadata": {}, "outputs": [], "source": ["gtab.bvecs.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "5fcce168", "metadata": {}, "outputs": [], "source": ["show_image(actor.point(gtab.gradients, window.colors.blue, point_radius=100))"]}, {"cell_type": "markdown", "id": "87d8d2cd", "metadata": {}, "source": ["Lets have a look at the data and plot the first volume."]}, {"cell_type": "code", "execution_count": 1, "id": "ea4ba77f", "metadata": {}, "outputs": [], "source": ["i = 0\ncur_img = index_img(img, i)\nplot_anat(cur_img, cut_coords=(0,0,2), draw_cross=False, figure=plt.figure(figsize=(18,4)), cmap='magma', \n              vmin=0, vmax=1600, title=\"bval = %g, bvec=%s\"%(gtab.bvals[i], str(np.round(gtab.bvecs[i,:],2))))\n\ni = 38\ncur_img = index_img(img, i)\nplot_anat(cur_img, cut_coords=(0,0,2), draw_cross=False, figure=plt.figure(figsize=(18,4)), cmap='magma', \n              vmin=0, vmax=400, title=\"bval = %g, bvec=%s\"%(gtab.bvals[i], str(np.round(gtab.bvecs[i,:],2))))\n\ni = 70\ncur_img = index_img(img, i)\nplot_anat(cur_img, cut_coords=(0,0,2), draw_cross=False, figure=plt.figure(figsize=(18,4)), cmap='magma', \n              vmin=0, vmax=400, title=\"bval = %g, bvec=%s\"%(gtab.bvals[i], str(np.round(gtab.bvecs[i,:],2))))"]}, {"cell_type": "markdown", "id": "10176567", "metadata": {}, "source": ["As you can see the diffusion unweighted volume (also called `b0` since the `b` value is zero) is brighter than diffusion weighted volumes. The other volumes have properties that depend on the diffusion orientation.\n\n**Excercise: plot other diffusion weighted and unweighted volumes.**"]}, {"cell_type": "markdown", "id": "d86a16bf", "metadata": {}, "source": ["# Fitting a model of diffusion signal"]}, {"cell_type": "code", "execution_count": 1, "id": "58c26c33", "metadata": {}, "outputs": [], "source": ["csa_model = CsaOdfModel(gtab, sh_order=8)"]}, {"cell_type": "code", "execution_count": 1, "id": "c90a87a8", "metadata": {}, "outputs": [], "source": ["data_small = data[30:50, 65:85, 38:39]\ncsa_fit_small = csa_model.fit(data_small)"]}, {"cell_type": "code", "execution_count": 1, "id": "d58401bb", "metadata": {}, "outputs": [], "source": ["csa_odf_small = csa_fit_small.odf(peaks.default_sphere)"]}, {"cell_type": "markdown", "id": "933a3a36", "metadata": {}, "source": ["## Ploting orientation probability distributions"]}, {"cell_type": "code", "execution_count": 1, "id": "830b7dab", "metadata": {}, "outputs": [], "source": ["fodf_spheres_small = actor.odf_slicer(csa_odf_small, sphere=peaks.default_sphere, scale=0.9, norm=False, colormap='plasma')\nshow_image(fodf_spheres_small)"]}, {"cell_type": "markdown", "id": "d90916b9", "metadata": {}, "source": ["## Ploting principal orientations"]}, {"cell_type": "code", "execution_count": 1, "id": "81f706d5", "metadata": {}, "outputs": [], "source": ["csd_peaks_small = peaks_from_model(model=csa_model,\n                                   data=data_small,\n                                   sphere=peaks.default_sphere,\n                                   relative_peak_threshold=.5,\n                                   min_separation_angle=25,\n                                   parallel=True)\n\nfodf_peaks_small = actor.peak_slicer(csd_peaks_small.peak_dirs, csd_peaks_small.peak_values)\nshow_image(fodf_peaks_small)"]}, {"cell_type": "markdown", "id": "84cb98c7", "metadata": {}, "source": ["**Excercise: change the `sh_order` parameter**"]}, {"cell_type": "markdown", "id": "66c52146", "metadata": {}, "source": ["## Fitting model in the whole brain"]}, {"cell_type": "code", "execution_count": 1, "id": "b56d2741", "metadata": {}, "outputs": [], "source": ["labels_img = nb.load(\"../input/aparc-reduced.nii/aparc-reduced.nii\")\nplot_roi(math_img(\"(labels == 1) | (labels == 2)\", labels=labels_img), index_img(img, 0),figure=plt.figure(figsize=(18,4)),)"]}, {"cell_type": "code", "execution_count": 1, "id": "ca827419", "metadata": {}, "outputs": [], "source": ["labels = labels_img.get_data()\nwhite_matter = (labels == 1) | (labels == 2)\ncsa_model = shm.CsaOdfModel(gtab, 6)\ncsa_fit = csa_model.fit(data)\ncsa_peaks = peaks.peaks_from_model(model=csa_model,\n                                   data=data,\n                                   sphere=peaks.default_sphere,\n                                   relative_peak_threshold=.8,\n                                   min_separation_angle=45,\n                                   mask=white_matter)"]}, {"cell_type": "code", "execution_count": 1, "id": "95f6020e", "metadata": {}, "outputs": [], "source": ["gfa_img = nb.Nifti1Image(csa_peaks.gfa, img.affine)\nplot_stat_map(gfa_img, index_img(img,0),figure=plt.figure(figsize=(18,4)))"]}, {"cell_type": "markdown", "id": "1bd28777", "metadata": {}, "source": ["# Reconstructing white matter tracks "]}, {"cell_type": "markdown", "id": "1a5fa694", "metadata": {}, "source": ["## Picking the seed"]}, {"cell_type": "code", "execution_count": 1, "id": "cf32b3b2", "metadata": {}, "outputs": [], "source": ["classifier = ThresholdTissueClassifier(csa_peaks.gfa, .25)"]}, {"cell_type": "code", "execution_count": 1, "id": "7fe8379d", "metadata": {}, "outputs": [], "source": ["plot_roi(math_img(\"x == 2\", x=labels_img), index_img(img, 0), figure=plt.figure(figsize=(18,4)))"]}, {"cell_type": "code", "execution_count": 1, "id": "09011f1f", "metadata": {}, "outputs": [], "source": ["seed_mask = labels == 2\nseeds = utils.seeds_from_mask(seed_mask, density=[2, 2, 2], affine=img.affine)"]}, {"cell_type": "markdown", "id": "035970a5", "metadata": {}, "source": ["## Deterministic tracking"]}, {"cell_type": "code", "execution_count": 1, "id": "16be31c6", "metadata": {}, "outputs": [], "source": ["# Initialization of LocalTracking. The computation happens in the next step.\nstreamlines_generator = LocalTracking(csa_peaks, classifier, seeds, img.affine, step_size=.5)\n\n# Generate streamlines object\nstreamlines = Streamlines(streamlines_generator)\n\ncolor = line_colors(streamlines)\nstreamlines_actor = actor.line(streamlines, line_colors(streamlines))\nshow_image(streamlines_actor)"]}, {"cell_type": "markdown", "id": "d2678918", "metadata": {}, "source": ["## Probabilistic tracking"]}, {"cell_type": "code", "execution_count": 1, "id": "1a3d46e3", "metadata": {}, "outputs": [], "source": ["prob_dg = ProbabilisticDirectionGetter.from_shcoeff(csa_fit.shm_coeff,\n                                                    max_angle=30.,\n                                                    sphere=peaks.default_sphere)\n\nstreamlines_generator = LocalTracking(prob_dg, classifier, seeds, img.affine,\n                                      step_size=.5, max_cross=1)\n\n# Generate streamlines object.\nstreamlines = Streamlines(streamlines_generator)\nstreamlines_actor = actor.line(streamlines, line_colors(streamlines))\nshow_image(streamlines_actor)"]}, {"cell_type": "markdown", "id": "4557f6da", "metadata": {}, "source": ["**Excercise: repeat both types of tracking - are the results the same each time?**"]}, {"cell_type": "markdown", "id": "613a9559", "metadata": {}, "source": ["# Connectivity analysis"]}, {"cell_type": "markdown", "id": "c216d4fd", "metadata": {}, "source": ["## Whole brain white matter tracking"]}, {"cell_type": "code", "execution_count": 1, "id": "038b8828", "metadata": {}, "outputs": [], "source": ["seeds = utils.seeds_from_mask(white_matter, density=2)\nstreamline_generator = EuDX(csa_peaks.peak_values, csa_peaks.peak_indices,\n                            odf_vertices=peaks.default_sphere.vertices,\n                            a_low=.05, step_sz=.5, seeds=seeds)\naffine = streamline_generator.affine\n\nstreamlines = Streamlines(streamline_generator, buffer_size=512)\n\nshow_image(actor.line(streamlines, line_colors(streamlines)))"]}, {"cell_type": "code", "execution_count": 1, "id": "aff7e209", "metadata": {}, "outputs": [], "source": ["len(streamlines)"]}, {"cell_type": "markdown", "id": "25f20bfa", "metadata": {}, "source": ["## Filtering streamlines"]}, {"cell_type": "code", "execution_count": 1, "id": "eaf78ca9", "metadata": {}, "outputs": [], "source": ["cc_slice = labels == 2\ncc_streamlines = utils.target(streamlines, cc_slice, affine=affine)\ncc_streamlines = Streamlines(cc_streamlines)\n\nother_streamlines = utils.target(streamlines, cc_slice, affine=affine,\n                                 include=False)\nother_streamlines = Streamlines(other_streamlines)\nassert len(other_streamlines) + len(cc_streamlines) == len(streamlines)"]}, {"cell_type": "code", "execution_count": 1, "id": "00778606", "metadata": {}, "outputs": [], "source": ["len(cc_streamlines)"]}, {"cell_type": "markdown", "id": "9edf7bab", "metadata": {}, "source": ["## Connectivity matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "54aa45d1", "metadata": {}, "outputs": [], "source": ["plot_roi(labels_img, index_img(img, 0), figure=plt.figure(figsize=(18,4)))"]}, {"cell_type": "code", "execution_count": 1, "id": "a8943582", "metadata": {}, "outputs": [], "source": ["np.unique(np.array(labels))"]}, {"cell_type": "code", "execution_count": 1, "id": "1830e1a9", "metadata": {}, "outputs": [], "source": ["plot_roi(math_img(\"x == 0\", x=labels_img), index_img(img, 0), figure=plt.figure(figsize=(18,4)))"]}, {"cell_type": "code", "execution_count": 1, "id": "b2d8b738", "metadata": {}, "outputs": [], "source": ["plot_roi(math_img(\"x == 1\", x=labels_img), index_img(img, 0), figure=plt.figure(figsize=(18,4)))"]}, {"cell_type": "code", "execution_count": 1, "id": "1bb398ac", "metadata": {}, "outputs": [], "source": ["M, grouping = utils.connectivity_matrix(cc_streamlines, labels, affine=affine,\n                                        return_mapping=True,\n                                        mapping_as_streamlines=True)\nM[:3, :] = 0\nM[:, :3] = 0\nplt.imshow(np.log1p(M), interpolation='nearest')"]}, {"cell_type": "markdown", "id": "fc9d1af1", "metadata": {}, "source": ["**Excercise: estimate connectivity matrix for all streamlines (not just those going through CC)**"]}, {"cell_type": "markdown", "id": "31d52f5e", "metadata": {}, "source": ["What is the strongest connection?"]}, {"cell_type": "code", "execution_count": 1, "id": "7bbc9d35", "metadata": {}, "outputs": [], "source": ["np.argmax(M)\nfrom numpy import unravel_index\nnew_M = M.copy()\n#new_M[11,54] = 0\n#new_M[54,11] = 0\nunravel_index(new_M.argmax(), new_M.shape)"]}, {"cell_type": "markdown", "id": "23b3c309", "metadata": {}, "source": ["## Bundle density map"]}, {"cell_type": "code", "execution_count": 1, "id": "c38f9eaa", "metadata": {}, "outputs": [], "source": ["from nilearn.plotting import plot_stat_map\nsource_region = 32\ntarget_region = 75\nlr_superiorfrontal_track = grouping[source_region, target_region]\nshape = labels.shape\ndm = utils.density_map(lr_superiorfrontal_track, shape, affine=affine)\ndm_img = nb.Nifti1Image(dm.astype(\"int16\"), img.affine)\npl = plot_stat_map(dm_img, index_img(img,0), figure=plt.figure(figsize=(18,4)))\npl.add_contours(math_img(\"x == %d\"%source_region, x=labels_img))\npl.add_contours(math_img(\"x == %d\"%target_region, x=labels_img))"]}, {"cell_type": "markdown", "id": "eb989da4", "metadata": {}, "source": ["**Excercise: create density maps for other tracks**"]}, {"cell_type": "markdown", "id": "489137f5", "metadata": {}, "source": ["Looking for more data to play with? Check out https://www.kaggle.com/openneuro/ds001378"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}