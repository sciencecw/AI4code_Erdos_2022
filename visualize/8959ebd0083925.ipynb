{"cells": [{"cell_type": "code", "execution_count": 1, "id": "4d5ec70f", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "1166376a", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "b25f5bca", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "id": "41f303c8", "metadata": {}, "source": ["**EXPLORATORY DATA ANALYSIS - Initial Investigation to understand the Data**"]}, {"cell_type": "code", "execution_count": 1, "id": "7ef5c065", "metadata": {}, "outputs": [], "source": ["print(train.dtypes)"]}, {"cell_type": "code", "execution_count": 1, "id": "fdf9392b", "metadata": {}, "outputs": [], "source": ["train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "eb01d496", "metadata": {}, "outputs": [], "source": ["train.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "88ff9171", "metadata": {}, "outputs": [], "source": ["print(train.nunique())"]}, {"cell_type": "code", "execution_count": 1, "id": "f82b9688", "metadata": {}, "outputs": [], "source": ["train.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "4a0ce427", "metadata": {}, "outputs": [], "source": ["train.info()"]}, {"cell_type": "markdown", "id": "32fc7a7c", "metadata": {}, "source": ["DATA UNDERSTANDING"]}, {"cell_type": "code", "execution_count": 1, "id": "ea85d1f9", "metadata": {}, "outputs": [], "source": ["import seaborn as sns\nimport matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 1, "id": "26060869", "metadata": {}, "outputs": [], "source": ["numeric_variables = [\"PassengerId\", \"Pclass\", \"Survived\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\ncategorical_variables = [\"Name\" , \"Sex\", \"Ticket\", \"Embarked\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "cf46b3f0", "metadata": {}, "outputs": [], "source": ["sns.barplot(x = \"Pclass\" , y = \"Survived\" , data = train)\n#Passenger class 1 people has survived more"]}, {"cell_type": "code", "execution_count": 1, "id": "5e73a902", "metadata": {}, "outputs": [], "source": ["Pclass1=train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize=True)[1]*100\nPclass2=train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize=True)[1]*100\nPclass3=train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize=True)[1]*100\nPclass_Values=[Pclass1,Pclass2,Pclass3]\nplt.pie(Pclass_Values, labels=('Pclass1','Pclass2','Pclass3') ,explode=(0.1,0.0,0.0), autopct='%1.1f%%')"]}, {"cell_type": "code", "execution_count": 1, "id": "a63e5169", "metadata": {}, "outputs": [], "source": ["sns.barplot(x = \"Sex\" , y = \"Survived\" , data = train)\n#females has survived more"]}, {"cell_type": "code", "execution_count": 1, "id": "4b9480f5", "metadata": {}, "outputs": [], "source": ["Females=train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize=True)[1]*100\nmales=train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize=True)[1]*100\nSex_values=[males,Females]\nplt.pie(Sex_values, labels=('males','Females'),explode=(0.0,0.1),autopct='%1.1f%%')"]}, {"cell_type": "code", "execution_count": 1, "id": "222d445d", "metadata": {}, "outputs": [], "source": ["sns.barplot(x = \"SibSp\" , y = \"Survived\" , data = train)\n#people with 1 siblings survived more"]}, {"cell_type": "code", "execution_count": 1, "id": "4269453d", "metadata": {}, "outputs": [], "source": ["a = train[\"Survived\"][train['SibSp'] == 0].value_counts(normalize=True)[1]*100\nb = train[\"Survived\"][train['SibSp'] == 1].value_counts(normalize=True)[1]*100\nc = train[\"Survived\"][train['SibSp'] == 2].value_counts(normalize=True)[1]*100\nd = train[\"Survived\"][train['SibSp'] == 3].value_counts(normalize=True)[1]*100\ne = train[\"Survived\"][train['SibSp'] == 4].value_counts(normalize=True)[1]*100\nSibling_values=[a,b,c,d,e]\nplt.pie(Sibling_values, labels=('SibSp0','SibSp1','SibSp2','SibSp3','SibSp4'),explode=(0.1,0.1,0.1,0.1,0.1), autopct='%1.1f%%')"]}, {"cell_type": "code", "execution_count": 1, "id": "2d8cf2f4", "metadata": {}, "outputs": [], "source": ["sns.barplot(x = \"Parch\" , y = \"Survived\" , data = train)\n#people with parch = 3 survived more"]}, {"cell_type": "code", "execution_count": 1, "id": "6384af9a", "metadata": {}, "outputs": [], "source": ["P0=train[\"Survived\"][train[\"Parch\"] == 0].value_counts(normalize=True)[1]*100\nP1=train[\"Survived\"][train[\"Parch\"] == 1].value_counts(normalize=True)[1]*100\nP2=train[\"Survived\"][train[\"Parch\"] == 2].value_counts(normalize=True)[1]*100\nP3=train[\"Survived\"][train[\"Parch\"] == 3].value_counts(normalize=True)[1]*100\nP5=train[\"Survived\"][train[\"Parch\"] == 5].value_counts(normalize=True)[1]*100\nParch_values=[P0,P1,P2,P3,P5]\nplt.pie(Parch_values, labels=('Parch0','Parch1','Parch2','Parch3','Parch5'),explode=(0.0,0.0,0.0,0.1,0.0),autopct='%1.1f%%')"]}, {"cell_type": "markdown", "id": "41b5a12a", "metadata": {}, "source": ["MISSING VALUE ANALYSIS"]}, {"cell_type": "code", "execution_count": 1, "id": "cdeb3da2", "metadata": {}, "outputs": [], "source": ["train.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "3031d6fd", "metadata": {}, "outputs": [], "source": ["missing_value_percentage = print(train.isnull().sum()/len(train))\nmissing_value_percentage"]}, {"cell_type": "markdown", "id": "5002f2cf", "metadata": {}, "source": ["drop cabin as it has a huge number of missing values and few other variables which are not important for the model"]}, {"cell_type": "code", "execution_count": 1, "id": "0205088e", "metadata": {}, "outputs": [], "source": ["train = train.drop([\"Cabin\", \"Name\", \"Fare\", \"Ticket\"], axis = 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "71490cbd", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "8a4df8c9", "metadata": {}, "outputs": [], "source": ["print(train.isnull().sum())\n\n#lets impute other missing values "]}, {"cell_type": "code", "execution_count": 1, "id": "cee0ede4", "metadata": {}, "outputs": [], "source": ["#impute age with mean as it is numeric \n#impute embarked with mode as it is categorical\ntrain['Age'] = train['Age'].fillna(train['Age'].mean())\ntrain[\"Embarked\"] = pd.Categorical(train[\"Embarked\"])\ntrain[\"Embarked\"] = train[\"Embarked\"].cat.codes\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(train[\"Embarked\"].mode())\nprint(train.isnull().sum())\n"]}, {"cell_type": "code", "execution_count": 1, "id": "dd0a217f", "metadata": {}, "outputs": [], "source": ["train[\"Embarked\"] = train[\"Embarked\"].astype(\"object\")\nprint(train.dtypes)"]}, {"cell_type": "code", "execution_count": 1, "id": "e3823e66", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "e9623b2a", "metadata": {}, "outputs": [], "source": ["train[\"Sex\"] = pd.Categorical(train[\"Sex\"])\ntrain[\"Sex\"] = train[\"Sex\"].cat.codes\ntrain[\"Sex\"] = train[\"Sex\"].astype(\"object\")\n\n#male = 1, female = 0"]}, {"cell_type": "code", "execution_count": 1, "id": "c22ee783", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "a4d1c5dc", "metadata": {}, "outputs": [], "source": ["train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "88dbe1c3", "metadata": {}, "outputs": [], "source": ["train.describe()"]}, {"cell_type": "markdown", "id": "4c9f2589", "metadata": {}, "source": ["Outlier analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "9a66b148", "metadata": {}, "outputs": [], "source": ["numeric_variables2 = [\"Pclass\", \"Survived\", \"Age\",]\ncategorical_variables2 = [ \"Sex\", \"Embarked\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "722f57e0", "metadata": {}, "outputs": [], "source": ["import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfor i in numeric_variables2 :\n    print(i)\n    sns.boxplot(y = train[i])\n    plt.xlabel(i)\n    plt.ylabel(\"Values\")\n    plt.title(\"Boxplot of \" + i)\n    plt.show()"]}, {"cell_type": "markdown", "id": "8dfefa58", "metadata": {}, "source": ["**there is lot of outliers in the data so lets replace those outliers with NA and impute it **"]}, {"cell_type": "code", "execution_count": 1, "id": "586c1669", "metadata": {}, "outputs": [], "source": ["# Identify outliers\n#calculate Inner Fence, Outer Fence, and IQR\n\nfor i in numeric_variables2:\n    print(i)\n    q75, q25 = np.percentile(train.loc[:,i], [75, 25])\n    iqr = q75 - q25\n    Innerfence = q25 - (iqr*1.5)\n    Upperfence = q75 + (iqr*1.5)\n    print(\"Innerfence= \"+str(Innerfence))\n    print(\"Upperfence= \"+str(Upperfence)) \n    print(\"IQR =\"+str(iqr))\n    \n\n# replace outliers with NA\n\n    train.loc[train[i]<Innerfence, i] = np.nan\n    train.loc[train[i]>Upperfence, i] = np.nan"]}, {"cell_type": "code", "execution_count": 1, "id": "f515f0a2", "metadata": {}, "outputs": [], "source": ["print(train.isnull().sum()/len(train))"]}, {"cell_type": "code", "execution_count": 1, "id": "5d5c13d3", "metadata": {}, "outputs": [], "source": ["#impute age with mean\ntrain['Age'] = train['Age'].fillna(train['Age'].mean())\nprint(train.isnull().sum())        "]}, {"cell_type": "code", "execution_count": 1, "id": "d9aa1232", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "b6709424", "metadata": {}, "outputs": [], "source": ["train.dtypes"]}, {"cell_type": "markdown", "id": "8f5a6155", "metadata": {}, "source": ["**FEATURE SELECTION**"]}, {"cell_type": "code", "execution_count": 1, "id": "39dece21", "metadata": {}, "outputs": [], "source": ["numeric_variables3 = [\"PassengerId\", \"Survived\", \"Pclass\", \"Age\", \"SibsSp\", \"Parch\"]"]}, {"cell_type": "markdown", "id": "3347c6de", "metadata": {}, "source": ["**CORRELATION ANALYSIS**"]}, {"cell_type": "code", "execution_count": 1, "id": "5ef7acc7", "metadata": {}, "outputs": [], "source": ["Correlation = train.loc[:, numeric_variables3]\ncorrelation_result = Correlation.corr()\nprint(correlation_result)\n    "]}, {"cell_type": "code", "execution_count": 1, "id": "b50fa7a0", "metadata": {}, "outputs": [], "source": ["heatmap =  sns.heatmap(correlation_result)\n\n#No collinearity is found"]}, {"cell_type": "code", "execution_count": 1, "id": "a60f53da", "metadata": {}, "outputs": [], "source": ["#Data Distribution\n\nx = train.drop([\"Survived\"], axis = 1)\ny = train[\"Survived\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "c1ba2427", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split \n\n#divide the data into train and test\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=0)"]}, {"cell_type": "markdown", "id": "95fb5188", "metadata": {}, "source": ["MODELLING"]}, {"cell_type": "markdown", "id": "ff7d04b4", "metadata": {}, "source": ["RANDOM FOREST"]}, {"cell_type": "code", "execution_count": 1, "id": "8c66ff22", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\n\nRM_model = RandomForestClassifier(n_jobs = 100, n_estimators = 100, random_state = 123)\nRM_model.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "06c50451", "metadata": {}, "outputs": [], "source": ["RM_model.score(x_test, y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "6a11f71f", "metadata": {}, "outputs": [], "source": ["y_predrm = RM_model.predict(x_test)\n\n#Accuracy\n\naccuracy_rm = round(accuracy_score(y_predrm, y_test)*100,2)\nprint(accuracy_rm)"]}, {"cell_type": "code", "execution_count": 1, "id": "420477b3", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import classification_report  \nprint(classification_report(y_predrm, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "269f6241", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix \nprint(confusion_matrix(y_predrm, y_test))"]}, {"cell_type": "markdown", "id": "1972ce1a", "metadata": {}, "source": ["LOGISTIC REGRESSION"]}, {"cell_type": "code", "execution_count": 1, "id": "1c818a43", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\nLR_Model = LogisticRegression()\nLR_Model.fit(x_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "c8966cfb", "metadata": {}, "outputs": [], "source": ["LR_Model.score(x_test,y_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "5df1bd09", "metadata": {}, "outputs": [], "source": ["y_predlr = LR_Model.predict(x_test)\n\n#Accuracy\naccuracy_lr = round(accuracy_score(y_predlr, y_test) * 100, 2)\nprint(\"Accuracy:\",accuracy_lr)"]}, {"cell_type": "code", "execution_count": 1, "id": "2a12cc96", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_predlr, y_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "97a03577", "metadata": {}, "outputs": [], "source": ["print(confusion_matrix(y_predlr, y_test))"]}, {"cell_type": "markdown", "id": "ff658d80", "metadata": {}, "source": ["It is found that in normal cases Random Forest is a better model for the given dataset, hypertuning can be done to improve the accuracy far more better"]}, {"cell_type": "markdown", "id": "0c2044df", "metadata": {}, "source": ["Predict in Test data"]}, {"cell_type": "code", "execution_count": 1, "id": "d3824c09", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d728c54a", "metadata": {}, "outputs": [], "source": ["#Drop unnecessary columns \ntest = test.drop(['Name','Ticket','Fare','Cabin'], axis=1)\ntest.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "c14bf493", "metadata": {}, "outputs": [], "source": ["#Convert datatype\ntest[\"Sex\"] = pd.Categorical(test[\"Sex\"])\ntest[\"Sex\"] = test[\"Sex\"].cat.codes\ntest[\"Sex\"] = test[\"Sex\"].astype(\"object\")\n\ntest[\"Embarked\"] = pd.Categorical(test[\"Embarked\"])\ntest[\"Embarked\"] = test[\"Embarked\"].cat.codes\ntest[\"Embarked\"] = test[\"Embarked\"].astype(\"object\")\n\ntest.head()\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "9b14922b", "metadata": {}, "outputs": [], "source": ["#Check for NA values\ntest.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "36ff6b86", "metadata": {}, "outputs": [], "source": ["test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())"]}, {"cell_type": "code", "execution_count": 1, "id": "b3a4ebb1", "metadata": {}, "outputs": [], "source": ["test.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "f3ce25b9", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "ac4b932b", "metadata": {}, "outputs": [], "source": ["test[\"Survived\"] = RM_model.predict(test)"]}, {"cell_type": "code", "execution_count": 1, "id": "64feb66d", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "72627d80", "metadata": {}, "outputs": [], "source": ["predicted_test = test.drop(['Pclass','Sex','Age','SibSp', \"Parch\", \"Embarked\"], axis=1)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "9c9a619c", "metadata": {}, "outputs": [], "source": ["y_output = predicted_test[\"Survived\"]\n"]}, {"cell_type": "code", "execution_count": 1, "id": "1b895c08", "metadata": {}, "outputs": [], "source": ["given_output = pd.read_csv(\"../input/gender_submission.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "44bd8710", "metadata": {}, "outputs": [], "source": ["y_given= given_output[\"Survived\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "1dd97a87", "metadata": {}, "outputs": [], "source": ["accuracy_final = round(accuracy_score(y_output, y_given) * 100, 2)\nprint(\"Accuracy:\",accuracy_final)"]}, {"cell_type": "code", "execution_count": 1, "id": "b129eb8d", "metadata": {}, "outputs": [], "source": ["print(confusion_matrix(y_output, y_given))"]}, {"cell_type": "code", "execution_count": 1, "id": "2ecf229a", "metadata": {}, "outputs": [], "source": ["sns.countplot(x=\"Survived\",data=test , )"]}, {"cell_type": "code", "execution_count": 1, "id": "aa033682", "metadata": {}, "outputs": [], "source": ["test['Survived'].value_counts()"]}, {"cell_type": "markdown", "id": "d816c48e", "metadata": {}, "source": ["got 77.03 % accuracy with resembelence to the actual output, the model can be hypertuned , variable engineered etc can be done to improve the accuracy of the model "]}, {"cell_type": "code", "execution_count": 1, "id": "041a8ee1", "metadata": {}, "outputs": [], "source": ["predicted_test.to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}