{"cells": [{"cell_type": "markdown", "id": "7d8a8507", "metadata": {}, "source": ["# Times series with LSTM "]}, {"cell_type": "markdown", "id": "584a0ad5", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 1. Introduction"]}, {"cell_type": "markdown", "id": "fa753baa", "metadata": {}, "source": ["The goal of this kernel is to work with times series using Keras. I will develop an easy example using a dataset with information related to the weather in Dehli from 2013 till 2017. \nThe objective will be to predict the temperature having some daily information as the wind speed, pressure and humidity. \nWith this purpose, I will preprocess the data, transforming variables and reshaping the data in order to work with Keras. Finally, I will create a LSTM neural network which will be trained and saved. It can be used for futures predictions and result visualizations."]}, {"cell_type": "markdown", "id": "7dadab4a", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 2. Import libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "f11974d3", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, LSTM\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score as R2_score\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\n\nfrom IPython.display import display_html\n\nimport os\n"]}, {"cell_type": "markdown", "id": "d8d92187", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 3. Load data"]}, {"cell_type": "markdown", "id": "e5a58fa5", "metadata": {}, "source": ["There are two different datasets: training and test. Both have the same structure, containing the data collected in Dehli from  January 2013 to April 2017.\n\nThe columns of both datasets are teh same. See description below: \n\n* date: Date of format YYYY-MM-DD.\n* meantemp: Mean temperature averaged out from multiple 3 hour intervals in a day.\n* humidity: Humidity value for the day (units are grams of water vapor per cubic meter volume of air).\n* wind_speed: Wind speed measured in kmph.\n* meanpressure: Pressure reading of weather (measure in atm)\n    \nTo make it easier, I will concatenate both sets and just work with a single dataframe."]}, {"cell_type": "code", "execution_count": 1, "id": "5a0db0ba", "metadata": {}, "outputs": [], "source": ["data_train = pd.read_csv('../input/daily-climate-time-series-data/DailyDelhiClimateTrain.csv',sep=',')\ndata_train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "65f08388", "metadata": {}, "outputs": [], "source": ["data_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "ff78cfd8", "metadata": {}, "outputs": [], "source": ["data_test = pd.read_csv('../input/daily-climate-time-series-data/DailyDelhiClimateTest.csv',sep=',')\ndata_test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "ff9cbe45", "metadata": {}, "outputs": [], "source": ["data_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "a9dc9d7a", "metadata": {}, "outputs": [], "source": ["data = pd.concat([data_train,data_test])\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "c002c7d6", "metadata": {}, "outputs": [], "source": ["data.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "f9d07ef3", "metadata": {}, "outputs": [], "source": ["data.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "3607823b", "metadata": {}, "outputs": [], "source": ["data.describe()"]}, {"cell_type": "markdown", "id": "46edc3bb", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 4. Initial preprocessing and data visualization"]}, {"cell_type": "markdown", "id": "835f8321", "metadata": {}, "source": ["I will convert the date column to datetime and rename some of the columns to simplify the following process. "]}, {"cell_type": "code", "execution_count": 1, "id": "4d1ecadd", "metadata": {}, "outputs": [], "source": ["data['date'] = pd.to_datetime(data['date'])"]}, {"cell_type": "code", "execution_count": 1, "id": "3fb4a695", "metadata": {}, "outputs": [], "source": ["data = data.rename(columns={\"meantemp\":\"temp\",\"wind_speed\":\"wind\",\"meanpressure\":\"pressure\"})"]}, {"cell_type": "code", "execution_count": 1, "id": "6c75b96a", "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "f7c5735a", "metadata": {}, "outputs": [], "source": ["print(\"Starting date of time series: \", data.date.min())\nprint(\"Final date of time series:    \", data.date.max())"]}, {"cell_type": "code", "execution_count": 1, "id": "a756cdbd", "metadata": {}, "outputs": [], "source": ["dates = data['date'].values\ntemp  = data['temp'].values\nhumidity = data['humidity'].values\nwind = data['wind'].values\npressure = data['pressure'].values"]}, {"cell_type": "markdown", "id": "56eb0d3e", "metadata": {}, "source": ["Let\u00b4s plot the temperature during the two years time frame. \nWe can see the cyclical behavior each year, obviously the temperature gets higher in summer and goes down in winter. "]}, {"cell_type": "code", "execution_count": 1, "id": "b6e9995f", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nplt.plot(dates, temp)\nplt.title('Temperature average',\n          fontsize=20);"]}, {"cell_type": "markdown", "id": "2cb87459", "metadata": {}, "source": ["Zooming the graphic above we see how the temperature changes from one day to another but it has a tendency depending on the period of the year. "]}, {"cell_type": "code", "execution_count": 1, "id": "69122ec8", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nplt.plot(dates, temp, 'o-')\nplt.title('Temperature average (3 hours interval)', fontsize=20)\nplt.axis([dates[-150],dates[-1],0,50]);"]}, {"cell_type": "markdown", "id": "c8c637ab", "metadata": {}, "source": ["The idea is to transform the variable to be predicted. I will use a logarithmic transformation but first let\u00b4s plot the histogram of the original variable and the transformed one. \n\nThe purpose of this transformation is to standarizated the original variable and also supressed possible outliers. "]}, {"cell_type": "code", "execution_count": 1, "id": "a46c27cb", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nplt.hist(temp, bins=30)\nplt.xlabel('Temperature', fontsize=20)\nplt.subplot(1,2,2)\naux = np.log( temp[1:] / temp[0:-1]  )\nplt.hist(aux, bins=30)\nplt.xlabel('Logarithmic temperature increment', fontsize=20)\nplt.show()\nprint(\"Temperature average                      :\", temp.mean())\nprint(\"Logarithmic temperature increment average:\", aux.mean())"]}, {"cell_type": "code", "execution_count": 1, "id": "2055fa00", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nplt.plot(dates[1:], aux)\nplt.title('Temperature (Logarithmic)',\n          fontsize=20);"]}, {"cell_type": "markdown", "id": "c60ff823", "metadata": {}, "source": ["## <font color=\"fcc200\"> 5. Variable transformation"]}, {"cell_type": "markdown", "id": "8a888d54", "metadata": {}, "source": ["I will create the function used to transform the original variable (temperature) and also the one needed to undo the transformation. This second function will be used  to obtain the final predictions."]}, {"cell_type": "code", "execution_count": 1, "id": "1a3aef79", "metadata": {}, "outputs": [], "source": ["eps = 1e-11\n\nNAN = np.NAN\n\n# Logarithmic transformation\n\ndef transform_logratios(serie):\n    aux = np.log((serie[1:]+eps) / (serie[0:-1]+eps))\n    return np.hstack( ([NAN], aux))\ndef inverse_transform_logratios(log_ratio, temp_prev):\n    return np.multiply(temp_prev, np.exp(log_ratio))"]}, {"cell_type": "code", "execution_count": 1, "id": "d878fa99", "metadata": {}, "outputs": [], "source": ["transform = transform_logratios\ninverse_transform = inverse_transform_logratios"]}, {"cell_type": "code", "execution_count": 1, "id": "8bc6b874", "metadata": {}, "outputs": [], "source": ["scaler = MinMaxScaler()\ntransformed = scaler.fit_transform(data.loc[:, [\"humidity\",\"wind\",\"pressure\"]])"]}, {"cell_type": "code", "execution_count": 1, "id": "bfbcdf4d", "metadata": {}, "outputs": [], "source": ["transformed = pd.DataFrame(transformed, columns = [\"humidity_s\",\"wind_s\",\"pressure_s\"])\ntransformed.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "6324b9d0", "metadata": {}, "outputs": [], "source": ["humidity_s = transformed['humidity_s'].values\nwind_s = transformed['wind_s'].values\npressure_s = transformed['pressure_s'].values"]}, {"cell_type": "markdown", "id": "21811985", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 6. Data winnowing"]}, {"cell_type": "markdown", "id": "1bf39149", "metadata": {}, "source": ["In order to work with Keras, the data needs to be reshaped and treated. The variables needs to be converted to dummies (not in our case since the dataset we are working with doens\u00b4t need any conversion) and also, very important, needs to be winnowed. \n\nIt means, Keras will process the data in different windows and we have to define this windows. With that purpose, I will use the following functions where: \n\n* series: all variables involved in our model, including the one to be predicted. \n* target: variable to predict.\n* prev_known: variable that can be used in advance to improve our model. For example, we could add information related to weekends or holidays which could shed some information to the purpose of a model. If we would like to know the sales of a supermarket, it is not the same during the week or weekend. It is important to make sure we can use these variable in advance also in a supposed production model (none of these variable in this kernel since weather variables cannot be known previously).\n* W_in: it is the window or frecuency we will split our dataset.\n* W_out: it is the exit window, which is one since we just want to know the next day prediction. "]}, {"cell_type": "code", "execution_count": 1, "id": "87f619fd", "metadata": {}, "outputs": [], "source": ["def winnowing(series, target, prev_known,\n               W_in=1, W_out=1):\n    n = len(series[0])\n    dataX = NAN*np.ones((n,W_in,len(series)))\n    if np.sometrue([s.dtype == object for s in series]):\n        dataX = dataX.astype(object)\n    if W_out==1:\n        dataY = series[target].copy()\n    else:\n        dataY = NAN*np.ones((n,W_out))\n        if series[target].dtype == object:\n            dataY = dataY.astype(object)\n        dataY[:,0] = series[target].copy()\n        for i in range(1,W_out):\n            dataY[:-i,i] = dataY[i:,0].copy()\n    \n    for i in range(n):\n        for j,s in enumerate(prev_known):\n            int_s = int(s) \n            ini_X = max([0,W_in-i-int_s])\n            dataX[i, ini_X:,j] = \\\n            series[j][max([0,i-W_in+int_s]):min([n,i+int_s])]\n    \n    return dataX, dataY\n"]}, {"cell_type": "code", "execution_count": 1, "id": "1035a739", "metadata": {}, "outputs": [], "source": ["def my_dfs_display(dfs,names):\n    df_styler = []\n    for df,n in zip(dfs,names):\n        df_styler.append(df.style.set_table_attributes(\"style='display:inline'\").\\\n                         set_caption(n))\n    display_html(df_styler[0]._repr_html_()+\"__\"+df_styler[1]._repr_html_(),\n                 raw=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "e84efef0", "metadata": {}, "outputs": [], "source": ["def info_winnowing(X,Y,names_series,name_target,times=None):\n    c0  = '\\033[1m'  \n    c1  = '\\033[0m'  \n    W_in = X.shape[1]\n    if len(Y.shape)==1:\n        W_out = 1\n    else:\n        W_out = Y.shape[1]\n    print(len(X), \"windows created \\n\")\n    print(\"X.shape={}\".format(X.shape),\" Y.shape={}\".format(Y.shape),\"\\n\")\n    for t in range(len(X)):\n        print(c0,\"Window %d:\"%t, c1)\n        if times is None:\n            names_ts = [\"t=\"+str(t+i-W_in) for i in range(W_in)]\n            names_ts_pred = [\"t=\"+str(t+i) for i in range(W_out)]\n        else:\n            times = list(times)\n            if (t-W_in)<0:\n                names_ts = [\"?\"+str(i) for i in range(W_in-t)] + times[:t]\n            else:\n                names_ts = times[(t-W_in):t]\n            if (t+W_out-1)>=len(times):\n                names_ts_pred = times[t:] + [\"?\"+str(i) for i in range(W_out-(len(times)-t))]\n            else:\n                names_ts_pred = times[t:(t+W_out)]\n        aux1 = pd.DataFrame(X[t].T,columns=names_ts,index=names_series)\n        aux2 = pd.DataFrame([Y[t]],columns=names_ts_pred,\n                            index=[name_target])\n        if W_out==1:\n            my_dfs_display((aux1,aux2),\n                           (\"X[{}].shape={}\".format(t,X[t].shape),\n                            \"Y[{}]={}\".format(t,Y[t])))\n        else:\n            my_dfs_display((aux1,aux2),\n                           (\"X[{}].shape={}\".format(t,X[t].shape),\n                            \"Y[{}].shape={}\".format(t,Y[t].shape)))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "bda33f02", "metadata": {}, "outputs": [], "source": ["logratio_temp = transform(temp)\n\nseries = [logratio_temp, humidity_s, wind_s, pressure_s]\nprev_known = [False, False, False, False]"]}, {"cell_type": "code", "execution_count": 1, "id": "657f1d4c", "metadata": {}, "outputs": [], "source": ["print(np.shape(series))\nprint(np.shape(prev_known))"]}, {"cell_type": "code", "execution_count": 1, "id": "75b7ee2b", "metadata": {}, "outputs": [], "source": ["lookback = 6  # Window_in\n\nX, y = winnowing (series, target=0, prev_known=prev_known,\n                  W_in=lookback)\n\nprint(X.shape, np.shape(y))"]}, {"cell_type": "markdown", "id": "5c6735df", "metadata": {}, "source": ["I have used a window of 6 days. After trying different windows, 6 days is the one which gives me a better prediction.\n\nWe can see below the final structure created and how it will be passed to the neural network. We see how we have a 6 days window with 4 variables for each day."]}, {"cell_type": "code", "execution_count": 1, "id": "1c9e8ae3", "metadata": {}, "outputs": [], "source": ["info_winnowing(X[:20],y[:20],\n                 names_series=[\"logratio_temp\",\n                                 \"humidity_s\", \"wind_s\",\n                                 \"pressure_s\"],\n                 name_target=\"logratio_temp\",\n                 times=dates)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a95614c2", "metadata": {}, "outputs": [], "source": ["print(X.shape)\nprint(np.shape(temp))"]}, {"cell_type": "markdown", "id": "7fa4d50c", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 7. Training and test sets"]}, {"cell_type": "markdown", "id": "48d7de00", "metadata": {}, "source": ["Next, I will split the dataset in training and test."]}, {"cell_type": "code", "execution_count": 1, "id": "db9ed2d5", "metadata": {}, "outputs": [], "source": ["X_train = X[(lookback+1):len(data_train)]\ny_train = y[(lookback+1):len(data_train)]\ntemp_train = temp[(lookback+1):len(data_train)]\ntemp_test  = temp[len(data_train):]\nX_test  = X[len(data_train):]\ny_test  = y[len(data_train):]\n\nprint(np.shape(temp_train))\nprint(np.shape(temp_test))"]}, {"cell_type": "code", "execution_count": 1, "id": "ef912fee", "metadata": {}, "outputs": [], "source": ["temp_prev_train =  np.hstack(( [NAN], temp_train[:-1]))\ntemp_prev_test  =  np.hstack(( temp_train[-1:],\n                                      temp_test[:-1]))\ndates_train     = dates[(lookback+1):len(data_train)]\ndates_test      = dates[len(data_train):]"]}, {"cell_type": "code", "execution_count": 1, "id": "311d87f9", "metadata": {}, "outputs": [], "source": ["print(X_train.shape, y_train.shape)"]}, {"cell_type": "markdown", "id": "b60852fe", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 8. Model with Keras"]}, {"cell_type": "markdown", "id": "a9410ef1", "metadata": {}, "source": ["Finally, the network needs to be created. It is a really simple network where the window size needs to be again specify. "]}, {"cell_type": "code", "execution_count": 1, "id": "928777cf", "metadata": {}, "outputs": [], "source": ["model = Sequential()\nmodel.add(LSTM(10, input_shape=(lookback, X_train.shape[2]),\n#              kernel_regularizer='l1'\n              )\n         )\nmodel.add(Dense(1,\n#                kernel_regularizer='l1'\n               )\n         )\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse']) # 'RMSprop'\n# mean_absolute_error\n\nimport keras.backend as K\nprint(K.get_value(model.optimizer.lr))"]}, {"cell_type": "code", "execution_count": 1, "id": "fda8e095", "metadata": {}, "outputs": [], "source": ["model.optimizer.lr"]}, {"cell_type": "code", "execution_count": 1, "id": "755e2286", "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "markdown", "id": "4b7f834f", "metadata": {}, "source": ["With the purpose of training and saving the final network, the next functions will be implemented to choose the one that gives the better result (lowest mean square error)."]}, {"cell_type": "code", "execution_count": 1, "id": "dbaf5bbb", "metadata": {}, "outputs": [], "source": ["def training_graphic(tr_mse, val_mse):\n    ax=plt.figure(figsize=(10,4)).gca()\n    plt.plot(1+np.arange(len(tr_mse)), tr_mse)\n    plt.plot(1+np.arange(len(val_mse)), val_mse)\n    plt.title('mse', fontsize=18)\n    plt.xlabel('time', fontsize=18)\n    plt.ylabel('mse', fontsize=18)\n    plt.legend(['Training', 'Validation'], loc='upper left')\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "12649c22", "metadata": {}, "outputs": [], "source": ["epochs = 200\nbatch_size = 64\nNval = 200\ncontrol_val = True\nsave_training_tensorboard = False\n\n\nif not control_val:\n    history = model.fit(X_train, y_train, epochs=epochs,\n                        batch_size=batch_size, verbose=2)\n    \nelse:    \n    acum_tr_mse = []\n    acum_val_mse = []\n    filepath=\"best_model.h5\"\n    checkpoint = ModelCheckpoint(filepath, monitor='val_mse', verbose=2,\n                                 save_best_only=True,\n                                 mode='min') \n\n    if save_training_tensorboard:\n        callbacks_list = callbacks + [checkpoint]\n    else:\n        callbacks_list = [checkpoint]\n    \n    for e in range(epochs):\n        history = model.fit(X_train[:-Nval], y_train[:-Nval],\n                            batch_size=batch_size,\n                            epochs=1,\n                            callbacks=callbacks_list,\n                            verbose=0,\n                            validation_data=(X_train[-Nval:], y_train[-Nval:]))\n        \n        acum_tr_mse  += history.history['mse']\n        acum_val_mse += history.history['val_mse']\n        \n        if (e+1)%50 == 0:\n            training_graphic(acum_tr_mse, acum_val_mse)"]}, {"cell_type": "markdown", "id": "961a0e6d", "metadata": {}, "source": ["We can load the model already trained and just makes predictions with it."]}, {"cell_type": "code", "execution_count": 1, "id": "d3c4c7cf", "metadata": {}, "outputs": [], "source": ["model = load_model('best_model.h5') "]}, {"cell_type": "markdown", "id": "fe030b52", "metadata": {}, "source": ["## <font color=\"#fcc200\"> 9. Predictions"]}, {"cell_type": "markdown", "id": "ab7ca7ea", "metadata": {}, "source": ["We just need to apply our model to get the predictions undoing the logarithmic transformation and also the prediction visualizations and the different errors depending on the future time frames. "]}, {"cell_type": "code", "execution_count": 1, "id": "bbbeb297", "metadata": {}, "outputs": [], "source": ["y_train_prediction = model.predict(X_train).flatten()\ny_test_prediction = model.predict(X_test).flatten()"]}, {"cell_type": "code", "execution_count": 1, "id": "d4369502", "metadata": {}, "outputs": [], "source": ["temp_train_pred = inverse_transform(y_train_prediction,\n                                          temp_prev_train)\ntemp_test_pred  = inverse_transform(y_test_prediction,\n                                          temp_prev_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "aad09ac7", "metadata": {}, "outputs": [], "source": ["temp_train_pred"]}, {"cell_type": "code", "execution_count": 1, "id": "60229c40", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,7))\nplt.plot(dates_train, temp_train, '--', c='royalblue',\n         label=\"Training\")\nplt.plot(dates_train, temp_train_pred,  c='darkorange',\n         label=\"Training daily predictions\")\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=14)\nplt.axis([dates_train[4],dates_train[-1],0,75])\nplt.legend(fontsize=14);"]}, {"cell_type": "code", "execution_count": 1, "id": "6f4f48fa", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nplt.plot(dates_train, temp_train, '--', c='royalblue',\n         label='Training')\nplt.plot(dates_train, temp_train_pred,  c='darkorange',\n         label='Training predictions')\nplt.plot(dates_test, temp_test, '--',   c='green',\n         label='Test')\nplt.plot(dates_test, temp_test_pred,    c='red',\n         label='Test predictions')\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=14)\nplt.title('Daily predictions', fontsize=16)\nplt.legend(fontsize=14);"]}, {"cell_type": "code", "execution_count": 1, "id": "69643ce1", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,5))\nplt.plot(dates_train, temp_train, '--', c='royalblue',\n         label='Training')\nplt.plot(dates_train, temp_train_pred,  c='darkorange',\n         label='Training predictions')\nplt.plot(dates_test, temp_test, '--',   c='green',\n         label='Test')\nplt.plot(dates_test, temp_test_pred,    c='red',\n         label='Test predictions')\nplt.title('Daily predictions (zoom)', fontsize=16)\nplt.legend(fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=14)\nplt.axis([dates_train[-200],dates_test[-100],0,50]);"]}, {"cell_type": "code", "execution_count": 1, "id": "23cf055e", "metadata": {}, "outputs": [], "source": ["# R2 scores\nprint(\"R2 - Training      : \",\n      R2_score(temp_train[1:], temp_train_pred[1:]))\nprint(\"R2 - Test          : \",\n      R2_score(temp_test, temp_test_pred))\nprint(\"r2 - Interval 1 day     : \",\n      R2_score(temp_test[1:], temp_test[:-1]))\nprint(\"R2 - Interval 1 week : \",\n      R2_score(temp_test[7:], temp_test[:-7]))\nprint(\"R2 - Interval 4 weeks: \",\n      R2_score(temp_test[28:], temp_test[:-28]))\nprint(\"R2 - Interval 1 year: \",\n      R2_score(temp_train[7*52:], temp_train[:-7*52]))"]}, {"cell_type": "code", "execution_count": 1, "id": "db5621fb", "metadata": {}, "outputs": [], "source": ["# RMSEs\nsqrt = np.sqrt\nprint(\"RMSE - Training      : \",\n      sqrt(mean_squared_error(temp_train[1:],\n                              temp_train_pred[1:])))\nprint(\"RMSE - Test          : \",\n      sqrt(mean_squared_error(temp_test,\n                              temp_test_pred)))\nprint(\"RMSE - Interval 1 day    : \",\n      sqrt(mean_squared_error(temp_test[1:],\n                              temp_test[:-1])))\nprint(\"RMSE - Interval 1 week : \",\n      sqrt(mean_squared_error(temp_test[7:],\n                              temp_test[:-7])))\nprint(\"RMSE - Interval 4 weeks: \",\n      sqrt(mean_squared_error(temp_test[28:],\n                              temp_test[:-28])))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}