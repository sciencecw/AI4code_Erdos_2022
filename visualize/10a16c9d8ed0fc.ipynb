{"cells": [{"cell_type": "markdown", "id": "0d664bbb", "metadata": {}, "source": ["![](https://lh3.googleusercontent.com/proxy/z9ilC4bvRfBqWs83SCvP_xo8V7eGgsilTqugH0axpWybkxLXuZk87CApVuuOrbbeXRa10Ungs5oHfhnNeda5uyMdSjrwcg8uSJXFW1kZvLJmXERERxuZIVovtwlYB_xhYhgkewkGqBH0V0POEio)"]}, {"cell_type": "markdown", "id": "8ce11eb3", "metadata": {}, "source": ["# Aloca\u00e7\u00e3o Latente de Dirichlet (LDA)\n\n*\"No processamento de linguagem natural, a Aloca\u00e7\u00e3o Latente de Dirichlet (LDA) \u00e9 um <mark>modelo estat\u00edstico generativo que permite que conjuntos de observa\u00e7\u00f5es sejam explicados por grupos n\u00e3o observados que explicam o porqu\u00ea algumas partes dos dados s\u00e3o semelhantes</mark>. Por exemplo, se as observa\u00e7\u00f5es s\u00e3o palavras coletadas em documentos, ele postula que cada documento \u00e9 uma mistura de um pequeno n\u00famero de t\u00f3picos e que a cria\u00e7\u00e3o de cada palavra \u00e9 atribu\u00edvel a um dos t\u00f3picos do documento\"* - [Wikip\u00e9dia](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)\n\n\n# LDAvis\n\nLDAvis s\u00e3o ferramentas para criar uma <mark>visualiza\u00e7\u00e3o interativa usando p\u00e1gina web</mark>, de um modelo de t\u00f3pico que foi ajustado a um corpus de dados de texto usando a **Aloca\u00e7\u00e3o de Dirichlet Latente (LDA)**. Dado os par\u00e2metros estimados do modelo de t\u00f3pico, ele calcula v\u00e1rias estat\u00edsticas de resumo como entrada para uma visualiza\u00e7\u00e3o interativa criada com o D3.js que \u00e9 acessada por meio de um navegador. <mark>O objetivo \u00e9 ajudar os usu\u00e1rios a interpretar os t\u00f3picos em seu modelo de t\u00f3pico LDA</mark>.\n\n* [LDAvis Introduction](https://cran.r-project.org/web/packages/LDAvis/vignettes/details.pdf)"]}, {"cell_type": "code", "execution_count": 1, "id": "0c3374d7", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport re, nltk, gensim\nimport requests\nimport json\nfrom sklearn.externals import joblib\n\n# Sklearn\nfrom sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom pprint import pprint\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline"]}, {"cell_type": "markdown", "id": "5324698a", "metadata": {}, "source": ["# Importando os Dados"]}, {"cell_type": "code", "execution_count": 1, "id": "9b13c2e3", "metadata": {}, "outputs": [], "source": ["filename = \"../input/brazilian-music-samba-lyrics/samba_dataset.csv\"\ndf = pd.read_csv(filename, sep=\"|\")\ndf.head(3)"]}, {"cell_type": "markdown", "id": "5ed836ba", "metadata": {}, "source": ["# Tratando o texto"]}, {"cell_type": "code", "execution_count": 1, "id": "a16ac594", "metadata": {}, "outputs": [], "source": ["# cada letra de samba \u00e9 um documento\ndata = [lyrics for lyrics in df.letra] \nprint(\"Temos %d documentos.\" %len(data))"]}, {"cell_type": "markdown", "id": "7b1174bc", "metadata": {}, "source": ["### Tokeniza\u00e7\u00e3o dos docs"]}, {"cell_type": "code", "execution_count": 1, "id": "408c2efe", "metadata": {}, "outputs": [], "source": ["def sent_to_words(sentences):\n    for sentence in sentences:\n        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n\ndata_words = list(sent_to_words(data))\n\nprint(data_words[:1])"]}, {"cell_type": "markdown", "id": "0db3bfa0", "metadata": {}, "source": ["### Removendo Stopwords"]}, {"cell_type": "code", "execution_count": 1, "id": "0c2b10c2", "metadata": {}, "outputs": [], "source": ["def removeStops(texts, stopwords):\n    texts_out = []\n    for sent in texts:\n        texts_out.append(\" \".join([token for token in sent if token not in stopwords]))\n    return texts_out\n\n\nstopwords = nltk.corpus.stopwords.words('portuguese')\nstopwords += [\"nao\", \"so\", \"pra\", \"pro\", \"pras\", \"pros\"]\n# Do lemmatization keeping only Noun, Adj, Verb, Adverb\ndata_without_stops = removeStops(data_words, stopwords)\n\n# sem stopwords\nprint(data_without_stops[:2])"]}, {"cell_type": "markdown", "id": "3e04cd77", "metadata": {}, "source": ["# Criando a matriz Documento-Palavra\n\nO algoritmo de modelo de t\u00f3pico LDA requer uma matriz de palavras do documento como entrada principal.\n\nVoc\u00ea pode criar um usando o CountVectorizer. No c\u00f3digo abaixo, eu configurei o CountVectorizer para considerar palavras que ocorreram pelo menos 10 vezes (min_df), remova palavras irrelevantes em ingl\u00eas, converta todas as palavras em min\u00fasculas e uma palavra pode conter n\u00fameros e alfabetos de pelo menos 3 para ser qualificado como uma palavra."]}, {"cell_type": "code", "execution_count": 1, "id": "c3ea798d", "metadata": {}, "outputs": [], "source": ["vectorizer = CountVectorizer(analyzer='word',       \n                             min_df=10,                        # minimum reqd occurences of a word \n                             # stop_words='english',             # remove stop words\n                             lowercase=True,                   # convert all words to lowercase\n                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n                             # max_features=50000,             # max number of uniq words\n                            )\n\n# data_vectorized = vectorizer.fit_transform(data_lemmatized)\ndata_vectorized = vectorizer.fit_transform(data_without_stops)"]}, {"cell_type": "markdown", "id": "c2b65c11", "metadata": {}, "source": ["# Verificando qu\u00e3o Esparsa \u00e9 a Matriz\n\nBasta verificar a porcentagem de pontos diferentes de zero na matriz documento-palavra.\n\nComo a maioria das c\u00e9lulas nessa matriz ser\u00e1 zero, estou interessado em saber qual porcentagem de c\u00e9lulas cont\u00e9m valores diferentes de zero."]}, {"cell_type": "code", "execution_count": 1, "id": "4ddc9338", "metadata": {}, "outputs": [], "source": ["# Materialize the sparse data\ndata_dense = data_vectorized.todense()\n\n# Compute Sparsicity = Percentage of Non-Zero cells\nprint(\"Sparsicity: \", round(((data_dense > 0).sum()/data_dense.size)*100, 2), \"%\")"]}, {"cell_type": "markdown", "id": "cab2d4e4", "metadata": {}, "source": ["# Treinando o Modelo LDA com Sklearn\n\nTudo est\u00e1 pronto para criar um modelo de Aloca\u00e7\u00e3o Dirichlet Latente (LDA). Vamos inicializar um e chamar fit_transform () para criar o modelo LDA.\n\nNeste exemplo, eu defini os n_topics como 5. Mais tarde, encontraremos o n\u00famero ideal usando grid search."]}, {"cell_type": "code", "execution_count": 1, "id": "ac32853b", "metadata": {}, "outputs": [], "source": ["lda_model = LatentDirichletAllocation(n_components=5,              \n                                      max_iter=10,               \n                                      learning_method='online',   \n                                      random_state=100,          \n                                      batch_size=128,            \n                                      evaluate_every = -1,       \n                                      n_jobs = -1             \n                                     )\nlda_output = lda_model.fit_transform(data_vectorized)\n\nprint(lda_model)"]}, {"cell_type": "markdown", "id": "29b992e5", "metadata": {}, "source": ["# Avaliando a performance do modelo com a perplexidade e probabilidade logar\u00edtmica\n\nUm modelo com maior probabilidade logar\u00edtmica e menor perplexidade (exp (-1. * Probabilidade logar\u00edtmica por palavra)) \u00e9 considerado bom. Vamos verificar o nosso modelo."]}, {"cell_type": "code", "execution_count": 1, "id": "5682b721", "metadata": {}, "outputs": [], "source": ["# Probabilidade logaritmica: quanto maior melhor\nprint(\"probabilidade logaritmica: \", round(lda_model.score(data_vectorized), 2))\n\n# Perplexidade: menor melhor.  exp(-1. * log-Probabilidade logaritmica por palavra)\nprint(\"Perplexidade: \", round(lda_model.perplexity(data_vectorized), 2))\n\nprint(\"Par\u00e2metros:\")\npprint(lda_model.get_params())"]}, {"cell_type": "markdown", "id": "a0b8f4bb", "metadata": {}, "source": ["A perplexidade pode n\u00e3o ser a melhor medida para avaliar modelos de t\u00f3picos, porque n\u00e3o considera o contexto e as associa\u00e7\u00f5es sem\u00e2nticas entre as palavras. Isso pode ser capturado usando a medida de coer\u00eancia de t\u00f3pico."]}, {"cell_type": "markdown", "id": "4dd57614", "metadata": {}, "source": ["# UsandoGridSearch para encontrar melhor modelo LDA \n\nO par\u00e2metro de ajuste mais importante para modelos LDA \u00e9 ```n_components``` (n\u00famero de t\u00f3picos). Al\u00e9m disso, vamos pesquisar ```learning_decay``` (que controla a taxa de aprendizado) tamb\u00e9m.\n\nAl\u00e9m desses, outros poss\u00edveis par\u00e2metros de pesquisa podem ser ```learning_offset```  e ```max_iter```. Vale a pena experimentar se voc\u00ea tiver recursos de computa\u00e7\u00e3o suficientes.\n\nA pesquisa em grade constr\u00f3i v\u00e1rios modelos LDA para todas as combina\u00e7\u00f5es poss\u00edveis de valores de par\u00e2metros no par\u00e2metro param_grid. Portanto, <mark>esse processo pode consumir muito tempo e recursos</mark>."]}, {"cell_type": "code", "execution_count": 1, "id": "4aa7771a", "metadata": {}, "outputs": [], "source": ["# Define Search Param\nsearch_params = {'n_components': [5, 10, 15], 'learning_decay': [.5, .7, .9]}\n\n# Init the Model\nlda = LatentDirichletAllocation()\n\n# Init Grid Search Class\nmodel = GridSearchCV(lda, param_grid=search_params)\n\n# Do the Grid Search\nmodel.fit(data_vectorized)"]}, {"cell_type": "markdown", "id": "55d9d456", "metadata": {}, "source": ["# Escolhendo o \"melhor\" modelo"]}, {"cell_type": "code", "execution_count": 1, "id": "c7ad4f37", "metadata": {}, "outputs": [], "source": ["# Melhor modelo\nbest_lda_model = model.best_estimator_\n\n# Hiperpar\u00e2metros do modelo\nprint(\"Melhores par\u00e2metros: \", model.best_params_)\n\n# probabilidade logar\u00edtmica\nprint(\"Melhor score de probabilidade logar\u00edtmica: \", model.best_score_)\n\n# Perplexidade\nprint(\"Perplexidade do modelo: \", best_lda_model.perplexity(data_vectorized))"]}, {"cell_type": "markdown", "id": "0f5220ec", "metadata": {}, "source": ["# Comparando os scores de performance dos modelos LDA"]}, {"cell_type": "code", "execution_count": 1, "id": "bde2c239", "metadata": {}, "outputs": [], "source": ["results = pd.DataFrame(model.cv_results_)\n\ncurrent_palette = sns.color_palette(\"Set2\", 3)\n\nplt.figure(figsize=(12,8))\n\nsns.lineplot(data=results,\n             x='param_n_components',\n             y='mean_test_score',\n             hue='param_learning_decay',\n             palette=current_palette,\n             marker='o'\n            )\n\nplt.show()"]}, {"cell_type": "markdown", "id": "6c7ee0c1", "metadata": {}, "source": ["# T\u00f3pico dominante em cada documento\n\nPara classificar um documento como pertencente a um t\u00f3pico espec\u00edfico, uma abordagem l\u00f3gica \u00e9 ver qual t\u00f3pico tem a maior contribui\u00e7\u00e3o para esse documento e atribu\u00ed-lo.\n\nNa tabela abaixo, destaquei em verde todos os principais t\u00f3picos de um documento e atribu\u00ed o t\u00f3pico mais dominante em sua pr\u00f3pria coluna."]}, {"cell_type": "code", "execution_count": 1, "id": "a5617582", "metadata": {}, "outputs": [], "source": ["# Create Document - Topic Matrix\nlda_output = best_lda_model.transform(data_vectorized)\n\n# column names\ntopicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n\n# index names\ndocnames = [\"Doc\" + str(i) for i in range(len(data))]\n\n# Make the pandas dataframe\ndf_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n\n# Get dominant topic for each document\ndominant_topic = np.argmax(df_document_topic.values, axis=1)\ndf_document_topic['dominant_topic'] = dominant_topic\n\n# Styling\ndef color_green(val):\n    color = 'green' if val > .1 else 'black'\n    return 'color: {col}'.format(col=color)\n\ndef make_bold(val):\n    weight = 700 if val > .1 else 400\n    return 'font-weight: {weight}'.format(weight=weight)\n\n# Apply Style\ndf_document_topics = df_document_topic.style.applymap(color_green).applymap(make_bold)\ndf_document_topics_first10 = df_document_topic[:10].style.applymap(color_green).applymap(make_bold)\ndf_document_topics_first10"]}, {"cell_type": "markdown", "id": "a54c7fec", "metadata": {}, "source": ["# Quantidade de Documentos em Cada T\u00f3pico"]}, {"cell_type": "code", "execution_count": 1, "id": "f54ffb1a", "metadata": {}, "outputs": [], "source": ["df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\ndf_topic_distribution.columns = ['Topic Num', 'Num Documents']\ndf_topic_distribution"]}, {"cell_type": "markdown", "id": "f5ab9ec5", "metadata": {}, "source": ["# Visualizando nosso modelo LDA com o pyLDAvis"]}, {"cell_type": "markdown", "id": "cb2cf855", "metadata": {}, "source": ["Para vizualizar o gr\u00e1fico, execute os comandos abaixo no seu jupyer notebook, isso ir\u00e1 abrir uma p\u00e1gina no seu localhost:\n```python\npyLDAvis.enable_notebook()\npanel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\npyLDAvis.show(panel)```"]}, {"cell_type": "markdown", "id": "e57a244b", "metadata": {}, "source": ["O gr\u00e1fico interativo que ser\u00e1 gerado ter\u00e1 a seguinte \"cara\":\n\n![](https://media.giphy.com/media/dt0myZkpmNjrW4IaXi/giphy.gif)"]}, {"cell_type": "markdown", "id": "33c5ef52", "metadata": {}, "source": ["# Top 5 palavras por t\u00f3pico"]}, {"cell_type": "code", "execution_count": 1, "id": "2ded5f54", "metadata": {}, "outputs": [], "source": ["vocab = vectorizer.get_feature_names()\n\n# data_vectorized\ntopic_words = {}\nn_top_words = 5\n\nfor topic, comp in enumerate(best_lda_model.components_):\n    # for the n-dimensional array \"arr\":\n    # argsort() returns a ranked n-dimensional array of arr, call it \"ranked_array\"\n    # which contains the indices that would sort arr in a descending fashion\n    # for the ith element in ranked_array, ranked_array[i] represents the index of the\n    # element in arr that should be at the ith index in ranked_array\n    # ex. arr = [3,7,1,0,3,6]\n    # np.argsort(arr) -> [3, 2, 0, 4, 5, 1]\n    # word_idx contains the indices in \"topic\" of the top num_top_words most relevant\n    # to a given topic ... it is sorted ascending to begin with and then reversed (desc. now)    \n    word_idx = np.argsort(comp)[::-1][:n_top_words]\n\n    # store the words most relevant to the topic\n    topic_words[topic] = [vocab[i] for i in word_idx]\n    \nfor topic, words in topic_words.items():\n    print('Topic: %d' % topic)\n    print('  %s' % ', '.join(words))"]}, {"cell_type": "markdown", "id": "e7499b2b", "metadata": {}, "source": ["# Principais Artistas em cada T\u00f3pico"]}, {"cell_type": "code", "execution_count": 1, "id": "6704ac77", "metadata": {}, "outputs": [], "source": ["# tranformando objeto style em um dataframe pandas\ndf2 = pd.DataFrame(data=df_document_topics.data, columns=df_document_topics.columns)\ndf2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "a4f95488", "metadata": {}, "outputs": [], "source": ["# associando os interpretes aos t\u00f3picos \n# dos sambas que eles cantam\ndf2[\"artista\"] = df[\"artista\"].tolist()\ndf2.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "503dd3d0", "metadata": {}, "outputs": [], "source": ["# Artistas que mais aparecem dentro de cada t\u00f3pico\ndf2.groupby([\"dominant_topic\"])['artista'].agg(pd.Series.mode).to_frame()"]}, {"cell_type": "code", "execution_count": 1, "id": "1ba08d07", "metadata": {}, "outputs": [], "source": ["# os 5 artistas que mais aparecem no\n# t\u00f3pico 0 e quantidade de sambas \ndf2[df2[\"dominant_topic\"]==0].groupby([\"artista\"]).size().sort_values(ascending=False)[:5]"]}, {"cell_type": "code", "execution_count": 1, "id": "7d09344a", "metadata": {}, "outputs": [], "source": ["# os 5 artistas que mais aparecem no\n# t\u00f3pico 1 e quantidade de sambas \ndf2[df2[\"dominant_topic\"]==1].groupby([\"artista\"]).size().sort_values(ascending=False)[:5]"]}, {"cell_type": "code", "execution_count": 1, "id": "a17b0d09", "metadata": {}, "outputs": [], "source": ["# os 5 artistas que mais aparecem no\n# t\u00f3pico 2 e quantidade de sambas \ndf2[df2[\"dominant_topic\"]==2].groupby([\"artista\"]).size().sort_values(ascending=False)[:5]"]}, {"cell_type": "code", "execution_count": 1, "id": "be898b60", "metadata": {}, "outputs": [], "source": ["# os 5 artistas que mais aparecem no\n# t\u00f3pico 3 e quantidade de sambas \ndf2[df2[\"dominant_topic\"]==3].groupby([\"artista\"]).size().sort_values(ascending=False)[:5]"]}, {"cell_type": "code", "execution_count": 1, "id": "61a2d08f", "metadata": {}, "outputs": [], "source": ["# os 5 artistas que mais aparecem no\n# t\u00f3pico 4 e quantidade de sambas \ndf2[df2[\"dominant_topic\"]==4].groupby([\"artista\"]).size().sort_values(ascending=False)[:5]"]}, {"cell_type": "markdown", "id": "a5267204", "metadata": {}, "source": ["# Reconhecimentos\n\nO que fiz acima foi um estudo inspirado no artigo escrito por Selva Prabhakaran:\n\n* [LDA in Python \u2013 How to grid search best topic models?](https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}