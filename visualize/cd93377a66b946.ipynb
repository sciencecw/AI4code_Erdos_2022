{"cells": [{"cell_type": "code", "execution_count": 1, "id": "df798134", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "0e73d2c0", "metadata": {}, "outputs": [], "source": ["filepath_train = \"../input/30-days-of-ml/train.csv\"\nfilepath_test = \"../input/30-days-of-ml/test.csv\"\n\ndf_train = pd.read_csv(filepath_train, index_col=0)\ndf_test = pd.read_csv(filepath_test, index_col=0)\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "4271963f", "metadata": {}, "outputs": [], "source": ["#df_test.reset_index(drop=True, inplace=True)\ndf_test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "40358c5a", "metadata": {}, "outputs": [], "source": ["df_train.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "6cd320c6", "metadata": {}, "outputs": [], "source": ["print(\"Shape of train data: \" , df_train.shape)\nprint(\"Shape of test data: \" , df_test.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "266f061e", "metadata": {}, "outputs": [], "source": ["# seprating numerical and object columns from train and test data\n\ncols_train_numeric = df_train.select_dtypes('float64').columns\ncols_test_numeric = df_test.select_dtypes('float64').columns\n\ncols_train_object = df_train.select_dtypes('object').columns\ncols_test_object = df_test.select_dtypes('object').columns\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "52d5d9cf", "metadata": {}, "outputs": [], "source": ["import seaborn as sns\nimport matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 1, "id": "3aa202ab", "metadata": {}, "outputs": [], "source": ["\n\n# visualizing any missimg value in train data\nplt.rcParams['figure.figsize'] = (12, 10)\nsns.heatmap(df_train.isnull(), yticklabels=False, cmap='viridis')\n\n# it is clear from graph that we have no missimg value"]}, {"cell_type": "code", "execution_count": 1, "id": "f53d0f6a", "metadata": {}, "outputs": [], "source": ["# checking missimg values for test data\nsns.heatmap(df_test.isnull(), yticklabels=False, cmap='viridis')"]}, {"cell_type": "markdown", "id": "c3298fae", "metadata": {}, "source": ["checking if the test data contains any columns other than  the columns of train data, the print statment is empty, so that means there are no such columns"]}, {"cell_type": "code", "execution_count": 1, "id": "83b0785b", "metadata": {}, "outputs": [], "source": ["extra_cols = [col for col in df_test.columns if col not in df_train.columns ]\nprint(extra_cols)"]}, {"cell_type": "markdown", "id": "4e640787", "metadata": {}, "source": ["Now checking skewness and kurtosis of the test and train dataframe"]}, {"cell_type": "code", "execution_count": 1, "id": "a506141b", "metadata": {}, "outputs": [], "source": ["df_train.skew()"]}, {"cell_type": "code", "execution_count": 1, "id": "7401b168", "metadata": {}, "outputs": [], "source": ["df_test.skew()"]}, {"cell_type": "code", "execution_count": 1, "id": "548e5114", "metadata": {}, "outputs": [], "source": ["df_train.kurt()"]}, {"cell_type": "code", "execution_count": 1, "id": "f9cfe198", "metadata": {}, "outputs": [], "source": ["df_test.kurt()"]}, {"cell_type": "markdown", "id": "dd8f2273", "metadata": {}, "source": ["**Correlation**"]}, {"cell_type": "code", "execution_count": 1, "id": "957219b4", "metadata": {}, "outputs": [], "source": ["plt.rcParams['figure.figsize'] = (14, 12)\nsns.heatmap(df_train.corr(), annot=True, cmap=\"Blues\")"]}, {"cell_type": "markdown", "id": "eba49ad9", "metadata": {}, "source": ["**Checking cardinality of data**"]}, {"cell_type": "code", "execution_count": 1, "id": "66f7d328", "metadata": {}, "outputs": [], "source": ["different_categories = [ col for col in df_train.select_dtypes('object').columns if df_train[col].nunique() > 15]\nprint(\"columns with high cardinality for train data are: \", different_categories)\n\ndifferent_categories = [ col for col in df_test.select_dtypes('object').columns if df_test[col].nunique() > 15]\nprint(\"columns with high cardinality for test data are: \", different_categories)"]}, {"cell_type": "markdown", "id": "2961ef22", "metadata": {}, "source": ["checking if columns of test data contains any category/value that is not present in the columns of train data"]}, {"cell_type": "code", "execution_count": 1, "id": "923aebdf", "metadata": {}, "outputs": [], "source": ["result = []\nfor i in cols_test_object:\n    train = set(df_train[i].unique())\n    test = set(df_test[i].unique())\n    \n    result.append(test.issubset(train))\n    \nprint(result)"]}, {"cell_type": "markdown", "id": "52f6d2ff", "metadata": {}, "source": ["***Splitting the train and testing data***"]}, {"cell_type": "code", "execution_count": 1, "id": "3542c7da", "metadata": {}, "outputs": [], "source": ["X_train = df_train.drop('target', axis=1)\ny_train = df_train['target']"]}, {"cell_type": "code", "execution_count": 1, "id": "3b9f2861", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import OneHotEncoder"]}, {"cell_type": "code", "execution_count": 1, "id": "a4c1c993", "metadata": {}, "outputs": [], "source": ["encoder  = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\nX_train_cat_encoded = pd.DataFrame(encoder.fit_transform(X_train[cols_train_object.to_list()]))\nX_train_cat_encoded.index = X_train.index\nX_train_cat_encoded.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "e66f7748", "metadata": {}, "outputs": [], "source": ["X_train.drop(cols_train_object.to_list(), axis=1, inplace=True)\nX_train"]}, {"cell_type": "code", "execution_count": 1, "id": "240ff405", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train_encoded_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_train_encoded_scaled"]}, {"cell_type": "code", "execution_count": 1, "id": "64de2472", "metadata": {}, "outputs": [], "source": ["X_test_cat_encoded = pd.DataFrame(encoder.transform(df_test[cols_test_object.to_list()]))\nX_test_cat_encoded.index = df_test.index\nX_test_cat_encoded.reset_index(drop=True, inplace=True)\nX_test_cat_encoded"]}, {"cell_type": "code", "execution_count": 1, "id": "1a9c1bd6", "metadata": {}, "outputs": [], "source": ["df_test.drop(cols_test_object.to_list(), axis=1, inplace=True)\ndf_test\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2a26cfd6", "metadata": {}, "outputs": [], "source": ["\nscaler = StandardScaler()\n\nX_test_encoded_scaled = pd.DataFrame(scaler.fit_transform(df_test), columns=df_test.columns)\nX_test_encoded_scaled.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "ea916a00", "metadata": {}, "outputs": [], "source": ["X_test_encoded_scaled.reset_index(drop=True, inplace=True)\nX_test_cat_encoded.reset_index(drop=True, inplace=True)\nX_test = pd.concat([X_test_cat_encoded, X_test_encoded_scaled],join='inner', axis=1)\nX_test"]}, {"cell_type": "markdown", "id": "1f6fe2c6", "metadata": {}, "source": ["Removing the categorical columns and concating numerical columns"]}, {"cell_type": "code", "execution_count": 1, "id": "41b62f32", "metadata": {}, "outputs": [], "source": ["\nX_train_encoded_scaled.reset_index(drop=True, inplace=True)\nX_train_cat_encoded.reset_index(drop=True, inplace=True)\nX_train = pd.concat([X_train_cat_encoded, X_train_encoded_scaled],join='inner', axis=1)\nX_train"]}, {"cell_type": "markdown", "id": "35310e1e", "metadata": {}, "source": ["splitting the data into training and testing"]}, {"cell_type": "code", "execution_count": 1, "id": "f1a4b488", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV"]}, {"cell_type": "code", "execution_count": 1, "id": "c2caa9a7", "metadata": {}, "outputs": [], "source": ["X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "execution_count": 1, "id": "d72cc6ac", "metadata": {}, "outputs": [], "source": ["lin_reg_model = LinearRegression()\nlin_reg_model.fit(X_train, y_train)\n\npredictions = lin_reg_model.predict(X_valid)\n\nmse = mean_squared_error(y_valid, predictions)\nprint(\"Error for linear Regression: \", np.sqrt(mse))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "6725ee1a", "metadata": {}, "outputs": [], "source": ["decision_tree_model = DecisionTreeRegressor()\ndecision_tree_model.fit(X_train, y_train)\n\npredictions = decision_tree_model.predict(X_valid)\n\nmse = mean_squared_error(y_valid, predictions)\nprint(\"Error for Decision Tree: \", np.sqrt(mse))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "eb924442", "metadata": {}, "outputs": [], "source": ["model_forest = RandomForestRegressor() \nmodel_forest.fit(X_train, y_train)\n\npredictions = model_forest.predict(X_valid)\n\nmse = mean_squared_error(y_valid, predictions)\nprint(\"Error for random forest : \", np.sqrt(mse))"]}, {"cell_type": "code", "execution_count": 1, "id": "b6b19d36", "metadata": {}, "outputs": [], "source": ["test_predictions = model_forest.predict(X_test)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ce9c4fee", "metadata": {}, "outputs": [], "source": ["\nX_test"]}, {"cell_type": "code", "execution_count": 1, "id": "4ad632e6", "metadata": {}, "outputs": [], "source": ["# Save the predictions to a CSV file\noutput = pd.DataFrame({'id': df_test.index,\n                       'target': test_predictions})\noutput.to_csv('submission.csv', index=False)\n\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}