{"cells": [{"cell_type": "code", "execution_count": 1, "id": "3acf9f9e", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n## Most Important\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image\nimport scipy\n\n## less Important\nfrom functools import partial\nimport os\nfrom scipy import stats\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,AveragePooling2D\nfrom keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\n\n## Sklearn\nfrom sklearn import datasets\n## Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n## Metrics\nfrom sklearn.metrics import accuracy_score\n\n## tensorflow & Keras\nimport tensorflow as tf    ## i will use tf for every thing and for keras using tf.keras\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "ced303a0", "metadata": {}, "source": ["# Reading Data"]}, {"cell_type": "code", "execution_count": 1, "id": "8439ed57", "metadata": {}, "outputs": [], "source": ["train_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/train.csv')\ntrain_images = Path(r'../input/arabic-hwr-ai-pro-intake1/train')\n\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntrain_images_paths.head()"]}, {"cell_type": "markdown", "id": "1651ba94", "metadata": {}, "source": ["# Explore the data"]}, {"cell_type": "code", "execution_count": 1, "id": "eaac2233", "metadata": {}, "outputs": [], "source": ["img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1"]}, {"cell_type": "code", "execution_count": 1, "id": "cf46049d", "metadata": {}, "outputs": [], "source": ["# know th shape \nprint('Number of Instances in train_set =>', len(train_images_paths))\nprint('Number of Instances in train_labels =>', len(train_labels))\n\nprint()\n\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is =>', img.shape)"]}, {"cell_type": "markdown", "id": "119b1201", "metadata": {}, "source": ["# Data Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "90c176fd", "metadata": {}, "outputs": [], "source": ["train_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 2 channels\n\nfor idx, path in enumerate(train_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    train_full_set[idx] = img\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint('train_full_labels.shape =>', train_full_labels.shape)"]}, {"cell_type": "markdown", "id": "440d41d7", "metadata": {}, "source": ["# Split the data"]}, {"cell_type": "code", "execution_count": 1, "id": "779377bd", "metadata": {}, "outputs": [], "source": ["X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.2, shuffle=True, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "ed5b349f", "metadata": {}, "outputs": [], "source": ["#Onehot Encoding the labels.\nimport keras\nimport keras.utils\nfrom keras import utils as np_utils\nfrom sklearn.utils.multiclass import unique_labels\nfrom tensorflow.keras.utils import to_categorical\n\n\n\n#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\ny_train=to_categorical(y_train)\ny_valid=to_categorical(y_valid)\n\n#Verifying the dimension after one hot encoding\nprint((X_train.shape,y_train.shape))\nprint((X_valid.shape,y_valid.shape))"]}, {"cell_type": "markdown", "id": "f6bcc142", "metadata": {}, "source": ["# Model training"]}, {"cell_type": "code", "execution_count": 1, "id": "30416420", "metadata": {}, "outputs": [], "source": ["from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,AveragePooling2D\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e383adf0", "metadata": {}, "outputs": [], "source": ["# model = tf.keras.models.Sequential([\n#     tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu',input_shape=(32, 32, 3)),\n#     tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n#     tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n#     tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n#     tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ),\n#     tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n#     tf.keras.layers.GlobalAveragePooling2D(),\n#     tf.keras.layers.Dense(29, activation='softmax')\n \n# ])"]}, {"cell_type": "code", "execution_count": 1, "id": "a8b2b723", "metadata": {}, "outputs": [], "source": ["allow_soft_placement=True\n"]}, {"cell_type": "code", "execution_count": 1, "id": "3d1a7fa4", "metadata": {}, "outputs": [], "source": ["nets = 5\nmodel = [0] *nets\nfor j in range(nets):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape=(32, 32, 3)))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Dropout(0.4))\n\n    #Second Layer of CNN\n    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Dropout(0.4))\n\n    #Third layer of CNN\n    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Flatten())\n    model[j].add(Dropout(0.4))\n\n    #Output layer\n    model[j].add(Dense(29, activation='softmax'))\n\n    # Compile each model\n    model[j].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    early_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "1b69c198", "metadata": {}, "outputs": [], "source": ["model"]}, {"cell_type": "code", "execution_count": 1, "id": "338f26c4", "metadata": {}, "outputs": [], "source": ["len(model)"]}, {"cell_type": "code", "execution_count": 1, "id": "43eaf50d", "metadata": {}, "outputs": [], "source": ["# Generate batches of tensor image data with real-time data augmentation more detail: https://keras.io/preprocessing/image/\ndatagen = ImageDataGenerator(rotation_range=2, zoom_range = 0.1, width_shift_range=0.1, height_shift_range=0.1)\ndatagen.fit(X_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "71203ab7", "metadata": {}, "outputs": [], "source": ["batch_size = 32 # Handle 32 pictures at each round\nepochs = 240 "]}, {"cell_type": "code", "execution_count": 1, "id": "01cd4824", "metadata": {}, "outputs": [], "source": ["for j in range(5):\n    print(f'Individual Net : {j+1}')   \n    model[j].fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                                        epochs = epochs, steps_per_epoch=X_train.shape[0] // batch_size,\n                                        validation_data = (X_valid,y_valid), \n                                        callbacks=[ReduceLROnPlateau(monitor='loss', patience=3, factor=0.1)], \n                                        verbose=2)"]}, {"cell_type": "code", "execution_count": 1, "id": "a8304610", "metadata": {}, "outputs": [], "source": ["# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n# early_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "62374bf9", "metadata": {}, "outputs": [], "source": ["# history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n#                     epochs=10, batch_size=32, callbacks=[early_stopp])"]}, {"cell_type": "code", "execution_count": 1, "id": "dbb474aa", "metadata": {}, "outputs": [], "source": ["model"]}, {"cell_type": "markdown", "id": "e7e846fb", "metadata": {}, "source": ["# Evaluate on test set"]}, {"cell_type": "code", "execution_count": 1, "id": "895079b7", "metadata": {}, "outputs": [], "source": ["test_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/test.csv')\ntest_images = Path(r'../input/arabic-hwr-ai-pro-intake1/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "1c418ed7", "metadata": {}, "outputs": [], "source": ["print('Number of Instances in test_set is', len(test_images_paths))\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2d8381c0", "metadata": {}, "outputs": [], "source": ["test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(test_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    test_full_set[idx] = img\n    \nprint('test_full_set.shape =>', test_full_set.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "bcfe0ecf", "metadata": {}, "outputs": [], "source": ["# y_preds_classes = np.argmax(model.predict(test_full_set), axis=-1)\n# Predict labels with models\nlabels = []\nfor m in model:\n    predicts = np.argmax(m.predict(test_full_set), axis=1)\n    labels.append(predicts)\n    \n# Ensemble with voting\nlabels = np.array(labels)\nlabels = np.transpose(labels, (1, 0))\nlabels = scipy.stats.mode(labels, axis=1)[0]\nlabels = np.squeeze(labels)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e5c9ba0e", "metadata": {}, "outputs": [], "source": ["labels.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "1bb361bf", "metadata": {}, "outputs": [], "source": ["test_labels['label'] = labels"]}, {"cell_type": "code", "execution_count": 1, "id": "19c1ff4f", "metadata": {}, "outputs": [], "source": ["test_labels"]}, {"cell_type": "code", "execution_count": 1, "id": "650f92b9", "metadata": {}, "outputs": [], "source": ["# Dump predictions into submission file\npd.DataFrame({'ImageId' : np.arange(1, predicts.shape[0] + 1), 'Label' : labels }).to_csv('/kaggle/working/submission.csv', index=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "2cf516cc", "metadata": {}, "outputs": [], "source": ["# test_labels['label'] = y_preds_classes\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ecea4ad6", "metadata": {}, "outputs": [], "source": ["# test_labels\n"]}, {"cell_type": "code", "execution_count": 1, "id": "eac20268", "metadata": {}, "outputs": [], "source": ["test_labels[['id', 'label']].to_csv('/kaggle/working/submission.csv', index=False)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}