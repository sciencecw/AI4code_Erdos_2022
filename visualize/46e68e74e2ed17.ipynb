{"cells": [{"cell_type": "markdown", "id": "ddb0e9c5", "metadata": {}, "source": ["## Human Activity Recognition Using Smartphones Data Set"]}, {"cell_type": "markdown", "id": "a3692a47", "metadata": {}, "source": ["# `Introduction`\n\nWe will be using the [Human Activity Recognition with Smartphones](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) database, which was built from the recordings of study participants performing activities of daily living (ADL) while carrying a smartphone with an embedded inertial sensors. The objective is to classify activities into one of the six activities (walking, walking upstairs, walking downstairs, sitting, standing, and laying) performed.\n\nFor each record in the dataset it is provided: \n\n- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. \n- Triaxial Angular velocity from the gyroscope. \n- A 561-feature vector with time and frequency domain variables. \n- Its activity label. \n\nMore information about the features is available on the website above."]}, {"cell_type": "markdown", "id": "359a7450", "metadata": {}, "source": ["# `Plan for data exploration`\n1. Exploring data \n    * Examine the data types and value_counts\n2. feature engineering \n    * see the data distribution\n    * removing unimportant data if found \n    * dealing with missing (NaN) values if found\n    * feature scalling for continuous variables if needed\n3. encoding\n    * encoding for categorical variables if found as to Encode the activity label as an integer\n4. Spliting the Data\n5. Applying classification models\n    * Logistic Regression\n    * K-Nearest Neighbors (KNeighbors)\n    * Decision Trees\n    * Ensemble Methods (Gradient Boosting) \n6. Selecting the best model\n7. Next steps"]}, {"cell_type": "markdown", "id": "a17d0e0f", "metadata": {}, "source": ["# `Exploring and feature engineering`"]}, {"cell_type": "code", "execution_count": 1, "id": "4a10f2e8", "metadata": {}, "outputs": [], "source": ["# importing\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold,GridSearchCV\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\n\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "95691935", "metadata": {}, "outputs": [], "source": ["# filepath = 'data/Human_Activity_Recognition_Using_Smartphones_Data.csv'\ntrain = pd.read_csv('../input/human-activity-recognition-with-smartphones/train.csv')\ntest = pd.read_csv('../input/human-activity-recognition-with-smartphones/test.csv')\ntrain.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "6aee8d25", "metadata": {}, "outputs": [], "source": ["train.dtypes.value_counts()"]}, {"cell_type": "markdown", "id": "548a3a63", "metadata": {}, "source": ["The data columns are all floats except for the activity label."]}, {"cell_type": "code", "execution_count": 1, "id": "38bf27ab", "metadata": {}, "outputs": [], "source": ["# see the min and max of data excluding the target\nprint('min = ',train.iloc[:, :-1].min().value_counts())\nprint('max = ',train.iloc[:, :-1].max().value_counts())"]}, {"cell_type": "markdown", "id": "440fbcd7", "metadata": {}, "source": ["The data are all scaled from -1 (minimum) to 1.0 (maximum)."]}, {"cell_type": "code", "execution_count": 1, "id": "3509bce2", "metadata": {}, "outputs": [], "source": ["# Examine the breakdown of activities-- to see if balanced or not\ntrain.Activity.value_counts(normalize=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "42be8cd5", "metadata": {}, "outputs": [], "source": ["train.isnull().sum().all() and test.isnull().sum().all()"]}, {"cell_type": "markdown", "id": "e35c5dc5", "metadata": {}, "source": ["# `encoding`"]}, {"cell_type": "markdown", "id": "cc574386", "metadata": {}, "source": ["Scikit learn classifiers won't accept a sparse matrix for the prediction column. Thus, either `LabelEncoder` needs to be used to convert the activity labels to integers, or if `DictVectorizer` is used, the resulting matrix must be converted to a non-sparse array.  \n\nwe will use `LabelEncoder` to fit_transform the \"Activity\" column, and look at 5 random values."]}, {"cell_type": "code", "execution_count": 1, "id": "69a745d0", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ntrain['Activity'] = le.fit_transform(train.Activity)\ntest['Activity'] = le.fit_transform(test.Activity)\ntrain['Activity'].sample(5)\n## END SOLUTION"]}, {"cell_type": "markdown", "id": "5c2157f4", "metadata": {}, "source": ["# `looking at correlation`\n\n* Calculate the correlations between the dependent variables.\n* Create a histogram of the correlation values\n* Identify those that are most correlated (either positively or negatively)."]}, {"cell_type": "code", "execution_count": 1, "id": "200a289f", "metadata": {}, "outputs": [], "source": ["# Calculate the correlation values\nfeature_cols = train.columns[:-1]\ncorr_values = train[feature_cols].corr()\n\n# Simplify by emptying all the data below the diagonal\ntril_index = np.tril_indices_from(corr_values)\n\n# Make the unused values NaNs\nfor coord in zip(*tril_index):\n    corr_values.iloc[coord[0], coord[1]] = np.NaN\n    \n# Stack the data and convert to a data frame\ncorr_values = (corr_values\n               .stack()\n               .to_frame()\n               .reset_index()\n               .rename(columns={'level_0':'feature1',\n                                'level_1':'feature2',\n                                0:'correlation'}))\n\n# Get the absolute values for sorting\ncorr_values['abs_correlation'] = corr_values.correlation.abs()\ncorr_values"]}, {"cell_type": "code", "execution_count": 1, "id": "930fb8a3", "metadata": {}, "outputs": [], "source": ["# The most highly correlated values\ncorr_values.sort_values('correlation', ascending=False).query('abs_correlation>0.8')"]}, {"cell_type": "markdown", "id": "c02dec9a", "metadata": {}, "source": ["# `Data split`\n\n* This can be done using any method, but consider using Scikit-learn's `StratifiedShuffleSplit` to maintain the same ratio of predictor classes.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e6b235ba", "metadata": {}, "outputs": [], "source": ["X_train = train[feature_cols]\nX_test = test[feature_cols]\ny_train = train['Activity']\ny_test  = test['Activity']"]}, {"cell_type": "code", "execution_count": 1, "id": "c4155925", "metadata": {}, "outputs": [], "source": ["y_train.value_counts(normalize=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "1a9fe09b", "metadata": {}, "outputs": [], "source": ["y_test.value_counts(normalize=True)"]}, {"cell_type": "markdown", "id": "f0f171e6", "metadata": {}, "source": ["we maintained the distribution of the target class seccussfuly"]}, {"cell_type": "markdown", "id": "8642023a", "metadata": {}, "source": ["# `Applying classification models`\n\n- Logistic Regression\n- K-Nearest Neighbors (KNeighbors)\n- Decision Trees\n- Ensemble Methods (Gradient Boosting)"]}, {"cell_type": "markdown", "id": "d5ae66f2", "metadata": {}, "source": ["## `1.Logistic Regression`"]}, {"cell_type": "code", "execution_count": 1, "id": "5d2becb1", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n# Standard logistic regression\nlr = LogisticRegression(solver='liblinear').fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "ab9348ff", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegressionCV\n# L1 regularized logistic regression\nlr_l1 = LogisticRegressionCV(Cs=10, cv=4, penalty='l1', solver='liblinear').fit(X_train, y_train)\n# L2 regularized logistic regression\nlr_l2 = LogisticRegressionCV(Cs=10, cv=4, penalty='l2', solver='liblinear').fit(X_train, y_train)"]}, {"cell_type": "markdown", "id": "72777d78", "metadata": {}, "source": ["* Predict and store the class for each model.\n* Store the probability for the predicted class for each model. "]}, {"cell_type": "code", "execution_count": 1, "id": "76f750a7", "metadata": {}, "outputs": [], "source": ["# Predict the class and the probability for each\ny_pred = list()\ny_prob = list()\n\ncoeff_labels = ['lr', 'l1', 'l2']\ncoeff_models = [lr, lr_l1, lr_l2]\n\nfor lab,mod in zip(coeff_labels, coeff_models):\n    y_pred.append(pd.Series(mod.predict(X_test), name=lab))\n    y_prob.append(pd.Series(mod.predict_proba(X_test).max(axis=1), name=lab))\n    \ny_pred = pd.concat(y_pred, axis=1)\ny_prob = pd.concat(y_prob, axis=1)\ny_pred.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "655426fe", "metadata": {}, "outputs": [], "source": ["y_prob.head()"]}, {"cell_type": "markdown", "id": "1faa7e58", "metadata": {}, "source": ["### `error metrics`\n\nFor each model, calculate the following error metrics: \n* Accuracy\n* Precision\n* Recall\n* F-score\n* Confusion Matrix"]}, {"cell_type": "code", "execution_count": 1, "id": "241414ba", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\nfrom sklearn.preprocessing import label_binarize\n\nmetrics = list()\ncm = dict()\n\nfor lab in coeff_labels:\n\n    precision, recall, fscore, _ = score(y_test, y_pred[lab], average='weighted')\n    \n    accuracy = accuracy_score(y_test, y_pred[lab])\n    \n    # ROC-AUC scores can be calculated by binarizing the data\n    auc = roc_auc_score(label_binarize(y_test, classes=[0,1,2,3,4,5]),\n              label_binarize(y_pred[lab], classes=[0,1,2,3,4,5]), \n              average='weighted')\n    \n    cm[lab] = confusion_matrix(y_test, y_pred[lab])\n    \n    metrics.append(pd.Series({'precision':precision, 'recall':recall, \n                              'fscore':fscore, 'accuracy':accuracy,\n                              'auc':auc}, \n                             name=lab))\n\nmetrics = pd.concat(metrics, axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "83308508", "metadata": {}, "outputs": [], "source": ["metrics"]}, {"cell_type": "code", "execution_count": 1, "id": "668f2d56", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import f1_score\n\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)\nf1_lr = f1_score(y_pred, y_test, average='weighted')\nf1_lr"]}, {"cell_type": "code", "execution_count": 1, "id": "2de9b17c", "metadata": {}, "outputs": [], "source": ["## Display or plot the confusion matrix for each model.\n\nfig, axList = plt.subplots(nrows=2, ncols=2)\naxList = axList.flatten()\nfig.set_size_inches(12, 10)\n\naxList[-1].axis('off')\n\nfor ax,lab in zip(axList[:-1], coeff_labels):\n    sns.heatmap(cm[lab], ax=ax, annot=True, fmt='d');\n    ax.set(title=lab);\n    \nplt.tight_layout()"]}, {"cell_type": "markdown", "id": "3f2b8204", "metadata": {}, "source": ["## `2.K-Nearest Neighbors (KNeighbors)`"]}, {"cell_type": "code", "execution_count": 1, "id": "15a42776", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import f1_score\n\nknn = KNeighborsClassifier(n_neighbors=3, weights='distance')\nknn = knn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nf1_knn = f1_score(y_pred, y_test, average='weighted')\nf1_knn"]}, {"cell_type": "markdown", "id": "5f858d5b", "metadata": {}, "source": ["## `3.Decision Trees`"]}, {"cell_type": "code", "execution_count": 1, "id": "4b9681de", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntuning_parameters = {'max_depth':[2,4,6,8,10],\n                     'min_samples_leaf':[2,4,6,8,10], \n                     'min_samples_split':[2,4,6,8,10]}\n\nscorer = make_scorer(f1_score, average = 'micro')\nGR = GridSearchCV(DecisionTreeClassifier(random_state=42), tuning_parameters, scoring=scorer,)\nGR = GR.fit(X_train, y_train)\n\nprint('GR.best_estimator_: ', GR.best_estimator_)\nprint('GR.best_score_: ', GR.best_score_)\nprint('GR.best_params_: ', GR.best_params_)"]}, {"cell_type": "code", "execution_count": 1, "id": "21b77951", "metadata": {}, "outputs": [], "source": ["GR.best_score_, GR.best_params_"]}, {"cell_type": "code", "execution_count": 1, "id": "d945cba8", "metadata": {}, "outputs": [], "source": ["y_pred = GR.predict(X_test)\nf1_dt = f1_score(y_pred, y_test, average='weighted')\nf1_dt"]}, {"cell_type": "markdown", "id": "665ec286", "metadata": {}, "source": ["## `4.GradientBoosting`"]}, {"cell_type": "code", "execution_count": 1, "id": "0b2d54ed", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingClassifier\nGBC = GradientBoostingClassifier(max_features=5, n_estimators=100, random_state=42)\nGBC.fit(X_train.values, y_train.values)\ny_pred = GBC.predict(X_test)\nf1_GBC = f1_score(y_pred, y_test, average='weighted')\nf1_GBC"]}, {"cell_type": "markdown", "id": "1f6a2c7e", "metadata": {}, "source": ["# `Selecting best model`"]}, {"cell_type": "code", "execution_count": 1, "id": "cb9a750f", "metadata": {}, "outputs": [], "source": ["pd.DataFrame({'Logistic Regression':f1_lr, 'KNN':f1_knn, \n                              'Decision Trees':f1_dt, 'Gradient Boosting':f1_GBC},index = ['F1_SCORE'])"]}, {"cell_type": "markdown", "id": "84b4676a", "metadata": {}, "source": ["### so we will chooce `GradientBoostingClassifier` or `logistic regression`"]}, {"cell_type": "markdown", "id": "b1ae3383", "metadata": {}, "source": ["# `key findings`"]}, {"cell_type": "markdown", "id": "21ac98d7", "metadata": {}, "source": ["logistic regression without regularization got us the highest F1_Score so we will choose it and Decision Trees took too long and got the worst score"]}, {"cell_type": "markdown", "id": "e5042db1", "metadata": {}, "source": ["# `Next steps`"]}, {"cell_type": "markdown", "id": "75d0c7b7", "metadata": {}, "source": ["we can use another encoding method like `LabelBinarizer` and we can try another ensemble method like `Random forest`"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}