{"cells": [{"cell_type": "markdown", "id": "9c67cbe2", "metadata": {}, "source": ["## ZIPF'S LAW VALIDATION BY PLOTTING WORD FREQUENCY <BR>\n<font color=red>Word Frequency distribution can be considered as one of the basic statistical analysis that can be done on text data.<BR>\nZipf's Law is a discrete probability distribution for the frequency of the words in the corpus or in other terms probability of encountering a word in the corpus. Ranking is done in such a way that, rank 1 is given to the most frequent word, rank 2 to the next frequent, and so on. This also indicates that Zipf's law follows power-law distribution. </font>\n![ZIPF's%20law.PNG](attachment:ZIPF's%20law.PNG)    \n    \nAs you an see from the plot above, the Language Builder words (For Example: is,an,the) or words that can be called as STOPWORDS would be the most frequent words in your dataset and the least significant words, since they do not add any useful information.\n<HR>\nIn this notebook we can validate Zipf's law, whether it holds true with our corpus by plotting the word frequencies.\n    </hr>"]}, {"cell_type": "code", "execution_count": 1, "id": "849c6084", "metadata": {}, "outputs": [], "source": ["#Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#Importing the String module\nimport string\nfrom nltk import FreqDist\nfrom nltk.corpus import stopwords"]}, {"cell_type": "code", "execution_count": 1, "id": "ba54a895", "metadata": {}, "outputs": [], "source": ["#To ignore warning messages\nimport warnings\nwarnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": 1, "id": "d5ef895f", "metadata": {}, "outputs": [], "source": ["#To display the full text column instead of truncating one\npd.set_option('display.max_colwidth', -1)"]}, {"cell_type": "code", "execution_count": 1, "id": "536ee953", "metadata": {}, "outputs": [], "source": ["#Reading the train file\ndf = pd.read_csv(\"/kaggle/input/spooky-author-identification/train.zip\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4745f602", "metadata": {}, "outputs": [], "source": ["#Head of the dataframe\ndf.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "42610865", "metadata": {}, "outputs": [], "source": ["#Dimension of the dataframe\ndf.shape"]}, {"cell_type": "markdown", "id": "7ddc6ac9", "metadata": {}, "source": ["There are 19579 excerpts in our train set."]}, {"cell_type": "markdown", "id": "73ab0045", "metadata": {}, "source": ["From the first few columns, we can see that there are many punctuations present in the text data like `Comma` which we will clean before creating the text corpus, so that it wont impact the final words."]}, {"cell_type": "code", "execution_count": 1, "id": "824d601d", "metadata": {}, "outputs": [], "source": ["#Python provides a constant called string.punctuation that provides a great list of punctuation characters. \nprint(string.punctuation)"]}, {"cell_type": "code", "execution_count": 1, "id": "acccc5b1", "metadata": {}, "outputs": [], "source": ["def remove_punctuations(input_col):\n    \"\"\"To remove all the punctuations present in the text.Input the text column\"\"\"\n    table = str.maketrans('','',string.punctuation)\n    return input_col.translate(table)"]}, {"cell_type": "code", "execution_count": 1, "id": "667a0d37", "metadata": {}, "outputs": [], "source": ["#Applying the remove_punctuation function\ndf['text'] = df['text'].apply(remove_punctuations)"]}, {"cell_type": "code", "execution_count": 1, "id": "871f81f2", "metadata": {}, "outputs": [], "source": ["def build_corpus(text_col):\n    \"\"\"To build a text corpus by stitching all the records together.Input the text column\"\"\"\n    corpus = \"\"\n    for sent in text_col:\n        corpus += sent\n    return corpus"]}, {"cell_type": "code", "execution_count": 1, "id": "1575e7ce", "metadata": {}, "outputs": [], "source": ["#Building the corpus\ncorpus = build_corpus(df['text'])"]}, {"cell_type": "code", "execution_count": 1, "id": "5becfff5", "metadata": {}, "outputs": [], "source": ["#Converting all the words into lowercase\ncorpus = corpus.lower()"]}, {"cell_type": "code", "execution_count": 1, "id": "da605132", "metadata": {}, "outputs": [], "source": ["#Some part of the Text Corpus\ncorpus[:1000]"]}, {"cell_type": "markdown", "id": "0d174240", "metadata": {}, "source": ["If you skim through the Corpus, you can find that we are having a clean text corpus as of now. We will go ahead and create a word list now."]}, {"cell_type": "code", "execution_count": 1, "id": "2ed7a273", "metadata": {}, "outputs": [], "source": ["#Splitting the entire corpus\ncorpus = corpus.split()"]}, {"cell_type": "code", "execution_count": 1, "id": "3c3afa0e", "metadata": {}, "outputs": [], "source": ["#Observing the first few words\nprint(corpus[:50])"]}, {"cell_type": "code", "execution_count": 1, "id": "489048fc", "metadata": {}, "outputs": [], "source": ["def plot_word_frequency(words,top_n=10):\n    \"\"\"Function to plot the word frequencies\"\"\"\n    word_freq = FreqDist(words)\n    labels = [element[0] for element in word_freq.most_common(top_n)]\n    counts = [element[1] for element in word_freq.most_common(top_n)]\n    plt.figure(figsize=(15,5))\n    plt.title(\"Most Frequent Words in the Corpus - Including STOPWORDS\")\n    plt.ylabel(\"Count\")\n    plt.xlabel(\"Word\")\n    plot = sns.barplot(labels,counts)\n    return plot"]}, {"cell_type": "code", "execution_count": 1, "id": "9f688414", "metadata": {}, "outputs": [], "source": ["plot_word_frequency(corpus,20)"]}, {"cell_type": "markdown", "id": "83dc4000", "metadata": {}, "source": ["You can find that, most of the words present over here in the top occuring list are STOPWORDS and the most frequenct word here is `the` and that is obvious. <br>\nThis is in line with what we were expecting - The most frequent words in the corpus are Language Builders.\nWe can remove the stopwords and try plotting again to find out the most occuring words in the corpus"]}, {"cell_type": "code", "execution_count": 1, "id": "82984316", "metadata": {}, "outputs": [], "source": ["corpus_without_stop = [word for word in corpus if word not in stopwords.words(\"english\")]"]}, {"cell_type": "code", "execution_count": 1, "id": "41c4e30b", "metadata": {}, "outputs": [], "source": ["plot_word_frequency(corpus_without_stop,20)"]}, {"cell_type": "markdown", "id": "b8dfdd00", "metadata": {}, "source": ["We can now see the most frequent words of the corpus after removing stopwords.These are just 20 most frquent words, but there are many others too and these words would be the words with most significance in our corpus and which lies in the middle range of the Zip's Law distribution. "]}, {"cell_type": "markdown", "id": "6697b05e", "metadata": {}, "source": ["### LOG-LOG PLOT for Frequency vs Rank"]}, {"cell_type": "code", "execution_count": 1, "id": "2c0a39ba", "metadata": {}, "outputs": [], "source": ["#Creating a FreqDist object\nfd=FreqDist()"]}, {"cell_type": "code", "execution_count": 1, "id": "d12059aa", "metadata": {}, "outputs": [], "source": ["#Creating ranks and frequencies\nranks = []\nfreqs = []\nfor i in corpus:\n    fd[i] +=1\nfor rank,word in enumerate(fd):\n    ranks.append(rank+1)\n    freqs.append(fd[word])"]}, {"cell_type": "code", "execution_count": 1, "id": "a44c7786", "metadata": {}, "outputs": [], "source": ["#Plotting the distribution\nplt.figure(figsize=(20,7))\nplt.loglog(freqs,ranks)\nplt.xlabel('Rank')\nplt.ylabel('Frequency')\nplt.title(\"Zipf's Distribution\")\nplt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}