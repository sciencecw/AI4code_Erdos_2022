{"cells": [{"cell_type": "markdown", "id": "8192071f", "metadata": {}, "source": ["# Background\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSq1nErz3DSY70KK_pIBgBVeNrXbn7NXr5tfomCAAF0f0VotIbt&usqp=CAU)\n\nThe 1992 LA Riots occurred in Los Angeles County during April and May of 1992.  There were already underlying ethnic tensions, but the riots were sparked by the jury acquittal of the 4 officers responsible for usage of excessive force in the beating and arrest of Rodney King.  Ultimately the riots resulted in 63 deaths, thousands of injuries, and $1 billion in damages.  In this dataset, we have information on the 63 deaths that occurred in relation the LA Riots.  We will be plotting them using Folium to see if there are any patterns with their locations. \n"]}, {"cell_type": "markdown", "id": "377ad45c", "metadata": {}, "source": ["Importing packages"]}, {"cell_type": "code", "execution_count": 1, "id": "de8923a6", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport folium\nfrom sklearn.cluster import KMeans\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "b6d88b75", "metadata": {}, "source": ["### Basic Information on the Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "d1bcaa78", "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n\n#importing the data\nfilename = '../input/los-angeles-1992-riot-deaths-from-la-times/la-riots-deaths.csv'\ndata = pd.read_csv(filename)\n#Exploring the data\ndata.info()\ndata.head()\n"]}, {"cell_type": "markdown", "id": "89e32ad2", "metadata": {}, "source": ["As we can see the dataset gives us basic information on each of the deaths, such as their name, age, race, location, etc...Let's extract the longitude and latitude values so that we can plot them and get insights on clustering."]}, {"cell_type": "code", "execution_count": 1, "id": "d47c9992", "metadata": {}, "outputs": [], "source": ["\n#Here I am switching latitude and longitude because it is incorrectly labeled in the dataset.\nlongitude = data['lat'].values\nlatitude = data['lon'].values"]}, {"cell_type": "code", "execution_count": 1, "id": "ead30bbd", "metadata": {}, "outputs": [], "source": ["\nm = folium.Map(location=[34.0593, -118.274], zoom_start = 10)\n\n# I skipped 51 because that one showed up as a NaN.\nfor i in range(63):\n    if (i != 51):\n        folium.Marker([latitude[i],longitude[i]],popup = data.loc[i,'Full Name'] ).add_to(m)\nm        "]}, {"cell_type": "code", "execution_count": 1, "id": "ea08ceed", "metadata": {}, "outputs": [], "source": ["plt.plot(data['lat'], data['lon'],'.')\nplt.title('Plot of Deaths')\nplt.show()"]}, {"cell_type": "markdown", "id": "7a9ac28c", "metadata": {}, "source": ["### Testing Different Numbers of Clusters\nWe will try out different number of clusters using KMeans clustering and then decide what the best number of clusters is by seeing when the SSE score stops improving significantly."]}, {"cell_type": "code", "execution_count": 1, "id": "c22d1d7f", "metadata": {}, "outputs": [], "source": ["#I decided to just fill in the missing value for the following kmeans clustering.\nvalues = {'lat': 34.0593, 'lon':-118.274}\nfilleddata = data.fillna(value=values)"]}, {"cell_type": "code", "execution_count": 1, "id": "a57842df", "metadata": {}, "outputs": [], "source": ["def get_kmeans_score(data, center):\n    '''\n    returns the kmeans score regarding SSE for points to centers\n    INPUT:\n        data - the dataset you want to fit kmeans to\n        center - the number of centers you want (the k value)\n    OUTPUT:\n        score - the SSE score for the kmeans model fit to the data\n    '''\n  \n    kmeans = KMeans(n_clusters=center)\n    model = kmeans.fit(data)\n    score = np.abs(model.score(data))\n    \n    return score\n\nscores = []\ncenters = list(range(1,11))\n\nfor center in centers:\n    scores.append(get_kmeans_score(filleddata.loc[: ,['lon','lat']], center))\n    \nplt.plot(centers, scores, linestyle='--', marker='o', color='b');\nplt.xlabel('Number of Centers');\nplt.ylabel('SSE');\nplt.title('SSE vs. Number');"]}, {"cell_type": "markdown", "id": "fee15d19", "metadata": {}, "source": ["So it looks like we have two clusters, according to the elbow method, since after 2 there is insignificant improvement. Now let's find their coordinates so that we can plot them on the map as well."]}, {"cell_type": "code", "execution_count": 1, "id": "9680f2ac", "metadata": {}, "outputs": [], "source": ["kmeans = KMeans(n_clusters=2)\n\nkmeans.fit(filleddata.loc[: ,['lon','lat']]).cluster_centers_\n#I am not sure why it's switching the coordinates for the first cluster"]}, {"cell_type": "code", "execution_count": 1, "id": "a41165d8", "metadata": {}, "outputs": [], "source": ["\n#Plotting the two centers \nfolium.Marker([34.02756075,-118.28079299],popup = 'Cluster Center', icon=folium.Icon(color='red') ).add_to(m)\nfolium.Marker([34.0593,-118.274],popup = 'Cluster Center', icon=folium.Icon(color='red') ).add_to(m)\n\nm"]}, {"cell_type": "markdown", "id": "3e63b4fe", "metadata": {}, "source": ["The two main clusters that the KMeans algorithm found were one centered around University Park and one centered around Westlake. "]}, {"cell_type": "markdown", "id": "bc69bb7a", "metadata": {}, "source": ["## Further Studies and Finishing Thoughts\nThis was my very first notebook and I was just excited to publish it, so I welcome all comments and suggestions!  To further study this data, I could try out different clustering algorithms besides KMeans.  Also, I could look at a Racial breakdown of the deaths. "]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}