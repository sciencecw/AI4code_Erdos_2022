{"cells": [{"cell_type": "code", "execution_count": 1, "id": "9a04346a", "metadata": {}, "outputs": [], "source": ["import numpy as np \nimport pandas as pd \nimport pyodbc \nimport matplotlib.pyplot as plt\n\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.offline as ply\nply.init_notebook_mode(connected=True)\nimport plotly.express as px\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"]}, {"cell_type": "code", "execution_count": 1, "id": "14e3e377", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv(\"/kaggle/input/covid19-in-turkey/covid_19_data_tr.csv\")\nsehir_data = pd.read_csv(\"../input/number-of-cases-in-the-city-covid19-turkey/number_of_cases_in_the_city.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4b729372", "metadata": {}, "outputs": [], "source": ["data"]}, {"cell_type": "code", "execution_count": 1, "id": "303467e4", "metadata": {}, "outputs": [], "source": ["print(data.shape[0])\nprint(data.shape[1])\nprint(data.columns.tolist())\nprint(data.dtypes)"]}, {"cell_type": "code", "execution_count": 1, "id": "9178941b", "metadata": {}, "outputs": [], "source": ["print(data['Country/Region'].value_counts())"]}, {"cell_type": "code", "execution_count": 1, "id": "a0de510c", "metadata": {}, "outputs": [], "source": ["print(data['Confirmed'].describe())"]}, {"cell_type": "code", "execution_count": 1, "id": "85f01888", "metadata": {}, "outputs": [], "source": ["data.groupby('Country/Region').mean()"]}, {"cell_type": "code", "execution_count": 1, "id": "7072ca5c", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n%matplotlib inline"]}, {"cell_type": "code", "execution_count": 1, "id": "2243b2ae", "metadata": {}, "outputs": [], "source": ["ax = plt.axes()\nax.scatter(data.Deaths, data.Recovered)\n\n# Label the axes\nax.set(xlabel='\u00d6len Ki\u015fi',\n       ylabel='Kurtar\u0131lan Ki\u015fi',\n       title='\u00d6len ve Kurtar\u0131lan Ki\u015fi');"]}, {"cell_type": "markdown", "id": "1bac125d", "metadata": {}, "source": ["# \u015eehir Verileri"]}, {"cell_type": "code", "execution_count": 1, "id": "4de30e07", "metadata": {}, "outputs": [], "source": ["sehir_data"]}, {"cell_type": "code", "execution_count": 1, "id": "b44229d4", "metadata": {}, "outputs": [], "source": ["sehir_data.rename(columns = {\"Province\":\"\u015eehir\", \"Number of Case\":\"Vaka Say\u0131s\u0131\"},\n                 inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "00b39a85", "metadata": {}, "outputs": [], "source": ["sehir_data.sort_values(by=[\"Vaka Say\u0131s\u0131\"], ascending=False, inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "6d02f042", "metadata": {}, "outputs": [], "source": ["fig = px.pie(\n    sehir_data.head(),\n    values = \"Vaka Say\u0131s\u0131\",\n    names = \"\u015eehir\",\n    title = \"En Y\u00fcksek Vaka Say\u0131s\u0131na Sahip 5 \u015eehir\"\n)\nfig.update_traces(textposition=\"inside\", textinfo=\"percent+label\")\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "6449e826", "metadata": {}, "outputs": [], "source": ["sehir_temp_data = sehir_data[5:]\nfig = px.pie(\n    sehir_temp_data,\n    values = \"Vaka Say\u0131s\u0131\",\n    names = \"\u015eehir\",\n    title = \"Di\u011fer \u015eehirlerdeki Vaka Say\u0131s\u0131\",\n    hover_data =[\"Vaka Say\u0131s\u0131\"]\n)\nfig.update_traces(textposition=\"inside\", textinfo=\"percent+label\")\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "5015c85d", "metadata": {}, "outputs": [], "source": ["fig = px.bar(\n    sehir_data[0:5],\n    x = \"\u015eehir\",\n    y = \"Vaka Say\u0131s\u0131\",\n    title = \"En Y\u00fcksek Vaka Say\u0131s\u0131na Sahip 5 \u015eehir\"\n)\nfig.update_layout(barmode=\"group\")\nfig.update_traces(\n    marker_color='rgba(240, 92, 92, 0.6)',\n    marker_line_color=\"rgba(191, 18, 18, 1)\",\n)\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "9b45161e", "metadata": {}, "outputs": [], "source": ["fig = px.bar(\n    sehir_data[5:15],\n    x = \"\u015eehir\",\n    y = \"Vaka Say\u0131s\u0131\",\n    title = \"En Y\u00fcksek Vaka Say\u0131s\u0131na Sahip [5-15] Aral\u0131\u011f\u0131ndaki \u015eehirler\")\nfig.update_layout(barmode=\"group\")\nfig.update_traces(\n    marker_color='rgba(215,137,86,0.6)',\n    marker_line_color=\"rgba(153, 83, 36, 1)\",\n)\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "c225a411", "metadata": {}, "outputs": [], "source": ["fig = px.bar(\n    sehir_data[15:],\n    x = \"\u015eehir\",\n    y = \"Vaka Say\u0131s\u0131\",\n    title = \"En Y\u00fcksek Vaka Say\u0131s\u0131na Sahip [15-81] Aral\u0131\u011f\u0131ndaki \u015eehirler\",\n    \n)\nfig.update_layout(barmode=\"group\")\nfig.update_traces(marker_color='rgb(158,202,225)',\n                  marker_line_color=\"rgb(8,48,107)\",\n                 )\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "f5082a6d", "metadata": {}, "outputs": [], "source": ["df=data.filter(['Last_Update','Confirmed','Deaths','Recovered'])\ndf.head(75)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "be897ab3", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(16,8))\nplt.plot(df['Confirmed'], label='Confirmed cases')"]}, {"cell_type": "code", "execution_count": 1, "id": "18017928", "metadata": {}, "outputs": [], "source": ["df1 = pd.read_csv('../input/covid19-coronavirus/2019_nCoV_data.csv')\ndf1.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "98ce4e1b", "metadata": {}, "outputs": [], "source": ["df1 = df1.astype({\"Confirmed\": int, \"Deaths\": int, \"Recovered\" : int})\ndf1 = df1.filter([\"Date\", \"Province/State\", \"Country\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"])\ndf1.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "3a1a4a89", "metadata": {}, "outputs": [], "source": ["df1['Date1'] = pd.to_datetime(df1['Date'])\ndf1['Date'] = df1['Date1'].dt.date\ndf1['Last Update1'] = pd.to_datetime(df1['Last Update'])\ndf1['Last Update'] = df1['Last Update1'].dt.date\ndf1 = df1.filter([\"Date\", \"Province/State\", \"Country\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"])\ndf1.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "0d2fe858", "metadata": {}, "outputs": [], "source": ["df1['Location'] = df1['Country'] + ', ' + df1['Province/State'].fillna('N/A')\n\ndaily = pd.DataFrame(columns=df1.columns)\n\nfor item in df1['Location'].unique():\n    a = df1[df1['Location']==item].set_index('Date')\n    a = a.rename_axis('Date').reset_index()\n    daily = daily.append(a, sort=False, ignore_index=True)\n\ndf1_daily = daily.sort_values(['Date','Country','Province/State'])\ndf1_daily = df1_daily.reset_index()\ndf1_daily = df1_daily.filter([\"Date\", \"Province/State\", \"Country\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Location\"])\ndf1_daily.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "4befd5c7", "metadata": {}, "outputs": [], "source": ["df1_date = df1_daily.filter([\"Date\",  \"Confirmed\", \"Deaths\", \"Recovered\"])\ndf1_date = df1_date.groupby(df1_date[\"Date\"]).sum()\ndf1_date.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "e9b2a34e", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(11,6))\nplt.plot(df1_date, marker='o')\nplt.title('Total Number of Coronavirus Cases by Date')\nplt.legend(df1_date.columns)\nplt.xticks(rotation=75)\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "66e62809", "metadata": {}, "outputs": [], "source": ["df1_date = df1_date.reset_index()\ndf1_date"]}, {"cell_type": "code", "execution_count": 1, "id": "7f7dbceb", "metadata": {}, "outputs": [], "source": ["df1_date['Date'] = pd.to_datetime(df1_date.Date,format='%Y-%m-%d')\ndf1_date.index = df1_date['Date']\n\nplt.figure(figsize=(16,8))\nplt.plot(df1_date['Confirmed'], label='Confirmed cases')"]}, {"cell_type": "markdown", "id": "3177f993", "metadata": {}, "source": ["# Splits"]}, {"cell_type": "code", "execution_count": 1, "id": "84ef53b2", "metadata": {}, "outputs": [], "source": ["mask = sehir_data.dtypes == np.object\ncategorical_cols = sehir_data.columns[mask]"]}, {"cell_type": "code", "execution_count": 1, "id": "3d7cee80", "metadata": {}, "outputs": [], "source": ["# Kac tane ekstra sutun olusturulacagini belirleme\nnum_ohc_cols = (sehir_data[categorical_cols]\n                .apply(lambda x: x.nunique())\n                .sort_values(ascending=False))\n\n\n# Yalnizca bir deger varsa kodlamaya gerek yoktur\nsmall_num_ohc_cols = num_ohc_cols.loc[num_ohc_cols>1]\n\n# one-hot sutun satisi, kategori sayisindan bir azdir. \nsmall_num_ohc_cols -= 1\n\n# Bu, orjinal sutunlarin cikarildigi varsayilan 215 sutundur.\n\nsmall_num_ohc_cols.sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "e7ba9700", "metadata": {}, "outputs": [], "source": ["from warnings import simplefilter\nsimplefilter(action='ignore', category=FutureWarning)\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n# Verilerin kopyasi\ndata_ohc = sehir_data.copy()\n\n# Kodlayicilar\nle = LabelEncoder()\nohc = OneHotEncoder()\n\nfor col in num_ohc_cols.index:\n    \n    # Integer encode the string categories\n    dat = le.fit_transform(data_ohc[col]).astype(np.int)\n    \n    # orjinal sutunu dataframeden kaldirma\n    data_ohc = data_ohc.drop(col, axis=1)\n\n    # one-hot kod verileri-- bir aralikli array dondurur\n    new_dat = ohc.fit_transform(dat.reshape(-1,1))\n\n    # Benzersiz sutun adlari olusturma\n    n_cols = new_dat.shape[1]\n    col_names = ['_'.join([col, str(x)]) for x in range(n_cols)]\n\n    # Yeni dataframe olusturma\n    new_df = pd.DataFrame(new_dat.toarray(), \n                          index=data_ohc.index, \n                          columns=col_names)\n\n    # Yeni verileri dataframe'e ekleme\n    data_ohc = pd.concat([data_ohc, new_df], axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "e34296e5", "metadata": {}, "outputs": [], "source": ["# Sutun farki yukarida hesaplandigi gibidir\ndata_ohc.shape[1] - sehir_data.shape[1]"]}, {"cell_type": "code", "execution_count": 1, "id": "0f1b8952", "metadata": {}, "outputs": [], "source": ["print(data.shape[1])\n\n# dataframe'den string sutunlarin kaldirilmasi\ndata = sehir_data.drop(num_ohc_cols.index, axis=1)\n\nprint(data.shape[1])"]}, {"cell_type": "code", "execution_count": 1, "id": "938e0c17", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n\ny_col = 'Vaka Say\u0131s\u0131'\n\n# one-hot kodlanmamis verileri bolme\nfeature_cols = [x for x in data.columns if x != y_col]\nX_data = data[feature_cols]\ny_data = data[y_col]\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, \n                                                    test_size=0.3, random_state=42)\n# one-hot kodlanmis verileri bolme\nfeature_cols = [x for x in data_ohc.columns if x != y_col]\nX_data_ohc = data_ohc[feature_cols]\ny_data_ohc = data_ohc[y_col]\n\nX_train_ohc, X_test_ohc, y_train_ohc, y_test_ohc = train_test_split(X_data_ohc, y_data_ohc, \n                                                    test_size=0.3, random_state=42)"]}, {"cell_type": "code", "execution_count": 1, "id": "1caaeb0d", "metadata": {}, "outputs": [], "source": ["# Ayni olduklarindan emin olmak icin endeksleri karsilastirin\n(X_train_ohc.index == X_train.index).all()"]}, {"cell_type": "code", "execution_count": 1, "id": "0c23338a", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nLR = LinearRegression()\n\n# Hata degerleri icin depolama\nerror_df = list()\n\n# one-hot kodlanmamis veriler\nLR = LR.fit(X_train, y_train)\ny_train_pred = LR.predict(X_train)\ny_test_pred = LR.predict(X_test)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train, y_train_pred),\n                           'test' : mean_squared_error(y_test,  y_test_pred)},\n                           name='no enc'))\n\n# one-hot kodlanmis veriler\nLR = LR.fit(X_train_ohc, y_train_ohc)\ny_train_ohc_pred = LR.predict(X_train_ohc)\ny_test_ohc_pred = LR.predict(X_test_ohc)\n\nerror_df.append(pd.Series({'train': mean_squared_error(y_train_ohc, y_train_ohc_pred),\n                           'test' : mean_squared_error(y_test_ohc,  y_test_ohc_pred)},\n                          name='one-hot enc'))\n\n# Sonuclari bir araya getirin\nerror_df = pd.concat(error_df, axis=1)\nerror_df"]}, {"cell_type": "code", "execution_count": 1, "id": "a1bd304b", "metadata": {}, "outputs": [], "source": ["# Kopyalama uyarilariyla ayari sessize alma\npd.options.mode.chained_assignment = None"]}, {"cell_type": "code", "execution_count": 1, "id": "d57c1326", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n\n\nscalers = {'standard': StandardScaler(),\n           'minmax': MinMaxScaler(),\n           'maxabs': MaxAbsScaler()}\n\ntraining_test_sets = {\n    'not_encoded': (X_train, y_train, X_test, y_test),\n    'one_hot_encoded': (X_train_ohc, y_train_ohc, X_test_ohc, y_test_ohc)}\n\n\n# Onceden olceklendirdigimiz bir seyi olceklendirmemek icin \n# float sutunlarin listesini ve float verilerini alin \n# Orijinal verileri her seferinde \u00f6lceklememiz gerekiyor\nmask = X_train.dtypes == np.float\nfloat_columns = X_train.columns[mask]\n\n# initialize model\nLR = LinearRegression()\n\n# tum olas\u0131 kombinasyonlari tekrarlayin ve hatalari alin\nerrors = {}\nfor encoding_label, (_X_train, _y_train, _X_test, _y_test) in training_test_sets.items():\n    for scaler_label, scaler in scalers.items():\n        trainingset = _X_train.copy()  # kopyalayin cunku bunu bir kereden fazla olceklemek istemiyoruz.\n        testset = _X_test.copy()\n        trainingset[float_columns] = scaler.fit_transform(trainingset[float_columns])\n        testset[float_columns] = scaler.transform(testset[float_columns])\n        LR.fit(trainingset, _y_train)\n        predictions = LR.predict(testset)\n        key = encoding_label + ' - ' + scaler_label + 'scaling'\n        errors[key] = mean_squared_error(_y_test, predictions)\n\nerrors = pd.Series(errors)\nprint(errors.to_string())\nprint('-' * 80)\nfor key, error_val in errors.items():\n    print(key, error_val)"]}, {"cell_type": "code", "execution_count": 1, "id": "a2f9293c", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\nsns.set_context('talk')\nsns.set_style('ticks')\nsns.set_palette('dark')\n\nax = plt.axes()\n#  y_test, y_test_pred kullanilacak\nax.scatter(y_test, y_test_pred, alpha=.5)\n\nax.set(xlabel='Do\u011fruluk De\u011feri', \n       ylabel='Tahmin',\n       title='Linear Regression');"]}, {"cell_type": "markdown", "id": "5302b577", "metadata": {}, "source": ["# LINEAR REGRESSION"]}, {"cell_type": "code", "execution_count": 1, "id": "8ef58906", "metadata": {}, "outputs": [], "source": ["df1_date['Date'] = pd.to_datetime(df1_date.Date,format='%Y-%m-%d')\ndf1_date.index = df1_date['Date']\n\ndata = df1_date.sort_index(ascending=True, axis=0)\n\nnew_data = pd.DataFrame(index=range(0,len(df1_date)),columns=['Date', 'Confirmed'])\n\nfor i in range(0,len(data)):\n    new_data['Date'][i] = data['Date'][i]\n    new_data['Confirmed'][i] = data['Confirmed'][i]\nnew_data\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0eeb9432", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(new_data['Date'], new_data['Confirmed'], random_state = 0)\nX_train = pd.DataFrame(X_train)\nX_test = pd.DataFrame(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "b97b6451", "metadata": {}, "outputs": [], "source": ["from fastai.tabular import add_datepart\nadd_datepart(X_train, 'Date')\nX_train.drop('Elapsed', axis=1, inplace=True)  #elapsed will be the time stamp\nX_train = X_train.filter([ \"Year\", \"Month\", \"Day\"])\nX_train\n\nadd_datepart(X_test, 'Date')\nX_test.drop('Elapsed', axis=1, inplace=True)  #elapsed will be the time stamp\nX_test = X_test.filter([ \"Year\", \"Month\", \"Day\"])\nX_test"]}, {"cell_type": "code", "execution_count": 1, "id": "0d411298", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "dbf5f0a4", "metadata": {}, "outputs": [], "source": ["preds = model.predict(X_test)\nrms=np.sqrt(np.mean(np.power((np.array(y_test)-np.array(preds)),2)))\nrms"]}, {"cell_type": "code", "execution_count": 1, "id": "c5d2f789", "metadata": {}, "outputs": [], "source": ["preds\n"]}, {"cell_type": "code", "execution_count": 1, "id": "46fbe049", "metadata": {}, "outputs": [], "source": ["new_data"]}, {"cell_type": "markdown", "id": "89c7d06d", "metadata": {}, "source": ["# SKEW"]}, {"cell_type": "code", "execution_count": 1, "id": "25c30fce", "metadata": {}, "outputs": [], "source": ["sehir_data.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "4cb0d171", "metadata": {}, "outputs": [], "source": ["skew = pd.DataFrame(sehir_data.skew())\nskew.columns = ['skew']\nskew['too_skewed'] = skew['skew'] > .75\nskew"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}