{"cells": [{"cell_type": "markdown", "id": "a9dbebfa", "metadata": {}, "source": ["## About This Notebook\n\n* This is an experiment to explore the **B**ack **P**ropagation **T**hrough **T**ime Concept using Stateful LSTM.\n* The hidden and cell state are carried from One batch to the another.\n* This provides a useful connection between batches.\n* The trained word embedding can be used for future work.\n\n![image.png](attachment:image.png)"]}, {"cell_type": "code", "execution_count": 1, "id": "25b071f6", "metadata": {}, "outputs": [], "source": ["# Importing Libaries\nimport requests\nfrom torch.backends import cudnn\nimport re\nimport spacy\nimport torch\nimport nltk\nfrom matplotlib import pyplot\nimport pandas as pd,numpy as np\nfrom torch.autograd import Variable"]}, {"cell_type": "code", "execution_count": 1, "id": "398cdf8d", "metadata": {}, "outputs": [], "source": ["# Setting up device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]}, {"cell_type": "code", "execution_count": 1, "id": "c714d503", "metadata": {}, "outputs": [], "source": ["device"]}, {"cell_type": "code", "execution_count": 1, "id": "04a53407", "metadata": {}, "outputs": [], "source": ["# torch internal optimization\ncudnn.benchmark = True"]}, {"cell_type": "markdown", "id": "7c06fb73", "metadata": {}, "source": ["## Getting the Text"]}, {"cell_type": "code", "execution_count": 1, "id": "e700ca82", "metadata": {}, "outputs": [], "source": ["response = requests.get('http://www.gutenberg.org/files/11/11-0.txt')\ntext = response.text"]}, {"cell_type": "code", "execution_count": 1, "id": "6efb01be", "metadata": {}, "outputs": [], "source": ["text[:100]"]}, {"cell_type": "code", "execution_count": 1, "id": "33453952", "metadata": {}, "outputs": [], "source": ["len(text)"]}, {"cell_type": "markdown", "id": "c57f9268", "metadata": {}, "source": ["## Cleaning the Text"]}, {"cell_type": "code", "execution_count": 1, "id": "c8b6abeb", "metadata": {}, "outputs": [], "source": ["# Sentence Tokenizer\nsentModel = spacy.load(\"en_core_web_sm\",disable=['parser','tagger', 'ner'])\nsentModel.add_pipe(sentModel.create_pipe('sentencizer'))"]}, {"cell_type": "code", "execution_count": 1, "id": "678c0b28", "metadata": {}, "outputs": [], "source": ["# Global cleaning of the text\ndef cleanText(text):\n    text = text.strip()\n    text = re.sub(r'\\n+',' ',text)\n    doc = sentModel(text)\n    #text = ' '.join([str(token.lemma_.strip().lower()) for token in sentModel(text) if token.lemma_.strip()])\n    #text = text.replace('-pron-','')\n    textList = [senttoken.text.lower() for senttoken in doc.sents]\n    return ' '.join(textList)"]}, {"cell_type": "code", "execution_count": 1, "id": "e3108fdb", "metadata": {}, "outputs": [], "source": ["# All Sentensed Tokenized\ntextRefined,tokenList = [],[] \ntextRefinedTemp=cleanText(text)\ntextRefined = textRefinedTemp"]}, {"cell_type": "code", "execution_count": 1, "id": "719b6ba1", "metadata": {}, "outputs": [], "source": ["textRefined[:100]"]}, {"cell_type": "markdown", "id": "44ccb60e", "metadata": {}, "source": ["* ## Case 1 : Lets build single word predictor"]}, {"cell_type": "markdown", "id": "bbb4e409", "metadata": {}, "source": ["# # Use Case\n* Get the next word in a sequence ('*the project gutenberg ebook of alices adventures in wonderland by lewis*') : \n    \n       Input :  the project gutenberg ebook of alices adventures in wonderland by\n       Output : lewis"]}, {"cell_type": "code", "execution_count": 1, "id": "f77a8973", "metadata": {}, "outputs": [], "source": ["# Importing Libraries\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import nn"]}, {"cell_type": "code", "execution_count": 1, "id": "3acd38c8", "metadata": {}, "outputs": [], "source": ["# Dataset Class Builder\nclass datasetClass(Dataset):\n    \n    def __init__(self,text):\n        super(datasetClass,self).__init__()\n        self.textList = text.split()\n        self.text,self.char2idx,self.idx2char,self.textSplit,self.textOriginal,self.trainX,self.trainY= '','','','','','',''\n        self.preprocessing()\n        self.encoding()\n        self.x,self.y= self.segmentation(self.text)\n        self.x,self.y = self.x.to(device),self.y.to(device)\n    \n    # Clean function\n    def clean(self,text):\n        #text = unidecode(text)\n        REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n        BAD_SYMBOLS_RE = re.compile('[^0-9a-z +_]')\n        text = re.sub(' +',' ',text)\n        text = re.sub('\\n+',' ',text)\n        text = REPLACE_BY_SPACE_RE.sub(' ', text)\n        text = BAD_SYMBOLS_RE.sub('', text)\n        text = text.lower()\n        text = re.sub(' +',' ',text)\n        text = re.sub('\\n+',' ',text)\n        text.strip()\n        return text\n    \n    # Character Encoding \n    def encoding(self,):\n        self.idx2char = {idx:token for idx,token in enumerate(set(self.text.split()))}\n        self.char2idx = {token:idx for idx,token in enumerate(set(self.text.split()))}\n    \n\n    # TrainX , TrainY dataset preperation\n    def segmentation(self,text,ngram=10):\n        '''\n         Segemention for making windowed input of size (10) and output (1) , Total = 11\n         Please check the variables (self.trainX,self.trainY) for further analysis.\n        '''\n        self.textSplit = [self.char2idx[token] for token in text.split()]\n        self.textOriginal = [token for token in text.split()]\n        self.trainX,self.trainY = zip(*[((self.textOriginal[idx:idx+(ngram)]),self.textOriginal[idx+ngram]) for idx,token in enumerate(self.textSplit[:-ngram])])\n        x,y = zip(*[((self.textSplit[idx:idx+(ngram)]),self.textSplit[idx+ngram]) for idx,token in enumerate(self.textSplit[:-ngram])])\n        x,y = torch.tensor(x,dtype=torch.long),torch.tensor(y,dtype=torch.long)\n        return x,y\n    \n    # Cleaning for sentences\n    def preprocessing(self,):\n        self.text = ' '.join([self.clean(itemStr) for itemStr in self.textList])\n     \n    def  __getitem__(self,index):\n        return self.x[index],self.y[index]\n    \n    def __len__(self,):\n        return len(self.y)"]}, {"cell_type": "code", "execution_count": 1, "id": "7451d07d", "metadata": {}, "outputs": [], "source": ["# Model Building \nclass Model(nn.Module):\n    def __init__(self,vocabSize,embedDim,targetDim,sentenceLength):\n        super(Model,self).__init__()\n        self.sentenceLength = sentenceLength\n        self.embeddingLayer1 = nn.Embedding(vocabSize,embedDim)\n        self.lstmLayer1 = nn.LSTM(embedDim,100,num_layers=1)\n        self.linearLayer1 = nn.Linear(100*self.sentenceLength,targetDim)\n        self.logsoftmaxLayer1 = nn.LogSoftmax(dim=1)\n        self.hidden = Variable(torch.zeros(1,self.sentenceLength,100,requires_grad=True)).to(device)\n        self.cell = Variable(torch.zeros(1,self.sentenceLength,100,requires_grad=True)).to(device)\n        \n        \n    def forward(self,x,hidden,cell):\n        x = self.embeddingLayer1(x)\n        x, (self.hidden, self.cell) = self.lstmLayer1(x,(self.hidden,self.cell))\n        x = x.view(-1,self.sentenceLength*100)\n        x = self.linearLayer1(x)\n        x = self.logsoftmaxLayer1(x)\n        return x,(self.hidden,self.cell)"]}, {"cell_type": "code", "execution_count": 1, "id": "b5004d5a", "metadata": {}, "outputs": [], "source": ["def reinitialize(hidden,state,sentence_length):\n    '''\n    Reinitializing the layers hidden,state\n    This will be used to carry on the hidden/state till certain epochs.\n    '''\n    #print(hidden.shape,state.shape)\n    hidden = Variable(torch.zeros(1,sentence_length,100,requires_grad=True)).to(device)\n    state = Variable(torch.zeros(1,sentence_length,100,requires_grad=True)).to(device)\n    return hidden,state"]}, {"cell_type": "code", "execution_count": 1, "id": "d263fdd4", "metadata": {}, "outputs": [], "source": ["traintext = textRefined[:int(0.8*len(textRefined))]"]}, {"cell_type": "code", "execution_count": 1, "id": "26790e20", "metadata": {}, "outputs": [], "source": ["testtext = textRefined[int(0.8*len(textRefined)):]"]}, {"cell_type": "code", "execution_count": 1, "id": "4149c465", "metadata": {}, "outputs": [], "source": ["datasetClassObj = datasetClass(textRefined)"]}, {"cell_type": "code", "execution_count": 1, "id": "bb8d292c", "metadata": {}, "outputs": [], "source": ["datasetClassTestObj = datasetClass(testtext)"]}, {"cell_type": "code", "execution_count": 1, "id": "f879f14a", "metadata": {}, "outputs": [], "source": ["print('X1 : ',datasetClassObj.trainX[0],'Y1 : ',datasetClassObj.trainY[0])\nprint('X2 : ',datasetClassObj.trainX[1],'Y2 : ',datasetClassObj.trainY[1])\nprint('X3 : ',datasetClassObj.trainX[2],'Y3 : ',datasetClassObj.trainY[2])"]}, {"cell_type": "code", "execution_count": 1, "id": "81fd774f", "metadata": {}, "outputs": [], "source": ["print('Length of the sentence : ',len(datasetClassObj.trainX[0]))"]}, {"cell_type": "code", "execution_count": 1, "id": "f9f73cf5", "metadata": {}, "outputs": [], "source": ["# Model Configs\nvocabSize = len(datasetClassObj.idx2char)\ntargetDim = len(datasetClassObj.char2idx)\nsentenceLength = 10\nembedDim = 10\nepochs = 100\nbs = 64"]}, {"cell_type": "code", "execution_count": 1, "id": "679b2cfb", "metadata": {}, "outputs": [], "source": ["dataloaderClassObj = DataLoader(datasetClassObj,batch_size=bs,shuffle=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "a2bb8a80", "metadata": {}, "outputs": [], "source": ["dataloaderClassTestObj = DataLoader(datasetClassTestObj,batch_size=bs,shuffle=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "9a44f1bc", "metadata": {}, "outputs": [], "source": ["# Length of the vocab\nprint(len(datasetClassObj.char2idx))\nprint(len(datasetClassTestObj.char2idx))"]}, {"cell_type": "code", "execution_count": 1, "id": "d6b37ffe", "metadata": {}, "outputs": [], "source": ["datasetClassObj.x,datasetClassObj.y"]}, {"cell_type": "code", "execution_count": 1, "id": "6cf0099d", "metadata": {}, "outputs": [], "source": ["modelObj = Model(vocabSize,embedDim,targetDim,sentenceLength)"]}, {"cell_type": "code", "execution_count": 1, "id": "497a7163", "metadata": {}, "outputs": [], "source": ["modelObj.to(device)"]}, {"cell_type": "code", "execution_count": 1, "id": "3705288f", "metadata": {}, "outputs": [], "source": ["x,y = next(iter(dataloaderClassObj))"]}, {"cell_type": "code", "execution_count": 1, "id": "3ef0868b", "metadata": {}, "outputs": [], "source": ["# Forward Pass\nhidden,cell = reinitialize(hidden=0,state=0,sentence_length=10)\n_,(_,_) = modelObj(x,hidden,cell)"]}, {"cell_type": "code", "execution_count": 1, "id": "7d6781d2", "metadata": {}, "outputs": [], "source": ["# Loss Function and Optimizer\nloss_function = nn.NLLLoss()\noptimizer = torch.optim.Adam(modelObj.parameters(), lr=0.001)"]}, {"cell_type": "code", "execution_count": 1, "id": "66887f39", "metadata": {}, "outputs": [], "source": ["# To detect anomaly for gradient error detection \ntorch.autograd.set_detect_anomaly(True)"]}, {"cell_type": "code", "execution_count": 1, "id": "a3ccfff5", "metadata": {}, "outputs": [], "source": ["# Statefull LSTM\nmodelObj.hidden,modelObj.cell = reinitialize(hidden=0,state=0,sentence_length=10)\nlosses = []\nfor epoch in range(epochs):\n    modelObj.train()\n    for x,y in dataloaderClassObj:\n        modelObj.hidden.detach_()\n        modelObj.cell.detach_()\n        ypred,(modelObj.hidden,modelObj.cell) = modelObj(x,modelObj.hidden,modelObj.cell)\n        loss = loss_function(ypred,y)\n        loss.backward()\n        with torch.no_grad():\n            optimizer.step()\n            modelObj.zero_grad()\n    print('epoch',epoch,loss)\n    losses.append(loss)"]}, {"cell_type": "code", "execution_count": 1, "id": "5b883ade", "metadata": {}, "outputs": [], "source": ["# Training Loss\nlossesCpu = [float(item.to('cpu')) for item in losses]"]}, {"cell_type": "code", "execution_count": 1, "id": "80cf196e", "metadata": {}, "outputs": [], "source": ["# Training Loss Graph\npyplot.plot(lossesCpu)"]}, {"cell_type": "code", "execution_count": 1, "id": "c08816af", "metadata": {}, "outputs": [], "source": ["# Fitment Test\nhidden,cell = reinitialize(hidden=0,state=0,sentence_length=10)\npercentage = []\nfor x,y in dataloaderClassObj:\n    modelObj.eval()\n    ypred,(_,_) = modelObj(x,hidden,cell)\n    predictedWord = [datasetClassObj.idx2char[int(item)] for item in torch.argmax(ypred,dim=1)]\n    actualWord = [datasetClassObj.idx2char[int(item)] for item in y]\n    percentage.append(sum([actualWord[index]== predictedWord[index] for index,word in enumerate(actualWord)])/len(actualWord)*100)"]}, {"cell_type": "code", "execution_count": 1, "id": "913a858d", "metadata": {}, "outputs": [], "source": ["pyplot.plot(percentage)"]}, {"cell_type": "code", "execution_count": 1, "id": "44d8d794", "metadata": {}, "outputs": [], "source": ["# Unit Test with sample of length 10(mandatory)\n# For best prediction the input should be in a batch of specific batchsize \n\nmodelObj.eval()\ninpTest =  ['the','gutenberg', 'ebook', 'of', 'alices', 'adventures', 'in', 'wonderland', 'by', 'lewis']"]}, {"cell_type": "code", "execution_count": 1, "id": "431dfd96", "metadata": {}, "outputs": [], "source": ["# To get the words in the vocab \n#datasetClassObj.char2idx"]}, {"cell_type": "code", "execution_count": 1, "id": "8149827e", "metadata": {}, "outputs": [], "source": ["hidden,cell = reinitialize(hidden=0,state=0,sentence_length=10)\nmodelObj.eval()\nxValid = torch.tensor([datasetClassObj.char2idx[token] for token in inpTest],dtype=torch.long).to(device)\n\nprint('Convert Text to Index : ', xValid)\n\nypredValid,(_,_) = modelObj(xValid.unsqueeze(0),hidden,cell)\nypredValid = torch.argmax(ypredValid,dim=1)\n\nprint('Prediction : ', ypredValid,'\\n\\n')\n\nprint('Input in Text : ',inpTest)\nprint('Prediction in Text : ', datasetClassObj.idx2char[int(ypredValid.to('cpu'))])"]}, {"cell_type": "code", "execution_count": 1, "id": "c44f3d54", "metadata": {}, "outputs": [], "source": ["PATH = r'/kaggle/working/SingleWordPredictor'\n\ntorch.save({\n            'epochs': epochs,\n            'model_state_dict': modelObj.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss,\n            }, PATH)"]}, {"cell_type": "markdown", "id": "7b093933", "metadata": {}, "source": ["## Word Embeddings"]}, {"cell_type": "code", "execution_count": 1, "id": "bc639684", "metadata": {}, "outputs": [], "source": ["len(list(datasetClassObj.char2idx.keys()))"]}, {"cell_type": "code", "execution_count": 1, "id": "a719384f", "metadata": {}, "outputs": [], "source": ["wordEmbedding = {}"]}, {"cell_type": "code", "execution_count": 1, "id": "ebf82fde", "metadata": {}, "outputs": [], "source": ["# Embeddings\nmodelObj.eval()\ninpTest = list(datasetClassObj.char2idx.keys())\nxTest = torch.tensor([datasetClassObj.char2idx[token] for token in inpTest],dtype=torch.long).to(device)"]}, {"cell_type": "code", "execution_count": 1, "id": "f276a5a3", "metadata": {}, "outputs": [], "source": ["embeddingLookupFrame = pd.DataFrame(modelObj.embeddingLayer1(xTest).to('cpu').detach().numpy(),index=inpTest)"]}, {"cell_type": "code", "execution_count": 1, "id": "649e5473", "metadata": {}, "outputs": [], "source": ["embeddingLookupFrame.head(10)"]}, {"cell_type": "code", "execution_count": 1, "id": "3950170b", "metadata": {}, "outputs": [], "source": ["embeddingLookupFrame.loc['impossible'].values"]}, {"cell_type": "code", "execution_count": 1, "id": "3e6915dc", "metadata": {}, "outputs": [], "source": ["searchWord = embeddingLookupFrame.loc['son'].values"]}, {"cell_type": "code", "execution_count": 1, "id": "7b90860b", "metadata": {}, "outputs": [], "source": ["def distance(row,searchWord):\n    return  np.linalg.norm(row.values-searchWord,ord=2)"]}, {"cell_type": "code", "execution_count": 1, "id": "a335ff8d", "metadata": {}, "outputs": [], "source": ["searchSeries = embeddingLookupFrame.apply(distance,args=(searchWord,),axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "a0c47b8e", "metadata": {}, "outputs": [], "source": ["searchSeries.sort_values()[:10]"]}, {"cell_type": "markdown", "id": "de226938", "metadata": {}, "source": ["# Next Steps :\n\n1. Training and Testing with Actual Bigger corpus.\n2. Using the embeddings, as these embeddings are context based.\n"]}, {"cell_type": "markdown", "id": "8a7de485", "metadata": {}, "source": ["## Credits :\nGutenberg Corpus : 'http://www.gutenberg.org/files/11/11-0.txt"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}