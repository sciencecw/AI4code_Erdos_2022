{"cells": [{"cell_type": "markdown", "id": "8264efff", "metadata": {}, "source": ["## Introduction\n\nIn this notebook, we will be looking at one of the most important steps in building a machine learning model - **Feature Selection**. How we select our features from the dataset will determine how accurate the model will be when trained and being tested.\n\nWe will use some statistical tests like Chi-square to select features which will only improve our model."]}, {"cell_type": "code", "execution_count": 1, "id": "fc57dee5", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_selection import chi2, SelectKBest\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "id": "151420c8", "metadata": {}, "source": ["## Load and Prepare the Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "08a9554c", "metadata": {}, "outputs": [], "source": ["# Load the data\n\ndata = pd.read_csv('../input/mobile-price-classification/train.csv')\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "fca5911a", "metadata": {}, "outputs": [], "source": ["# Split into features and target variables\n\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]"]}, {"cell_type": "markdown", "id": "dcdabde3", "metadata": {}, "source": ["## Compare and Select N-best features using SelectKBest"]}, {"cell_type": "code", "execution_count": 1, "id": "257c1aa5", "metadata": {}, "outputs": [], "source": ["# Call the constructor to select 10 best features according to their Chi-square tests against the target variable\nbest_features = SelectKBest(score_func=chi2, k = 10)\n\nfit = best_features.fit(X, y)"]}, {"cell_type": "code", "execution_count": 1, "id": "f0d80f15", "metadata": {}, "outputs": [], "source": ["chi_scores = pd.DataFrame(fit.scores_)\ncolumns = pd.DataFrame(X.columns)\n\nfeatureScores = pd.concat([columns, chi_scores], axis = 1)\nfeatureScores.columns = ['Feature', 'Score']\n\nfeatureScores.sort_values(by = 'Score', ascending = False)"]}, {"cell_type": "markdown", "id": "7cfd3678", "metadata": {}, "source": ["As we can see from the above DataFrame and from our own experience, the RAM for a smartphone is the most significant feature to determine its price range. Also, some really good indicators are: dimensions of the phone, battery power, and its internal memory."]}, {"cell_type": "markdown", "id": "8ec456e3", "metadata": {}, "source": ["## Feature Importance\n\nAnother techinque which we will be using is the feature importance. Here, we will be using a tree-based model to assign an importance to each of the feature in the dataset."]}, {"cell_type": "code", "execution_count": 1, "id": "89293fac", "metadata": {}, "outputs": [], "source": ["# Initialize a RandomForestClassifier model and fit our dataset\nmodel = RandomForestClassifier()\nmodel.fit(X, y)"]}, {"cell_type": "code", "execution_count": 1, "id": "27b103c3", "metadata": {}, "outputs": [], "source": ["# From this model, we get importance scores for each feature\nmodel.feature_importances_"]}, {"cell_type": "code", "execution_count": 1, "id": "badf1eeb", "metadata": {}, "outputs": [], "source": ["featureImp = pd.DataFrame(model.feature_importances_, index = X.columns, columns = ['Importance'])\nfeatureImp = featureImp.sort_values(by = 'Importance', ascending = False)\nfeatureImp"]}, {"cell_type": "markdown", "id": "70905f18", "metadata": {}, "source": ["Again, we get similar result from the model also. RAM is the most important feature for determining the price range of any mobile."]}, {"cell_type": "code", "execution_count": 1, "id": "888a2c8c", "metadata": {}, "outputs": [], "source": ["# Let's plot the importance score for the features\nplt.figure(figsize = (10, 5))\nplt.xticks(rotation = 90)\nplt.bar(featureImp.index, featureImp['Importance'])"]}, {"cell_type": "markdown", "id": "c1577d95", "metadata": {}, "source": ["From the above plot, we can see that after a fwe features, there isn't much importance left and we can select the first 4-5 features and our model will be sufficiently accurate."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}