{"cells": [{"cell_type": "markdown", "id": "a228a341", "metadata": {}, "source": ["![image.png](attachment:image.png)"]}, {"cell_type": "markdown", "id": "eb0c5bab", "metadata": {}, "source": ["![image.png](attachment:image.png)"]}, {"cell_type": "markdown", "id": "4587ea39", "metadata": {}, "source": ["![image.png](attachment:image.png)"]}, {"cell_type": "markdown", "id": "b6dd1547", "metadata": {}, "source": ["https://datahack.analyticsvidhya.com/contest/janatahack-customer-segmentation/#About"]}, {"cell_type": "code", "execution_count": 1, "id": "be8d60e5", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "bcf2ac90", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)  \nfrom sklearn import metrics, preprocessing, model_selection\nfrom sklearn.model_selection import train_test_split,cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score\n\nimport matplotlib.pyplot as plt                                      # to plot graph\n%matplotlib inline\nimport xgboost as xgb\nimport lightgbm as lgb\nSEED = 1\n\n#To ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": 1, "id": "017a5ca7", "metadata": {}, "outputs": [], "source": ["file = r'/kaggle/input/analytics-vidhya-janatahack-customer-segmentation/'\ntrain_df = pd.read_csv(file+'Train_aBjfeNk.csv')\ntest_df = pd.read_csv(file+'Test_LqhgPWU.csv')\nsub_df = pd.read_csv(file+'sample_submission_wyi0h0z.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "918371a8", "metadata": {}, "outputs": [], "source": ["train_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "b0dd72ba", "metadata": {}, "outputs": [], "source": ["test_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "f2c3c49a", "metadata": {}, "outputs": [], "source": ["sub_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "74cd96fc", "metadata": {}, "outputs": [], "source": ["print(train_df.shape, test_df.shape,sub_df.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "e53e43e1", "metadata": {}, "outputs": [], "source": ["train_df['Segmentation'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "deadd79d", "metadata": {}, "outputs": [], "source": ["train_df.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "eaf8c505", "metadata": {}, "outputs": [], "source": ["test_df.isnull().sum()"]}, {"cell_type": "markdown", "id": "69590c2a", "metadata": {}, "source": ["### Exploratory Data Analysis"]}, {"cell_type": "markdown", "id": "fda0df7d", "metadata": {}, "source": ["#### Checking missing values"]}, {"cell_type": "code", "execution_count": 1, "id": "be442174", "metadata": {}, "outputs": [], "source": ["missing_df = train_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.loc[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(8,6))\nrects = ax.barh(ind, missing_df.missing_count.values, color='blue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "903364b6", "metadata": {}, "outputs": [], "source": ["missingvalues_prop = (train_df.isnull().sum()/len(train_df)).reset_index()\nmissingvalues_prop.columns = ['field','proportion']\nmissingvalues_prop = missingvalues_prop.sort_values(by = 'proportion', ascending = False)\n# print(missingvalues_prop)\nmissingvaluescols = missingvalues_prop[missingvalues_prop['proportion'] > 0.10].field.tolist()\nprint(missingvaluescols)"]}, {"cell_type": "code", "execution_count": 1, "id": "fe364018", "metadata": {}, "outputs": [], "source": ["# Normalise can be set to true to print the proportions instead of Numbers.\ntrain_df['Segmentation'].value_counts(normalize=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "da0e6e2e", "metadata": {}, "outputs": [], "source": ["train_df['Segmentation'].value_counts().plot.bar(figsize=(4,4),title='Segmentation - Split for Train Dataset')\nplt.xlabel('ExtraTime')\nplt.ylabel('Count')"]}, {"cell_type": "code", "execution_count": 1, "id": "74ad4acb", "metadata": {}, "outputs": [], "source": ["plt.figure(1)\nplt.subplot(221)\ntrain_df['Gender'].value_counts(normalize=True).plot.bar(figsize=(20,10), fontsize = 15.0)\nplt.title('Gender', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n\n\nplt.subplot(222)\ntrain_df['Ever_Married'].value_counts(normalize=True).plot.bar(figsize=(20,10), fontsize = 15.0)\nplt.title('Ever_Married', fontweight=\"bold\",fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n\nplt.subplot(223)\ntrain_df['Graduated'].value_counts(normalize=True).plot.bar(figsize=(20,10), fontsize = 15.0)\nplt.title('Graduated', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n\nplt.subplot(224)\ntrain_df['Work_Experience'].value_counts(normalize=True).plot.bar(figsize=(20,10), fontsize = 15.0)\nplt.title('Work_Experience', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\nplt.tight_layout()"]}, {"cell_type": "code", "execution_count": 1, "id": "2d215f4f", "metadata": {}, "outputs": [], "source": ["plt.figure(1)\nplt.subplot(221)\ntrain_df['Spending_Score'].value_counts(normalize=True).plot.bar(figsize=(20,10), fontsize = 15.0)\nplt.title('Spending_Score', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n\n\nplt.subplot(222)\ntrain_df['Family_Size'].value_counts(normalize=True).plot.bar(figsize=(20,10), fontsize = 15.0)\nplt.title('Family_Size', fontweight=\"bold\",fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n\nplt.subplot(223)\ntrain_df['Var_1'].value_counts(normalize=True).plot.bar(figsize=(20,10), fontsize = 15.0)\nplt.title('Var_1', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0428cb41", "metadata": {}, "outputs": [], "source": ["plt.figure(1)\nplt.subplot(121)\nsns.distplot(train_df['Age'])\n\nplt.subplot(122)\ntrain_df['Age'].plot.box(figsize=(16,5))\n\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "468231dd", "metadata": {}, "outputs": [], "source": ["train_df.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "770de7de", "metadata": {}, "outputs": [], "source": ["Gender=pd.crosstab(train_df['Gender'],train_df['Segmentation'])\nEver_Married=pd.crosstab(train_df['Ever_Married'],train_df['Segmentation'])\nGraduated=pd.crosstab(train_df['Graduated'],train_df['Segmentation'])\nProfession=pd.crosstab(train_df['Profession'],train_df['Segmentation'])\n\n\n\nGender.div(Gender.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nEver_Married.div(Ever_Married.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nGraduated.div(Graduated.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nProfession.div(Profession.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nplt.tight_layout()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2217975f", "metadata": {}, "outputs": [], "source": ["Work_Experience=pd.crosstab(train_df['Work_Experience'],train_df['Segmentation'])\nEver_Married=pd.crosstab(train_df['Ever_Married'],train_df['Segmentation'])\nGraduated=pd.crosstab(train_df['Graduated'],train_df['Segmentation'])\nProfession=pd.crosstab(train_df['Profession'],train_df['Segmentation'])\n\n\n\nWork_Experience.div(Work_Experience.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nEver_Married.div(Ever_Married.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nGraduated.div(Graduated.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nProfession.div(Profession.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "c1268a06", "metadata": {}, "outputs": [], "source": ["# * join the datasets\ntrain_df['is_train']  = 1\ntest_df['Segmentation'] = -1\ntest_df['is_train'] = 0"]}, {"cell_type": "code", "execution_count": 1, "id": "741d8a41", "metadata": {}, "outputs": [], "source": ["full_df = train_df.append(test_df)"]}, {"cell_type": "code", "execution_count": 1, "id": "3c6350e6", "metadata": {}, "outputs": [], "source": ["full_df.head()"]}, {"cell_type": "markdown", "id": "054072df", "metadata": {}, "source": ["### Feature Engineering"]}, {"cell_type": "code", "execution_count": 1, "id": "3b0d3fc3", "metadata": {}, "outputs": [], "source": ["full_df.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "fac0b5da", "metadata": {}, "outputs": [], "source": ["full_df.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "51c9753f", "metadata": {}, "outputs": [], "source": ["# append train and test data\ntestcount = len(test_df)\ncount = len(full_df)-testcount\nprint(count)\n\ntrain = full_df[:count]\ntest = full_df[count:]\ntrain_df = train.copy()\ntest_df = test.copy()"]}, {"cell_type": "code", "execution_count": 1, "id": "ad221951", "metadata": {}, "outputs": [], "source": ["full_df.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "d9d5ada4", "metadata": {}, "outputs": [], "source": ["cols = ['ID', 'Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n       'Work_Experience', 'Spending_Score', 'Family_Size', 'Var_1',\n        'is_train' ]\nfor col in cols:\n    if train_df[col].dtype==object:\n        print(col)\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n        train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n        test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))"]}, {"cell_type": "code", "execution_count": 1, "id": "612d767c", "metadata": {}, "outputs": [], "source": ["X = train_df.drop(['Segmentation', 'is_train' ,'ID'],axis=1)\ny = train_df['Segmentation'].values\n\ntrain_X = X.copy()\ntrain_y = y.copy()\n\ntest_X = test_df.drop(['Segmentation', 'is_train' ,'ID'],axis=1)\nprint(X.shape, test_X.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "a786fb10", "metadata": {}, "outputs": [], "source": ["X.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d82a11b5", "metadata": {}, "outputs": [], "source": ["test_X.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "2d2ce4de", "metadata": {}, "outputs": [], "source": ["X.isnull().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "452f8575", "metadata": {}, "outputs": [], "source": ["params = {}\nparams['learning_rate'] = 0.01\nparams['n_estimators'] = 10000\nparams['objective'] = 'multiclass'\nparams['boosting_type'] = 'gbdt'"]}, {"cell_type": "code", "execution_count": 1, "id": "4655fcd7", "metadata": {}, "outputs": [], "source": ["feature_cols = X.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "9532b0d9", "metadata": {}, "outputs": [], "source": ["X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                  stratify=y, \n                                                  random_state=1234, \n                                                  test_size=0.20, shuffle=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "221d2493", "metadata": {}, "outputs": [], "source": ["cat_cols = ['Gender','Ever_Married', 'Graduated', 'Profession','Family_Size',\n            'Spending_Score','Var_1']\nlabel_col = 'Segmentation'"]}, {"cell_type": "code", "execution_count": 1, "id": "5b71d27c", "metadata": {}, "outputs": [], "source": ["clf = lgb.LGBMClassifier(**params)\n    \nclf.fit(X_train, y_train, early_stopping_rounds=200,\n        eval_set=[(X_valid, y_valid)], \n        eval_metric='multi_error', verbose=False, categorical_feature=cat_cols)\n\neval_score = accuracy_score(y_valid, clf.predict(X_valid[feature_cols]))\n\nprint('Eval ACC: {}'.format(eval_score))"]}, {"cell_type": "code", "execution_count": 1, "id": "bfe194d0", "metadata": {}, "outputs": [], "source": ["preds = clf.predict(test_X[feature_cols])"]}, {"cell_type": "code", "execution_count": 1, "id": "132c0a8a", "metadata": {}, "outputs": [], "source": ["np.unique(preds, return_counts=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "de6f8579", "metadata": {}, "outputs": [], "source": ["sub_df['Segmentation'] = preds\n\nsub_df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "a8429167", "metadata": {}, "outputs": [], "source": ["# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\nname = \"baseline_lgb.csv\"\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = name):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\n# create a link to download the dataframe\ncreate_download_link(sub_df)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}