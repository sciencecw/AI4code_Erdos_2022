{"cells": [{"cell_type": "code", "execution_count": 1, "id": "bffe9076", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder"]}, {"cell_type": "markdown", "id": "9613ed2e", "metadata": {}, "source": ["# 1. Let us first load the data and check what it contains"]}, {"cell_type": "code", "execution_count": 1, "id": "1f3ade05", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\ntest_full=test.copy(deep=True)\ntrain.head()"]}, {"cell_type": "markdown", "id": "01b4c395", "metadata": {}, "source": ["Check for missing data"]}, {"cell_type": "code", "execution_count": 1, "id": "4b95a492", "metadata": {}, "outputs": [], "source": ["train.info()"]}, {"cell_type": "markdown", "id": "d6ee8caf", "metadata": {}, "source": ["Let us drop the column 'Cabin' since it contains a lot of missing data. Also Name and Ticket are unique values per passenger so we can drop these."]}, {"cell_type": "code", "execution_count": 1, "id": "c74f06a6", "metadata": {}, "outputs": [], "source": ["train.drop(columns=['Cabin','Name','Ticket','PassengerId'],inplace=True)\ntest.drop(columns=['Cabin','Name','Ticket','PassengerId'],inplace=True)\n\ntrain.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "376a9550", "metadata": {}, "outputs": [], "source": ["test.info()"]}, {"cell_type": "markdown", "id": "b3031a0a", "metadata": {}, "source": ["Let us fill the null values of Age with the median and the null values for Embarked with the mode. For Fare in test data, we fill using median also."]}, {"cell_type": "code", "execution_count": 1, "id": "2a57cef3", "metadata": {}, "outputs": [], "source": ["train.Age.fillna(train.Age.median(),inplace=True)\ntest.Age.fillna(test.Age.median(),inplace=True)\n\ntest.Fare.fillna(test.Age.median(),inplace=True)\n\ntrain.Embarked.fillna(train.Embarked.mode()[0],inplace=True)\ntest.Embarked.fillna(test.Embarked.mode()[0],inplace=True)"]}, {"cell_type": "markdown", "id": "8b3c9acd", "metadata": {}, "source": ["Then, let us convert the categorical values into numbers. We use LabelEncoder on this.\nWe have two features to transform: Sex and Embarked"]}, {"cell_type": "code", "execution_count": 1, "id": "1f1bf07b", "metadata": {}, "outputs": [], "source": ["labeler = LabelEncoder()\n\ntrain['Sex']=labeler.fit_transform(train['Sex'])\ntrain['Embarked']=labeler.fit_transform(train['Embarked'])\n\ntest['Sex']=labeler.fit_transform(test['Sex'])\ntest['Embarked']=labeler.fit_transform(test['Embarked'])"]}, {"cell_type": "markdown", "id": "adc97121", "metadata": {}, "source": ["Separate the independent and dependent variables."]}, {"cell_type": "code", "execution_count": 1, "id": "0737e3f7", "metadata": {}, "outputs": [], "source": ["y_train = train['Survived']\nX_train = train.drop(columns='Survived')"]}, {"cell_type": "markdown", "id": "b492b408", "metadata": {}, "source": ["# 2. Visualizations"]}, {"cell_type": "code", "execution_count": 1, "id": "cdbb334b", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,6))\ncorr = train.corr()\nsns.heatmap(abs(corr),cmap='Blues',annot=True)"]}, {"cell_type": "markdown", "id": "20bdacf4", "metadata": {}, "source": ["### Takeaway: Sex and Pclass has the strongest correlation to Survival.\n\nI am planning to use Logistic Regression for this problem. So let us check if multi-collinearity exists using VIF."]}, {"cell_type": "code", "execution_count": 1, "id": "7f649449", "metadata": {}, "outputs": [], "source": ["vif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif[\"features\"] = X_train.columns\nvif"]}, {"cell_type": "markdown", "id": "e4a93b1f", "metadata": {}, "source": ["### Takeaway: Since no feature has VIF Factor>10, we can be confident to retain all features."]}, {"cell_type": "markdown", "id": "2ace3e17", "metadata": {}, "source": ["# 3. Model"]}, {"cell_type": "markdown", "id": "f22d58fb", "metadata": {}, "source": ["First we scale the data and run a quick and dirty model."]}, {"cell_type": "code", "execution_count": 1, "id": "c093ab25", "metadata": {}, "outputs": [], "source": ["scale = StandardScaler()\nX_train = scale.fit_transform(X_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "78258a64", "metadata": {}, "outputs": [], "source": ["lr = linear_model.LogisticRegression()\nlr.fit(X_train,y_train)\nlr.score(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "2550684c", "metadata": {}, "outputs": [], "source": ["predictions = lr.predict(test)\noutput=pd.DataFrame({'PassengerId': test_full.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}