{"cells": [{"cell_type": "markdown", "id": "6d6e925b", "metadata": {}, "source": ["# Visualize attributes correlation and predict international appearances of a player as a classification problem. "]}, {"cell_type": "markdown", "id": "bc23d0d4", "metadata": {}, "source": ["### Import Libraries"]}, {"cell_type": "code", "execution_count": 1, "id": "9b791b58", "metadata": {}, "outputs": [], "source": ["#Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport seaborn as sns\nfrom scipy import stats\nimport seaborn as sn\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import confusion_matrix"]}, {"cell_type": "markdown", "id": "f5192403", "metadata": {}, "source": ["### Import OS"]}, {"cell_type": "code", "execution_count": 1, "id": "c63a7d28", "metadata": {}, "outputs": [], "source": ["#Import os\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"]}, {"cell_type": "markdown", "id": "7f011df0", "metadata": {}, "source": ["### Read Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "db58f3b3", "metadata": {}, "outputs": [], "source": ["#Read dataset\ndf = pd.read_csv('../input/football-manager-data/dataset.csv', sep = ',')"]}, {"cell_type": "markdown", "id": "e383f083", "metadata": {}, "source": ["### Test Data are readed properly"]}, {"cell_type": "code", "execution_count": 1, "id": "20de0e4d", "metadata": {}, "outputs": [], "source": ["#Test Data are readed properly\ndf.tail(10)"]}, {"cell_type": "markdown", "id": "eb174e24", "metadata": {}, "source": ["### Create custom function to read missing values per column"]}, {"cell_type": "code", "execution_count": 1, "id": "09f63f30", "metadata": {}, "outputs": [], "source": ["def missing_values_table(df):\n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        return mis_val_table_ren_columns"]}, {"cell_type": "markdown", "id": "c93d582e", "metadata": {}, "source": ["### Get column types, count nans, get stats "]}, {"cell_type": "code", "execution_count": 1, "id": "27e5bcb6", "metadata": {}, "outputs": [], "source": ["#Get column types\ndf.info()\n\n#Get statistics (avg,median,percentiles) for all columns of dataset\nstats = df.describe()\n\nprint(stats)"]}, {"cell_type": "code", "execution_count": 1, "id": "f980cb6d", "metadata": {}, "outputs": [], "source": ["#Count missing values\nmissing_values_table(df)"]}, {"cell_type": "markdown", "id": "f246a3f6", "metadata": {}, "source": ["### Create a barchat based on Age bins (6-year bins)"]}, {"cell_type": "code", "execution_count": 1, "id": "f1c04a04", "metadata": {}, "outputs": [], "source": ["bins= [14,20,26,32,38,44,50,56]\nplt.hist(df['Age'].values, bins=bins, edgecolor=\"k\")\nplt.xticks(bins)\nplt.show()"]}, {"cell_type": "markdown", "id": "0c706205", "metadata": {}, "source": ["#### Most players are between 20 and 26 years old"]}, {"cell_type": "markdown", "id": "d5739e5a", "metadata": {}, "source": ["### Create correlation matrix for numeric variables****\n"]}, {"cell_type": "code", "execution_count": 1, "id": "cb1960f6", "metadata": {}, "outputs": [], "source": ["#Slice dataframe for specific columns in order to inspect correlations (seperate dfs for Attack, Mental)\n\n#Attack\ncorr_df_attack = df.loc[:, ['Age', 'Height','Dribbling', 'Finishing','Crossing','Heading','Technique','Composure','IntCaps','IntGoals']]\n\n#Mental\ncorr_df_mental = df.loc[:, ['Age', 'Height','Aggression', 'Anticipation','Bravery','Concentration','Ambition','Loyalty','Professional','Sportsmanship','Temperament','Controversy','Adaptability','Dirtiness','IntCaps','IntGoals']]\n\n#Inspect corr matrix attack\ncorrMatrix_attack = corr_df_attack.corr()\nfig, ax = plt.subplots(figsize=(15,15)) \nax = sn.heatmap(corrMatrix_attack, annot=True)\nplt.show()"]}, {"cell_type": "markdown", "id": "1afec1ac", "metadata": {}, "source": ["#### Many correlations here are obvious i.e IntCaps, IntGoals etc. Some noteworthy correlations here are Age~Composure and in general combinations that are not predictable. All correlations for attackers main attributes are predictable."]}, {"cell_type": "code", "execution_count": 1, "id": "25e1f31b", "metadata": {}, "outputs": [], "source": ["#Inspect corr matrix mental\ncorrMatrix_mental = corr_df_mental.corr()\nfig, ax = plt.subplots(figsize=(15,15)) \nax = sn.heatmap(corrMatrix_mental, annot=True)\nplt.show()"]}, {"cell_type": "markdown", "id": "6ba93cef", "metadata": {}, "source": ["#### Mental correlations are more interesting in an insights point of view. We observe that Age is medium correlated with Anticipation & Concentration but maybe its obvious due to a player's experience. These are attrbute that increase with time. "]}, {"cell_type": "markdown", "id": "581d5d82", "metadata": {}, "source": ["### Inspect players with >0 IntCaps (Correlation matrices)"]}, {"cell_type": "code", "execution_count": 1, "id": "d31cb442", "metadata": {}, "outputs": [], "source": ["#Inspect players with >0 IntCaps\n\ninternational = df.loc[df['IntCaps'] > 0]\n\n#From 159.541 players, 9636 have made >0 international appearances\n\n#Inspect the corralations but only for international players \n\n#Attack\ncorr_df_attack_int = international.loc[:, ['Age', 'Height','Dribbling', 'Finishing','Crossing','Heading','Technique','Composure','IntCaps','IntGoals']]\ncorr_df_mental_int = international.loc[:, ['Age', 'Height','Aggression', 'Anticipation','Bravery','Concentration','Ambition','Loyalty','Professional','Sportsmanship','Temperament','Controversy','Adaptability','Dirtiness','IntCaps','IntGoals']]\n\n#Inspect corr matrix attack\ncorrMatrix_attack_int = corr_df_attack_int.corr()\nfig, ax = plt.subplots(figsize=(15,15)) \nax = sn.heatmap(corrMatrix_attack_int, annot=True)\nplt.show()\n"]}, {"cell_type": "markdown", "id": "a5fc3c0f", "metadata": {}, "source": ["#### For players with at least 1 internation cap we get the same correlation matrix for previous compared attributes and we notice that for a (random) selected pool of attributes composure is the most highly correlated attribute with IntCaps. "]}, {"cell_type": "code", "execution_count": 1, "id": "02e4babe", "metadata": {}, "outputs": [], "source": ["#Inspect corr matrix mental\ncorrMatrix_mental_int = corr_df_mental_int.corr()\nfig, ax = plt.subplots(figsize=(15,15)) \nax = sn.heatmap(corrMatrix_mental_int, annot=True)\nplt.show()"]}, {"cell_type": "markdown", "id": "cd529f63", "metadata": {}, "source": ["#### For players with at least 1 internation cap we get the same mental attributes correlation matrix for previous compared attributes and we notice that for a (random) selected pool of attributes Anticipation is the most highly correlated attribute with IntCaps. Also, for international players bravery is more correlated with Concentration. "]}, {"cell_type": "markdown", "id": "37036032", "metadata": {}, "source": ["### Pair Scatterplots for IntCaps and Controversy-Adaptability-Dirtiness"]}, {"cell_type": "code", "execution_count": 1, "id": "e353c410", "metadata": {}, "outputs": [], "source": ["#Pair Scatterplots for IntCaps and Controversy-Adaptability-Dirtiness\ng = sns.pairplot(data= df.query('IntCaps > 0'),\n                  y_vars=['IntCaps'],\n                  x_vars=['Controversy','Adaptability','Dirtiness'],\n                kind=\"reg\")"]}, {"cell_type": "markdown", "id": "11679c9c", "metadata": {}, "source": ["#### We get the plots to inspect the behaviour of the data points between Controversy, Adaptability, Dirtiness with International appearances."]}, {"cell_type": "markdown", "id": "83916ff6", "metadata": {}, "source": ["### Create categorical variable for IntCaps"]}, {"cell_type": "code", "execution_count": 1, "id": "8d604ad0", "metadata": {}, "outputs": [], "source": ["#Create categorical variable for IntCaps\n\n#Inspect IntCaps distribution only for those who hade made a single or more appearances\ninternational['IntCaps'].describe()\n\ndef caps_categorical(row):\n   if  (row['IntCaps'] <= 7):\n       return 0\n   else:\n       return 1\n   \ninternational['IntCaps_categorical'] = international.apply (lambda row: caps_categorical(row), axis=1)\ninternational['IntCaps_categorical'].value_counts()"]}, {"cell_type": "markdown", "id": "b2938651", "metadata": {}, "source": ["#### We create a new binary categorical variable which classifies the number of International Appearances based on the median value. We do this in order to implement classification algorithms trying to predict a player's number of international caps based on some of his attributes"]}, {"cell_type": "markdown", "id": "9a325cef", "metadata": {}, "source": ["# Predic IntCaps_categorical based on attributes (Classfication problem)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "77406569", "metadata": {}, "outputs": [], "source": ["# Perform Feature Selection from a pool of variables\nX = international.iloc[:, 22:73]\ny = international['IntCaps_categorical']\n\ncols = list(X.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = X[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)"]}, {"cell_type": "markdown", "id": "fc68162e", "metadata": {}, "source": ["#### From the total pool of attributes (GK attributes are excluded) a backward elimination is performed in order to find the most important predictor variables"]}, {"cell_type": "markdown", "id": "21a98eea", "metadata": {}, "source": ["## Create Logistic Regression Model "]}, {"cell_type": "code", "execution_count": 1, "id": "5d9d6897", "metadata": {}, "outputs": [], "source": ["# Create Logistic Regression Model \n\n# Slice Dataset\nX = international[['ImportantMatches', 'Adaptability', 'Ambition', 'Loyalty', 'Pressure', 'Sportsmanship', 'Temperament', 'Controversy']]\ny = international[['IntCaps_categorical']]\ny['IntCaps_categorical'].value_counts()\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n#Inspect y_test counts\ny_test['IntCaps_categorical'].value_counts()\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n#ylabel = True\n#xlabel = Predicted\n\nprint(cm)\n\n#Extract metrics\nprecision_recall_fscore_support(y_test, y_pred, average='macro')\n#precision, recall, fscore, support\n"]}, {"cell_type": "markdown", "id": "1c529ac4", "metadata": {}, "source": ["### There's an accuracy of almost 60%. Errors are normally distributed and they do not occur for a specific category. Players with more than 7 international appearances are 1197. The prediction is better than a naive model but of course the model's accuracy is still too low."]}, {"cell_type": "markdown", "id": "7ad6f5fb", "metadata": {}, "source": ["## Create Artificial Neural Network Model "]}, {"cell_type": "code", "execution_count": 1, "id": "76a4d142", "metadata": {}, "outputs": [], "source": ["# Create Artificial Neural Network Model \nX = international[['ImportantMatches', 'Adaptability', 'Ambition', 'Loyalty', 'Pressure', 'Sportsmanship', 'Temperament', 'Controversy']]\ny = international['IntCaps_categorical']\n\n# Encoding categorical data\nlabelencoder_y = LabelEncoder()\ny = labelencoder_y.fit_transform(y)\n\n#Make the ANN\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(6, activation = 'relu', input_dim = 8))\n\n# Adding the second hidden layer\nclassifier.add(Dense(6, activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(1, activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 1, epochs = 20)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n\nprint(cm)\n\n#Extract metrics\nprecision_recall_fscore_support(y_test, y_pred, average='macro')\n#precision, recall, fscore, support\n"]}, {"cell_type": "markdown", "id": "44dbc71b", "metadata": {}, "source": ["### The ANN is trained for 20 epochs with the stohastic gradient descent method. It consists of 2 hidden layers with 6 neurons. The model's accuracy is approximately 60%. Errors are normally distributed and they do not occur for a specific category. Model predicts better players with less than 7 caps. The prediction is again better than a naive model but of course the model's accuracy is still too low."]}, {"cell_type": "markdown", "id": "26561062", "metadata": {}, "source": ["## Create Random Forest Model"]}, {"cell_type": "code", "execution_count": 1, "id": "377e3de3", "metadata": {}, "outputs": [], "source": ["#Create Random Forest Model\nX = international[['ImportantMatches', 'Adaptability', 'Ambition', 'Loyalty', 'Pressure', 'Sportsmanship', 'Temperament', 'Controversy']]\ny = international['IntCaps_categorical']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', max_depth = 3, random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n\nprint(cm)\n\n#Extract metrics\nprecision_recall_fscore_support(y_test, y_pred, average='macro')\n#precision, recall, fscore, support\n"]}, {"cell_type": "markdown", "id": "1ec8b797", "metadata": {}, "source": ["#### The Random forest model is consisted of 10 trees, the quality of split is measured by the information gained(entropy) and the the maximum depth of the tree is 3. The model's accuracy ranges at 60%. Errors still normally distributed. The prediction is again better than a naive model. "]}, {"cell_type": "markdown", "id": "907c2d79", "metadata": {}, "source": ["## Overall, the tested models give approximately the same results. This was an approach to predict a player's international appearances. Of course, don't forget that players are increasing their attributes as they play for the international teams. "]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}