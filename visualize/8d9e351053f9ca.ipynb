{"cells": [{"cell_type": "code", "execution_count": 1, "id": "64770429", "metadata": {}, "outputs": [], "source": ["import sys\nsys.path.append('../input/timmdataset/pytorch-image-models-master')\nimport timm"]}, {"cell_type": "code", "execution_count": 1, "id": "6ee6eab1", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom tqdm import tqdm\nimport cv2\nfrom skimage import io\nimport time\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, RandomCrop,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport tqdm.notebook as tq\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import softmax"]}, {"cell_type": "code", "execution_count": 1, "id": "300893cb", "metadata": {}, "outputs": [], "source": ["CFG = {\n    'img_size': 512,\n    'vit_img': 384,\n    'tta': 3,\n    'valid_bs': 48,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'effnet_model_b3' : ['tf_efficientnet_b3_ns_model_2.pth','tf_efficientnet_b3_ns_model_5.pth','tf_efficientnet_b3_ns_model_4.pth','tf_efficientnet_b3_ns_model_1.pth','tf_efficientnet_b3_ns_model_3.pth'],\n    'effnet_model_b4' : ['tf_efficientnet_b4_ns_model_3.pth','tf_efficientnet_b4_ns_model_5.pth','tf_efficientnet_b4_ns_model_2.pth','tf_efficientnet_b4_ns_model_1.pth','tf_efficientnet_b4_ns_model_4.pth'],\n    'resnet_models' : ['resnet50d_model_1.pth','resnet50d_model_4.pth','resnet50d_model_3.pth','resnet50d_model_2.pth','resnet50d_model_5.pth'],\n    'resnext_models' : ['resnext50d_32x4d_model_5.pth','resnext50d_32x4d_model_3.pth','resnext50d_32x4d_model_1.pth','resnext50d_32x4d_model_2.pth','resnext50d_32x4d_model_4.pth'],\n    'resnext101_models' : ['ig_resnext101_32x8d_model_1.pth','ig_resnext101_32x8d_model_2.pth','ig_resnext101_32x8d_model_3.pth','ig_resnext101_32x8d_model_4.pth','ig_resnext101_32x8d_model_5.pth'],\n    'vit_models' : ['vit_base_patch16_384_model_2.pth','vit_base_patch16_384_model_5.pth','vit_base_patch16_384_model_1.pth','vit_base_patch16_384_model_3.pth','vit_base_patch16_384_model_4.pth']\n}"]}, {"cell_type": "code", "execution_count": 1, "id": "aa2e7417", "metadata": {}, "outputs": [], "source": ["class DiseaseDatasetInference(torch.utils.data.Dataset):\n\n    def __init__ (self, df, transform=None, opt_label=True):\n        self.df = df.reset_index(drop=True).copy()\n        self.transform = transform\n        self.opt_label = opt_label\n\n        if self.opt_label:\n            self.data = [(row['image_id'], row['label']) for _, row in self.df.iterrows()]\n\n        else:\n            self.data = [(row['image_id']) for _, row in self.df.iterrows()]\n\n        self.data = np.asarray(self.data)\n  \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__ (self, index):\n            # np.random.shuffle(self.data)\n        if self.opt_label:\n            image_path, label = self.data[index]    \n        else:\n            image_path = self.data[index]\n\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n\n        if self.opt_label == True:\n            return (image, int(label))\n\n        else:\n            return image"]}, {"cell_type": "code", "execution_count": 1, "id": "180745e4", "metadata": {}, "outputs": [], "source": ["def get_inference_Vit_transforms():\n    return Compose([\n#             RandomCrop(CFG['vit_img'], CFG['vit_img'], p=0.5),\n            CenterCrop(CFG['vit_img'], CFG['vit_img'], p=0.5),\n            Resize(CFG['vit_img'], CFG['vit_img']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n            \n        ], p=1.)"]}, {"cell_type": "code", "execution_count": 1, "id": "46c888a7", "metadata": {}, "outputs": [], "source": ["def get_inference_transforms():\n    return Compose([\n#             RandomCrop(CFG['img_size'], CFG['img_size'], p=0.5),\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=0.5),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n            \n        ], p=1.)"]}, {"cell_type": "code", "execution_count": 1, "id": "9e2998b7", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv')\nPATH = '/kaggle/input/cassava-leaf-disease-classification/test_images/'"]}, {"cell_type": "code", "execution_count": 1, "id": "29ffd2ce", "metadata": {}, "outputs": [], "source": ["test_csv = df.copy()\ntest_csv['image_id'] = PATH + test_csv['image_id']\n\ntest_ds = DiseaseDatasetInference(test_csv, transform=get_inference_transforms(), opt_label=False)\ntest_ds_vit = DiseaseDatasetInference(test_csv, transform=get_inference_Vit_transforms(), opt_label=False)\n\ntest_loader = torch.utils.data.DataLoader(test_ds, batch_size=CFG['valid_bs'], shuffle=False, pin_memory=False) \ntest_loader_vit = torch.utils.data.DataLoader(test_ds_vit, batch_size=CFG['valid_bs'], shuffle=False, pin_memory=False) "]}, {"cell_type": "code", "execution_count": 1, "id": "7e201a9e", "metadata": {}, "outputs": [], "source": ["def inference (model, data_loader, device):\n    preds = []\n    model.eval()\n    test_tqdm = tq.tqdm(data_loader, total=len(data_loader), desc=\"Testing\", position=0, leave=True)\n    for images in test_tqdm:\n        images = images.to(device)\n        preds.extend(model(images).detach().cpu().numpy())\n    return preds"]}, {"cell_type": "markdown", "id": "feda3ad8", "metadata": {}, "source": ["# **EfficientNet**"]}, {"cell_type": "code", "execution_count": 1, "id": "165d5458", "metadata": {}, "outputs": [], "source": ["class Effnet(nn.Module):\n    def __init__(self, model_name = 'tf_efficientnet_b3_ns', pretrained = False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained = pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, 5)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x"]}, {"cell_type": "markdown", "id": "376accce", "metadata": {}, "source": ["# EfficientNet B3"]}, {"cell_type": "code", "execution_count": 1, "id": "6cdb55ab", "metadata": {}, "outputs": [], "source": ["path_effnet = '../input/torch-my-cassava-effnetb3/'\n\nmodel_name = 'tf_efficientnet_b3_ns'\neffnet_preds = []\neffnet_model = Effnet(model_name = model_name)\nfor effnet_model_name in CFG['effnet_model_b3']:\n    print(\"Model: \", effnet_model_name)\n    effnet_model.to(CFG['device'])\n    effnet_model.load_state_dict(torch.load(path_effnet+effnet_model_name, map_location=torch.device(CFG['device'])))\n    with torch.no_grad():\n        for i in range(CFG['tta']):\n            effnet_preds += [inference(effnet_model, test_loader, CFG['device'])]\neffnet_preds = np.mean(effnet_preds, axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "50c48abd", "metadata": {}, "outputs": [], "source": ["effnet_outcomes_b3 = pd.concat([df['image_id'], pd.DataFrame(effnet_preds)], axis=1).sort_values(['image_id'])"]}, {"cell_type": "markdown", "id": "701b7546", "metadata": {}, "source": ["# EfficientNet B4"]}, {"cell_type": "code", "execution_count": 1, "id": "78e6bc38", "metadata": {}, "outputs": [], "source": ["# path_effnet = '../input/torch-my-cassava-effnetb4/'\n\n\n# model_name = 'tf_efficientnet_b4_ns'\n# effnet_preds = []\n# effnet_model = Effnet(model_name = model_name)\n# for effnet_model_name in CFG['effnet_model_b4']:\n#     print(\"Model: \", effnet_model_name)\n#     effnet_model.to(CFG['device'])\n#     effnet_model.load_state_dict(torch.load(path_effnet+effnet_model_name, map_location=torch.device(CFG['device'])))\n#     with torch.no_grad():\n#         for i in range(CFG['tta']):\n#             effnet_preds += [inference(effnet_model, test_loader, CFG['device'])]\n# effnet_preds = np.mean(effnet_preds, axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "6cbe069a", "metadata": {}, "outputs": [], "source": ["# effnet_outcomes_b4 = pd.concat([df['image_id'], pd.DataFrame(effnet_preds)], axis=1).sort_values(['image_id'])"]}, {"cell_type": "markdown", "id": "9e9a5e92", "metadata": {}, "source": ["# **ResNet**"]}, {"cell_type": "code", "execution_count": 1, "id": "6e64b641", "metadata": {}, "outputs": [], "source": ["class CustomResNet(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, 5)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x"]}, {"cell_type": "markdown", "id": "5c8a1232", "metadata": {}, "source": ["# ResNet50d"]}, {"cell_type": "code", "execution_count": 1, "id": "dadf579c", "metadata": {}, "outputs": [], "source": ["# resnet_preds = []\n# path_resnet = '../input/torch-my-cassava-resnet50d/'\n\n# model_name = 'resnet50d'\n\n# resnet_model = CustomResNet(model_name = model_name)\n# resnet_model.to(CFG['device'])\n# for resnet_model_name in CFG['resnet_models']:\n#     print(\"Model: \", resnet_model_name)\n#     resnet_model.load_state_dict(torch.load(path_resnet + resnet_model_name, \n#                                              map_location=torch.device(CFG['device'])))\n#     with torch.no_grad():\n#         for i in range(CFG['tta']):\n#             resnet_preds += [inference(resnet_model, test_loader, CFG['device'])]\n# resnet_preds = np.mean(resnet_preds, axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "d981ccc4", "metadata": {}, "outputs": [], "source": ["# resnet_outcomes = pd.concat([df['image_id'], pd.DataFrame(resnet_preds)], axis=1).sort_values(['image_id'])"]}, {"cell_type": "markdown", "id": "d95c479f", "metadata": {}, "source": ["# ResNext50d"]}, {"cell_type": "code", "execution_count": 1, "id": "36035323", "metadata": {}, "outputs": [], "source": ["resnet_preds = []\npath_resnet = '../input/torch-my-cassava-resnext50d/'\n\nmodel_name = 'resnext50d_32x4d'\n\nresnet_model = CustomResNet(model_name = model_name)\nresnet_model.to(CFG['device'])\nfor resnet_model_name in CFG['resnext_models']:\n    print(\"Model: \", resnet_model_name)\n    resnet_model.load_state_dict(torch.load(path_resnet + resnet_model_name, \n                                             map_location=torch.device(CFG['device'])))\n    with torch.no_grad():\n        for i in range(CFG['tta']):\n            resnet_preds += [inference(resnet_model, test_loader, CFG['device'])]\nresnet_preds = np.mean(resnet_preds, axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "9ec062ee", "metadata": {}, "outputs": [], "source": ["resnext_outcomes = pd.concat([df['image_id'], pd.DataFrame(resnet_preds)], axis=1).sort_values(['image_id'])"]}, {"cell_type": "markdown", "id": "9279b3a2", "metadata": {}, "source": ["# ResNext 101"]}, {"cell_type": "code", "execution_count": 1, "id": "cdb8d91a", "metadata": {}, "outputs": [], "source": ["# resnet_preds = []\n# path_resnet = '../input/torch-my-cassava-resnext101/'\n\n# model_name = 'ig_resnext101_32x8d'\n\n# resnet_model = CustomResNet(model_name = model_name)\n# resnet_model.to(CFG['device'])\n# for resnet_model_name in CFG['resnext101_models']:\n#     print(\"Model: \", resnet_model_name)\n#     resnet_model.load_state_dict(torch.load(path_resnet + resnet_model_name, \n#                                              map_location=torch.device(CFG['device'])))\n#     with torch.no_grad():\n#         for i in range(CFG['tta']):\n#             resnet_preds += [inference(resnet_model, test_loader, CFG['device'])]\n# resnet_preds = np.mean(resnet_preds, axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "164ba424", "metadata": {}, "outputs": [], "source": ["# resnext_outcomes = pd.concat([df['image_id'], pd.DataFrame(resnet_preds)], axis=1).sort_values(['image_id'])"]}, {"cell_type": "markdown", "id": "64ad4b4e", "metadata": {}, "source": ["# ViT"]}, {"cell_type": "code", "execution_count": 1, "id": "ea72a892", "metadata": {}, "outputs": [], "source": ["class ViTClassifier(nn.Module):\n    def __init__(self, model_name = 'vit_base_patch16_384', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, 5)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x"]}, {"cell_type": "code", "execution_count": 1, "id": "242e8290", "metadata": {}, "outputs": [], "source": ["path_vit = '../input/torch-my-cassava-vit-16-384/'\n\n\nmodel_name = 'vit_base_patch16_384'\nvit_preds = []\nvit_model = ViTClassifier(model_name = model_name)\nfor vit_model_name in CFG['vit_models']:\n    print(\"Model: \", vit_model_name)\n    vit_model.to(CFG['device'])\n    vit_model.load_state_dict(torch.load(path_vit+vit_model_name, map_location=torch.device(CFG['device'])))\n    with torch.no_grad():\n        for i in range(CFG['tta']):\n            vit_preds += [inference(vit_model, test_loader_vit, CFG['device'])]\nvit_preds = np.mean(vit_preds, axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "16ca1ab7", "metadata": {}, "outputs": [], "source": ["vit_outcomes = pd.concat([df['image_id'], pd.DataFrame(vit_preds)], axis=1).sort_values(['image_id'])"]}, {"cell_type": "markdown", "id": "82a5baea", "metadata": {}, "source": ["# Ensemble"]}, {"cell_type": "code", "execution_count": 1, "id": "e2b1880a", "metadata": {}, "outputs": [], "source": ["# final_preds = (effnet_outcomes_b3.drop('image_id', axis=1) * 0.25 + effnet_outcomes_b4.drop('image_id', axis=1) * 0.25 + resnet_outcomes.drop('image_id', axis=1) * 0.25 + resnext_outcomes.drop('image_id', axis=1) * 0.25).to_numpy()\nfinal_preds = (resnext_outcomes.drop('image_id', axis=1) * 0.4 + vit_outcomes.drop('image_id', axis=1) * 0.3 + effnet_outcomes_b3.drop('image_id', axis=1) * 0.3).to_numpy()\n# final_preds = (resnext_outcomes.drop('image_id', axis=1) * 0.5 + effnet_outcomes_b3.drop('image_id', axis=1) * 0.5).to_numpy()\nfinal_preds = softmax(final_preds).argmax(1)"]}, {"cell_type": "code", "execution_count": 1, "id": "26924c9a", "metadata": {}, "outputs": [], "source": ["submit = pd.DataFrame({'image_id': df['image_id'].values, 'label': final_preds})\nsubmit.to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}