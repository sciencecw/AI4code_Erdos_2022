{"cells": [{"cell_type": "code", "execution_count": 1, "id": "9e7fc5ee", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re # Import Regular Expression Library\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "8c14a2fc", "metadata": {}, "outputs": [], "source": ["data=pd.read_csv(\"../input/Restaurant_Reviews.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "907f991b", "metadata": {}, "outputs": [], "source": ["#Exchange the characters not between in \"a-z\" and \"A-Z\" with space character\ncomment=re.sub('[^a-zA-Z]',' ',data['Review'][0])\n#Now data is not DataFrame anymore. It's string!"]}, {"cell_type": "code", "execution_count": 1, "id": "5d25528c", "metadata": {}, "outputs": [], "source": ["comment=comment.lower() #transfom all the characters into lower case"]}, {"cell_type": "code", "execution_count": 1, "id": "d221c10f", "metadata": {}, "outputs": [], "source": ["comment=comment.split() #transform the sentence into word list"]}, {"cell_type": "code", "execution_count": 1, "id": "937d2111", "metadata": {}, "outputs": [], "source": ["#remove the stopwords\nfrom nltk.corpus import stopwords\nstopwords_en = stopwords.words('english')\nprint(stopwords_en)"]}, {"cell_type": "code", "execution_count": 1, "id": "5714b1c7", "metadata": {}, "outputs": [], "source": ["#Stemming and Lemmatization\nfrom nltk.stem.porter import PorterStemmer\nps= PorterStemmer() \ncomment=[ps.stem(kelime) for kelime in comment if not kelime in set(stopwords.words('english'))]\n#If the word is not stopwords, throw it into the list\n#Since we write in square brackets, the values returned from the function will be defined as a list\ncomment= ' '.join(comment) #Merge all words in comment with a space between them and put them in comment. Comment is string now"]}, {"cell_type": "markdown", "id": "38f031d8", "metadata": {}, "source": ["# Preprocessing"]}, {"cell_type": "code", "execution_count": 1, "id": "03f45808", "metadata": {}, "outputs": [], "source": ["#repeat all the steps for all the reviews in Dataset\ncomments=[]\nfor i in range(1000):\n    comment=re.sub('[^a-zA-Z]',' ',data['Review'][i])\n    comment=comment.lower() #transfom all the characters into lower case\n    comment=comment.split()\n    comment=[ps.stem(kelime) for kelime in comment if not kelime in set(stopwords.words('english'))]\n    comment= ' '.join(comment) #Merge all words in comment with a space between them and put them in comment. Comment is string now\n    comments.append(comment)\ncomments"]}, {"cell_type": "markdown", "id": "f67c09bd", "metadata": {}, "source": ["# Feature Extraction"]}, {"cell_type": "code", "execution_count": 1, "id": "441e1b79", "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import CountVectorizer\ncv= CountVectorizer(max_features=1000) #Take 2000 words most common used\nX = cv.fit_transform(comments).toarray()#independent variable\ny = data.iloc[:,1].values  #dependent variable"]}, {"cell_type": "markdown", "id": "b418bd8d", "metadata": {}, "source": ["# Machine Learning"]}, {"cell_type": "code", "execution_count": 1, "id": "695ed711", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\ngnb= GaussianNB()\ngnb.fit(X_train,y_train)\ny_pred=gnb.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "0fd9ab78", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix\ncm= confusion_matrix(y_test,y_pred)\nprint(cm)"]}, {"cell_type": "markdown", "id": "38545781", "metadata": {}, "source": ["That's ALL"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}