{"cells": [{"cell_type": "markdown", "id": "076f192e", "metadata": {}, "source": ["# Creating a POS Tagger"]}, {"cell_type": "markdown", "id": "747e73fc", "metadata": {}, "source": ["We can train a classifier to work out which suffixes are most informative for POS tagging. We can begin by finding out what the most common suffixes are"]}, {"cell_type": "code", "execution_count": 1, "id": "59981224", "metadata": {}, "outputs": [], "source": ["from nltk.corpus import brown\nfrom nltk import FreqDist\n\nsuffix_fdist = FreqDist()\nfor word in brown.words():\n    word = word.lower()\n    suffix_fdist[word[-1:]] += 1\n    suffix_fdist[word[-2:]] += 1\n    suffix_fdist[word[-3:]] += 1\n    \nsuffix_fdist"]}, {"cell_type": "code", "execution_count": 1, "id": "b71256e5", "metadata": {}, "outputs": [], "source": ["common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\ncommon_suffixes[:10]"]}, {"cell_type": "markdown", "id": "7bfb1dc7", "metadata": {}, "source": ["Next, we'll define a feature extractor function which checks a given word for these suffixes:"]}, {"cell_type": "code", "execution_count": 1, "id": "caf0a687", "metadata": {}, "outputs": [], "source": ["def pos_features(word):\n    features = {}\n    for suffix in common_suffixes:\n        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n    return features\n\npos_features('test')"]}, {"cell_type": "markdown", "id": "22391e49", "metadata": {}, "source": ["Now that we've defined our feature extractor, we can use it to train a new decision tree classifier:"]}, {"cell_type": "code", "execution_count": 1, "id": "d0754288", "metadata": {}, "outputs": [], "source": ["tagged_words = brown.tagged_words(categories='news')\nfeaturesets = [(pos_features(n), g) for (n,g) in tagged_words]\nfeaturesets[0]"]}, {"cell_type": "code", "execution_count": 1, "id": "9acc4bff", "metadata": {}, "outputs": [], "source": ["from nltk import DecisionTreeClassifier\nfrom nltk.classify import accuracy\n\ncutoff = int(len(featuresets) * 0.1)\ntrain_set, test_set = featuresets[cutoff:], featuresets[:cutoff]"]}, {"cell_type": "code", "execution_count": 1, "id": "42fa5b39", "metadata": {}, "outputs": [], "source": ["classifier = DecisionTreeClassifier.train(train_set) # NLTK is a teaching toolkit which is not really optimized for speed. Therefore, this may take forever. For speed, use scikit-learn for the classifiers."]}, {"cell_type": "code", "execution_count": 1, "id": "7166baac", "metadata": {}, "outputs": [], "source": ["accuracy(classifier, test_set)"]}, {"cell_type": "code", "execution_count": 1, "id": "234ab06d", "metadata": {}, "outputs": [], "source": ["classifier.classify(pos_features('cats'))"]}, {"cell_type": "code", "execution_count": 1, "id": "64d5122e", "metadata": {}, "outputs": [], "source": ["classifier.pseudocode(depth=4)"]}, {"cell_type": "markdown", "id": "b6ee665c", "metadata": {}, "source": ["To improve the classifier, we can add contextual features:\n\n```py\ndef pos_features(sentence, i): [1]\n    features = {\"suffix(1)\": sentence[i][-1:],\n                \"suffix(2)\": sentence[i][-2:],\n                \"suffix(3)\": sentence[i][-3:]}\n    if i == 0:\n        features[\"prev-word\"] = \"<START>\"\n    else:\n        features[\"prev-word\"] = sentence[i-1]\n    return features\n```\n\nThen, instead of working with tagged words, we work with tagged sentences:\n```py\ntagged_sents = brown.tagged_sents(categories='news')\n```\n\nWe can then improve this further by adding more features such as `prev-tag` etc."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}