{"cells": [{"cell_type": "code", "execution_count": 1, "id": "26c27d1a", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "5a60bd9c", "metadata": {}, "source": ["**IMPORTING THE DATASET**"]}, {"cell_type": "code", "execution_count": 1, "id": "de65228d", "metadata": {}, "outputs": [], "source": ["fashion=keras.datasets.fashion_mnist"]}, {"cell_type": "markdown", "id": "0e5b937b", "metadata": {}, "source": ["**SPLITTING DATASET INTO TRAINING AND TESTING SET**"]}, {"cell_type": "code", "execution_count": 1, "id": "4247d029", "metadata": {}, "outputs": [], "source": ["(train_images,train_labels),(test_images,test_labels)=fashion.load_data()"]}, {"cell_type": "markdown", "id": "502456f3", "metadata": {}, "source": ["**NORMALIZING THE PIXELS**\n\nSince the pixels of picture are in range 0 to 255. So, we divide them by 255 to get the values in the range of 0 to 1."]}, {"cell_type": "code", "execution_count": 1, "id": "fb97f196", "metadata": {}, "outputs": [], "source": ["train_images=train_images/255.0\ntest_images=test_images/255.0"]}, {"cell_type": "code", "execution_count": 1, "id": "d5330340", "metadata": {}, "outputs": [], "source": ["train_images[0].shape"]}, {"cell_type": "code", "execution_count": 1, "id": "0f4ad165", "metadata": {}, "outputs": [], "source": ["train_images=train_images.reshape(len(train_images),28,28,1)\ntest_images=test_images.reshape(len(test_images),28,28,1)"]}, {"cell_type": "markdown", "id": "3a59ccca", "metadata": {}, "source": ["**HYPERPARAMETER TUNING FOR ADDING THE LAYERS WITH BEST PARAMETERS**"]}, {"cell_type": "code", "execution_count": 1, "id": "e9932d3d", "metadata": {}, "outputs": [], "source": ["def build_model(hp):  \n    model = keras.Sequential([\n    keras.layers.Conv2D(\n        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n        activation='relu',\n        input_shape=(28,28,1)\n    ),\n    keras.layers.Conv2D(\n        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n        activation='relu'\n    ),\n    keras.layers.Flatten(),\n    keras.layers.Dense(\n        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n        activation='relu'\n    ),\n    keras.layers.Dense(10, activation='softmax')\n    ])\n  \n    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n  \n    return model"]}, {"cell_type": "code", "execution_count": 1, "id": "4b4eb009", "metadata": {}, "outputs": [], "source": ["from kerastuner import RandomSearch\nfrom kerastuner.engine.hyperparameters import HyperParameters"]}, {"cell_type": "markdown", "id": "57edbfd6", "metadata": {}, "source": ["**SETTING THE VALUES**"]}, {"cell_type": "code", "execution_count": 1, "id": "82dde5d3", "metadata": {}, "outputs": [], "source": ["tuner_search=RandomSearch(build_model,\n                         objective=\"val_accuracy\",\n                         max_trials=5,\n                         directory=\"output\",\n                         project_name=\"Fashion\")"]}, {"cell_type": "markdown", "id": "fa6a3ce2", "metadata": {}, "source": ["**RUNNING THE MODEL ON THE ABOVE GIVEN PARAMAETRS**"]}, {"cell_type": "code", "execution_count": 1, "id": "0306d152", "metadata": {}, "outputs": [], "source": ["tuner_search.search(train_images,train_labels,epochs=3,validation_split=0.3)"]}, {"cell_type": "markdown", "id": "c2ddf324", "metadata": {}, "source": ["**TO KNOW THE BEST MODEL PARAMETERS**"]}, {"cell_type": "code", "execution_count": 1, "id": "eed17804", "metadata": {}, "outputs": [], "source": ["model=tuner_search.get_best_models(num_models=1)[0]"]}, {"cell_type": "code", "execution_count": 1, "id": "cdb00563", "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "markdown", "id": "cc2ba499", "metadata": {}, "source": ["**TRAINING THE MODEL ON TRAINING DATASET**"]}, {"cell_type": "code", "execution_count": 1, "id": "6f78caf8", "metadata": {}, "outputs": [], "source": ["model.fit(train_images, train_labels, epochs=10, validation_split=0.1, initial_epoch=3)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}