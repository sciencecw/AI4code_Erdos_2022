{"cells": [{"cell_type": "markdown", "id": "67d4ab3a", "metadata": {}, "source": ["### Modification of Kernel by another Kaggle User ### \nI looked through some datasets and kernels and found this one interesting. For some predictions near the end, the score achieved was always 100%, which seemed unusually high. I noticed that the data used for the predictions was 100% correlated due to some generated features being mutually exclusive. Here is a different take on the predictions, where the correlations are removed.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "62126cd6", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "2a4a6cae", "metadata": {}, "source": ["# IMPORTING LIBRARIES"]}, {"cell_type": "code", "execution_count": 1, "id": "f4c6bf96", "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix"]}, {"cell_type": "markdown", "id": "ea3d5b11", "metadata": {}, "source": ["# LOADING LA METRO-BIKE-SHARE-TRIP-DATASET"]}, {"cell_type": "code", "execution_count": 1, "id": "d8995de8", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv(\"../input/metro-bike-share-trip-data.csv\")"]}, {"cell_type": "markdown", "id": "1eed275e", "metadata": {}, "source": ["# DATA EXPLORATION"]}, {"cell_type": "code", "execution_count": 1, "id": "a9497b80", "metadata": {}, "outputs": [], "source": ["print ('There are',len(train.columns),'columns:')\nfor x in train.columns:\n    print(x+' ',end=',')"]}, {"cell_type": "code", "execution_count": 1, "id": "43c4b64e", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "9168138b", "metadata": {}, "outputs": [], "source": ["train.tail()"]}, {"cell_type": "code", "execution_count": 1, "id": "11a61181", "metadata": {}, "outputs": [], "source": ["print(\"Number of columns (features) in the given dataset is :\",train.shape[1])\nprint(\"Number of rows (entries) in the given dataset is :\",train.shape[0])"]}, {"cell_type": "code", "execution_count": 1, "id": "f3c9778a", "metadata": {}, "outputs": [], "source": ["train.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "1b3bd785", "metadata": {}, "outputs": [], "source": ["train_na = (train.isnull().sum()*100)/len(train)\nprint(\"Percentage of Missing Data in each feature:\")\ntrain_na.sort_values(ascending=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "00ae55b0", "metadata": {}, "outputs": [], "source": ["sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')"]}, {"cell_type": "markdown", "id": "20dfa38f", "metadata": {}, "source": ["# DROPPING NULL VALUES.\nSince the dataset features such as Starting Station ID,Starting Station Latitude,Starting Station Longitude,Ending Station ID,Ending Station Latitude ,Ending Station Longitude,Bike ID ,Plan Duration,Starting Lat-Long,Ending Lat-Long contains some null values. So before moving on further with the dataset we need to drop null values so that these null values can create problems while moving forward."]}, {"cell_type": "code", "execution_count": 1, "id": "bf04d81b", "metadata": {}, "outputs": [], "source": ["train = train.dropna()"]}, {"cell_type": "code", "execution_count": 1, "id": "df57dd4a", "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\nax.scatter(train['Passholder Type'], train['Duration'])\nplt.ylabel('Duration (in seconds)', fontsize=13)\nplt.xlabel('PassHolder Type', fontsize=13)\nplt.show()"]}, {"cell_type": "markdown", "id": "2b5db232", "metadata": {}, "source": ["# DISTANCE CALCULATION\nUsing the Starting Station Latitude and Longitude and Ending Station Latitude and Longitude we can calculate the distance travelled by the user. This extra feature calculated can be used to fit into the model as it can help in improving the predicting ability of the model."]}, {"cell_type": "code", "execution_count": 1, "id": "3f6ddaac", "metadata": {}, "outputs": [], "source": ["l = []\nimport math \ndegrees_to_radians = math.pi/180.0\ndef distance_on_unit_sphere(lat1, long1, lat2, long2):\n    phi1 = (90.0 - lat1)*degrees_to_radians\n    phi2 = (90.0 - lat2)*degrees_to_radians\n    \n    theta1 = long1*degrees_to_radians\n    theta2 = long2*degrees_to_radians\n    \n    a = ((math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2)) +(math.cos(phi1)*math.cos(phi2)))\n    if a>1:\n        a=0.999999\n    dis = math.acos( a )\n    return dis*6373\nfor i in range(97825):\n    l.append(distance_on_unit_sphere(train['Starting Station Latitude'].iloc[i],\n                                     train['Starting Station Longitude'].iloc[i],\n                                     train['Ending Station Latitude'].iloc[i],\n                                     train['Ending Station Longitude'].iloc[i]))"]}, {"cell_type": "markdown", "id": "a759c9c5", "metadata": {}, "source": ["Adding all the important features to a temporary dataframe temp "]}, {"cell_type": "code", "execution_count": 1, "id": "80347e72", "metadata": {}, "outputs": [], "source": ["temp = pd.DataFrame(data=[train['Duration'],\n                               train['Starting Station Latitude'],\n                               train['Starting Station Longitude'],\n                               train['Ending Station Latitude'],\n                               train['Ending Station Longitude'],\n                               train['Plan Duration']],\n                               index=['Duration',\n                                      'Starting Station Latitude',\n                                      'Starting Station Longitude',\n                                      'Ending Station Latitude',\n                                      'Ending Station Longitude',\n                                      'Plan Duration'])"]}, {"cell_type": "markdown", "id": "5867eea1", "metadata": {}, "source": ["Creating a new dataframe distance having the newly calculated distances under the Distance column"]}, {"cell_type": "code", "execution_count": 1, "id": "cf15a702", "metadata": {}, "outputs": [], "source": ["distance = pd.DataFrame({'Distance':l})"]}, {"cell_type": "code", "execution_count": 1, "id": "4cc19bc3", "metadata": {}, "outputs": [], "source": ["new_train = temp.T"]}, {"cell_type": "code", "execution_count": 1, "id": "4747d20b", "metadata": {}, "outputs": [], "source": ["print(\"Shape of new train \",new_train.shape)\nprint (\"Shape of distance \",distance.shape)"]}, {"cell_type": "code", "execution_count": 1, "id": "96939c48", "metadata": {}, "outputs": [], "source": ["new_train = new_train.reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "27a734a6", "metadata": {}, "outputs": [], "source": ["new_train = pd.concat([distance,\n                       new_train,\n                       pd.get_dummies(data=train['Passholder Type']).reset_index(),\n                       pd.get_dummies(data=train['Trip Route Category'],drop_first=True).reset_index()],\n                       axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "f2e9ac28", "metadata": {}, "outputs": [], "source": ["new_train = new_train.drop('index',axis=1)\nnew_train.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "c4b0708e", "metadata": {}, "outputs": [], "source": ["print(\"There are 3 different types of Passholder : \")\ntrain['Passholder Type'].value_counts()"]}, {"cell_type": "markdown", "id": "7868bf04", "metadata": {}, "source": ["# From below here, I modified the training data to remove obious correlations between Flex Pass, Monthly Pass, Walk-up and Plan Duration\n\n## USING LOGISTIC REGRESSION TO PREDICT WHETHER PASSHOLDER TYPE IS \"Walk-up\" OR \"Not\""]}, {"cell_type": "code", "execution_count": 1, "id": "c49bff56", "metadata": {}, "outputs": [], "source": ["X1 = new_train.drop(columns=['Flex Pass','Monthly Pass','Walk-up','Plan Duration'])\ny1 = new_train['Walk-up']"]}, {"cell_type": "code", "execution_count": 1, "id": "4e66229a", "metadata": {}, "outputs": [], "source": ["X_train,X_test,y_train,y_test = train_test_split(X1,y1,test_size=0.33)"]}, {"cell_type": "code", "execution_count": 1, "id": "ddd8c0ea", "metadata": {}, "outputs": [], "source": ["lr = LogisticRegression()"]}, {"cell_type": "code", "execution_count": 1, "id": "009b4e3f", "metadata": {}, "outputs": [], "source": ["lr.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "7745ece6", "metadata": {}, "outputs": [], "source": ["pred1 = lr.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "f9067b9f", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test,pred1))"]}, {"cell_type": "code", "execution_count": 1, "id": "b12c2895", "metadata": {}, "outputs": [], "source": ["print(confusion_matrix(y_test,pred1))"]}, {"cell_type": "markdown", "id": "69444dd2", "metadata": {}, "source": ["# USING RANDOM FOREST CLASSIFIER TO PREDICT WHETHER THE PASSHOLDER TYPE IS \"Monthly Pass\" OR \"Not\""]}, {"cell_type": "code", "execution_count": 1, "id": "268d5beb", "metadata": {}, "outputs": [], "source": ["X2 = new_train.drop(columns=['Flex Pass','Monthly Pass','Walk-up','Plan Duration'])\ny2 = new_train['Monthly Pass']\nX_train,X_test,y_train,y_test = train_test_split(X2,y2,test_size=0.33)"]}, {"cell_type": "code", "execution_count": 1, "id": "160bfe5d", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "500ddeff", "metadata": {}, "outputs": [], "source": ["clf = RandomForestClassifier()"]}, {"cell_type": "code", "execution_count": 1, "id": "74690490", "metadata": {}, "outputs": [], "source": ["clf.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "51a11c86", "metadata": {}, "outputs": [], "source": ["pred2 = clf.predict(X_test)\n# pred2 = clf2.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "e9c3ed0f", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test,pred2))"]}, {"cell_type": "code", "execution_count": 1, "id": "175f442b", "metadata": {}, "outputs": [], "source": ["print(confusion_matrix(y_test,pred2))"]}, {"cell_type": "markdown", "id": "eb2d838e", "metadata": {}, "source": ["# USING DECISION TREE CLASSIFIER TO PREDICT WHETHER THE PASSHOLDER TYPE IS \"Flex Pass\" OR \"Not\""]}, {"cell_type": "code", "execution_count": 1, "id": "97eca939", "metadata": {}, "outputs": [], "source": ["X3 = new_train.drop(columns=['Flex Pass','Monthly Pass','Walk-up','Plan Duration'])\ny3 = new_train['Flex Pass']\nX_train,X_test,y_train,y_test = train_test_split(X3,y3,test_size=0.33)"]}, {"cell_type": "code", "execution_count": 1, "id": "92bafa5f", "metadata": {}, "outputs": [], "source": ["print(X3.head())"]}, {"cell_type": "code", "execution_count": 1, "id": "4a7933de", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier"]}, {"cell_type": "code", "execution_count": 1, "id": "f791c291", "metadata": {}, "outputs": [], "source": ["clf2 = DecisionTreeClassifier()"]}, {"cell_type": "code", "execution_count": 1, "id": "5c81f5ff", "metadata": {}, "outputs": [], "source": ["clf2.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "88accdfa", "metadata": {}, "outputs": [], "source": ["pred3 = clf2.predict(X_test)"]}, {"cell_type": "code", "execution_count": 1, "id": "faa069d0", "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test,pred3))"]}, {"cell_type": "code", "execution_count": 1, "id": "a37008e2", "metadata": {}, "outputs": [], "source": ["print(confusion_matrix(y_test,pred3))"]}, {"cell_type": "markdown", "id": "d940ed00", "metadata": {}, "source": ["### Conclusion\nWe find that the decision tree classifier is fairly accurate for deciding whether a user holds a flex pass or not. Now, it would be interesting to examine which features of the data set have the strongest effect on the classification."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}