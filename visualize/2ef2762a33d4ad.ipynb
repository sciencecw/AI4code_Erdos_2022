{"cells": [{"cell_type": "code", "execution_count": 1, "id": "a605363a", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "6e8bd422", "metadata": {}, "source": ["## Data Analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "9f8a2218", "metadata": {}, "outputs": [], "source": ["%matplotlib inline\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 1, "id": "e0f436b8", "metadata": {}, "outputs": [], "source": ["df_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "8b496043", "metadata": {}, "outputs": [], "source": ["df = pd.concat((df_train,df_test),axis=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "61009a56", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "7382f91d", "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "cab92fad", "metadata": {}, "outputs": [], "source": ["sns.scatterplot(x='Electrical',y='SalePrice',data=df)"]}, {"cell_type": "code", "execution_count": 1, "id": "d25f9ec1", "metadata": {}, "outputs": [], "source": ["total = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total,percent],axis=1,keys=['Total','Percent'])\nmissing_data.head(30)"]}, {"cell_type": "code", "execution_count": 1, "id": "8d88c1d6", "metadata": {}, "outputs": [], "source": ["drop_features = list(missing_data.index[missing_data.Percent >= .00136])"]}, {"cell_type": "code", "execution_count": 1, "id": "d23e479a", "metadata": {}, "outputs": [], "source": ["drop_features.remove('SalePrice')"]}, {"cell_type": "code", "execution_count": 1, "id": "e6075558", "metadata": {}, "outputs": [], "source": ["# drop columns with too many NaNs\ndf_cleaned = df.drop(columns=drop_features)"]}, {"cell_type": "markdown", "id": "41b83326", "metadata": {}, "source": ["#### Clean the testdata to have all 1459 rows to submit data"]}, {"cell_type": "code", "execution_count": 1, "id": "143e4204", "metadata": {}, "outputs": [], "source": ["df_cleaned.Utilities.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "ce080f07", "metadata": {}, "outputs": [], "source": ["missing_rows_idx = df_cleaned.drop('SalePrice',axis=1).isnull().any(axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "4c8d618c", "metadata": {}, "outputs": [], "source": ["# if there is no Bsmt values then most like there is no basement at all\ndf_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)] = df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].fillna({\"BsmtFinSF1\":0,\"BsmtFinSF2\":0,\"BsmtFullBath\":0,\"BsmtHalfBath\":0,\"BsmtUnfSF\":0,\"TotalBsmtSF\":0})\n# Basically all the Utilities are AllPub\ndf_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)] = df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].fillna({\"Utilities\":\"AllPub\"})\n# Garage most likely to be zero if missing in report...\ndf_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)] = df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].fillna({\"GarageArea\":0,\"GarageCars\":0})\n# Houses in the neighborhood Sawyer saletype are probably WD\ndf_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)] = df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].fillna({\"SaleType\":\"WD\"})\n# Just go with typical functional\ndf_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)] = df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].fillna({\"Functional\":\"Typ\"})\n# When the ExterCond and ExterQual are both TA, these are most likely values for that neighboord Edwards\ndf_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)] = df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].fillna({\"Exterior1st\":\"Wd Sdng\",\"Exterior2nd\":\"Wd Sdng\"})\n# Just go with typical \ndf_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)] = df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].fillna({\"KitchenQual\":\"TA\"})"]}, {"cell_type": "code", "execution_count": 1, "id": "ce30582a", "metadata": {}, "outputs": [], "source": ["# Houses in the neighborhood Sawyer are probably WD...\ndf_cleaned[df_cleaned.loc[:,\"Neighborhood\"] == \"Sawyer\"].SaleType.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "74c9dadd", "metadata": {}, "outputs": [], "source": ["df_cleaned.KitchenQual.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "fcebe71b", "metadata": {}, "outputs": [], "source": ["df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)]"]}, {"cell_type": "code", "execution_count": 1, "id": "7a172571", "metadata": {}, "outputs": [], "source": ["df_cleaned.loc[np.logical_and(np.logical_and(df_cleaned.ExterCond==\"TA\",df_cleaned.ExterQual==\"TA\"),df_cleaned.Neighborhood==\"Edwards\")].Exterior1st.value_counts()\ndf_cleaned.loc[np.logical_and(df_cleaned.Exterior1st==\"Wd Sdng\",np.logical_and(np.logical_and(df_cleaned.ExterCond==\"TA\",df_cleaned.ExterQual==\"TA\"),df_cleaned.Neighborhood==\"Edwards\"))].Exterior2nd.value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "96e8e4a0", "metadata": {}, "outputs": [], "source": ["df_cleaned.loc[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)]"]}, {"cell_type": "code", "execution_count": 1, "id": "b8aac85d", "metadata": {}, "outputs": [], "source": ["df_cleaned[np.logical_and(df_cleaned.Id>1460,missing_rows_idx)].info()"]}, {"cell_type": "code", "execution_count": 1, "id": "6f21d346", "metadata": {}, "outputs": [], "source": ["# drop the few rows with NaNs\ndf_cleaned = df_cleaned.dropna(subset=[col for col in df_cleaned.columns if col != 'SalePrice'],how='any')"]}, {"cell_type": "code", "execution_count": 1, "id": "c1def7cb", "metadata": {}, "outputs": [], "source": ["df_cleaned = pd.get_dummies(df_cleaned)"]}, {"cell_type": "code", "execution_count": 1, "id": "d89d1c1c", "metadata": {}, "outputs": [], "source": ["# too many plots to do pairwise, so just do individual plts one at a time\nfor name in df.columns:\n    plt.figure\n    sns.scatterplot(x=name,y='SalePrice',data=df)\n    plt.xticks(rotation=90)\n    plt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "af9473d2", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,10));\nsns.heatmap(data=df_train.corr(),vmin=-1,vmax=1,linewidths=.3,cmap='jet',square=True);"]}, {"cell_type": "code", "execution_count": 1, "id": "59113964", "metadata": {}, "outputs": [], "source": ["# check if pearson correlation is above .8\nplt.figure(figsize=(15,10));\nsns.heatmap(data=abs(df_train.corr())>.50,vmin=0,vmax=1,linewidths=.3,cmap='YlGnBu',square=True);"]}, {"cell_type": "markdown", "id": "2a1a1647", "metadata": {}, "source": ["## Feature Engineering"]}, {"cell_type": "code", "execution_count": 1, "id": "ad8c4791", "metadata": {}, "outputs": [], "source": ["df_cleaned['TotalFlrSF'] = df_cleaned['1stFlrSF'] + df_cleaned['2ndFlrSF'] + df_cleaned['TotalBsmtSF']\ndf_cleaned['Total_Bathrooms'] = (df_cleaned['FullBath'] + (0.5*df_cleaned['HalfBath']) + \n                               df_cleaned['BsmtFullBath'] + (0.5*df_cleaned['BsmtHalfBath']))\n\ndf_cleaned['Total_porch_sf'] = (df_cleaned['OpenPorchSF'] + df_cleaned['3SsnPorch'] +\n                              df_cleaned['EnclosedPorch'] + df_cleaned['ScreenPorch'] +\n                             df_cleaned['WoodDeckSF'])"]}, {"cell_type": "markdown", "id": "08f6f13e", "metadata": {}, "source": ["## Split into train and test"]}, {"cell_type": "code", "execution_count": 1, "id": "6c67dbae", "metadata": {}, "outputs": [], "source": ["X_train_cleaned = df_cleaned[df_cleaned.Id <= 1460]\nX_test_cleaned = df_cleaned[df_cleaned.Id > 1460]"]}, {"cell_type": "code", "execution_count": 1, "id": "3a8f8c0d", "metadata": {}, "outputs": [], "source": ["X_test_Ids = X_test_cleaned.pop('Id')\nX_test_cleaned.pop('SalePrice');\nX_train_Ids = X_train_cleaned.pop('Id')"]}, {"cell_type": "code", "execution_count": 1, "id": "3418837f", "metadata": {}, "outputs": [], "source": ["y_train_cleaned = X_train_cleaned.pop('SalePrice')"]}, {"cell_type": "code", "execution_count": 1, "id": "0860871d", "metadata": {}, "outputs": [], "source": ["from scipy import stats\nX_trained_cleaned = X_train_cleaned[(np.abs(stats.zscore(X_train_cleaned)) < 10).all(axis=1)]"]}, {"cell_type": "markdown", "id": "ce4b6458", "metadata": {}, "source": ["## Select K best features"]}, {"cell_type": "code", "execution_count": 1, "id": "bbfeb576", "metadata": {}, "outputs": [], "source": ["from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression\nkbest = SelectKBest(mutual_info_regression,k=int(np.floor(len(X_train_cleaned.columns)/4))).fit(X_train_cleaned,y_train_cleaned)\nkbest_idx = kbest.get_support(indices=True)"]}, {"cell_type": "markdown", "id": "bd2a03ff", "metadata": {}, "source": ["## Data Transformation and Preparation"]}, {"cell_type": "code", "execution_count": 1, "id": "19074648", "metadata": {}, "outputs": [], "source": ["X_train = X_train_cleaned.iloc[:,kbest_idx]\nX_test = X_test_cleaned.iloc[:,kbest_idx]"]}, {"cell_type": "code", "execution_count": 1, "id": "732f2999", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "6c28b666", "metadata": {}, "outputs": [], "source": ["X_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)"]}, {"cell_type": "markdown", "id": "786b4909", "metadata": {}, "source": ["## Get best Model"]}, {"cell_type": "code", "execution_count": 1, "id": "980e325c", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor \n\nfrom sklearn.metrics import r2_score"]}, {"cell_type": "code", "execution_count": 1, "id": "59f439a9", "metadata": {}, "outputs": [], "source": ["rff = RandomForestRegressor()"]}, {"cell_type": "code", "execution_count": 1, "id": "2c1854a8", "metadata": {}, "outputs": [], "source": ["params = {\n    \"n_estimators\":[10,100,500,1000,3000],\n    \"max_depth\":[10,50,100,None],\n    \"min_samples_split\":[2,5,10],\n    \"max_features\":[\"auto\",\"sqrt\",\"log2\",None]\n}\ngs = RandomizedSearchCV(rff,param_distributions=params,n_iter=100,scoring='neg_mean_squared_error')"]}, {"cell_type": "code", "execution_count": 1, "id": "7f13e7cf", "metadata": {}, "outputs": [], "source": ["gs.fit(X_train_scaled,y_train_cleaned)"]}, {"cell_type": "code", "execution_count": 1, "id": "72dc5b8b", "metadata": {}, "outputs": [], "source": ["# Utility function to report best scores\ndef report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")"]}, {"cell_type": "code", "execution_count": 1, "id": "41233f10", "metadata": {}, "outputs": [], "source": ["report(gs.cv_results_)"]}, {"cell_type": "code", "execution_count": 1, "id": "6bf5edef", "metadata": {}, "outputs": [], "source": ["y_pred_train = gs.best_estimator_.predict(X_train_scaled)\nsns.scatterplot(x=y_pred_train,y=y_train_cleaned)\nprint(\"R2: \",r2_score(y_train_cleaned,y_pred_train))"]}, {"cell_type": "code", "execution_count": 1, "id": "2f2bfe84", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingRegressor"]}, {"cell_type": "code", "execution_count": 1, "id": "19d65622", "metadata": {}, "outputs": [], "source": ["gbb = GradientBoostingRegressor()"]}, {"cell_type": "code", "execution_count": 1, "id": "c9dd8b76", "metadata": {}, "outputs": [], "source": ["params = {\n    \"loss\":['ls','lad','huber','quantile'],\n    \"learning_rate\":[.1,.01,.005,.0005],\n    \"n_estimators\":[100,500,3000],\n    \"min_samples_split\":[2,5,10,20],\n    \"max_features\":[\"auto\",\"sqrt\",\"log2\",None]\n}\n\ngs2 = RandomizedSearchCV(gbb,param_distributions=params,n_iter=100,scoring='neg_mean_squared_error')\ngs2.fit(X_train_scaled,y_train_cleaned)"]}, {"cell_type": "code", "execution_count": 1, "id": "5dfea6e3", "metadata": {}, "outputs": [], "source": ["report(gs2.cv_results_)"]}, {"cell_type": "code", "execution_count": 1, "id": "26836e28", "metadata": {}, "outputs": [], "source": ["y_pred_train = gs2.best_estimator_.predict(X_train_scaled)\nsns.scatterplot(x=y_pred_train,y=y_train_cleaned)\nprint(\"R2: \",r2_score(y_train_cleaned,y_pred_train))"]}, {"cell_type": "code", "execution_count": 1, "id": "add8ddc6", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import Lasso\nparams = {\n    \"alpha\":[.1,.2,.3,.4,.5,.6,.7,.8,.9,1]\n}\nlasso = Lasso()\ngs3 = RandomizedSearchCV(lasso,param_distributions=params,n_iter=100,scoring='neg_mean_squared_error',cv=5)\ngs3.fit(X_train_scaled,y_train_cleaned)"]}, {"cell_type": "code", "execution_count": 1, "id": "9c69690b", "metadata": {}, "outputs": [], "source": ["y_pred_train = gs3.best_estimator_.predict(X_train_scaled)\nsns.scatterplot(x=y_pred_train,y=y_train_cleaned)\nprint(\"R2: \",r2_score(y_train_cleaned,y_pred_train))"]}, {"cell_type": "code", "execution_count": 1, "id": "94bcce58", "metadata": {}, "outputs": [], "source": ["y_pred =.2*gs.best_estimator_.predict(X_test_scaled) + .6*gs2.best_estimator_.predict(X_test_scaled) + .2 * gs3.best_estimator_.predict(X_test_scaled)\nsubmission = pd.DataFrame({\"Id\":X_test_Ids,\"SalePrice\":y_pred})\nsubmission.to_csv(\"submission1\",index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}