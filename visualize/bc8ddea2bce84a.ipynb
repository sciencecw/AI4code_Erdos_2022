{"cells": [{"cell_type": "markdown", "id": "505e337d", "metadata": {}, "source": ["*This kernel is made using the kernel https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6*"]}, {"cell_type": "code", "execution_count": 1, "id": "3d2073e4", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "id": "6964a0b6", "metadata": {}, "source": ["**IMPORT TRAIN TEST DATA**"]}, {"cell_type": "code", "execution_count": 1, "id": "a4f89e42", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")"]}, {"cell_type": "markdown", "id": "07d21163", "metadata": {}, "source": ["**CHECK SHAPE OF DATASET**"]}, {"cell_type": "code", "execution_count": 1, "id": "8bb4acd2", "metadata": {}, "outputs": [], "source": ["train.shape, test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "f793c28e", "metadata": {}, "outputs": [], "source": ["# ASSIGN X_train AND y_train\nX_train = train.drop('label',axis = 1)\ny_train = train.label"]}, {"cell_type": "code", "execution_count": 1, "id": "cdb4d7f3", "metadata": {}, "outputs": [], "source": ["y_train.value_counts()"]}, {"cell_type": "markdown", "id": "f82980bb", "metadata": {}, "source": ["*VISUALISING THE TARGET VARIABLE*"]}, {"cell_type": "code", "execution_count": 1, "id": "02493578", "metadata": {}, "outputs": [], "source": ["import seaborn as sns \nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = 15, 9\n\nsns.countplot(y_train);"]}, {"cell_type": "code", "execution_count": 1, "id": "dfc37a3a", "metadata": {}, "outputs": [], "source": ["# Checking for null values in train and test\nX_train.isnull().any().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "80c67c8f", "metadata": {}, "outputs": [], "source": ["test.isnull().any().sum()"]}, {"cell_type": "markdown", "id": "0df1295f", "metadata": {}, "source": ["**PERFORMING GRAYSCALE NORMALIZATION**"]}, {"cell_type": "code", "execution_count": 1, "id": "703f0cc5", "metadata": {}, "outputs": [], "source": ["X_train /= 255.\ntest /= 255."]}, {"cell_type": "markdown", "id": "eac2806d", "metadata": {}, "source": ["**RESHAPING IMAGES TO 3D WITH ONE CHANNEL SINCE ITS GREYSCALE**"]}, {"cell_type": "code", "execution_count": 1, "id": "977e34cf", "metadata": {}, "outputs": [], "source": ["# Setting height and widht to 28px and canal to 1\n\nX_train = X_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)"]}, {"cell_type": "code", "execution_count": 1, "id": "50d5ca29", "metadata": {}, "outputs": [], "source": ["# One Hot Encoding target values\nfrom keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes = 10)"]}, {"cell_type": "markdown", "id": "7347bdd8", "metadata": {}, "source": ["**TRAIN TEST SPLIT THE DATA**"]}, {"cell_type": "code", "execution_count": 1, "id": "94a3145a", "metadata": {}, "outputs": [], "source": ["# Create train and validation sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state= 3)"]}, {"cell_type": "code", "execution_count": 1, "id": "38da55d1", "metadata": {}, "outputs": [], "source": ["# Example\ng = plt.imshow(X_train[0][:,:,0])"]}, {"cell_type": "markdown", "id": "14bced39", "metadata": {}, "source": ["**CREATING CONVOLUTIONAL NEURAL NET**"]}, {"cell_type": "code", "execution_count": 1, "id": "7483fa18", "metadata": {}, "outputs": [], "source": ["from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization"]}, {"cell_type": "code", "execution_count": 1, "id": "eeda2b8b", "metadata": {}, "outputs": [], "source": ["model = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n                 input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))"]}, {"cell_type": "code", "execution_count": 1, "id": "9f801026", "metadata": {}, "outputs": [], "source": ["# Assigning the Optimizer\nfrom keras.optimizers import Adamax\noptimizer = Adamax(lr=0.001)"]}, {"cell_type": "code", "execution_count": 1, "id": "b062af2d", "metadata": {}, "outputs": [], "source": ["# Compiling the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"]}, {"cell_type": "markdown", "id": "cff58743", "metadata": {}, "source": ["**With the ReduceLROnPlateau function from Keras.callbacks, we can choose to reduce the LR by half if the accuracy is not improved after 3 epochs.**"]}, {"cell_type": "code", "execution_count": 1, "id": "b9ad09b7", "metadata": {}, "outputs": [], "source": ["from keras.callbacks import ReduceLROnPlateau\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)"]}, {"cell_type": "markdown", "id": "06d8a553", "metadata": {}, "source": ["**REDUCING OVERFITTING WITH DATA AUGMENTATION**"]}, {"cell_type": "code", "execution_count": 1, "id": "ddee96e9", "metadata": {}, "outputs": [], "source": ["from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n                             rotation_range=10,\n                             zoom_range = 0.1,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1)\n\ndatagen.fit(X_train)"]}, {"cell_type": "markdown", "id": "818a7467", "metadata": {}, "source": ["**FIT THE TRAINING SET AND CHECK ACCURACY**"]}, {"cell_type": "code", "execution_count": 1, "id": "d03007c5", "metadata": {}, "outputs": [], "source": ["%%time\n\nmodel.fit_generator(datagen.flow(X_train,y_train, batch_size= 86),\n                                  epochs = 100, validation_data = (X_val,y_val),\n                                  verbose = 2, steps_per_epoch=X_train.shape[0] // 86,\n                                  callbacks=[learning_rate_reduction])"]}, {"cell_type": "code", "execution_count": 1, "id": "df147cc9", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix\n\n# Predict the validation dataset\ny_pred = model.predict(X_val)\n# Convert predictions to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nsns.heatmap(confusion_mtx, annot=True, fmt='d');"]}, {"cell_type": "markdown", "id": "2a7da213", "metadata": {}, "source": ["**FINDING INCORRECT PREDICTIONS \nCode used from kernel = https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6**"]}, {"cell_type": "code", "execution_count": 1, "id": "7d07bc61", "metadata": {}, "outputs": [], "source": ["# Difference between predicted labels and true labels\nerrors = (y_pred_classes - y_true != 0)\n\ny_pred_classes_errors = y_pred_classes[errors]\ny_pred_errors = y_pred[errors]\ny_true_errors = y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\ny_pred_errors_prob = np.max(y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, y_pred_classes_errors, y_true_errors)"]}, {"cell_type": "markdown", "id": "5b645a19", "metadata": {}, "source": ["**PREDICT THE RESULTS**"]}, {"cell_type": "code", "execution_count": 1, "id": "a3555c40", "metadata": {}, "outputs": [], "source": ["# predict results\nresults = model.predict(test)\n\n# change predictions to one hot vectors\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")"]}, {"cell_type": "code", "execution_count": 1, "id": "9b4e8499", "metadata": {}, "outputs": [], "source": ["submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}