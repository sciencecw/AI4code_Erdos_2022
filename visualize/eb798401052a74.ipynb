{"cells": [{"cell_type": "code", "execution_count": 1, "id": "1f190f5f", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "f10bc530", "metadata": {}, "source": ["# IMPORTING DATA"]}, {"cell_type": "markdown", "id": "d1926543", "metadata": {}, "source": ["**In order to import the data, pandas function read_csv is used**"]}, {"cell_type": "code", "execution_count": 1, "id": "bae81eaa", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndf.head()"]}, {"cell_type": "markdown", "id": "caee9256", "metadata": {}, "source": ["**.info() function is used to check the columns data types so it can be processed further**"]}, {"cell_type": "code", "execution_count": 1, "id": "09f08c15", "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "markdown", "id": "42910f7e", "metadata": {}, "source": ["# DATA CLEANING"]}, {"cell_type": "markdown", "id": "b1b5a992", "metadata": {}, "source": ["**Checked the duplicate values based on ID column, if theres none, the column can be dropped since its no longer serves a purpose in the analysis**"]}, {"cell_type": "code", "execution_count": 1, "id": "d0efcedb", "metadata": {}, "outputs": [], "source": ["duplicates = df.duplicated(subset='id')\ndf[duplicates]"]}, {"cell_type": "code", "execution_count": 1, "id": "af74096d", "metadata": {}, "outputs": [], "source": ["df = df.drop(['id'],axis=1)"]}, {"cell_type": "markdown", "id": "34c86f22", "metadata": {}, "source": ["**Created a list containing columns based on their data types.**"]}, {"cell_type": "code", "execution_count": 1, "id": "4dbc25bf", "metadata": {}, "outputs": [], "source": ["date= list(df.select_dtypes(include=['datetime64[ns]']))\ncats= list(df.select_dtypes(include=['object','bool']) )\nnums= list(df.select_dtypes(include=['int64','float64']))\nprint(date)\nprint(cats)\nprint(nums)"]}, {"cell_type": "markdown", "id": "5e928e9e", "metadata": {}, "source": ["**Search for null values in the data.**"]}, {"cell_type": "code", "execution_count": 1, "id": "4f658c8a", "metadata": {}, "outputs": [], "source": ["df.isna().sum()"]}, {"cell_type": "markdown", "id": "6ff74244", "metadata": {}, "source": ["**Figured that there are 201 missing values in the data, .describe() function is used to check whether the \"mean\" values are close enough to the median. If they are close enough, it can be assumed that the mean is robust enough and the data doesnt really contain a lot of extreme outliers**"]}, {"cell_type": "code", "execution_count": 1, "id": "00ca8ece", "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "markdown", "id": "32ecf4f7", "metadata": {}, "source": ["**Since the mean and the median values are pretty close in the \"bmi\" column of the dataframe, the mean values can be used to fill the null.**"]}, {"cell_type": "code", "execution_count": 1, "id": "42ddcf96", "metadata": {}, "outputs": [], "source": ["df['bmi'].fillna(df['bmi'].mean(), inplace=True)"]}, {"cell_type": "markdown", "id": "e4ebb7b2", "metadata": {}, "source": ["**Search for the duplicate values in the dataframe, got 0 value.**"]}, {"cell_type": "code", "execution_count": 1, "id": "5355f5d8", "metadata": {}, "outputs": [], "source": ["df.duplicated().sum()"]}, {"cell_type": "markdown", "id": "4455c0b8", "metadata": {}, "source": ["**Boxplot are used to check whether there are outlier contained in the data. age_glucose_level dan bmi columns contains outlier based on the boxplot.**"]}, {"cell_type": "code", "execution_count": 1, "id": "9d6be424", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 7))\nfor i in range(0, len(nums)):\n    plt.subplot(2, 3, i+1)\n    sns.boxplot(y=df[nums[i]],color='green',orient='v')\n    plt.tight_layout()"]}, {"cell_type": "markdown", "id": "a04310b3", "metadata": {}, "source": ["**Distplot are used to check the distribution of the data. If the data are skewed we can list it to process it further.**"]}, {"cell_type": "code", "execution_count": 1, "id": "b3a51e9a", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 7))\nfor i in range(0, len(nums)):\n    plt.subplot(2, 3, i+1)\n    sns.distplot(df[nums[i]], color='gray')\n    plt.tight_layout()"]}, {"cell_type": "markdown", "id": "131f1a42", "metadata": {}, "source": ["**The distribution of avg_glucose_level and bmi columns are skewed to the left. Other than that, avg_glucose_level and bmi columns also contains outlier.**"]}, {"cell_type": "code", "execution_count": 1, "id": "8b7e8363", "metadata": {}, "outputs": [], "source": ["outlier = ['avg_glucose_level','bmi']\nskewed = ['avg_glucose_level','bmi']"]}, {"cell_type": "markdown", "id": "8369f2e9", "metadata": {}, "source": ["**Log transformation is used to remove the skewness from the data.**"]}, {"cell_type": "code", "execution_count": 1, "id": "0d229e3d", "metadata": {}, "outputs": [], "source": ["for col in skewed:\n    df[col] = np.log(df[col])"]}, {"cell_type": "code", "execution_count": 1, "id": "a4a7c73a", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(12, 5))\nfor i in range(0, len(nums)):\n    plt.subplot(2, len(nums)/2, i+1)\n    sns.distplot(df[nums[i]], color='gray')\n    plt.tight_layout()"]}, {"cell_type": "markdown", "id": "17e00db0", "metadata": {}, "source": ["**The distribution of avg_glucose_level and bmi columns are a lot better than before, its closer to normal distribution.**"]}, {"cell_type": "markdown", "id": "ffbab257", "metadata": {}, "source": ["**Remove the outlier from the data using z-score method because the data are already close to normal distribution thanks to the log transformation!**"]}, {"cell_type": "code", "execution_count": 1, "id": "d289cb20", "metadata": {}, "outputs": [], "source": ["from scipy import stats\nprint(f'Length of the data before filtering outlier: {len(df)}')\n\nfiltered_entries = np.array([True] * len(df))\n\nfor col in outlier:\n    zscore = abs(stats.zscore(df[col]))\n    filtered_entries = (zscore < 3) & filtered_entries\n    \ndf = df[filtered_entries]\n\nprint(f'Length of the data after filtering outlier: {len(df)}')"]}, {"cell_type": "markdown", "id": "2750b317", "metadata": {}, "source": ["# DATA ENCODING AND EXPLORATORY DATA ANALYSIS "]}, {"cell_type": "markdown", "id": "36500bf9", "metadata": {}, "source": ["**Used countplot just to see a brief summary of the categorical data.**"]}, {"cell_type": "code", "execution_count": 1, "id": "b8864a5c", "metadata": {}, "outputs": [], "source": ["for i in range(0, len(cats)):\n    plt.subplot(3, len(cats)/2, i+1)\n    sns.countplot(df[cats[i]], color='gray', orient='v')\n    plt.tight_layout()"]}, {"cell_type": "markdown", "id": "4021625f", "metadata": {}, "source": ["**Used .value_counts() function on the stroke/target columns to see whether the target are imbalanced, and it is!**"]}, {"cell_type": "code", "execution_count": 1, "id": "6fb8f2dc", "metadata": {}, "outputs": [], "source": ["df['stroke'].value_counts().plot(kind='bar')"]}, {"cell_type": "code", "execution_count": 1, "id": "a5d3169f", "metadata": {}, "outputs": [], "source": ["for col in cats:\n    print(str(col))\n    print(df[col].unique())"]}, {"cell_type": "markdown", "id": "06fea48e", "metadata": {}, "source": ["**Encode the data based on their unique values, labelencoding and one-hot encoding are used.**"]}, {"cell_type": "code", "execution_count": 1, "id": "9cd28547", "metadata": {}, "outputs": [], "source": ["labenco = []\nonehot = []\nfor col in cats:\n    if len(df[col].unique()) == 2:\n        labenco.append(col)\n    else:\n        onehot.append(col)\nprint(labenco)\nprint(onehot)"]}, {"cell_type": "code", "execution_count": 1, "id": "33d7c678", "metadata": {}, "outputs": [], "source": ["df_labencoded = df.copy()\nfor col in labenco:\n    df_labencoded[col] = df_labencoded[col].astype('category').cat.codes\ndf_labencoded.head()"]}, {"cell_type": "markdown", "id": "0957ac91", "metadata": {}, "source": ["**NUMERICAL VARIABLES EDA**"]}, {"cell_type": "markdown", "id": "b3143df6", "metadata": {}, "source": ["**Mainly, heatmap and barplot will be used hence its representative enough to see whether there are a correlation between the data.**"]}, {"cell_type": "code", "execution_count": 1, "id": "926c28fb", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 8))\nsns.heatmap(df_labencoded.corr(), cmap='Blues', annot=True, fmt='.2f')"]}, {"cell_type": "code", "execution_count": 1, "id": "fc9d142b", "metadata": {}, "outputs": [], "source": ["for col in nums:\n    plt.figure(figsize=(15, 8))\n    print(sns.barplot(x='stroke',y=col,data=df_labencoded))"]}, {"cell_type": "markdown", "id": "5f718348", "metadata": {}, "source": ["**Based from the heatmap and barplot above, it can be said that age, hypertension, and heart_disease columns can be used to predict stroke.**"]}, {"cell_type": "markdown", "id": "5ae55f83", "metadata": {}, "source": ["**ONEHOT ENCODING EDA**"]}, {"cell_type": "code", "execution_count": 1, "id": "88c561d7", "metadata": {}, "outputs": [], "source": ["for col in onehot:\n    df_loop = df_labencoded[[col,'stroke']].copy()\n    onehots = pd.get_dummies(df_loop[col], prefix=col)\n    df_loop = df_loop.join(onehots)\n    plt.figure(figsize=(15, 8))\n    print(sns.heatmap(df_loop.corr(), cmap='Blues', annot=True, fmt='.2f'))"]}, {"cell_type": "code", "execution_count": 1, "id": "2cf2afc8", "metadata": {}, "outputs": [], "source": ["for col in onehot:\n    df_loop = df_labencoded[[col,'stroke']].copy()\n    onehots = pd.get_dummies(df_loop[col], prefix=col)\n    df_loop = df_loop.join(onehots)\n    plt.figure(figsize=(15, 8))\n    print(sns.barplot(x=col,y='stroke',data=df_labencoded))"]}, {"cell_type": "markdown", "id": "0cd90d8f", "metadata": {}, "source": ["**Based on the heatmap and barplot above, it can be said that smoking_status and work_type can be used to predict stroke.**"]}, {"cell_type": "markdown", "id": "dff707e0", "metadata": {}, "source": ["# DATA STANDARDIZATION"]}, {"cell_type": "markdown", "id": "438fe96c", "metadata": {}, "source": ["**Create a new dataframe containing only the selected columns from the original dataframe.**"]}, {"cell_type": "code", "execution_count": 1, "id": "6044c498", "metadata": {}, "outputs": [], "source": ["selected_feat=['age','hypertension','heart_disease','work_type','smoking_status','stroke']\ndf_pre_model = df[selected_feat].copy()\ndf_pre_model.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "56cc63d9", "metadata": {}, "outputs": [], "source": ["onehot_pre_model = ['work_type','smoking_status']\nfor col in onehot_pre_model:\n    onehots = pd.get_dummies(df_pre_model[col], prefix=col)\n    df_pre_model = df_pre_model.join(onehots)\n    df_pre_model = df_pre_model.drop([col],axis=1)\ndf_pre_model.head()"]}, {"cell_type": "markdown", "id": "42cf4071", "metadata": {}, "source": ["**Age column's values are relatively larger compared to the other column's values in the data, so the age column's are standardized.**"]}, {"cell_type": "code", "execution_count": 1, "id": "64f1a465", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import MinMaxScaler, StandardScaler\ndf_model = df_pre_model.copy()\ndf_model['age'] = StandardScaler().fit_transform(df_pre_model['age'].values.reshape(len(df), 1))\ndf_model.head()"]}, {"cell_type": "markdown", "id": "650e2b8b", "metadata": {}, "source": ["# MODELING AND EVALUATION"]}, {"cell_type": "code", "execution_count": 1, "id": "ab017b5a", "metadata": {}, "outputs": [], "source": ["X = df_model.drop(['stroke'],axis=1)\ny = df_model['stroke']"]}, {"cell_type": "markdown", "id": "ce77ae08", "metadata": {}, "source": ["**Since the target values are imbalanced, SMOTE method for imbalanced data are used.**"]}, {"cell_type": "code", "execution_count": 1, "id": "54879168", "metadata": {}, "outputs": [], "source": ["from imblearn import under_sampling, over_sampling\nX_under, y_under = under_sampling.RandomUnderSampler(0.5).fit_resample(X, y)\nX_over, y_over = over_sampling.RandomOverSampler(0.5).fit_resample(X, y)\nX_over_SMOTE, y_over_SMOTE = over_sampling.SMOTE(0.5).fit_resample(X, y)"]}, {"cell_type": "code", "execution_count": 1, "id": "c2c0739d", "metadata": {}, "outputs": [], "source": ["print('Original')\nprint(pd.Series(y).value_counts())\nprint('UNDERSAMPLING')\nprint(pd.Series(y_under).value_counts())\nprint('OVERSAMPLING')\nprint(pd.Series(y_over).value_counts())\nprint('SMOTE')\nprint(pd.Series(y_over_SMOTE).value_counts())"]}, {"cell_type": "markdown", "id": "f0f9e9b6", "metadata": {}, "source": ["**As we can see above, the data are balanced!**"]}, {"cell_type": "markdown", "id": "7d5f130d", "metadata": {}, "source": ["**Created a function so it will be easier to evaluate a model.**"]}, {"cell_type": "code", "execution_count": 1, "id": "0070b3db", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\n\ndef eval_classification(model, pred, xtrain, ytrain, xtest, ytest):\n    print(\"Accuracy (Test Set): %.2f\" % accuracy_score(ytest, pred))\n    print(\"Precision (Test Set): %.2f\" % precision_score(ytest, pred))\n    print(\"Recall (Test Set): %.2f\" % recall_score(ytest, pred))\n    print(\"F1-Score (Test Set): %.2f\" % f1_score(ytest, pred))\n    \n    fpr, tpr, thresholds = roc_curve(ytest, pred, pos_label=1) # pos_label: label yang kita anggap positive\n    print(\"AUC: %.2f\" % auc(fpr, tpr))\n\ndef show_feature_importance(model):\n    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n    ax.invert_yaxis()\n\n    plt.xlabel('score')\n    plt.ylabel('feature')\n    plt.title('feature importance score')\n\ndef show_best_hyperparameter(model, hyperparameters):\n    for key, value in hyperparameters.items() :\n        print('Best '+key+':', model.get_params()[key])"]}, {"cell_type": "code", "execution_count": 1, "id": "249418d1", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X_over_SMOTE, y_over_SMOTE, test_size = 0.3, random_state = 42)"]}, {"cell_type": "markdown", "id": "a7aa884d", "metadata": {}, "source": ["**Predict the target using various model to see which one has the most satisfying result.**"]}, {"cell_type": "code", "execution_count": 1, "id": "dfa85c54", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(random_state=42)\nmodel.fit(X_train,y_train)\nprint(str(model)+' '+'EVALUATION')\n\ny_pred = model.predict(X_test)\neval_classification(model, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "code", "execution_count": 1, "id": "6e8ad7f2", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(random_state=42)\nmodel.fit(X_train,y_train)\nprint(str(model)+' '+'EVALUATION')\n\ny_pred = model.predict(X_test)\neval_classification(model, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "code", "execution_count": 1, "id": "fab54fbe", "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier()\nmodel.fit(X_train, y_train)\nprint(str(model)+' '+'EVALUATION')\n\ny_pred = model.predict(X_test)\neval_classification(model, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "code", "execution_count": 1, "id": "3c74d397", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier(random_state=42)\nmodel.fit(X_train, y_train)\nprint(str(model)+' '+'EVALUATION')\n\ny_pred = model.predict(X_test)\neval_classification(model, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "code", "execution_count": 1, "id": "4a35a2c8", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train,y_train)\nprint(str(model)+' '+'EVALUATION')\n\ny_pred = model.predict(X_test)\neval_classification(model, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "code", "execution_count": 1, "id": "5b18fa51", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import AdaBoostClassifier\nmodel = AdaBoostClassifier(random_state=42)\nmodel.fit(X_train,y_train)\nprint(str(model)+' '+'EVALUATION')\n\ny_pred = model.predict(X_test)\neval_classification(model, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "code", "execution_count": 1, "id": "97a6a1dc", "metadata": {}, "outputs": [], "source": ["from xgboost import XGBClassifier\nmodel = XGBClassifier(random_state=42)\nmodel.fit(X_train, y_train)\nprint(str(model)+' '+'EVALUATION')\n\ny_pred = model.predict(X_test)\neval_classification(model, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "markdown", "id": "89d5688f", "metadata": {}, "source": ["**The XGBoost model has the biggest accuracy and recall score, so it can be said that decision tree has the most satisfying result of the bunch. Other than that, the train score and the test score arent too far apart, theres only 2% of a difference in accuracy, so it can be said that the model are not overfitted.**"]}, {"cell_type": "markdown", "id": "981ae3db", "metadata": {}, "source": ["**Used hyperparameter tuning method to improve the model quality. Scoring method based on the recall value is used because we dont want to mispredict the patient who got stroke but we predict otherwise.**"]}, {"cell_type": "code", "execution_count": 1, "id": "71413977", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport numpy as np\n\nhyperparameters = {\n                    'max_depth' : [int(x) for x in np.linspace(10, 110, num = 11)],\n                    'min_child_weight' : [int(x) for x in np.linspace(1, 20, num = 11)],\n                    'gamma' : [float(x) for x in np.linspace(0, 1, num = 11)],\n                    'tree_method' : ['auto', 'exact', 'approx', 'hist'],\n\n                    'colsample_bytree' : [float(x) for x in np.linspace(0, 1, num = 11)],\n                    'eta' : [float(x) for x in np.linspace(0, 1, num = 100)],\n\n                    'lambda' : [float(x) for x in np.linspace(0, 1, num = 11)],\n                    'alpha' : [float(x) for x in np.linspace(0, 1, num = 11)]\n                    }\n\nxg = XGBClassifier(random_state=42)\nxg_tuned = RandomizedSearchCV(xg, hyperparameters,random_state=42, cv=5, scoring='recall')\nxg_tuned.fit(X_train,y_train)\n\ny_pred = xg_tuned.predict(X_test)\neval_classification(xg_tuned, y_pred, X_train, y_train, X_test, y_test)\nprint('Train score: ' + str(model.score(X_train, y_train)))\nprint('Test score:' + str(model.score(X_test, y_test)))"]}, {"cell_type": "markdown", "id": "8ea39a33", "metadata": {}, "source": ["**Since hyperparameter tuning doesnt provide a better recall score, we use the original xgboost model instead.**"]}, {"cell_type": "markdown", "id": "fe04be6a", "metadata": {}, "source": ["# CONCLUSION"]}, {"cell_type": "markdown", "id": "9e221940", "metadata": {}, "source": ["**We can be predict a stroke with a recall score of 83% and accuracy score of 92% that a patient with the disease can be predicted.**"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}