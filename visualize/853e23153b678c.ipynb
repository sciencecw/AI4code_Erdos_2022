{"cells": [{"cell_type": "code", "execution_count": 1, "id": "06085a67", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "b0a40197", "metadata": {}, "outputs": [], "source": ["#IMPORTING LIBARIES\nimport tensorflow as tf \nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator"]}, {"cell_type": "code", "execution_count": 1, "id": "ca4d2ee6", "metadata": {}, "outputs": [], "source": ["#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1./255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\ntraining_set = train_data.flow_from_directory('../input/cat-and-dog/training_set/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')"]}, {"cell_type": "code", "execution_count": 1, "id": "dfc09d82", "metadata": {}, "outputs": [], "source": ["#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1./255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('../input/cat-and-dog/test_set/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')"]}, {"cell_type": "code", "execution_count": 1, "id": "8fcdc1e6", "metadata": {}, "outputs": [], "source": ["#defining the CNN as a sequence of layers.\ncnn = tf.keras.models.Sequential()"]}, {"cell_type": "markdown", "id": "aa5b9d4a", "metadata": {}, "source": ["CNN IS DIVIDED INTO 4 STEPS\n\n* CONVOLUTION\n\n* POOLING\n\n* FLATTENING\n\n* FULL CONNECTION"]}, {"cell_type": "markdown", "id": "51103613", "metadata": {}, "source": ["# # **STEP - 1) ADDING CONVOLUTIONAL LAYER**"]}, {"cell_type": "code", "execution_count": 1, "id": "49a3d5ca", "metadata": {}, "outputs": [], "source": ["#adding 1st Convolutional layer\n#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))\n#activation function relu is applied to decrease any linearity that might have arrised while applying filters."]}, {"cell_type": "markdown", "id": "30a39986", "metadata": {}, "source": ["# **STEP - 2) APPLYING MAX POOLING**"]}, {"cell_type": "markdown", "id": "a2f4d895", "metadata": {}, "source": ["Here we will apply the max pooling.Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map."]}, {"cell_type": "code", "execution_count": 1, "id": "e41a38f0", "metadata": {}, "outputs": [], "source": ["# applying max pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"]}, {"cell_type": "markdown", "id": "5a97c6e8", "metadata": {}, "source": ["# **Addition of 2nd convolution layer.**"]}, {"cell_type": "code", "execution_count": 1, "id": "9367f503", "metadata": {}, "outputs": [], "source": ["#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"]}, {"cell_type": "code", "execution_count": 1, "id": "0534a095", "metadata": {}, "outputs": [], "source": ["#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"]}, {"cell_type": "markdown", "id": "f173662a", "metadata": {}, "source": ["# **STEP -3 ) FLATTENING**"]}, {"cell_type": "code", "execution_count": 1, "id": "9a2754fd", "metadata": {}, "outputs": [], "source": ["#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())"]}, {"cell_type": "markdown", "id": "f9cbe878", "metadata": {}, "source": ["# **STEP - 4 ) FULL CONNECTION**"]}, {"cell_type": "code", "execution_count": 1, "id": "9ab56945", "metadata": {}, "outputs": [], "source": ["#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))"]}, {"cell_type": "code", "execution_count": 1, "id": "9fa662a3", "metadata": {}, "outputs": [], "source": ["#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"]}, {"cell_type": "code", "execution_count": 1, "id": "41b83777", "metadata": {}, "outputs": [], "source": ["#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]}, {"cell_type": "code", "execution_count": 1, "id": "161e3748", "metadata": {}, "outputs": [], "source": ["#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)"]}, {"cell_type": "code", "execution_count": 1, "id": "d30f3b01", "metadata": {}, "outputs": [], "source": ["cnn.save('catdog_cnn_model.h5')"]}, {"cell_type": "code", "execution_count": 1, "id": "05a9b09f", "metadata": {}, "outputs": [], "source": ["from keras.models import load_model \nclassifier = load_model('catdog_cnn_model.h5')"]}, {"cell_type": "markdown", "id": "33967557", "metadata": {}, "source": ["# **PREDICTING VALUES**"]}, {"cell_type": "code", "execution_count": 1, "id": "fdc38273", "metadata": {}, "outputs": [], "source": ["import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices"]}, {"cell_type": "markdown", "id": "954e533a", "metadata": {}, "source": ["# **0 MEANS CATS AND 1 MEANS DOGS**"]}, {"cell_type": "code", "execution_count": 1, "id": "80bbd230", "metadata": {}, "outputs": [], "source": ["image.load_img('../input/cat-and-dog/test_set/test_set/cats/cat.4014.jpg')"]}, {"cell_type": "code", "execution_count": 1, "id": "575f7ad2", "metadata": {}, "outputs": [], "source": ["#importing images\ntest_img = image.load_img('../input/cat-and-dog/test_set/test_set/cats/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)"]}, {"cell_type": "code", "execution_count": 1, "id": "f0a8cd7a", "metadata": {}, "outputs": [], "source": ["image.load_img('../input/cat-and-dog/test_set/test_set/dogs/dog.4014.jpg')"]}, {"cell_type": "code", "execution_count": 1, "id": "c5ee0b6c", "metadata": {}, "outputs": [], "source": ["#importing images\ntest_img = image.load_img('../input/cat-and-dog/test_set/test_set/dogs/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}