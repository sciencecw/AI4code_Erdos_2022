{"cells": [{"cell_type": "markdown", "id": "cff81111", "metadata": {}, "source": ["# \u6982\u8981\n\nGNN\u3092\u7528\u3044\u305f\u30b7\u30f3\u30d7\u30eb\u306a\u30e2\u30c7\u30eb\u3067\u3059\u3002\n\n\u7279\u5fb4\u91cf\u3082\u9650\u308a\u306a\u304f\u5c11\u306a\u3044\u306e\u3067\u6539\u5584\u3059\u308c\u3070\u7d50\u69cb\u30b9\u30b3\u30a2\u4f38\u3073\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n\nNN\u306e\u69cb\u9020\u5468\u308a\u306b\u3064\u3044\u3066\u306f\u3001NN\u7cfb\u521d\u5fc3\u8005\u306a\u306e\u3067\u57fa\u672c\u7684\u306a\u30df\u30b9\u3082\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n\u3082\u3057\u898b\u3064\u3051\u305f\u65b9\uff08\u3082\u3057\u304f\u306f\u3053\u3046\u3057\u3066\u307f\u3066\u3082\u826f\u3044\u304b\u3082\uff01\uff09\u306a\u3069\u3042\u308c\u3070\n\u30b3\u30e1\u30f3\u30c8\u3044\u305f\u3060\u3051\u308b\u3068\u5b09\u3057\u3044\u3067\u3059\u3002\n"]}, {"cell_type": "markdown", "id": "4431b393", "metadata": {}, "source": ["# \u4e8b\u524d\u6e96\u5099"]}, {"cell_type": "code", "execution_count": 1, "id": "d881d3dd", "metadata": {}, "outputs": [], "source": ["!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric  -f https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html  -Uq"]}, {"cell_type": "markdown", "id": "65139d7f", "metadata": {}, "source": ["# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8aad\u307f\u8fbc\u307f"]}, {"cell_type": "code", "execution_count": 1, "id": "46302204", "metadata": {}, "outputs": [], "source": ["import os\nimport random\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\nfrom fastprogress import progress_bar\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import NNConv, TransformerConv, PNAConv\n\nimport torch_geometric.nn as pyg_nn\nimport torch_geometric.utils as pyg_utils\n\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nimport wandb\n\n\nimport datetime\nfrom pytz import timezone\nnow = datetime.datetime.now(timezone('UTC'))\nyyyymmdd_hhmm = \"{0:%Y%m%d_%H%M}\".format(now.astimezone(timezone('Asia/Tokyo')))"]}, {"cell_type": "code", "execution_count": 1, "id": "7c63f728", "metadata": {}, "outputs": [], "source": ["# \u4e71\u6570\u30b7\u30fc\u30c9\u306e\u56fa\u5b9a\ndef set_seed(seed: int):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(seed=42)"]}, {"cell_type": "code", "execution_count": 1, "id": "5c463421", "metadata": {}, "outputs": [], "source": ["NOTE_ID = 'CLB_N007'"]}, {"cell_type": "code", "execution_count": 1, "id": "13c224a3", "metadata": {}, "outputs": [], "source": ["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice"]}, {"cell_type": "markdown", "id": "d5fbccd1", "metadata": {}, "source": ["# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u30fb\u524d\u51e6\u7406\u30fb\u30de\u30fc\u30b8"]}, {"cell_type": "code", "execution_count": 1, "id": "d1e31105", "metadata": {}, "outputs": [], "source": ["DATA_DIR = Path(\"/kaggle/input/shigglecup-2nd/\")\nprint(os.listdir(DATA_DIR))"]}, {"cell_type": "code", "execution_count": 1, "id": "8125e837", "metadata": {}, "outputs": [], "source": ["df_train = pd.read_csv(DATA_DIR / \"train.csv\")\ndf_test = pd.read_csv(DATA_DIR / \"test.csv\")\ndf_team = pd.read_csv(DATA_DIR / \"team_id.csv\")\ndf_pokemon = pd.read_csv(DATA_DIR / \"pokemon.csv\")\ndf_type = pd.read_csv(DATA_DIR / \"typetable.csv\")\ndf_sub = pd.read_csv(DATA_DIR / \"sample_submission.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "fa0e375f", "metadata": {}, "outputs": [], "source": ["df_pokemon['Legendary'] = df_pokemon['Legendary'].apply(lambda x: 1 if x == True else 0)"]}, {"cell_type": "code", "execution_count": 1, "id": "a28b1a72", "metadata": {}, "outputs": [], "source": ["# \u6a19\u6e96\u5316\nstatus_cols = ['HP', 'Attack', 'Defense',\n       'Sp_Atk', 'Sp_Def', 'Speed', 'Generation']\nscaler = StandardScaler()\ndf_pokemon[status_cols] = scaler.fit_transform(df_pokemon[status_cols])"]}, {"cell_type": "code", "execution_count": 1, "id": "90b9353e", "metadata": {}, "outputs": [], "source": ["def merge_team(df_mart, df_team):\n    \"\"\"team\u60c5\u5831\u3092\u30de\u30fc\u30b8\"\"\"\n    pokemon_cols = ['pokemon_id_1', 'pokemon_id_2', 'pokemon_id_3',\n       'pokemon_id_4', 'pokemon_id_5', 'pokemon_id_6']\n\n    df_first = pd.merge(df_mart, df_team, left_on='first', right_on='team_id', how='left')\n    df_second = pd.merge(df_mart, df_team, left_on='second', right_on='team_id', how='left')\n\n    df_mart = pd.concat([\n                            df_mart,\n                            df_first[pokemon_cols].add_suffix('_first'),\n                            df_second[pokemon_cols].add_suffix('_second'),\n                        ], axis=1)\n    return df_mart"]}, {"cell_type": "code", "execution_count": 1, "id": "f0b37941", "metadata": {}, "outputs": [], "source": ["df_train = merge_team(df_train, df_team)\ndf_test = merge_team(df_test, df_team)\n\ndf_train.shape, df_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "e2047fcc", "metadata": {}, "outputs": [], "source": ["def merge_pokemon(df_mart, df_pokemon):\n    \"\"\"\u30dd\u30b1\u30e2\u30f3\u60c5\u5831\u3092\u30de\u30fc\u30b8\"\"\"\n    pokemon_cols = ['pokemon_id_1', 'pokemon_id_2', 'pokemon_id_3',\n       'pokemon_id_4', 'pokemon_id_5', 'pokemon_id_6']\n    pokemon_id_cols = [c + '_first' for c in pokemon_cols] + [c + '_second' for c in pokemon_cols]\n    pokemon_detail_cols = ['Type_1', 'Type_2', 'HP', 'Attack', 'Defense',\n        'Sp_Atk', 'Sp_Def', 'Speed', 'Generation', 'Legendary']\n\n    df_list = []\n    for col in pokemon_id_cols:\n        suffix = col[10:] # '_1_first'\u307f\u305f\u3044\u306a\n        \n        df_tmp = pd.merge(df_mart, df_pokemon, left_on=col, right_on='pokemon_id', how='left')\n        df_list.append(df_tmp[pokemon_detail_cols].add_suffix(suffix))\n    \n    df_mart = pd.concat([df_mart] + df_list, axis=1)\n\n    return df_mart"]}, {"cell_type": "code", "execution_count": 1, "id": "20250108", "metadata": {}, "outputs": [], "source": ["df_train = merge_pokemon(df_train, df_pokemon)\ndf_test = merge_pokemon(df_test, df_pokemon)\n\ndf_train.shape, df_test.shape"]}, {"cell_type": "markdown", "id": "95ffb1dc", "metadata": {}, "source": ["# \u30ce\u30fc\u30c9\u3068\u30a8\u30c3\u30b8\u3001\u30e9\u30d9\u30eb\u3092\u5b9a\u7fa9\n- GNN\u3067\u306f\u30ce\u30fc\u30c9\u3068\u30a8\u30c3\u30b8\u3068\u3044\u3046\uff12\u3064\u306e\u8981\u7d20\u306b\u3088\u3063\u3066\u30b0\u30e9\u30d5\u69cb\u9020\u304c\u4e0e\u3048\u3089\u308c\u307e\u3059\u3002\n    - \u4eca\u56de\u306f\u4ee5\u4e0b\u3067\u69cb\u9020\u3092\u3082\u305f\u305b\u307e\u3059\u3002\n    - \u30ce\u30fc\u30c9\uff1a\u30dd\u30b1\u30e2\u30f3\uff08first\u30c1\u30fc\u30e06\u4f53\u3001second\u30c1\u30fc\u30e06\u4f53\u306e\u5408\u8a0812\u4f53\uff09\n    - \u30a8\u30c3\u30b8\uff1a\u30dd\u30b1\u30e2\u30f3\u540c\u58eb\u306e\u5bfe\u6226\u7d44\u307f\u5408\u308f\u305b\uff08first\u30c1\u30fc\u30e06\u4f53\u3068second\u30c1\u30fc\u30e06\u5bfe\u306e\u5168\u7d44\u307f\u5408\u308f\u305b 6x6 = 36\u7d44\u307f\u5408\u308f\u305b\uff09\n\n\n- \u30ce\u30fc\u30c9\u3068\u30a8\u30c3\u30b8\u306b\u306f\u305d\u308c\u305e\u308c\u7279\u5fb4\u91cf\u3092\u3082\u305f\u305b\u3089\u308c\u307e\u3059\u3002\n    - \u4eca\u56de\u306f\u7c21\u5358\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7279\u5fb4\u91cf\u3092\u3082\u305f\u305b\u3066\u3044\u307e\u3059\u3002\n    - \u30ce\u30fc\u30c9\uff1a\u5404\u30dd\u30b1\u30e2\u30f3\u306e\u30b9\u30c6\u30fc\u30bf\u30b9\u5024\uff08\u6a19\u6e96\u5316\u6e08\u307f\uff09 -> 8\u7279\u5fb4\u91cf\n    - \u30a8\u30c3\u30b8\uff1a\u5bfe\u6226\u3059\u308b\u30dd\u30b1\u30e2\u30f3\u540c\u58eb\u306e\u30b9\u30d4\u30fc\u30c9\u5024\u306e\u5dee(first - second) -> 1\u7279\u5fb4\u91cf\n    \n    \n- \u30e9\u30d9\u30eb\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5024\u3002GNN\u3067\u306f\u3001\u5927\u304d\u304f\u30bf\u30b9\u30af\u306f\u300c\u30ce\u30fc\u30c9\u300d\u306e\u30e9\u30d9\u30eb\u3092\u5f53\u3066\u308b\u3082\u306e\u3068\u3001\u300c\u30b0\u30e9\u30d5\u69cb\u9020\u300d\u306e\u30e9\u30d9\u30eb\u3092\u5f53\u3066\u308b\u3082\u306e\u306e\uff12\u7a2e\u985e\u304c\u3042\u308b\u304c\u3001\u4eca\u56de\u306f\u5f8c\u8005\u3002\n- \u5404\u30b0\u30e9\u30d5\u69cb\u9020\uff08\uff1d\u5bfe\u6226\u30ab\u30fc\u30c9\uff09\u3067\u3069\u3063\u3061\u304c\u52dd\u3063\u305f\u306e\u304b\u3092\u5f53\u3066\u308b"]}, {"cell_type": "code", "execution_count": 1, "id": "ce6f23db", "metadata": {}, "outputs": [], "source": ["def build_nodes(sample: pd.DataFrame):\n    # speed_cols = [f\"Speed_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    speed_cols = [f\"Speed_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    hp_cols = [f\"HP_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    attack_cols = [f\"Attack_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    defense_cols = [f\"Defense_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    sp_atk_cols = [f\"Sp_Atk_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    sp_def_cols = [f\"Sp_Def_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    gen_cols = [f\"Generation_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    legend_cols = [f\"Legendary_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    x = np.vstack([\n                   sample[speed_cols].astype(float).values,\n                   sample[hp_cols].astype(float).values,\n                   sample[attack_cols].astype(float).values,\n                   sample[defense_cols].astype(float).values,\n                   sample[sp_atk_cols].astype(float).values,\n                   sample[sp_def_cols].astype(float).values,\n                   sample[gen_cols].astype(float).values,\n                   sample[legend_cols].astype(int).values,\n                   ]).T # [num_nodes, num_node_features]\n    return torch.tensor(x, dtype=torch.float)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "eba900c9", "metadata": {}, "outputs": [], "source": ["# \u30b5\u30f3\u30d7\u30eb\u78ba\u8a8d\n# 1\u8a66\u5408\u76ee\u306e12\u30dd\u30b1\u30e2\u30f3x8\u7279\u5fb4\u91cf\nx = build_nodes(df_train.iloc[0])\nprint(x)"]}, {"cell_type": "code", "execution_count": 1, "id": "54f67625", "metadata": {}, "outputs": [], "source": ["def build_edges(sample: pd.DataFrame):\n    speed_cols = [f\"Speed_{num}_{team}\" for team in ['first', 'second'] for num in range(1,7) ]\n    num_nodes = 12\n    speed_val = sample[speed_cols].astype(float).values\n\n    edge_idx, speed_diff = [], []\n    # 0-5: first team\n    # 6-11: second team\n    for f_poke in range(6):\n        for s_poke in range(6, 12):\n            edge_idx.append([f_poke,s_poke])\n            speed_diff.append(speed_val[f_poke] - speed_val[s_poke])\n            \n    edge_attr = np.vstack([speed_diff]).T # [num_edges, num_edge_features]\n    return torch.tensor(edge_idx, dtype=torch.long).t().contiguous(), torch.tensor(edge_attr, dtype=torch.float)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "45aa4711", "metadata": {}, "outputs": [], "source": ["# \u30b5\u30f3\u30d7\u30eb\u78ba\u8a8d\n# \u30a8\u30c3\u30b8\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\uff08\u3069\u306e\u30ce\u30fc\u30c9\u3092\u63a5\u7d9a\u3057\u3066\u3044\u308b\u304b\uff09\u3001\u3068\u30a8\u30c3\u30b8\u306e\u6301\u3064\u7279\u5fb4\u91cf\uff08\u30b9\u30d4\u30fc\u30c9\u5dee\uff09\nedge_index, edge_attr  = build_edges(df_train.iloc[0])\nprint(\"edge index:\", edge_index)\nprint(\"edge attr:\", edge_attr)"]}, {"cell_type": "code", "execution_count": 1, "id": "6859e2db", "metadata": {}, "outputs": [], "source": ["def build_labels(sample: pd.DataFrame):\n    y = sample.target\n    return torch.tensor(y, dtype=torch.long)"]}, {"cell_type": "code", "execution_count": 1, "id": "f117d51f", "metadata": {}, "outputs": [], "source": ["# \u30b5\u30f3\u30d7\u30eb\u78ba\u8a8d\ny = build_labels(df_train.iloc[0])\nprint(\"y:\", y)"]}, {"cell_type": "code", "execution_count": 1, "id": "0bbf3906", "metadata": {}, "outputs": [], "source": ["# Data\u3068\u3057\u3066\u307e\u3068\u3081\u305f\u5834\u5408\u306e\u30b5\u30f3\u30d7\u30eb\ndata = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\ndata"]}, {"cell_type": "code", "execution_count": 1, "id": "1efdf221", "metadata": {}, "outputs": [], "source": ["def build_data_list(df_input: pd.DataFrame, istrain=True):\n    data_list = []\n    for _, row in df_input.iterrows():\n        x = build_nodes(row)\n        edge_index, edge_attr = build_edges(row)\n        if istrain:\n            y = build_labels(row)\n        else:\n            y = 0\n        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n        data_list.append(data)\n    return data_list"]}, {"cell_type": "markdown", "id": "9c4fd52d", "metadata": {}, "source": ["# Config Definition"]}, {"cell_type": "code", "execution_count": 1, "id": "5d78d165", "metadata": {}, "outputs": [], "source": ["# config \u306e\u5b9a\u7fa9\u306f\u5f8c\u534a\u306b\u3082\u5206\u5272\u3057\u3066\u3067\u3066\u304d\u307e\u3059\u3002\u3002\nconfig = {\n   'loss_fn':  nn.CrossEntropyLoss(),\n    'batch_size': 64,\n    'node_hidden_channels': 8,\n    'edge_hidden_channels': 4,\n    'dropout_rate': 0.05,\n}"]}, {"cell_type": "markdown", "id": "db027749", "metadata": {}, "source": ["# Split\u3068DataLoader\n- \u4eca\u56de\u306f\u30b5\u30f3\u30d7\u30eb\u306a\u306e\u3067CV\u3067\u306f\u306a\u304f\u3001train-test split\u306a1fold\u5206\u3057\u304b\u5206\u3051\u3066\u307e\u305b\u3093\u3002\uff08\u5206\u5272\u306fGroupK\u3067\u5b9f\u65bd\uff09\n"]}, {"cell_type": "code", "execution_count": 1, "id": "308d01d0", "metadata": {}, "outputs": [], "source": ["fold_num = 6\nkf = GroupKFold(n_splits=fold_num)\n\nfor i, (train_idx, test_idx) in enumerate(kf.split(df_train, df_train['target'], groups=df_train[\"first\"])):\n    df_tr = df_train.iloc[train_idx]\n    df_va = df_train.iloc[test_idx]\n    break"]}, {"cell_type": "code", "execution_count": 1, "id": "99438515", "metadata": {}, "outputs": [], "source": ["df_tr.shape, df_va.shape, df_test.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "5f9249a2", "metadata": {}, "outputs": [], "source": ["train_data_list = build_data_list(df_tr)\nvalid_data_list = build_data_list(df_va)\ntest_data_list = build_data_list(df_test, istrain=False)"]}, {"cell_type": "code", "execution_count": 1, "id": "74916721", "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(train_data_list, batch_size=config['batch_size'], shuffle=True)\nvalid_loader = DataLoader(valid_data_list, batch_size=config['batch_size'], shuffle=False)\ntest_loader = DataLoader(test_data_list, batch_size=config['batch_size'], shuffle=False)"]}, {"cell_type": "markdown", "id": "ee954dbf", "metadata": {}, "source": ["# Modeling"]}, {"cell_type": "code", "execution_count": 1, "id": "bd413f33", "metadata": {}, "outputs": [], "source": ["class EarlyStopping:\n    def __init__(self, patience=7, mode=\"min\", delta=0.):\n        self.patience = patience\n        self.counter = 0\n        self.mode = mode\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n        if self.mode == \"min\":\n            self.val_score = np.Inf\n        else:\n            self.val_score = -np.Inf\n\n    def __call__(self, epoch_score, model, model_path):\n\n        if self.mode == \"min\":\n            score = -1.0 * epoch_score\n        else:\n            score = np.copy(epoch_score)\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model, model_path)\n        elif score < self.best_score: #  + self.delta\n            self.counter += 1\n            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            # ema.apply_shadow()\n            self.save_checkpoint(epoch_score, model, model_path)\n            # ema.restore()\n            self.counter = 0\n\n    def save_checkpoint(self, epoch_score, model, model_path):\n        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n            torch.save(model.state_dict(), model_path)\n        self.val_score = epoch_score"]}, {"cell_type": "code", "execution_count": 1, "id": "b18fad8d", "metadata": {}, "outputs": [], "source": ["class SimpleGCN(nn.Module):\n    def __init__(self,\n                 num_node_features: int,\n                 num_edge_features: int,\n                 node_hidden_channels: int,\n                 edge_hidden_channels: int,\n                 num_classes: int,\n                 dropout_rate: float):\n        super(SimpleGCN, self).__init__()\n\n        self.node_encoder = nn.Linear(num_node_features, node_hidden_channels)\n        self.edge_encoder = nn.Linear(num_edge_features, edge_hidden_channels)\n        self.conv1 = NNConv(in_channels=node_hidden_channels,\n                            out_channels=node_hidden_channels,\n                            nn=nn.Linear(edge_hidden_channels, \n                                         node_hidden_channels * node_hidden_channels))\n        self.conv2 = NNConv(in_channels=node_hidden_channels,\n                            out_channels=node_hidden_channels,\n                            nn=nn.Linear(edge_hidden_channels, \n                                         node_hidden_channels * node_hidden_channels))\n        self.dropout = nn.Dropout(dropout_rate)\n        self.bn = nn.BatchNorm1d(node_hidden_channels)\n        self.linear = nn.Linear(node_hidden_channels, num_classes)\n\n    def forward(self, data):\n        x = data.x\n        edge_index = data.edge_index\n        edge_attr = data.edge_attr\n        batch = data.batch\n\n        x = self.node_encoder(x) # [num_nodes, node_hidden_channels]\n        edge_attr = self.edge_encoder(edge_attr) # [num_edges, node_edge_features]\n        x = F.relu(self.conv1(x, edge_index, edge_attr)) # [num_nodes, node_hidden_channels]\n        x = F.relu(self.conv2(x, edge_index, edge_attr)) # [num_nodes, node_hidden_channels]\n        x = self.linear(x) # [num_nodes, num_classes]\n        x = self.dropout(x)\n        x = pyg_nn.global_mean_pool(x, batch)\n\n        return F.softmax(x, dim=1)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "1a5bdeb1", "metadata": {}, "outputs": [], "source": ["model = SimpleGCN(num_node_features=train_data_list[0].x.shape[1],\n                  num_edge_features=train_data_list[0].edge_attr.shape[1],\n                  node_hidden_channels=config['node_hidden_channels'],\n                  edge_hidden_channels=config['edge_hidden_channels'],\n                  num_classes=2,\n                  dropout_rate=config['dropout_rate'])\nmodel.to(device);"]}, {"cell_type": "code", "execution_count": 1, "id": "d2651c1d", "metadata": {}, "outputs": [], "source": ["config['optimizer'] = torch.optim.Adam(model.parameters(), lr=1e-3)\nconfig['early_stopping'] = EarlyStopping(patience=50, mode=\"min\")\noptimizer = config['optimizer']\nloss_fn = config['loss_fn']\nes = config['early_stopping']\n"]}, {"cell_type": "code", "execution_count": 1, "id": "d38cc6f7", "metadata": {}, "outputs": [], "source": ["def train_step(model, data_loader, config):\n    model.train()\n    preds, targets, losses = [], [], []\n    with tqdm(total=len(data_loader), unit=\"batch\") as pbar:\n        pbar.set_description(f\"[train] Epoch {epoch+1}/{EPOCH}\")\n        for batch_idx, data in enumerate(data_loader):\n            optimizer.zero_grad()\n            data = data.to(device)\n            target = data.y\n            output = model(data)\n            loss = loss_fn(output, target)\n            loss.backward()\n            optimizer.step()\n            losses.append(loss.item())\n            preds.append(torch.argmax(output, dim=1).detach().cpu().numpy())\n            targets.append(target.detach().cpu().numpy())\n            pbar.set_postfix(tr_loss=np.array(losses).mean(), \n                             auc=roc_auc_score(np.hstack(targets), np.hstack(preds)))\n            pbar.update(1)\n\ndef eval_step(model, data_loader, config):\n    model.eval()\n    preds, targets, losses = [], [], []\n    with tqdm(total=len(data_loader), unit=\"batch\") as pbar:\n        pbar.set_description(f\"[eval]  Epoch {epoch+1}/{EPOCH}\")\n        with torch.no_grad():\n            for batch_idx, data in enumerate(data_loader):\n                data = data.to(device)\n                target = data.y\n                output = model(data)\n                loss = loss_fn(output, target)\n                losses.append(loss.item())\n                target = target.cpu().numpy()\n                preds.append(torch.argmax(output, dim=1).detach().cpu().numpy())\n                targets.append(target)\n                pbar.set_postfix(va_loss=np.array(losses).mean(),\n                                 auc=roc_auc_score(np.hstack(targets), np.hstack(preds)))\n                pbar.update(1)\n    \n    val_loss = np.array(losses).mean()\n    return val_loss, model\n\ndef inference_step(model, data_loader):\n    model.eval()\n    logits, preds, targets = [], [], []\n    with tqdm(total=len(data_loader), unit=\"batch\") as pbar:\n        pbar.set_description(f\"[inference]\")\n        with torch.no_grad():\n            for data in data_loader:\n                data = data.to(device)\n                output = model(data)\n                logits.append(output.cpu().numpy())\n                output = torch.argmax(output, dim=1).cpu().numpy()\n                preds.append(output)\n                pbar.update(1)\n\n    return np.vstack(logits), np.hstack(preds)"]}, {"cell_type": "code", "execution_count": 1, "id": "7bd3c581", "metadata": {}, "outputs": [], "source": ["%%time\nEPOCH = 1000\n\nfor epoch in progress_bar(range(EPOCH)):\n    train_step(model, train_loader, config)\n    val_loss, model = eval_step(model, valid_loader, config)\n\n    es(val_loss, model, model_path=f\"./model_{yyyymmdd_hhmm}.pth\")\n    if es.early_stop:\n        print(\"Early stopping\")\n        break"]}, {"cell_type": "markdown", "id": "1ef2b088", "metadata": {}, "source": ["## Inference"]}, {"cell_type": "code", "execution_count": 1, "id": "f6e766a2", "metadata": {}, "outputs": [], "source": ["model.load_state_dict(torch.load(f'./model_{yyyymmdd_hhmm}.pth'))\ntest_proba, test_preds = inference_step(model, test_loader)\ntest_proba"]}, {"cell_type": "markdown", "id": "3b5690a1", "metadata": {}, "source": ["# Submission"]}, {"cell_type": "code", "execution_count": 1, "id": "8289b69e", "metadata": {}, "outputs": [], "source": ["df_sub.head(3)"]}, {"cell_type": "code", "execution_count": 1, "id": "e17517b6", "metadata": {}, "outputs": [], "source": ["df_sub['target'] = test_proba[:,1]"]}, {"cell_type": "code", "execution_count": 1, "id": "70c56243", "metadata": {}, "outputs": [], "source": ["df_sub.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "5be6821a", "metadata": {}, "outputs": [], "source": ["filename = f\"./{NOTE_ID}_{yyyymmdd_hhmm}_df_sub.csv\"\ndf_sub.to_csv(filename, index=None)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}