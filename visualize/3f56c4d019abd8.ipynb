{"cells": [{"cell_type": "markdown", "id": "91f9f688", "metadata": {}, "source": ["## RNN is used to deal with Sequential Data"]}, {"cell_type": "code", "execution_count": 1, "id": "7a7c66a3", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\nfrom keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": 1, "id": "1812cfe1", "metadata": {}, "outputs": [], "source": ["def plot_predictions(test,predicted):\n    plt.plot(test, color='red',label='Real IBM Stock Price')\n    plt.plot(predicted, color='blue',label='Predicted IBM Stock Price')\n    plt.title('IBM Stock Price Prediction')\n    plt.xlabel('Time')\n    plt.ylabel('IBM Stock Price')\n    plt.legend()\n    plt.show()\n\ndef return_rmse(test,predicted):\n    rmse = math.sqrt(mean_squared_error(test, predicted))\n    print(\"The root mean squared error is {}.\".format(rmse))"]}, {"cell_type": "code", "execution_count": 1, "id": "e13ee5d0", "metadata": {}, "outputs": [], "source": ["dataset = pd.read_csv('../input/IBM_2006-01-01_to_2018-01-01.csv', index_col='Date', parse_dates=['Date'])\ndataset.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "a3a418cc", "metadata": {}, "outputs": [], "source": ["# Checking for missing values\ntraining_set = dataset[:'2016'].iloc[:,1:2].values\ntest_set = dataset['2017':].iloc[:,1:2].values"]}, {"cell_type": "code", "execution_count": 1, "id": "d737f6fb", "metadata": {}, "outputs": [], "source": ["dataset[\"High\"][:'2016'].plot(figsize=(16,4),legend=True)\ndataset[\"High\"]['2017':].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set (Before 2017)','Test set (2017 and beyond)'])\nplt.title('IBM stock price')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "167a9c11", "metadata": {}, "outputs": [], "source": ["sc = MinMaxScaler(feature_range=(0,1))\ntraining_set_scaled = sc.fit_transform(training_set)"]}, {"cell_type": "code", "execution_count": 1, "id": "eb55de2d", "metadata": {}, "outputs": [], "source": ["# Since LSTMs store long term memory state, we create a data structure with 60 timesteps and 1 output\n# So for each element of training set, we have 60 previous training set elements \nX_train = []\ny_train = []\nfor i in range(60,2769):\n    X_train.append(training_set_scaled[i-60:i,0])\n    y_train.append(training_set_scaled[i,0])\nX_train, y_train = np.array(X_train), np.array(y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "cffa2951", "metadata": {}, "outputs": [], "source": ["print(y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "8c40cbf9", "metadata": {}, "outputs": [], "source": ["# Reshaping X_train for efficient modelling\n\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\nX_train.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "c62f616e", "metadata": {}, "outputs": [], "source": ["# LSTM architecture \n\nregressor = Sequential()\n\nregressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1)))\nregressor.add(Dropout(0.2))\n\nregressor.add(LSTM(units=50, return_sequences=True))\nregressor.add(Dropout(0.2))\n\nregressor.add(LSTM(units=50, return_sequences=True))\nregressor.add(Dropout(0.2))\n\nregressor.add(LSTM(units=50))\nregressor.add(Dropout(0.2))\n\nregressor.add(Dense(units=1))\n\nregressor.compile(optimizer='rmsprop',loss='mean_squared_error')\n# Fitting to the training set\nregressor.fit(X_train,y_train,epochs=50,batch_size=32)"]}, {"cell_type": "code", "execution_count": 1, "id": "e3650efc", "metadata": {}, "outputs": [], "source": ["# Now to get the test set ready in a similar way as the training set.\n# The following has been done so forst 60 entires of test set have 60 previous values which is impossible to get unless we take the whole \n# 'High' attribute data for processing\ndataset_total = pd.concat((dataset[\"High\"][:'2016'],dataset[\"High\"]['2017':]),axis=0)\ninputs = dataset_total[len(dataset_total)-len(test_set) - 60:].values\ninputs = inputs.reshape(-1,1)\ninputs  = sc.transform(inputs)"]}, {"cell_type": "code", "execution_count": 1, "id": "408a1390", "metadata": {}, "outputs": [], "source": ["# Preparing X_test and predicting the prices\nX_test = []\nfor i in range(60,311):\n    X_test.append(inputs[i-60:i,0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)"]}, {"cell_type": "code", "execution_count": 1, "id": "5e74d277", "metadata": {}, "outputs": [], "source": ["plot_predictions(test_set,predicted_stock_price)"]}, {"cell_type": "code", "execution_count": 1, "id": "77350c6d", "metadata": {}, "outputs": [], "source": ["# Evaluating our model\nreturn_rmse(test_set,predicted_stock_price)"]}, {"cell_type": "markdown", "id": "d3e7e6c5", "metadata": {}, "source": ["# Gated Recurrent Units GRU "]}, {"cell_type": "code", "execution_count": 1, "id": "c101ab05", "metadata": {}, "outputs": [], "source": ["regressorGRU = Sequential()\n\nregressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n\nregressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n\n\nregressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n\nregressorGRU.add(GRU(units=50, activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n\nregressorGRU.add(Dense(units=1))\n\nregressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n# Fitting to the training set\nregressorGRU.fit(X_train,y_train,epochs=50,batch_size=150)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "4d12033e", "metadata": {}, "outputs": [], "source": ["# Preparing X_test and predicting the prices\nX_test = []\nfor i in range(60,311):\n    X_test.append(inputs[i-60:i,0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\nGRU_predicted_stock_price = regressorGRU.predict(X_test)\nGRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)"]}, {"cell_type": "code", "execution_count": 1, "id": "1d5001a1", "metadata": {}, "outputs": [], "source": ["plot_predictions(test_set,GRU_predicted_stock_price)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}