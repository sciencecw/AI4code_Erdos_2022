{"cells": [{"cell_type": "markdown", "id": "048902af", "metadata": {}, "source": ["**This Notebook is by Soumyadip Sarkar and this version is simply to help him get going by using preprocessed data and fixing a few things.**\n\nIt is not a complete solution and it still has issues that I commented out and I will leave it to him to work through."]}, {"cell_type": "code", "execution_count": 1, "id": "bc9382c1", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "e1f2eba4", "metadata": {}, "outputs": [], "source": ["#!pip install -U pandas_bokeh"]}, {"cell_type": "code", "execution_count": 1, "id": "00d1b5ac", "metadata": {}, "outputs": [], "source": ["import cv2\nimport gc\nimport os\n\nimport numpy as np \nimport pandas as pd \n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n# import tensorflow.keras.applications.ResNet101 as resnet101\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# import pandas_bokeh\n# from bokeh.models.widgets import DataTable, TableColumn\n# from bokeh.models import ColumnDataSource\n\nfrom plotly.offline import iplot\nimport plotly as py\nimport plotly.tools as tls\nimport cufflinks as cf\n\npy.offline.init_notebook_mode(connected = True)\ncf.go_offline()\ncf.set_config_file(theme = 'solar')\n\n# pd.set_option('plotting.backend', 'pandas_bokeh')\n# pandas_bokeh.output_notebook()"]}, {"cell_type": "code", "execution_count": 1, "id": "9d12cf2c", "metadata": {}, "outputs": [], "source": ["print(tf.__version__)"]}, {"cell_type": "code", "execution_count": 1, "id": "bcbfa946", "metadata": {}, "outputs": [], "source": ["SEED = 42\nEPOCH = 20\nBATCH_SIZE = 32 #increased for small images taking less memory\nIMG_SIZE = 224\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)"]}, {"cell_type": "code", "execution_count": 1, "id": "1e486b35", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv',na_values=['unknown'])\ntest = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\nsubmission = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')\n\ntrain.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "327276bb", "metadata": {}, "outputs": [], "source": ["gc.collect()"]}, {"cell_type": "code", "execution_count": 1, "id": "85df7c5c", "metadata": {}, "outputs": [], "source": ["#DIR = '../input/siim-isic-melanoma-classification/jpeg/train/'\nDIR = '../input/siic-isic-224x224-images/train/'\nimg = []\nlabels = []\n#jpg = '.jpg'\npng = '.png'\n\nfor i in train['image_name']:\n    img.append(os.path.join(DIR,i)+png)\n    \nfor i in train['target']:\n    labels.append(i)\n    "]}, {"cell_type": "code", "execution_count": 1, "id": "f72b30bd", "metadata": {}, "outputs": [], "source": ["x_train,x_val,y_train,y_val = train_test_split(img,labels,test_size = 0.2,random_state = SEED)"]}, {"cell_type": "code", "execution_count": 1, "id": "57e15d3a", "metadata": {}, "outputs": [], "source": ["train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n                                         rescale=1./255,\n                                        rotation_range=40,\n                                         horizontal_flip=True,\n                                         vertical_flip= True,\n                                        width_shift_range=0.2,\n                                        height_shift_range=0.2,\n                                        \n)\n\nval_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n                                            rescale=1./255\n)"]}, {"cell_type": "code", "execution_count": 1, "id": "1eb70278", "metadata": {}, "outputs": [], "source": ["train_img = pd.DataFrame(x_train,columns=['image'])\ntrain_labels = pd.DataFrame(y_train,columns=['target'])\ntrain_data = pd.concat([train_img,train_labels],axis = 1)\n\nval_img = pd.DataFrame(x_val,columns=['image'])\nval_labels = pd.DataFrame(y_val,columns=['target'])\nval_data = pd.concat([val_img,val_labels],axis = 1)\n\ntrain_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "762061f5", "metadata": {}, "outputs": [], "source": ["train_img_gen = train_data_generator.flow_from_dataframe(train_data,\n    x_col='image',\n    y_col='target',\n    target_size=(IMG_SIZE,IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    class_mode='raw')\n\nval_img_gen = val_data_generator.flow_from_dataframe(val_data,\n                                                    x_col = 'image',\n                                                    y_col = 'target',\n                                                    target_size= (IMG_SIZE,IMG_SIZE),\n                                                    batch_size=BATCH_SIZE,\n                                                    shuffle=True,\n                                                    class_mode='raw')\n"]}, {"cell_type": "code", "execution_count": 1, "id": "e5fcc0b1", "metadata": {}, "outputs": [], "source": ["# # , because of class imbalance it's better to use focal loss rather than normal binary_crossentropy.You can read more about it here\n\n# def focal_loss(alpha=0.25,gamma=2.0):\n#     def focal_crossentropy(y_true, y_pred):\n#         bce = K.binary_crossentropy(y_true, y_pred)\n        \n#         y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n#         p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n#         alpha_factor = 1\n#         modulating_factor = 1\n\n#         alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n#         modulating_factor = K.pow((1-p_t), gamma)\n\n#         # compute the final loss and return\n#         return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n#     return focal_crossentropy"]}, {"cell_type": "code", "execution_count": 1, "id": "da154f19", "metadata": {}, "outputs": [], "source": ["from tensorflow.python.keras import backend as K\n\ndef focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy"]}, {"cell_type": "code", "execution_count": 1, "id": "644b6924", "metadata": {}, "outputs": [], "source": ["from tensorflow.keras import layers, models\n\nmodel = models.Sequential()\nmodel.add(tf.keras.applications.ResNet101(weights='imagenet',\n                                        include_top=False,\n                                        input_shape=(IMG_SIZE,IMG_SIZE,3)\n                                       ))\nmodel.add(layers.GlobalAveragePooling2D())\n#model.add(layers.Flatten())\n#model.add(layers.BatchNormalization())\n#model.add(layers.Dense(1024,activation= 'relu'))\n#model.add(layers.BatchNormalization())\n# model.add(layers.Dense(70000,activation= 'relu'))\n# model.add(layers.BatchNormalization())\n# model.add(layers.Dense(20000,activation= 'relu'))\n# model.add(layers.BatchNormalization())\n# model.add(layers.Dense(1000,activation= 'relu'))\n# model.add(layers.BatchNormalization())\n#model.add(layers.Dense(256,activation= 'relu'))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dense(1,activation='sigmoid'))\nmodel.layers[0].trainable = True\n\nmodel.compile(loss=[focal_loss(alpha=0.25,gamma=2.0)],metrics=[tf.keras.metrics.AUC()],optimizer='adam' )"]}, {"cell_type": "code", "execution_count": 1, "id": "a4a9e7c9", "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "code", "execution_count": 1, "id": "ffa70e11", "metadata": {}, "outputs": [], "source": ["# from tf.keras.callbacks import ModelCheckpoint\nfilepath = \"../working/saved_models-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath,monitor = 'val_loss',verbose = 1,save_best_only = True,mode = 'max')\ncallbacks_list = [checkpoint]"]}, {"cell_type": "code", "execution_count": 1, "id": "3827046a", "metadata": {}, "outputs": [], "source": ["from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_data.target),\n                                                 train_data.target)"]}, {"cell_type": "code", "execution_count": 1, "id": "9c79bb3b", "metadata": {}, "outputs": [], "source": ["class_weight ={\n    0:0.50893029,\n    1:28.49462366\n}\nprint(class_weight)"]}, {"cell_type": "code", "execution_count": 1, "id": "69c054e1", "metadata": {}, "outputs": [], "source": ["gc.collect()"]}, {"cell_type": "code", "execution_count": 1, "id": "21d90878", "metadata": {}, "outputs": [], "source": ["\nHistory = model.fit_generator(train_img_gen,\n                             steps_per_epoch=train_data.shape[0]//BATCH_SIZE,\n                             epochs=EPOCH,\n                             validation_data=val_img_gen,\n                             validation_steps=val_data.shape[0]//BATCH_SIZE,\n                             class_weight=class_weight,\n                             #callbacks=callbacks_list\n                             )\n\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "dc1d39e1", "metadata": {}, "outputs": [], "source": ["np.unique(train_data.target)"]}, {"cell_type": "code", "execution_count": 1, "id": "ed23121b", "metadata": {}, "outputs": [], "source": ["tr"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}