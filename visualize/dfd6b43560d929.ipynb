{"cells": [{"cell_type": "markdown", "id": "42d416d3", "metadata": {}, "source": ["This is my first notebook that I have ever worked after started to learn machine learning and I am glad for any comment or feedback."]}, {"cell_type": "markdown", "id": "4c761c5b", "metadata": {}, "source": ["![image.png](attachment:image.png)\n\n\nRMS Titanic, British luxury passenger liner that sank on April 14\u201315, 1912, during its maiden voyage, en route to New York City from Southampton, England, killing about 1,500 passengers and ship personnel. \n\nOne of the most famous tragedies in modern history, it inspired numerous stories, several films, and a musical and has been the subject of much scholarship and scientific speculation.\n\nFirstly, we should import our core libraries that we use to manipulate our data.\n"]}, {"cell_type": "markdown", "id": "ac040829", "metadata": {}, "source": ["# Getting Started"]}, {"cell_type": "code", "execution_count": 1, "id": "ee0c2cde", "metadata": {}, "outputs": [], "source": ["import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"]}, {"cell_type": "code", "execution_count": 1, "id": "6585a7c3", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"]}, {"cell_type": "markdown", "id": "844236d9", "metadata": {}, "source": ["Got the data seperately as train and test. \n\nWe will examine train data and build a model on it. After that, We'll try our model on the test data. \n\nLet's take the first look with train data.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a06388de", "metadata": {}, "outputs": [], "source": ["train.head(10)"]}, {"cell_type": "markdown", "id": "7a1c418e", "metadata": {}, "source": ["Everything looks as expected. However, it seems there are missing values in numerous features such as Age and Cabin so lets check it how many of them is null."]}, {"cell_type": "code", "execution_count": 1, "id": "dd403fd9", "metadata": {}, "outputs": [], "source": ["train.info()"]}, {"cell_type": "markdown", "id": "cf0b7d38", "metadata": {}, "source": ["We are lucky that the data do not have massive null values for many features, so there are 3 outcomes which are about Age, Cabin and Embarked.\n\n**AGE**\n1. There are approximately 280 missing values in the Age column that we may complete manually e.g. filling with mean values or median values..\n\n**EMBARKED**\n2. For Embarked, it is just 2 so we can either delete or complete them.\n\n**CABIN**\n3. As we can see there are huge amount of data are missing in Cabin column; moreover, I may complete them according to right possible values unless it has various values so lets take a look "]}, {"cell_type": "markdown", "id": "5fe1a95c", "metadata": {}, "source": ["Also we can conclude that there are columns that we can use as numerical value instead of string type so that we can get some correlation with survived column. \n\nI mean columns including object type data."]}, {"cell_type": "code", "execution_count": 1, "id": "b4b6ff1b", "metadata": {}, "outputs": [], "source": ["train[\"Cabin\"].value_counts()"]}, {"cell_type": "markdown", "id": "2f662d89", "metadata": {}, "source": ["147 different values ! It is impossible to complete that much missing data because we can not predict accurately each of them so we just delete the whole column.\n\nAlso we can delete PassengerId becuase we can separate them according to their index column, no need to PassengerId.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "57324c9e", "metadata": {}, "outputs": [], "source": ["train.drop(\"PassengerId\",axis=1,inplace=True)"]}, {"cell_type": "markdown", "id": "1422e0c6", "metadata": {}, "source": ["Let's move to first outcome to handle Age's missing values we can use median or mean of the data according to which one will get lower error. \n\nHere the values."]}, {"cell_type": "code", "execution_count": 1, "id": "7895d508", "metadata": {}, "outputs": [], "source": ["train.describe()"]}, {"cell_type": "code", "execution_count": 1, "id": "5137fba8", "metadata": {}, "outputs": [], "source": ["x = train[\"Age\"]\nsns.distplot(x)"]}, {"cell_type": "code", "execution_count": 1, "id": "e7c4a263", "metadata": {}, "outputs": [], "source": ["print(train[\"Age\"].median())\nprint(train[\"Age\"].mean())\nprint(train[\"Age\"].mode()[0])"]}, {"cell_type": "markdown", "id": "928f00ea", "metadata": {}, "source": ["We can select any of those values to fill age's missing values. \n\nI'll go with median"]}, {"cell_type": "code", "execution_count": 1, "id": "9cadee9b", "metadata": {}, "outputs": [], "source": ["median = train[\"Age\"].median()\ntrain[\"Age\"].fillna(median,inplace = True)"]}, {"cell_type": "markdown", "id": "f6d506ab", "metadata": {}, "source": ["For the third outcome, I have to handle Embarked and I can see values of it with countplot."]}, {"cell_type": "code", "execution_count": 1, "id": "827e5406", "metadata": {}, "outputs": [], "source": ["sns.countplot(train[\"Embarked\"])"]}, {"cell_type": "markdown", "id": "db37e93e", "metadata": {}, "source": ["There are huge amount of S in the column which means S is the mode and It is slightly reasonable that I prefer S to fill missing values of Embarked because S has high probability rather than others."]}, {"cell_type": "code", "execution_count": 1, "id": "cb27947e", "metadata": {}, "outputs": [], "source": ["train[\"Embarked\"].fillna(\"S\",inplace = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "a1a35090", "metadata": {}, "outputs": [], "source": ["train.info()"]}, {"cell_type": "markdown", "id": "bbc7ecc3", "metadata": {}, "source": ["We got it ! No more missing values that probably give us trouble except Cabin (we'll handle it later)"]}, {"cell_type": "markdown", "id": "9e3feb86", "metadata": {}, "source": ["Now I can use correlation map to see correlation between Survived and others. \n\nIf the number is close to 1, then there is a positive correlation ( if x goes up then y goes up ). \n\nIf the number is close to -1 then there is a negative correlation ( if x goes down then y goes up ). \n\nIn the image below, We can see it.\nIn addition, we can only see numerical data not string etc."]}, {"cell_type": "code", "execution_count": 1, "id": "f97aef5b", "metadata": {}, "outputs": [], "source": ["#correlation map\nf,ax=plt.subplots(figsize=(25, 25))\nsns.heatmap(train.corr(), annot=True, linewidths=.4, fmt= '.1f',ax=ax)\nplt.show()"]}, {"cell_type": "markdown", "id": "2433f5cc", "metadata": {}, "source": ["Or we can see the correlation just like.."]}, {"cell_type": "code", "execution_count": 1, "id": "9aefb053", "metadata": {}, "outputs": [], "source": ["corr_matrix = train.corr()\ncorr_matrix[\"Survived\"].sort_values(ascending = False)"]}, {"cell_type": "markdown", "id": "ad56f326", "metadata": {}, "source": ["For instance, Fare and Pclass have bigger correlation with Survived than others; however, It is not that massive correlation because the values are still small (0.25 and -0.33)."]}, {"cell_type": "markdown", "id": "a489cb10", "metadata": {}, "source": ["Now let's jump to feature engineering before prediction"]}, {"cell_type": "markdown", "id": "8d80b105", "metadata": {}, "source": ["# Feature Engineering"]}, {"cell_type": "markdown", "id": "3d7eb995", "metadata": {}, "source": ["While I was working on this notebook, I was stuck and I decided to be enlightened about the topic then I watched the Titanic movie and read Titanic's wiki page to acquire knowledge because I had no idea what I'm dealing with."]}, {"cell_type": "markdown", "id": "f06c6a0f", "metadata": {}, "source": ["After that, I learned the most critical thing about Titanic and I used it to get my final result. It was that while evacuation happening, women and children at higher classes (Pclass1 and Pclass2 mostly) were loaded first to lifeboat. In other words, if you are women or children at first or second class, you are survived with high probability."]}, {"cell_type": "markdown", "id": "655081ba", "metadata": {}, "source": ["So far, we filled and dropped some columns and we skimed through the correlation map what we should do next is apply some feature engineering stuff and get the data ready for prediction\n\n"]}, {"cell_type": "markdown", "id": "a31d80fb", "metadata": {}, "source": ["Firstly, let's handle categorical variables. My first target is Name and Ticket."]}, {"cell_type": "code", "execution_count": 1, "id": "d1414d78", "metadata": {}, "outputs": [], "source": ["train.loc[:,[\"Name\",\"Ticket\"]]"]}, {"cell_type": "markdown", "id": "3580aed7", "metadata": {}, "source": ["What I can get from the name are honorifics and surnames. With surnames and ticket numbers I can create family id"]}, {"cell_type": "code", "execution_count": 1, "id": "4c8e785a", "metadata": {}, "outputs": [], "source": ["train[\"Honorific\"] = train[\"Name\"].str.split(\",\",expand = True).iloc[:,1].str.split(\".\",expand = True).iloc[:,0].str.strip()\ntrain[\"Honorific\"].value_counts()"]}, {"cell_type": "markdown", "id": "3a1f1589", "metadata": {}, "source": ["Top 4 will be enough for prediction purposes that's why I'll do cut rest of them and use only top 4."]}, {"cell_type": "code", "execution_count": 1, "id": "ae4132a7", "metadata": {}, "outputs": [], "source": ["train = train.assign(Mr = (train[\"Honorific\"] == \"Mr\").astype(int))\ntrain = train.assign(Miss = (train[\"Honorific\"] == \"Miss\").astype(int))\ntrain = train.assign(Mrs = (train[\"Honorific\"] == \"Mrs\").astype(int))\ntrain = train.assign(Master = (train[\"Honorific\"] == \"Master\").astype(int))"]}, {"cell_type": "markdown", "id": "eed98f5a", "metadata": {}, "source": ["The Honorific is not needed. Hence, I should just delete it to avoid any kind of redundancy."]}, {"cell_type": "code", "execution_count": 1, "id": "2f7474dd", "metadata": {}, "outputs": [], "source": ["train.drop(\"Honorific\",axis=1,inplace=True)"]}, {"cell_type": "markdown", "id": "52acba2d", "metadata": {}, "source": ["To get family id I use an algorithm to select families uniquely. After that we don't have any job with ticket and name ; therefore, I delete them.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a32a75ef", "metadata": {}, "outputs": [], "source": ["train[\"Name\"] = train[\"Name\"].str.split(\",\",expand = True)[0]\n\nfamily = train.loc[:,[\"Name\",\"Ticket\"]]\nfamily[\"new\"] = family[\"Name\"] + family[\"Ticket\"]\n\ntrain[\"new\"] = train[\"Name\"] + train[\"Ticket\"]\nfamily_unique = family[\"new\"].unique().tolist()\nfamily_id = [i for i in range(1,len(family_unique)+1)]\n\nmerge_df = pd.DataFrame(data={\"new\":family_unique,\"FamilyID\":family_id})\n    \ntrain = train.join(merge_df.set_index(\"new\"), on='new')\ntrain.drop(\"new\",axis=1,inplace=True)\ntrain[\"FamilyID\"].fillna(0,inplace = True)\n\n\ntrain.drop([\"Name\",\"Ticket\"],axis=1,inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "56211fdf", "metadata": {}, "outputs": [], "source": ["import plotly.express as px\nfig = px.histogram(train, x=\"Sex\", color='Survived', barmode='group',\n             height=400)\nfig.show()"]}, {"cell_type": "markdown", "id": "8620750e", "metadata": {}, "source": ["It can be seen that most of the female survived but it is not coincidence because we already know the women and children first rule; therefore, the graph above is the result of that. We can split it up to more accurate prediction."]}, {"cell_type": "code", "execution_count": 1, "id": "9473e4e9", "metadata": {}, "outputs": [], "source": ["train = train.assign(Female = (lambda x: ((x[\"Sex\"] == \"female\")).astype(int)))\ntrain = train.assign(Male = (lambda x: ((x[\"Sex\"] == \"male\")).astype(int)))\ntrain.drop(\"Sex\",axis=1,inplace=True)"]}, {"cell_type": "markdown", "id": "bdee69cf", "metadata": {}, "source": ["Firstly, I select Pclass. I know that there are 3 different pclass 1,2 and 3; moreover, I want to observe that which one has most number of survived people and survived/all rate by each class\n\nTo see that I can use a stacked barplot from the plotly library\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0a085eab", "metadata": {}, "outputs": [], "source": ["import plotly.express as px\n\ndf_for_bar = train.loc[:,[\"Pclass\",\"Survived\"]]\ndf_for_bar[\"Survived\"].replace({0:\"No\",1:\"Yes\"},inplace = True)\n\nfig = px.histogram(df_for_bar, x=\"Pclass\", color='Survived')\n\nfig.update_layout(\n    xaxis_title_text='Pclass', \n    yaxis_title_text='Count', \n    bargap = 0.2)\nfig.show()"]}, {"cell_type": "markdown", "id": "90a8c97c", "metadata": {}, "source": ["What I see from table above is if you are first class passenger then you have high probability to survive but after that we cannot see which one comes next so we can calculate it directly."]}, {"cell_type": "code", "execution_count": 1, "id": "d80fa56d", "metadata": {}, "outputs": [], "source": ["number_rows = train.count()[0]\n\nrates = train[train[\"Survived\"]==1].groupby([\"Pclass\"]).count().iloc[:,0]\n\nprint(rates / number_rows)"]}, {"cell_type": "markdown", "id": "ccc8e993", "metadata": {}, "source": ["The biggest part of the survived people have first class ticket then third class and second class come accordingly.\n\n\nTherefore, First class has high probability to survive so our model can predict by just looking whether the passengers possess first class ticket or not. For that reason, It is better to separate Pclass according to their values 1,2 or 3.\n\n\nIn order to make this happen, we can use the famous OneHotEncoder function from sklearn lib.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "9ff29b29", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder()\n\nresults = ohe.fit_transform(train[\"Pclass\"].values.reshape(-1,1),).toarray()\n\ntrain[\"PClass_1\"] = 0\ntrain[\"PClass_2\"] = 0\ntrain[\"PClass_3\"] = 0\n\ntrain.iloc[:,[10,11,12]] = results\ntrain.iloc[:,[10,11,12]] = train.iloc[:,[10,11,12]].astype(int)"]}, {"cell_type": "markdown", "id": "422734a2", "metadata": {}, "source": ["Now we can approach Embarked same as Pclass.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "107653f1", "metadata": {}, "outputs": [], "source": ["df_for_pie = train[train[\"Survived\"]==1].groupby([\"Embarked\"]).count()\nfig = px.pie(df_for_pie, values='Survived', names=df_for_pie.index, title='Embarked Distribution Among Survived People')\nfig.show()"]}, {"cell_type": "markdown", "id": "dd4b7f65", "metadata": {}, "source": ["People who survived consist of highly people getting on the ship from S then C and Q come after that\n\nWe can split Embarked like Pclass; however, this time we can use different method instead of OneHotEncoder"]}, {"cell_type": "code", "execution_count": 1, "id": "d95c86f3", "metadata": {}, "outputs": [], "source": ["embarked_three = pd.get_dummies(train[\"Embarked\"])\ntrain = pd.concat([train,embarked_three],axis=1)\n\ntrain.drop(\"Embarked\",axis=1,inplace=True)"]}, {"cell_type": "markdown", "id": "323c6fd1", "metadata": {}, "source": ["Now we can think about how to use SibSp and and Parch. We can encode 1 if the passenger has any SibSp or Parch value rather than 0. Otherwise, it is zero\n"]}, {"cell_type": "code", "execution_count": 1, "id": "ebe661fa", "metadata": {}, "outputs": [], "source": ["train[\"NoChild\"] = train[\"Parch\"].loc[train[\"Parch\"]==0]\ntrain[\"NoChild\"] = train[\"NoChild\"].fillna(1).astype(int)\n\ntrain[\"NoSibSp\"] = train[\"SibSp\"].loc[train[\"SibSp\"]==0]\ntrain[\"NoSibSp\"] = train[\"NoSibSp\"].fillna(1).astype(int)"]}, {"cell_type": "markdown", "id": "10a23435", "metadata": {}, "source": ["How about family size ? It can make a difference\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b10024e9", "metadata": {}, "outputs": [], "source": ["train[\"FamilySize\"] = train[\"Parch\"] + train[\"SibSp\"]"]}, {"cell_type": "code", "execution_count": 1, "id": "1910f8d8", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "id": "032bd9e0", "metadata": {}, "source": ["Table above is our latest form; however, we will delete reduntant features and then I will use my last trick which is multiplying Age and Fare by Pclass because basically a 30 years old passenger in First class is not equal to another 30 years old passenger in Third class. Since,  evacuation of First class is happened firstly and Second class and Third class come later. By doing so, our model can predict better.\n\nIn Fare there are fares that more expensive than prior classes but by multiplacation we can get rid of it in order to expand range between fares for each classes."]}, {"cell_type": "code", "execution_count": 1, "id": "b783f2fe", "metadata": {}, "outputs": [], "source": ["fig = px.box(train[train[\"Fare\"] != 512.3292], x=\"Pclass\", y=\"Fare\")\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "4eb62e8d", "metadata": {}, "outputs": [], "source": ["train[\"Pclass\"].replace({1:3,3:1},inplace = True)  \ntrain[\"Fare\"] = train[\"Fare\"] * train[\"Pclass\"]\ntrain[\"Age\"] = train[\"Age\"] * train[\"Pclass\"] \ntrain[\"Pclass\"].replace({1:3,3:1},inplace = True)  "]}, {"cell_type": "code", "execution_count": 1, "id": "0c56b441", "metadata": {}, "outputs": [], "source": ["fig = px.box(train[train[\"Fare\"] < 700], x=\"Pclass\", y=\"Fare\")\nfig.show()"]}, {"cell_type": "markdown", "id": "c95c74f7", "metadata": {}, "source": ["Finally, let's drop reduntant features and jump to prediciton part."]}, {"cell_type": "code", "execution_count": 1, "id": "07f7e335", "metadata": {}, "outputs": [], "source": ["train.drop(train.loc[:,[\"Pclass\",\"Parch\",\"SibSp\",\"Cabin\"]],axis=1,inplace=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "adac07d6", "metadata": {}, "outputs": [], "source": ["y = train[\"Survived\"].copy()\ntrain.drop(\"Survived\",axis=1,inplace=True)"]}, {"cell_type": "markdown", "id": "bd09e553", "metadata": {}, "source": ["# Prediction\n"]}, {"cell_type": "markdown", "id": "82e3a011", "metadata": {}, "source": ["To split data I used Stratified sampling"]}, {"cell_type": "code", "execution_count": 1, "id": "572eeec3", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1,test_size=0.13,random_state=42)\nfor train_index,cv_index in split.split(train,y):\n    X_train, X_cv = train.loc[train_index], train.loc[cv_index]\n    y_train, y_cv = y.loc[train_index], y.loc[cv_index]"]}, {"cell_type": "markdown", "id": "cc57763d", "metadata": {}, "source": ["To see models prediction accuracy I implemented following function\n"]}, {"cell_type": "code", "execution_count": 1, "id": "69ab1b65", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy_score\ndef predict_model(model,X_train,y_train,X_cv,y_cv):\n    model.fit(X_train,y_train)\n    return accuracy_score(y_train,model.predict(X_train)),accuracy_score(y_cv,model.predict(X_cv))"]}, {"cell_type": "code", "execution_count": 1, "id": "16bce0b8", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\n\nlog_reg = LogisticRegression(max_iter=50000)\nprint(\"Logistic Regression    Train: \"+\"   CV:\".join(map(str,predict_model(log_reg,X_train,y_train,X_cv,y_cv))))\n\nrnd_clf = RandomForestClassifier()\nprint(\"Random Forest Classifier    Train: \"+\"   CV:\".join(map(str,predict_model(rnd_clf,X_train,y_train,X_cv,y_cv))))\n\nsvc = svm.SVC(max_iter=50000)\nprint(\"Support Vector Machine Classifier    Train: \"+\"   CV:\".join(map(str,predict_model(svc,X_train,y_train,X_cv,y_cv))))"]}, {"cell_type": "markdown", "id": "312ff6f0", "metadata": {}, "source": ["I chose logistic regression because it gave better result on test data.\n\nWe need to apply same functions to test data that we applied on train data so I just collect functions above in a function."]}, {"cell_type": "code", "execution_count": 1, "id": "ee32bbdb", "metadata": {}, "outputs": [], "source": ["train"]}, {"cell_type": "code", "execution_count": 1, "id": "0d75b5b0", "metadata": {}, "outputs": [], "source": ["train2 = pd.read_csv(\"/kaggle/input/titanic/train.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "7a340780", "metadata": {}, "outputs": [], "source": ["def all_changes(X):\n    X[\"Honorific\"] = X[\"Name\"].str.split(\",\",expand = True).iloc[:,1].str.split(\".\",expand = True).iloc[:,0].str.strip()\n    X = X.assign(Mr = (X[\"Honorific\"] == \"Mr\").astype(int))\n    X = X.assign(Miss = (X[\"Honorific\"] == \"Miss\").astype(int))\n    X = X.assign(Mrs = (X[\"Honorific\"] == \"Mrs\").astype(int))\n    X = X.assign(Master = (X[\"Honorific\"] == \"Master\").astype(int))\n    X.drop(\"Honorific\",axis=1,inplace=True)\n    \n    X[\"Name\"]=X[\"Name\"].str.split(\",\",expand = True)[0]\n    family = X.loc[:,[\"Name\",\"Ticket\"]]\n    family[\"new\"] = family[\"Name\"] + family[\"Ticket\"]\n    X[\"new\"] = X[\"Name\"] + X[\"Ticket\"]\n    family_unique = family[\"new\"].unique().tolist()\n    family_id = [i for i in range(1,len(family_unique)+1)]\n    merge_df = pd.DataFrame(data={\"new\":family_unique,\"FamilyID\":family_id})\n    \n    X = X.join(merge_df.set_index(\"new\"), on='new')\n    X.drop(\"new\",axis=1,inplace=True)\n    X[\"FamilyID\"].fillna(0,inplace = True)\n    \n    \n    X.drop(X.loc[:,[\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"]],axis=1,inplace=True)\n    \n    X = X.assign(Female = (lambda x: ((x[\"Sex\"] == \"female\")).astype(int)))\n    X = X.assign(Male = (lambda x: ((x[\"Sex\"] == \"male\")).astype(int)))\n    \n    \n    \n    mean = X[\"Age\"].mean()\n    X[\"Age\"].fillna(mean,inplace = True)\n       \n    \n    \n    X = X.assign(P_1 = (X[\"Pclass\"]== 1).astype(int))\n    X = X.assign(P_2 = (X[\"Pclass\"]== 2).astype(int))\n    X = X.assign(P_3 = (X[\"Pclass\"]== 3).astype(int))\n    \n    X[\"Embarked\"].fillna(\"S\",inplace = True)\n    \n    X = X.assign(C = (X[\"Embarked\"]==\"C\").astype(int))\n    X = X.assign(Q = (X[\"Embarked\"]==\"Q\").astype(int))\n    X = X.assign(S = (X[\"Embarked\"]==\"S\").astype(int))\n        \n\n    X[\"NoChild\"] = X[\"Parch\"].loc[X[\"Parch\"]==0]\n    X[\"NoSibSp\"] = X[\"SibSp\"].loc[X[\"SibSp\"]==0]\n    \n    X[\"NoChild\"] = X[\"NoChild\"].fillna(1).astype(int)\n    X[\"NoSibSp\"] = X[\"NoSibSp\"].fillna(1).astype(int)\n    \n\n    X[\"FamilySize\"] = X[\"Parch\"] + X[\"SibSp\"]\n  \n # - - --- - - - - - - -- - - - - - -- - - - -- - - - - -- - - - - - - -- - - - - - -\n    X[\"Pclass\"].replace({1:3,3:1},inplace = True)\n    \n    X[\"Fare\"] = X[\"Fare\"] * X[\"Pclass\"]\n    X[\"Age\"] = X[\"Age\"] * X[\"Pclass\"] \n    \n    X.rename(columns={\"P_1\":\"PClass_1\",\"P_2\":\"PClass_2\",\"P_3\":\"PClass_3\"},inplace=True)\n\n    X.drop(X.loc[:,[\"Sex\",\"Embarked\",\"Pclass\",\"Parch\",\"SibSp\"]],axis=1,inplace=True)\n    return X\n\n\ntrain2 = all_changes(train2)"]}, {"cell_type": "code", "execution_count": 1, "id": "ec0f99f1", "metadata": {}, "outputs": [], "source": ["test.info()"]}, {"cell_type": "markdown", "id": "1df5434b", "metadata": {}, "source": ["We had missing values in Cabin and Age same as train but we have only one row that does not have Fare value unlike train data. We can fill it and then use function we just implemented to finalize."]}, {"cell_type": "code", "execution_count": 1, "id": "eb06f88f", "metadata": {}, "outputs": [], "source": ["test[\"Fare\"].fillna(11,inplace = True)\ntest = all_changes(test)"]}, {"cell_type": "code", "execution_count": 1, "id": "2977baa7", "metadata": {}, "outputs": [], "source": ["test.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "8e1ed5d0", "metadata": {}, "outputs": [], "source": ["X_train.head()"]}, {"cell_type": "markdown", "id": "898a4e54", "metadata": {}, "source": ["Both dataframe are same according to their column order. "]}, {"cell_type": "code", "execution_count": 1, "id": "694eb032", "metadata": {}, "outputs": [], "source": ["test_result = log_reg.predict(test)\ntest_result = test_result.reshape(-1,1)\n\nresult = pd.DataFrame(data = {\"PassengerId\":np.arange(892,1310,1)})\nresult[\"Survived\"]= test_result\nresult.to_csv(r'result.csv',index = False, header=True)"]}, {"cell_type": "markdown", "id": "8ff90aeb", "metadata": {}, "source": ["It is the end ! Thanks for your precious comments and feedbacks.."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}