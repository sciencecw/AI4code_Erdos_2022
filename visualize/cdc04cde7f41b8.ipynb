{"cells": [{"cell_type": "markdown", "id": "de01979c", "metadata": {}, "source": ["# Linear Regression Model\n## by Vikram Jeet Singh"]}, {"cell_type": "code", "execution_count": 1, "id": "16ca9129", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "code", "execution_count": 1, "id": "82831fe6", "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nprint('Libraries imported succesfully')"]}, {"cell_type": "code", "execution_count": 1, "id": "9415c823", "metadata": {}, "outputs": [], "source": ["url='/kaggle/input/startup-logistic-regression/50_Startups.csv'\ndata=pd.read_csv(url)\ndata.head()"]}, {"cell_type": "markdown", "id": "afc17bcd", "metadata": {}, "source": ["## Analyzing the data"]}, {"cell_type": "markdown", "id": "5711b163", "metadata": {}, "source": ["#### Dimensions of Dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "e90f61e9", "metadata": {}, "outputs": [], "source": ["print('There are ',data.shape[0],'rows and ',data.shape[1],'columns in the dataset.')"]}, {"cell_type": "markdown", "id": "522853d4", "metadata": {}, "source": ["#### Duplicated Values"]}, {"cell_type": "code", "execution_count": 1, "id": "785c4e79", "metadata": {}, "outputs": [], "source": ["print('There are',data.duplicated().sum(),'duplicate values in the dateset.')"]}, {"cell_type": "markdown", "id": "fe4ac40d", "metadata": {}, "source": ["#### Null Values"]}, {"cell_type": "code", "execution_count": 1, "id": "740784c0", "metadata": {}, "outputs": [], "source": ["data.isnull().sum()"]}, {"cell_type": "markdown", "id": "2863d2b9", "metadata": {}, "source": ["##### Therefore there are zero null values in the dataset."]}, {"cell_type": "markdown", "id": "000211e2", "metadata": {}, "source": ["#### Schema of dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "754f68de", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "markdown", "id": "b3cb0dc8", "metadata": {}, "source": ["##### As we can observe that all the columns have the right data type they should have, so we need not to change anything."]}, {"cell_type": "markdown", "id": "b709b707", "metadata": {}, "source": ["#### Descriptive analysis of data"]}, {"cell_type": "code", "execution_count": 1, "id": "5b4965d1", "metadata": {}, "outputs": [], "source": ["data.describe()"]}, {"cell_type": "markdown", "id": "2323569b", "metadata": {}, "source": ["#### Correlation between the columns of dataset."]}, {"cell_type": "code", "execution_count": 1, "id": "0e89e8b8", "metadata": {}, "outputs": [], "source": ["data.corr()"]}, {"cell_type": "markdown", "id": "52e1bf70", "metadata": {}, "source": ["## Exploratory Data Analysis"]}, {"cell_type": "code", "execution_count": 1, "id": "46b3cb7d", "metadata": {}, "outputs": [], "source": ["# Correlation matrix\nc=data.corr()\nsns.heatmap(c,annot=True,cmap='Blues')"]}, {"cell_type": "markdown", "id": "305849b0", "metadata": {}, "source": ["From the heatmap above we can obseve that all three columns have a direct relationship with the profit, which is our target variable."]}, {"cell_type": "code", "execution_count": 1, "id": "3af7a9dd", "metadata": {}, "outputs": [], "source": ["sns.pairplot(data)"]}, {"cell_type": "markdown", "id": "9ecccfc8", "metadata": {}, "source": ["After this Pairplot, it is confirmed that there is a direct relationship of all the three numeric columns with our Profit. So lets use this relationship and make a model."]}, {"cell_type": "markdown", "id": "4bd68be7", "metadata": {}, "source": ["## Creating Model"]}, {"cell_type": "code", "execution_count": 1, "id": "4122b482", "metadata": {}, "outputs": [], "source": ["independent=['R&D Spend','Administration','Marketing Spend']\ny=data['Profit'].to_numpy()\ny=y.reshape(-1,1)\nx=data[independent].to_numpy()\nx,y"]}, {"cell_type": "code", "execution_count": 1, "id": "265e2e1a", "metadata": {}, "outputs": [], "source": ["# Splitting the data into train and test datasets\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.7,random_state=0)\nx_train"]}, {"cell_type": "markdown", "id": "9173a620", "metadata": {}, "source": ["#### Now let's use the data above and make a Linear regression model from the same."]}, {"cell_type": "code", "execution_count": 1, "id": "04e9409e", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\nmodel=LinearRegression()\nmodel.fit(x_train,y_train)\nprint('Model Trained')"]}, {"cell_type": "markdown", "id": "aff33d46", "metadata": {}, "source": ["##### Now lets see how much the model's prediction differs from actual values by comparing predictions and actual values\n"]}, {"cell_type": "code", "execution_count": 1, "id": "6eef8909", "metadata": {}, "outputs": [], "source": ["y_pred=model.predict(x_test)\ny_pred"]}, {"cell_type": "code", "execution_count": 1, "id": "0e6a4c23", "metadata": {}, "outputs": [], "source": ["df=pd.DataFrame(data={'Predicted value':y_pred.flatten(),'Actual Value':y_test.flatten()})\ndf"]}, {"cell_type": "markdown", "id": "c5360a14", "metadata": {}, "source": ["##### As we can see that the predicted value is somewhat near to the actual values, therefore, we can use this model for prediction. But first we need to calculate how much is the error generated."]}, {"cell_type": "code", "execution_count": 1, "id": "242f9e62", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import mean_absolute_error\nmae=mean_absolute_error(y_pred,y_test)\nmae"]}, {"cell_type": "markdown", "id": "15542b17", "metadata": {}, "source": ["#### So, the mean absolute error is 6489.6601704866425. Therefore our predicted value can be 6489.6601704866425 units greater than or less than the actual value."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}