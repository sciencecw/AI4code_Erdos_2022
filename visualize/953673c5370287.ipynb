{"cells": [{"cell_type": "markdown", "id": "899a9394", "metadata": {}, "source": ["# Project Overview"]}, {"cell_type": "markdown", "id": "ac17798e", "metadata": {}, "source": ["### What is the goal of Project [COVIEWED](https://www.coviewed.org/)?\n\nProject [COVIEWED](https://www.coviewed.org/)'s aim is to fight against misinformation on the web regarding the recent coronavirus pandemic / covid-19 outbreak. \n\nTo achieve this, we collect different types of claims from web sources with supporting or attacking evidence. \n\nThis information is used to train a machine learning classifier. \n\nOnce trained, we plan to release a browser extension that highlights potential true/false claims on a web page to assist users in their information gathering process."]}, {"cell_type": "markdown", "id": "a036c4b9", "metadata": {}, "source": ["### Organization\n\nWe have a public [Trello Board](https://trello.com/invite/b/jk00CW3u/9985740815b585156aaa22978a3067df/project-coviewed) and our project is completely open source and available on [Github](https://github.com/COVIEWED)."]}, {"cell_type": "markdown", "id": "4e99afbd", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "efd34af0", "metadata": {}, "source": ["# First Look: Submission Data"]}, {"cell_type": "code", "execution_count": 1, "id": "762406cc", "metadata": {}, "outputs": [], "source": ["!pip install -U yarl"]}, {"cell_type": "code", "execution_count": 1, "id": "3ce2004e", "metadata": {}, "outputs": [], "source": ["import os\nimport yarl\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nfrom collections import Counter\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 1, "id": "a1684e21", "metadata": {}, "outputs": [], "source": ["count_f = 0\nframes = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in sorted(filenames):\n        if filename.endswith('.tsv'):\n            fname = os.path.join(dirname, filename)\n            df = pd.read_csv(fname, sep='\\t')\n            frames.append(df)\n            print(\"%4i\"%count_f, \"|\", \"%6i\"%len(df), fname.split('/')[-1])\n            count_f+=1"]}, {"cell_type": "code", "execution_count": 1, "id": "b9a2471d", "metadata": {}, "outputs": [], "source": ["DATA = pd.concat(frames)\nlen(DATA)"]}, {"cell_type": "code", "execution_count": 1, "id": "60468cc9", "metadata": {}, "outputs": [], "source": ["DATA.sample(n=min(len(DATA),5))"]}, {"cell_type": "code", "execution_count": 1, "id": "92c07516", "metadata": {}, "outputs": [], "source": ["exclude_urls = ['reddit.','redd.','youtube','youtu.','twitter','facebook','fb','google.','.mp3','.pdf','/r/','imgur.']\nexclude_urls"]}, {"cell_type": "code", "execution_count": 1, "id": "e03a2a8f", "metadata": {}, "outputs": [], "source": ["submission_datetime = []\nurl_hosts = []\nfor created_utc, url in DATA[['created_utc','url']].values.tolist():\n    datetime = dt.datetime.fromtimestamp(int(created_utc))\n    submission_datetime.append(datetime)\n    try:\n        S = set([x in url for x in exclude_urls])\n        if len(S)==1 and not True in S:\n            url = yarl.URL(url)\n            url_hosts.append(url.host)\n    except:\n        print(url)\nprint(len(submission_datetime), len(url_hosts), min(submission_datetime), max(submission_datetime), sep='\\n')"]}, {"cell_type": "markdown", "id": "faff1fa5", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "be07af97", "metadata": {}, "source": ["# Top Domains by Submissions"]}, {"cell_type": "code", "execution_count": 1, "id": "b4b22842", "metadata": {}, "outputs": [], "source": ["TOP_N_URL_HOSTS = 25\n\nC = Counter(url_hosts)\nfor count_u, (url_host, count_host) in enumerate(sorted(C.items(), key=itemgetter(1), reverse=True)):\n    print(\"%6i\"%count_host, url_host)\n    if count_u>=TOP_N_URL_HOSTS:\n        break"]}, {"cell_type": "markdown", "id": "0915feb7", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "8b3716d3", "metadata": {}, "source": ["# Plot Submission Count by Day"]}, {"cell_type": "code", "execution_count": 1, "id": "d02b7b37", "metadata": {}, "outputs": [], "source": ["DATA['date'] = DATA.apply(lambda row: dt.date.fromtimestamp(int(row.created_utc)), axis=1)"]}, {"cell_type": "code", "execution_count": 1, "id": "ab74ca6b", "metadata": {}, "outputs": [], "source": ["D = DATA[['id','date']].groupby('date').count().sort_values('date', ascending=True)\nX, X_label, Y = [], [], []\nfor count_d, (date, count_id) in enumerate(zip(D.index, D.id)):\n    X.append(count_d)\n    Y.append(count_id)\n    X_label.append(date.strftime('%Y-%m-%d'))\nlen(X), len(Y), len(X_label)"]}, {"cell_type": "code", "execution_count": 1, "id": "e110f141", "metadata": {}, "outputs": [], "source": ["[i for i in range(len(X_label))][::7]"]}, {"cell_type": "code", "execution_count": 1, "id": "ea9ab020", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15,6))\nplt.scatter(X, Y)\nplt.plot(X, Y)\nfor w in [i for i in range(len(X_label))][::7]:\n    plt.vlines(w, min(Y)-0.1*max(Y), max(Y)+0.1*max(Y), color='k', alpha=0.25)\nplt.xticks([i for i in range(len(X_label))][::7], X_label[::7], rotation=60)\nplt.xlim(-1,len(X)+1)\nplt.ylim(0, max(Y)+0.1*max(Y))\nplt.title(\"News Articles submitted to /r/Coronavirus per Day\")\nplt.xlabel('date')\nplt.ylabel('submission count')\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "b34027c2", "metadata": {}, "outputs": [], "source": ["counts_per_hour_of_weekday = np.zeros((7,24)) # weekdays * hours in a day\nweekdays = dict()\nfor created_utc in DATA.created_utc.values.tolist():\n    current_datetime = dt.datetime.fromtimestamp(int(created_utc))\n    wd = current_datetime.weekday()\n    h = current_datetime.hour\n    counts_per_hour_of_weekday[wd,h]+=1\n    weekdays[wd] = current_datetime.strftime('%A')\nprint(counts_per_hour_of_weekday.shape)\nprint(weekdays)"]}, {"cell_type": "code", "execution_count": 1, "id": "d27741d2", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(14,6))\nplt.imshow(counts_per_hour_of_weekday)\nplt.yticks([k for k, v in weekdays.items()], [v for k, v in weekdays.items()])\nplt.xticks([i for i in range(counts_per_hour_of_weekday.shape[1])], [i for i in range(counts_per_hour_of_weekday.shape[1])])\nplt.ylabel('Day of the Week')\nplt.xlabel('Hour of the Day')\nplt.title('/r/Coronavirus submissions by hour of the day!')\nplt.show()"]}, {"cell_type": "markdown", "id": "c7cc5598", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "id": "eff6687f", "metadata": {}, "source": ["# Example: Load a News Article"]}, {"cell_type": "code", "execution_count": 1, "id": "b9bdb839", "metadata": {}, "outputs": [], "source": ["!git clone https://github.com/COVIEWED/coviewed_web_scraping"]}, {"cell_type": "code", "execution_count": 1, "id": "4344586f", "metadata": {}, "outputs": [], "source": ["!pip install -r coviewed_web_scraping/requirements.txt"]}, {"cell_type": "code", "execution_count": 1, "id": "ffc6eb1d", "metadata": {}, "outputs": [], "source": ["#EXAMPLE_URL = DATA[['url']].sample(n=1).url.values.tolist()[0]\nEXAMPLE_URL = 'https://edition.cnn.com/2020/03/04/health/debunking-coronavirus-myths-trnd/'\nprint(EXAMPLE_URL)"]}, {"cell_type": "code", "execution_count": 1, "id": "15857bf3", "metadata": {}, "outputs": [], "source": ["!echo {EXAMPLE_URL}"]}, {"cell_type": "code", "execution_count": 1, "id": "1bffc842", "metadata": {}, "outputs": [], "source": ["!rm coviewed_web_scraping/data/*.txt"]}, {"cell_type": "code", "execution_count": 1, "id": "1b863df4", "metadata": {}, "outputs": [], "source": ["!cd coviewed_web_scraping/ && python3 src/scrape.py -u={EXAMPLE_URL}"]}, {"cell_type": "code", "execution_count": 1, "id": "7b3ebf71", "metadata": {}, "outputs": [], "source": ["!ls coviewed_web_scraping/data/*.txt"]}, {"cell_type": "code", "execution_count": 1, "id": "b25385b4", "metadata": {}, "outputs": [], "source": ["data_path = 'coviewed_web_scraping/data/'\nfname = [f for f in os.listdir(data_path) if f.endswith('.txt')][0]\nwith open(os.path.join(data_path, fname), 'r') as my_file:\n    txt_data = my_file.readlines()\ntxt_data = [line.strip() for line in txt_data if line.strip()]\nlen(txt_data)"]}, {"cell_type": "code", "execution_count": 1, "id": "925e1e80", "metadata": {}, "outputs": [], "source": ["article_url = txt_data[0]\nprint(article_url)\narticle_published_datetime = txt_data[1]\nprint(article_published_datetime)"]}, {"cell_type": "code", "execution_count": 1, "id": "6763d167", "metadata": {}, "outputs": [], "source": ["article_title = txt_data[2]\nprint(article_title)"]}, {"cell_type": "code", "execution_count": 1, "id": "23b2f5b1", "metadata": {}, "outputs": [], "source": ["article_text = \"\\n\\n\".join(txt_data[3:])\nprint(article_text)"]}, {"cell_type": "code", "execution_count": 1, "id": "959284d9", "metadata": {}, "outputs": [], "source": ["print('List of claims from the article:', end='\\n\\n')\nfor row in article_text.splitlines():\n    if row.strip() and 'Myth:' in row:\n        print(row.strip()[len('Myth: '):])"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}