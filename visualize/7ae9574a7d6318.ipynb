{"cells": [{"cell_type": "markdown", "id": "cd4737c7", "metadata": {}, "source": ["![](https://m.economictimes.com/thumb/msid-69278711,width-1200,height-900,resizemode-4,imgsize-132321/home-insurance-getty.jpg)\n# Introduction \nThis is my first ML practice building a linear regression model. \nIn this dataset, we will perform an exploratory data analysis to understand correlation before building our model.\n"]}, {"cell_type": "markdown", "id": "12e82bf3", "metadata": {}, "source": ["## Importing required packages "]}, {"cell_type": "code", "execution_count": 1, "id": "d877b933", "metadata": {}, "outputs": [], "source": ["# Importing required packages\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols"]}, {"cell_type": "markdown", "id": "679c5f3b", "metadata": {}, "source": ["## Importing dataset and create an overview of dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "c36e15bc", "metadata": {}, "outputs": [], "source": ["def overview():\n    '''\n    Read a comma-separated values (csv) file into DataFrame.\n    Print 5 rows of data\n    Print number of rows and columns\n    Print datatype for each column\n    Print number of NULL/NaN values for each column\n    Print summary data\n    \n    Return:\n    data, rtype: DataFrame\n    '''\n    data = pd.read_csv('../input/insurance/insurance.csv')\n    print(\"The first 5 rows if data are:\\n\", data.head())\n    print(\"\\n\")\n    print(\"The (Row,Column) is:\\n\", data.shape)\n    print(\"\\n\")\n    print(\"Data type of each column:\\n\", data.dtypes)\n    print(\"\\n\")\n    print(\"The number of null values in each column are:\\n\", data.isnull().sum())\n    print(\"\\n\")\n    print(\"Numeric summary:\\n\", data.describe())\n    return data\n\ndf = overview()"]}, {"cell_type": "markdown", "id": "960f8eb1", "metadata": {}, "source": ["## Assigning numerical and categorical variables "]}, {"cell_type": "code", "execution_count": 1, "id": "7953cc25", "metadata": {}, "outputs": [], "source": ["# Sorting out numerical and categorical variables \ndef categorical_variable(df):\n    return list(df.select_dtypes(include = ['category', 'object']))\n\ndef numerical_variable(df):\n    return list(df.select_dtypes(exclude = ['category', 'object']))\n"]}, {"cell_type": "markdown", "id": "c43477a9", "metadata": {}, "source": ["## Performing EDA "]}, {"cell_type": "code", "execution_count": 1, "id": "a93cbeca", "metadata": {}, "outputs": [], "source": ["g = sns.catplot(x=\"smoker\", y=\"charges\",col_wrap=3, col=\"sex\",data= df, kind=\"box\",height=5, aspect=0.8);"]}, {"cell_type": "markdown", "id": "8d51cef7", "metadata": {}, "source": ["We can see that smokers have higher charges due to the possible health issues gathered from smoking. Let's see the rate of charges among different age."]}, {"cell_type": "code", "execution_count": 1, "id": "6c31e0cd", "metadata": {}, "outputs": [], "source": ["g = sns.catplot(x=\"smoker\", y=\"age\",col_wrap=3, col=\"sex\",data= df, kind=\"box\",height=5, aspect=0.8);"]}, {"cell_type": "markdown", "id": "d310b70a", "metadata": {}, "source": ["It seems that there are more male smokers as compared to female. Could that be the reason why the charges for male smokers are higher?"]}, {"cell_type": "markdown", "id": "a8aec33a", "metadata": {}, "source": ["## Changing categorical values to numeric \n- This is an important step as many machine learning algorithms are unable to support categorical values. \n- There are 2 ways we can deal with this:\n    - Label encoding\n    - One-hot encoding\n\n### Label encoding (Ordinal values)\nLabel encoding assigns each unique value to a different integer.\n![](https://i.imgur.com/tEogUAr.png)\n- This approach assumes an ordering of the categories: \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3).\n\n- This assumption makes sense in this example, because there is an indisputable ranking to the categories. Not all categorical variables have a clear ordering in the values, but we refer to those that do as ordinal variables. For tree-based models (like decision trees and random forests), you can expect label encoding to work well with ordinal variables.\n\n### One-hot encoding \n- One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data. To understand this, we'll work through an example.\n![](https://i.imgur.com/TW5m0aJ.png)\n- In the original dataset, \"Color\" is a categorical variable with three categories: \"Red\", \"Yellow\", and \"Green\". The corresponding one-hot encoding contains one column for each possible value, and one row for each row in the original dataset. Wherever the original value was \"Red\", we put a 1 in the \"Red\" column; if the original value was \"Yellow\", we put a 1 in the \"Yellow\" column, and so on.\n\n- In contrast to label encoding, one-hot encoding does not assume an ordering of the categories. Thus, you can expect this approach to work particularly well if there is no clear ordering in the categorical data (e.g., \"Red\" is neither more nor less than \"Yellow\"). We refer to categorical variables without an intrinsic ranking as nominal variables.\n\n- One-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally won't use it for variables taking more than 15 different values)."]}, {"cell_type": "code", "execution_count": 1, "id": "9b1eae39", "metadata": {}, "outputs": [], "source": ["# Changing categorical values to numeric\ndf2 = df.copy()\n#sex\nle = LabelEncoder()\nle.fit(df2.sex.drop_duplicates()) \ndf2.sex = le.transform(df2.sex)\n# smoker or not\nle.fit(df2.smoker.drop_duplicates()) \ndf2.smoker = le.transform(df2.smoker)\n#region\nle.fit(df2.region.drop_duplicates()) \ndf2.region = le.transform(df2.region)"]}, {"cell_type": "markdown", "id": "c8c57196", "metadata": {}, "source": ["## Measuring correlation\nGiven that some variables here are categorical data, we will need to use 1-way ANOVA test to calculate correlation.\n\nWe will be using 95% confidence interval (95% chance that the confidence interval you calculated contains the true population mean).\nThe null hypothesis is that they are independent.\nThe alternative hypothesis is that they are correlated in some way."]}, {"cell_type": "code", "execution_count": 1, "id": "9a5f5b58", "metadata": {}, "outputs": [], "source": ["print(df2.corr()['charges'])\n\nlm = ols('sex ~ charges', data = df2).fit()\ntable = sm.stats.anova_lm(lm)\nprint(\"P-value for 1-way ANOVA test between sex and charges is: \",table.loc['charges','PR(>F)'])\nlm1 = ols('smoker ~ charges', data = df2).fit()\ntable1 = sm.stats.anova_lm(lm1)\nprint(\"P-value for 1-way ANOVA test between smoker and charges is: \",table1.loc['charges','PR(>F)'])\nlm2 = ols('region ~ charges', data = df2).fit()\ntable2 = sm.stats.anova_lm(lm2)\nprint(\"P-value for 1-way ANOVA test between region and charges is: \",table2.loc['charges','PR(>F)'])"]}, {"cell_type": "markdown", "id": "c4e084bb", "metadata": {}, "source": ["- Here, you can see me perform a Pearson correlation test and a 1-way ANOVA test. 1-way AVOVA test is the right way to test correlation between a categorical and numerical data.\n- It seems that the smoker variable is highly correlated to charges. Hence, we will not drop this feature at the later step.\n- It seems that region has a P-value of > 0.05, hence, we accept the null hypothesis that they are independent."]}, {"cell_type": "markdown", "id": "ad5b287f", "metadata": {}, "source": ["## Performing a linear regression\n- This time, we include all features in X"]}, {"cell_type": "code", "execution_count": 1, "id": "072503de", "metadata": {}, "outputs": [], "source": ["# Creating training and testing dataset\ny = df2['charges']\nX = df2.drop(['charges'], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n\nlr = LinearRegression().fit(X_train,y_train)\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\n\nprint(lr.score(X_test,y_test))"]}, {"cell_type": "markdown", "id": "dfd4c1ee", "metadata": {}, "source": ["78.3% accuracy! Not that bad for the first model! Let's see if we can improve it by removing non-correlated features."]}, {"cell_type": "code", "execution_count": 1, "id": "00e9ff87", "metadata": {}, "outputs": [], "source": ["# Creating training and testing dataset\ny = df2['charges']\nX = df2.drop(['charges', 'region'], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)\n\nlr = LinearRegression().fit(X_train,y_train)\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\n\nprint(lr.score(X_test,y_test))"]}, {"cell_type": "markdown", "id": "268089e4", "metadata": {}, "source": ["78.1%.. A slight improvement! Now let's try using Polynomial regression!\n\n## Polynomial regression\n- A form of linear regression in which the relationship between the independent variable x and dependent variable y is modeled as an nth degree polynomial.\n- Why polynomial regression? An assumption in usual multiple linear regression analysis is that all the independent variables are independent. In polynomial regression model, this assumption is not satisfied."]}, {"cell_type": "code", "execution_count": 1, "id": "d912d157", "metadata": {}, "outputs": [], "source": ["# Creating training and testing dataset\ny = df2['charges']\nX = df2.drop(['charges', 'region'], axis = 1)\n\npoly_reg  = PolynomialFeatures(degree=2)\nX_poly = poly_reg.fit_transform(X)\n\nX_train,X_test,y_train,y_test = train_test_split(X_poly,y,test_size=0.20, random_state = 42)\n\nlin_reg = LinearRegression()\nlin_reg  = lin_reg.fit(X_train,y_train)\n\nprint(lin_reg.score(X_test,y_test))"]}, {"cell_type": "markdown", "id": "04a517f6", "metadata": {}, "source": ["Sweet! We see a huge improvement in the score! I believe more can be done to improve this model by performing feature selections and testing more complex models but since this is my first model, I shall end off here! Thank you for reading!"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}