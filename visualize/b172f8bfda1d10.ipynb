{"cells": [{"cell_type": "code", "execution_count": 1, "id": "a844eb76", "metadata": {}, "outputs": [], "source": ["\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n \ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')"]}, {"cell_type": "code", "execution_count": 1, "id": "40969413", "metadata": {}, "outputs": [], "source": ["#GOAL: Predict Housing Sales Prices (SalePrice)\n\ntrain.info()\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a1ddc06f", "metadata": {}, "outputs": [], "source": ["train.head()"]}, {"cell_type": "markdown", "id": "9e2c7f13", "metadata": {}, "source": ["**Part 1: Feature Engineering**"]}, {"cell_type": "code", "execution_count": 1, "id": "3e01b332", "metadata": {}, "outputs": [], "source": ["####DROP FEAUTURES WITH MAJORITY OF ELEMENTS MISSING\nmajority_missing = []\nfor col in train.columns:\n    if train[col].isnull().sum() >(train.shape[0])/2:\n        majority_missing.append(col)\n    \nreduced_train = train.drop(majority_missing, axis=1)\nreduced_test = test.drop(majority_missing, axis=1)\n\n"]}, {"cell_type": "code", "execution_count": 1, "id": "39b48642", "metadata": {}, "outputs": [], "source": ["test_nan = reduced_test.isnull().sum().sort_values(ascending = False) \nlen(test_nan[test_nan>=1])\n"]}, {"cell_type": "code", "execution_count": 1, "id": "0c19a407", "metadata": {}, "outputs": [], "source": ["#lets merge test and train to handle nan values at same time\n\ndf_all = pd.concat([reduced_train,reduced_test ],ignore_index=True)\ndf_all.shape, reduced_train.shape, reduced_test.shape #NOTE: first 1460 rows from training data last 1459 from test "]}, {"cell_type": "code", "execution_count": 1, "id": "839c257f", "metadata": {}, "outputs": [], "source": ["# replace all the categorical variable with their mode value and numerical variables with their median\ndf_all[\"Electrical\"].dtype, df_all[\"SalePrice\"].dtype # so categorical variables would have a data type of \"dtype(0)\" and integers \"dtype('float64')\""]}, {"cell_type": "code", "execution_count": 1, "id": "d6cbaec7", "metadata": {}, "outputs": [], "source": ["has_null = df_all.isnull().sum()\nhas_null[has_null>0]"]}, {"cell_type": "code", "execution_count": 1, "id": "427d2ae5", "metadata": {}, "outputs": [], "source": ["# to find categorical variable with missing features\nstr_missing = []\nfor col in df_all:\n    if df_all[col].dtype == df_all[\"Electrical\"].dtype:\n        if df_all[col].isnull().sum() >0:\n            str_missing.append(col)\nstr_missing"]}, {"cell_type": "code", "execution_count": 1, "id": "6088891e", "metadata": {}, "outputs": [], "source": ["#in the data description for FireplaceQu Na means it does not have that feature\ndf_all['FireplaceQu'] = df_all['FireplaceQu'].fillna('None')"]}, {"cell_type": "code", "execution_count": 1, "id": "42ebba24", "metadata": {}, "outputs": [], "source": [" # this will give us a list of all the columns that non nan inputs are a string since \n\nfor col in df_all:\n    if df_all[col].dtype == df_all[\"Electrical\"].dtype:\n        if df_all[col].isnull().sum() >0:\n            df_all[col] = df_all[col].fillna(df_all[col].mode()[0])\n            \n"]}, {"cell_type": "code", "execution_count": 1, "id": "d7f6026a", "metadata": {}, "outputs": [], "source": ["\nfor col in df_all:\n    if df_all[col].dtype == df_all['GarageArea'].dtype and col != 'SalePrice':\n        if df_all[col].isnull().sum() >0:\n            mean = df_all[col].mean()\n            df_all[col] = df_all[col].fillna(mean)\n            "]}, {"cell_type": "code", "execution_count": 1, "id": "92be95fe", "metadata": {}, "outputs": [], "source": ["def categorical(data):\n    cat_var = []\n    for col in data:\n        if df_all[col].dtype == df_all[\"Electrical\"].dtype:\n            cat_var.append(col)\n    return cat_var        "]}, {"cell_type": "code", "execution_count": 1, "id": "8f51605c", "metadata": {}, "outputs": [], "source": ["#now we need to hand categorical variables\ncat_var = categorical(df_all)\ndf_all = pd.get_dummies(df_all, columns = cat_var, drop_first = True)\n        "]}, {"cell_type": "code", "execution_count": 1, "id": "5af47cd5", "metadata": {}, "outputs": [], "source": ["#As noted previously first 1460 columns (inclusive) are from the training data and rest are from test data\ntrain_final = df_all.iloc[:1460,:]\ntest_final = df_all.iloc[1460:,:]\ntest_final = test_final.drop('SalePrice',axis=1) #since test data originally did not have the SalePrice feature, this is what we are estimating\n"]}, {"cell_type": "code", "execution_count": 1, "id": "2b9aa04a", "metadata": {}, "outputs": [], "source": ["#Check that no more columns with missing values\ntrain_final.isnull().sum().sort_values(ascending = True), test_final.isnull().sum().sort_values(ascending = True)"]}, {"cell_type": "markdown", "id": "4c95fe3c", "metadata": {}, "source": ["**Part 2: Fit the model** "]}, {"cell_type": "code", "execution_count": 1, "id": "32633bce", "metadata": {}, "outputs": [], "source": ["#from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n"]}, {"cell_type": "code", "execution_count": 1, "id": "a12111a3", "metadata": {}, "outputs": [], "source": ["model_xgb = xgb.XGBRegressor(learning_rate = 0.11)\nY= train_final['SalePrice']\nX= train_final.drop('SalePrice', axis = 1)\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state = 0)\nmodel_xgb.fit(X_train,Y_train)\n"]}, {"cell_type": "code", "execution_count": 1, "id": "8074f388", "metadata": {}, "outputs": [], "source": ["xgb_pred = model_xgb.predict(X_test)\nr2_score(Y_test, xgb_pred)"]}, {"cell_type": "code", "execution_count": 1, "id": "501b955d", "metadata": {}, "outputs": [], "source": ["\n# Use the model to make predictions\npredicted_prices = model_xgb.predict(test_final)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_prices)"]}, {"cell_type": "code", "execution_count": 1, "id": "0075ccb3", "metadata": {}, "outputs": [], "source": ["my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}