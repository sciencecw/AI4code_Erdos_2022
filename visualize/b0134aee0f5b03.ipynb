{"cells": [{"cell_type": "code", "execution_count": 1, "id": "a13e2151", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "d71b6c5e", "metadata": {}, "source": ["**Diagnose Data for Cleaning**\n\nWe need to diagnose and clean data before exploring.\n\nUnclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* Missing data\n* Different language\nLet's check how we use head, tail, columns, shape and info methods to diagnose data"]}, {"cell_type": "code", "execution_count": 1, "id": "908ebc85", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndata.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "cf890e72", "metadata": {}, "outputs": [], "source": ["data.tail()"]}, {"cell_type": "code", "execution_count": 1, "id": "245b7a98", "metadata": {}, "outputs": [], "source": ["data.columns"]}, {"cell_type": "code", "execution_count": 1, "id": "b7570482", "metadata": {}, "outputs": [], "source": ["data.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "2270d65d", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "markdown", "id": "5dc4a6d2", "metadata": {}, "source": ["**EXPLORATORY DATA ANALYSIS**\n\nvalue_counts(): Counts frequency of values\n\noutliers: the value that is considerably higher or lower from rest of the data\n\nLets say value at 75% is Q3 and value at 25% is Q1.\n\nOutlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n\nWe will use describe() method. Describe method includes:\n\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"]}, {"cell_type": "code", "execution_count": 1, "id": "3aa88506", "metadata": {}, "outputs": [], "source": ["print(data['age'].value_counts(dropna =False))  # if there are nan values that also be counted"]}, {"cell_type": "code", "execution_count": 1, "id": "5e3727b1", "metadata": {}, "outputs": [], "source": ["print(data['sex'].value_counts())"]}, {"cell_type": "code", "execution_count": 1, "id": "1b7808de", "metadata": {}, "outputs": [], "source": ["data.describe() #ignore null entries\n#564 chol is an outlier in this case for an example.\n#Q3 = 274.5, Q1 = 211, Outlier line = Q3 + 1.5(Q3-Q1) = 369,75"]}, {"cell_type": "markdown", "id": "08f25534", "metadata": {}, "source": ["**VISUAL EXPLORATORY DATA ANALYSIS**\n\nBox plots: visualize basic statistics like outliers, min/max or quantiles"]}, {"cell_type": "code", "execution_count": 1, "id": "abfb8b5f", "metadata": {}, "outputs": [], "source": ["# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column = 'chol',by = 'sex')"]}, {"cell_type": "markdown", "id": "d4f6080a", "metadata": {}, "source": ["**Tidy Data**\n\nWe tidy data with melt()."]}, {"cell_type": "code", "execution_count": 1, "id": "7b9590f5", "metadata": {}, "outputs": [], "source": ["data_new = data.head()    # I only take 5 rows into new data\ndata_new"]}, {"cell_type": "code", "execution_count": 1, "id": "5f96892c", "metadata": {}, "outputs": [], "source": ["melted = pd.melt(frame=data_new,id_vars = 'age', value_vars= ['chol','thalach'])\nmelted \n#melting is bridge between pandas and seaborn\n#named of variable and value are default indexes of melt function."]}, {"cell_type": "markdown", "id": "bc77c70a", "metadata": {}, "source": ["**Pivoting Data**\n\nReverse of melting."]}, {"cell_type": "code", "execution_count": 1, "id": "38d37797", "metadata": {}, "outputs": [], "source": ["# Index is age\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'age', columns = 'variable',values='value')"]}, {"cell_type": "markdown", "id": "693050c0", "metadata": {}, "source": ["**Concatenating Data**\n\nWe able to concatenate two dataframe."]}, {"cell_type": "code", "execution_count": 1, "id": "20cac5d2", "metadata": {}, "outputs": [], "source": ["data1 = data.head(3)\ndata2 = data.tail(3)\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row"]}, {"cell_type": "code", "execution_count": 1, "id": "391c3c1b", "metadata": {}, "outputs": [], "source": ["data1 = data['age'].head()\ndata2 = data['trestbps'].head()\ndata3 = data['thalach'].head()\nconc_data_col = pd.concat([data1, data2, data3],axis =1) # axis = 1 : adds dataframes in column\nconc_data_col"]}, {"cell_type": "markdown", "id": "33b3928a", "metadata": {}, "source": ["**Data Types**\n\nThere are 5 basic data types: object(string),boolean, integer, float and categorical.\n\nWe can make conversion data types like from str to categorical or from int to float\n\nWhy is category important:\n\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklearn"]}, {"cell_type": "code", "execution_count": 1, "id": "116e2999", "metadata": {}, "outputs": [], "source": ["data.dtypes"]}, {"cell_type": "code", "execution_count": 1, "id": "186908ff", "metadata": {}, "outputs": [], "source": ["data['age'] = data['age'].astype('float')\ndata['sex']  = data['sex'].astype('float')\n#The purpose is make the data much cleaner and readable.\ndata.dtypes"]}, {"cell_type": "markdown", "id": "d028ad0c", "metadata": {}, "source": ["**Missing Data and Testing with Assert**\n\nIf we encounter with missing data, what we can do:\n\n1. leave as is\n2. drop them with dropna()\n3. fill missing value with fillna()\n4. fill missing values with test statistics like mean\n5. Assert statement: check that you can turn on or turn off when you are done with your testing of the program"]}, {"cell_type": "code", "execution_count": 1, "id": "73db1d19", "metadata": {}, "outputs": [], "source": ["data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "6275e954", "metadata": {}, "outputs": [], "source": ["new_data = pd.read_csv('/kaggle/input/2020-us-general-election-turnout-rates/2020 November General Election - Turnout Rates.csv')\nnew_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "7616856d", "metadata": {}, "outputs": [], "source": ["new_data.shape"]}, {"cell_type": "code", "execution_count": 1, "id": "c750e8af", "metadata": {}, "outputs": [], "source": ["new_data.info()"]}, {"cell_type": "code", "execution_count": 1, "id": "6839013b", "metadata": {}, "outputs": [], "source": ["new_data['Vote for Highest Office (President)'] = new_data['Vote for Highest Office (President)'].astype('category')"]}, {"cell_type": "code", "execution_count": 1, "id": "9f5a891f", "metadata": {}, "outputs": [], "source": ["new_data[\"Vote for Highest Office (President)\"].value_counts(dropna =False)\n# as you can see there are  28 NaN value"]}, {"cell_type": "markdown", "id": "51d87e6d", "metadata": {}, "source": ["We can drop NaN values easily."]}, {"cell_type": "code", "execution_count": 1, "id": "6375e88c", "metadata": {}, "outputs": [], "source": ["n_data1=new_data   # also we will use data to fill missing value so I assign it to data1 variable\nn_data1[\"Vote for Highest Office (President)\"].dropna(inplace = True)"]}, {"cell_type": "code", "execution_count": 1, "id": "c46af893", "metadata": {}, "outputs": [], "source": ["new_data[\"Vote for Highest Office (President)\"].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "0c6101bd", "metadata": {}, "outputs": [], "source": ["assert new_data[\"Vote for Highest Office (President)\"].notnull().all()"]}, {"cell_type": "code", "execution_count": 1, "id": "873df1d7", "metadata": {}, "outputs": [], "source": ["new_data['Vote for Highest Office (President)'] = new_data['Vote for Highest Office (President)'].cat.add_categories('Unknown')\nnew_data['Vote for Highest Office (President)'].fillna('Unknown', inplace =True)"]}, {"cell_type": "code", "execution_count": 1, "id": "9123e55a", "metadata": {}, "outputs": [], "source": ["assert  new_data['Vote for Highest Office (President)'].notnull().all() #return nothing because we do not have NaN values"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}