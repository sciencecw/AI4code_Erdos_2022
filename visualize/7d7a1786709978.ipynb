{"cells": [{"cell_type": "markdown", "id": "974bbe62", "metadata": {}, "source": ["# Introduction\n\nFor a change of pace I'd like to try an unusual approach to this common challenge. Looking at how methods normally reserved for tabular data problems perform on the dataset.\n\nIt should be noted that all of these methods are likely to face a similar issue, that all columns are equally important. In image recognition it is often very helpful that pixels nearer to a selected pixel are assigned a higher importance in regard to that selected pixel than pixels far away from it. This is not desirable in tabular data and hence there is an issue, still it is interesting to see how far we might get.  "]}, {"cell_type": "code", "execution_count": 1, "id": "51dd0379", "metadata": {}, "outputs": [], "source": ["# Import Libraries\n\nimport numpy as np\nimport pandas as pd \nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os "]}, {"cell_type": "markdown", "id": "cc6a8949", "metadata": {}, "source": ["Let's look at the images"]}, {"cell_type": "code", "execution_count": 1, "id": "478815e2", "metadata": {}, "outputs": [], "source": ["# load data\ndf = pd.read_csv(r\"../input/digit-recognizer/train.csv\",dtype = np.float32)\n\n# Split data into features X and labels y\nX = df.iloc[:,1:].values / 255 \ny = df.iloc[:,0].values\n\nfig,ax = plt.subplots(2,5)\nfor i in range(10):\n    nparray = X[i].reshape(28,28)\n    image = Image.fromarray(nparray * 255)\n    ax[i%2][i//2].imshow(image)\nfig.show()"]}, {"cell_type": "markdown", "id": "7a3544fe", "metadata": {}, "source": ["Let's look at the distribution of classes in the dataset"]}, {"cell_type": "code", "execution_count": 1, "id": "502c8347", "metadata": {}, "outputs": [], "source": ["sns.histplot(y)"]}, {"cell_type": "markdown", "id": "dd640a24", "metadata": {}, "source": ["Roughly equal which is good. Interestingly I always figured MNIST would be completely balanced."]}, {"cell_type": "markdown", "id": "04f63bfe", "metadata": {}, "source": ["# Create Decision Tree and Visualize Result"]}, {"cell_type": "code", "execution_count": 1, "id": "a7ef6f86", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\ntree_set = df.copy()\ntarget = tree_set.iloc[:,0]\ntree_set_X = tree_set.iloc[:,1:] \n\nclf = DecisionTreeClassifier(max_depth=4)\nclf.fit(tree_set_X, target)\nclf.score(tree_set_X, target)"]}, {"cell_type": "markdown", "id": "283eec14", "metadata": {}, "source": ["With a max depth of 4 I find even this accuracy kind of crazy. Let's see it:"]}, {"cell_type": "code", "execution_count": 1, "id": "b5184255", "metadata": {}, "outputs": [], "source": ["lst = tree_set_X.columns.tolist()\ntext_representation = tree.export_text(clf, feature_names=lst)\nprint(text_representation)"]}, {"cell_type": "markdown", "id": "a377d9ca", "metadata": {}, "source": ["I'd say this is indicative that a few cental pixels can be definitive in this dataset in regards to which number they are."]}, {"cell_type": "code", "execution_count": 1, "id": "ea04248c", "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\ntrain_ratio = 0.90\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1 - train_ratio, stratify = y, random_state = 0)\n\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\nX_val = scaler.transform(X_val)"]}, {"cell_type": "code", "execution_count": 1, "id": "9cd65eb4", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import ExtraTreesClassifier\n\nclf = ExtraTreesClassifier(random_state=1)\n\nclf.fit(X_train, y_train)\nprint(clf.score(X_val, y_val))"]}, {"cell_type": "markdown", "id": "a840825b", "metadata": {}, "source": ["Now let's try it in binary"]}, {"cell_type": "code", "execution_count": 1, "id": "f9f39741", "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import Binarizer\n\nX_train_bin = Binarizer().fit_transform(X_train)\nX_val_bin = Binarizer().fit_transform(X_val)\n\nfig,ax = plt.subplots(2,5)\nfor i in range(10):\n    nparray = X_train_bin[i].reshape(28,28)\n    image = Image.fromarray(nparray * 255)\n    ax[i%2][i//2].imshow(image)\n    ax[i%2][i//2].title.set_text(round(y_train[i]))\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "4f2c45c8", "metadata": {}, "outputs": [], "source": ["et_clf = ExtraTreesClassifier(random_state=1)\n\net_clf.fit(X_train_bin, y_train)\nprint(et_clf.score(X_val_bin, y_val))"]}, {"cell_type": "markdown", "id": "2e3e9f2d", "metadata": {}, "source": ["That's getting better in terms of accuracy. Let's try and see if we can find the bad images."]}, {"cell_type": "code", "execution_count": 1, "id": "a87a824c", "metadata": {}, "outputs": [], "source": ["bad_image_list = []\nbad_image_list_y = []\nbad_predict = []\nfor _X, _y in zip(X_val_bin, y_val):\n    if et_clf.predict(_X.reshape(1, -1)) != _y:\n        bad_image_list.append(_X)\n        bad_image_list_y.append(_y)\n        bad_predict.append(et_clf.predict(_X.reshape(1, -1)).item())\n        if len(bad_image_list) > 9:\n            break\n    \nfig,ax = plt.subplots(2,5)\nfor i in range(10):\n    nparray = bad_image_list[i].reshape(28,28)\n    image = Image.fromarray(nparray * 255)\n    ax[i%2][i//2].imshow(image)\n    ax[i%2][i//2].title.set_text(\"Real: \" + str(round(bad_image_list_y[i])))\nfig.show()\n\nprint(\"Bad predictions:\")\nprint(bad_predict)"]}, {"cell_type": "markdown", "id": "52772a34", "metadata": {}, "source": ["Let's see a confusion matrix of this"]}, {"cell_type": "code", "execution_count": 1, "id": "7ae95980", "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(y_val, et_clf.predict(X_val_bin))\nsns.heatmap(conf_mat, vmax=10, cmap=\"Blues\")\nplt.show()"]}, {"cell_type": "markdown", "id": "4a6ad3d5", "metadata": {}, "source": ["# Stacking Models\n\nWe can try stacking models for better results."]}, {"cell_type": "code", "execution_count": 1, "id": "291504f2", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(random_state=1)\n\nrf_clf.fit(X_train_bin, y_train)\nprint(rf_clf.score(X_val_bin, y_val))"]}, {"cell_type": "code", "execution_count": 1, "id": "c9a0061c", "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n\ndt_clf = DecisionTreeClassifier(random_state=1)\n\ndt_clf.fit(X_train_bin, y_train)\nprint(dt_clf.score(X_val_bin, y_val))"]}, {"cell_type": "code", "execution_count": 1, "id": "c925d246", "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nestimators = [\n     ('rf', RandomForestClassifier(random_state=1)),\n     ('et', ExtraTreesClassifier(random_state=1))\n]\n\nstack_clf = StackingClassifier(\n    estimators=estimators, final_estimator=LogisticRegression()\n)\n\nstack_clf.fit(X_train_bin, y_train)\nprint(stack_clf.score(X_val_bin, y_val))"]}, {"cell_type": "markdown", "id": "b26b619b", "metadata": {}, "source": ["# Create Submission"]}, {"cell_type": "code", "execution_count": 1, "id": "12d6b11e", "metadata": {}, "outputs": [], "source": ["test_df = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntest_X = scaler.transform(test_df.values)\ntest_X = Binarizer().fit_transform(test_X)\npredicted = stack_clf.predict(test_X)"]}, {"cell_type": "markdown", "id": "adf9ffd8", "metadata": {}, "source": ["Check output visually"]}, {"cell_type": "code", "execution_count": 1, "id": "ea67253a", "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(2,5)\nfor i in range(10):\n    nparray = test_X[i].reshape(28,28)\n    image = Image.fromarray(nparray * 255)\n    ax[i%2][i//2].imshow(image)\n    ax[i%2][i//2].title.set_text(round(predicted[i]))\nfig.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "7f8aada9", "metadata": {}, "outputs": [], "source": ["submission = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\nprint(submission.head())\nsubmission[\"Label\"] = np.rint(predicted)\nsubmission = submission.astype(int)\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(submission.head())"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}